{"text": "Discovering Generative Models from Event Logs: Data-driven Simulation vs Deep Learning\n\nAbstract:\nA generative model is a statistical model that is able to generate new data instances from previously observed ones. In the context of business processes, a generative model creates new execution traces from a set of historical traces, also known as an event log. Two families of generative process simulation models have been developed in previous work: data-driven simulation models and deep learning models. Until now, these two approaches have evolved independently and their relative performance has not been studied. This paper fills this gap by empirically comparing a data-driven simulation technique with multiple deep learning techniques, which construct models are capable of generating execution traces with timestamped events. The study sheds light into the relative strengths of both approaches and raises the prospect of developing hybrid approaches that combine these strengths.\n\nMain:\n\n\n\n1 Introduction\nAn event log is a collection of execution traces of a business process. Each trace in a log consists of a sequence of events and each event consists of a process instance (case) identifier, an activity label, an activity start and end timestamp, and possibly also the resource who performed the activity and other attributes.\nA generative model of a business process is a statistical model constructed from an event log, which is able to generate traces that resemble those observed in the log as well as other traces of the process. Generative process models have several applications, including anomaly detection [13], predictive monitoring [17], and what-if analysis [3]. Two families of generative models have been studied in the literature: Data-Driven Simulation (DDS) and Deep Learning (DL) models.\nDDS models are discrete-event simulation models constructed from an event log. Several authors have proposed techniques for discovering DDS models, ranging from semi-automated techniques [12] to automated ones [3, 14]. A DDS model is generally constructed by first discovering a process model from an event log and then fitting a number of parameters (e.g. mean inter-arrival rate, branching probabilities, etc.) in a way that maximizes the similarity between the traces that the DDS model generates and those in (a subset of) the event log.\nOn the other hand, DL generative models are machine learning models consisting of interconnected layers of artificial neurons adjusted based on inputoutput pairs in order to maximize accuracy. Generative DL models have been widely studied in the context of predictive process monitoring [5, 11, 17, 18], where they are used to generate the remaining path (suffix) of an incomplete trace by repeatedly predicting the next event. It has been shown that these models can also be used to generate entire traces [2].\nTo date, the relative accuracy of these two families of generative process models has not been studied, barring a study that compares DL models vs automatically discovered process models that generate events without timestamps [16]. This paper fills this gap by empirically comparing these approaches using five event-logs with varying structural and temporal characteristics. Based on the evaluation results, the paper discusses the relative strengths and potential synergies of these approaches.\nThe paper is organized as follows. Sections 2 and 3 review DDS and DL generative modeling approaches, respectively, and introduce the approaches included in the evaluation. Section 4 presents the evaluation setup, while Section 5 discusses the results. Finally, Section 6 concludes and outlines future work.\n\n2 Data-driven simulation\nBusiness Process Simulation (BPS) is a quantitative process analysis technique in which a discrete-event model of a process is stochastically executed a number of times, and the resulting simulated execution traces are used to compute aggregate performance measures such as the average waiting times of activities or the average cycle time of the process [4].\nTypically, a BPS model consists of a process model enhanced with time and resource-related parameters such as the the inter-arrival time of cases and its associated Probability Distribution Function (PDF), the PDFs of each activity's processing times, a branching probability for each conditional branch in the process model, and the resource pool responsible for performing each activity type in the process model [4]. Such BPS models are stochastically executed by creating new cases according to the inter-arrival time PDF, and simulating the execution of each case following the control-flow semantics of the process model and the following activity execution rules: (i) If an activity in a case is enabled, and there is an available resource in the pool associated to this activity, the activity is started and allocated to one of the the available resources in the pool; (ii) When the completion time of an activity is reached, the resource allocated to the activity is made available again. Hence, the waiting time of an activity is entirely determined by the availability of a resource. Resources are assumed to be eager: as soon as a resource is assigned to an activity, the activity is started.\nA key ingredient for BPS is the availability of a BPS model that accurately reflects the actual dynamics of the process. Traditionally, BPS models are created manually by domain experts by gathering data from interviews, contextual inquiries, and on-site observation. In this approach, the accuracy of the BPS model is limited by the accuracy of the process model used as a starting point.\nSeveral techniques for discovering BPS models from event logs have been proposed [12, 14]. These approaches automate the extraction of the process model from an event log, and then enhance this model with all the simulation parameters derived from the event log (e.g. arrival rate). In this paper, we use the term DDS model to refer to a BPS model discovered from an event log.\nExisting approaches for discovering a DDS from an event log can be classified in two categories. The first category consists of approaches that provide conceptual guidance to discover BPS models. For example, [12] discusses how PM techniques can be used to extract, validate, and tune BPS model parameters, without seeking to provide fully automated support. Similarly, [19] outlines a series of steps to construct a DDS model using process mining techniques.\nThe second category of approaches seek to automate the extraction of simulation parameters. For example, [14] proposes a pipeline for constructing a DDS using process mining techniques. However, in this approach, the tuning of the simulation model (i.e.. fitting the parameters to the data) is left to the user.\nIn this paper, we use a DDS discovery method, namely Simod tool [3], which automates both the construction and the tuning of the DDS model. Simod combines several PM techniques to automate the generation, and validation of BPS models from an event log. Fig. 1 illustrates the steps of the Simod method: Pre-processing, Processing, Simulation, and Post-processing. In the Pre-processing stage, Simod extracts a BPMN model from data and guarantees its quality and coherence with the event log. The first step is the Control Flow Discovery, using the SplitMiner algorithm [1], which is known for being one of the fastest, simple, and accurate discovery algorithms. Next, Simod applies Trace alignment to assess the conformance between the discovered process model and each trace in the input log. The tool provides options for handling non-conformant traces, via removal, replacement, or repair, to ensure obtain full conformance, which is needed in the following stages.\nIn the Processing stage, Simod extracts the simulation parameters and assembles them in a single BPS model. The extracted parameters correspond to the Resource pools involved in the process, the probability density function (PDF) of Inter-arrival times and Activities durations, and the branching probabilities. The resource pool is discovered using the algorithm proposed by Song and Van der Aalst [15]; likewise, the resources are assigned to the different activities according to the frequency of execution. The inter-arrival times and activities durations PDFs are discovered by fitting a collection of possible distribution functions to the data series, selecting the one that yields the smallest standard error. For calculating the branching probabilities, the tool offers two options: assign equal values to each conditional branch or compute the traversal frequencies of the conditional branches by replaying the event log on the process model. Finally, once compiled all the simulation parameters, these are assembled with the BPMN model into a single data structure that can be interpreted by a discrete event simulator (e.g., Bimp) in the Simulation step.\nIn the Post-processing stage, Simod assesses the similarity between the event log generated by a simulation and the ground truth log, using a measure of similarity between event logs (ELS), which we introduce in Section 4. Simod then uses a Bayesian hyperparameter optimizer to explore the search space of all possible Simod parameter settings, in search for a configuration of parameters that leads to the highest ELS between the simulated log and a ground-truth log.\n\n3 Generative deep learning models of business processes\nIn recent years, the use of generative deep learning models has been widely studied in the field of predictive process monitoring. Multiple proposals [2, 5, 17] have demonstrated that such models achieve high accuracy for tasks such as predicting the next event of a running case (and its timestamp or other attribbutes such as the resource) as well as predicting the remaining path of an incomplete case.\nIn broad terms, a Deep Learning (DL) model is a network composed of multiple interconnected layers of neurons (perceptrons), which perform non-linear transformations of data [7]. The main goal of these transformations is training the network to learn the behaviors/patterns observed in the data. Theoretically, the more layers of neurons there are in the system, the more it becomes possible to detect higher-level patterns in the data thanks to the composition of complex functions [9]. In the literature multiple neural network architectures (e.g., feed-forward, convolutional, autoencoders, etc.) have been used in domains such as natural language processing or image processing. In the field of predictive process monitoring the most common type of neural network is the Recurrent Neural Networks (RNN) due to the sequential nature of the input event logs.\nIn particular, Evermann et al. [5] proposed an approach to generate the most likely remaining sequence of events (suffix) starting from a prefix of an ongoing case. However, this architecture cannot handle numerical features, and hence it cannot generate sequences of timestamped events. The approaches of Lin et al. and Taymouri et al. [11, 18] also shares this inability to predict timestamps and durations. An alternative approach by Tax et al. [17] can predict timestamps; however, it lacks flexibility in the management of high dimensional inputs due to one-hot-encode categorical features. As a result, its accuracy deteriorates as the number of categorical features increases. In [16], the same authors compare the performance of several techniques for predicting the next element in a sequence using real-life datasets. This latter study addresses the problem of predicting the next event's type, but it does not consider the problem of simultaneously predicting the next event and its timestamp. Finally, Nolle et al [13] propose a neural network architecture called BINet for real-time anomaly detection in business process executions.\nIn this paper, we use the DeepGenerator method proposed in [2] to train generative DL models for the task of generating complete event logs.\nThe DeepGenerator method extends previous approaches for training DL models with LSTM architectures, by including dimensionality control techniques such as the use of n-grams and embedded dimensions, as well as the exploration of random sampling following probability distribution for the category selection of the next predicted event. Since this method was designed to generate events with a single timestamp, we extended it in this paper to support the prediction of two timestamps. Similarly, we generalized the method and use it to train other kind of RNN architecture known as GRU to broaden the scope of the evaluation performed in this paper. Fig. 2 synthesizes the phases and stages for building predictive models with our method. Fig. 2 : Phases and steps for building DL models In the Pre-processing phase, we carry out a Transformation of the event log by generating n-sized sequences of events composed of activities, roles, and times. Here, we use encoding and scaling techniques depending on the data type of the event attribute (i.e., categorical, or continuous). In the case of the categorical attributes, i.e., activities and roles, they were encoded using the embedded dimensions technique. This method helps us to keep the dimensionality low, which enhances the performance of the neural network. The embedded dimensions are n-dimensional spaces in which the models can map the activities and roles according to their proximity. In the case of continuous attributes, that is, start and end timestamps, they are first relativized and later scaled over a range of [0, 1]. The relativization is carried out by first calculating two features: the event duration and the time-between-events. The duration of an event (a.k.a. the processing time) is the time difference between its end and its start timestamp. The time-between-events is the difference between the event's start and the end of the immediately preceding event in the same trace (a.k.a. the waiting time). All relative times are scaled using normalization and log-normalization depending on the variability of the times in the event log. Once the features are encoded, the next step is the Sequences creation step. In this step, we extract n-grams from each trace to create the example sequences to train the predictive models. One n-gram is generated for each step of the process execution and this is done for each attribute independently. Hence, we use four independent in-puts: activity prefixes, role prefixes, relativized event durations, and relativized time-between-events.\nIn the Model Training Phase, one of three possible stacked base architectures is selected for training. The network structures vary according to whether or not they share intermediate LSTM or GRU layers, considering that sometimes sharing information can help to differentiate execution patterns. Fig. 3 presents the general structure of the defined architectures. Finally, the Post-processing Phase includes the mechanisms for generating complete traces from a zero-prefix size. The way of doing this is using continuous feedback of the model with each newly generated event, until the generation of a finalization event. The category of the next event is selected randomly following the predicted probability distribution. This mechanism turns out to be the most suitable for the task of generating complete event logs by avoiding getting stuck in the higher probabilities, as was tested in [2].\n\n4 Evaluation\nThis section presents an empirical comparison of DDS and DL generative process models. The evaluation aims at addressing the following questions: what is the relative accuracy of these approaches when it comes to generating traces of events without timestamps? and what is their relative accuracy when it comes to generating traces of events with timestamps?\n\n4.1 Datasets\nWe evaluated the selected approaches using five event logs that contain both start and end timestamps:\n-The event log of a manufacturing production (MP) process contains the steps exported from an Enterprise Resource Planning (ERP) system [10].\n-The event log of a purchase-to-pay (P2P) process is a synthetic log generated from a model not available to the authors. 3 -The event log from an Academic Credentials Recognition (ACR) process of a Colombian University was gathered from its BPM system (Bizagi). -The W subset of the BPIC2012 4 event log, which is a log of a loan application process from a Dutch financial institution. The W subset of this log is composed of the events corresponding to activities performed by human resources (i.e. only activities that have a duration). -The W subset of the BPIC2017 5 event log, which is an updated version of the the BPIC2012 log. We carried out the extraction of the W-subset by following the recommendations reported by the winning teams participating in the BPIC 2017 challenge 6.\nTable 1 summarizes the characteristics of these logs. The BPIC2017W and BPIC2012W logs have the largest number of traces and events, while the MP, P2P and ACR have less traces but a higher average number of events per trace.\n\n4.2 Evaluation measures\nTo measure the accuracy of a generative process model, we use it to generate an event log (multiple times) and we measure the average similarity between the generated logs and a ground-truth event log. To this end, we define four measures of similarity between pairs of logs: Control-Flow Log Similarity (CFLS), Mean Absolute Error (MAE) of cycle times, Event Log Similarity (ELS), and Earth-Mover's Distance (EMD) of the histograms of activity processing times. CFLS is defined based on a measure of distance between pairs of traces: one trace coming from the original event log and the other from the generated log. We first convert each trace into a sequence of activity (i.e. we drop the timestamps and other attributes). In this way, a trace becomes a sequence of symbols (i.e. a string). We then measure the difference between two traces using the Damerau-Levenshtein distance, which is the minimum number of edit operations necessary to transform one string (a trace in our context) into another. The supported edit operations are insertion, deletion, substitution, and transposition. Transpositions are allowed without penalty when two activities are concurrent, meaning that they appear in any order, i.e. given two activities, we observe AB and BA in the log. Next, we normalize the resulting Damerau-Levenshtein distance by dividing the number edit operations by the length of the longest sequence. We then define the control-flow trace similarity as the one minus the normalized Damerau-Levenshtein distance. Given this trace similarity notion, we pair each trace in the generated log with a trace in the original log, in such a way that the sum of the trace similarities between the paired traces is maximal. This pairing is done using the Hungarian algorithm for computing optimal alignments [8]. Finally, we define the CFLS between the real and the generated log as the average similarity of the optimally paired traces.\nThe cycle time MAE measures the temporal similarity between two logs. The absolute error of a pair of traces T1 and T2 is the absolute value of the difference between the cycle time of T1 and that of T2. The cycle time MAE is the mean of the absolute errors over a collection of paired traces. Like for the CFLS measure, we use the Hungarian algorithm to pair each trace in the generated log with a corresponding trace in the original log.\nThe cycle time MAE is a rough measure of the temporal similarity between the traces in the original and the generated log. It does not take into account the timing of the events in a trace -only the cycle time of the full trace. To complement the cycle time MAE, we use the Earth Mover's Distance (EMD) between the normalized histograms of the mean durations of the activities in the ground-truth log vs the same histogram computed from the generated log. The EMD between two histograms H1 and H2 is the minimum number of units that need to be added to, removed to, or transferred across columns in H1 in order to transform it into H2. The EMD is zero if the observed mean activity durations in the two logs are identical, and it tends to one the more they differ.\nThe above measures focus either on the control-flow or on the temporal perspective. To complement them, we use the a measure that combines both perspective, namely the ELS as defined in [3]. This measure is defined in the same way as CLFS above, except that it uses a distance measure between traces that takes into account both the activity labels and the timestamps of activity labels. This distance measure between traces is called Business Process Trace Distance (BPTD). The BPTD measures the distance between traces composed of events that occur in time intervals. This metric is an adaptation of the CFLS metric that, in the case of label matching, assigns a penalty based on the differences in times. BPTD also supports parallelism, which commonly occurs in business processes. We have called ELS to the generalization of the BPTD to measure the distance between two event logs using the Hungarian algorithm.\n\n4.3 Experiment setup\nThe aim of the evaluation is to compare the accuracy of DDL models vs DL models discovered from event logs. Fig. 4 presents the pipeline we followed.\n\nFig. 4: Experimental pipeline\nWe used the holdup method with a temporal split criterion to divide the event logs into two folds: 70% for training and 30% for testing. Next, we use the training fold to train the DDS and the DL models. We use Simod's hyperparameter optimizer to tune the DDS model. The optimizer is set to explore 50 parameter configurations with five simulation runs per configuration, using the first 80% of the training fold to construct candidate DDS models and the remaining 20% for validation. We retained the DDS model that gave the best results on the validation sub-fold in terms of ELS averaged across the five runs. Next, for each model family (LSTM and GRU) we apply random search for hyperparameter optimization. Like in the DDS approach, we explore 50 random configurations with five runs each, using 80% of the training fold for model construction and 20% for validation. The above led us to one DDS, one LSTM and one GRU model per log. We then generated ten logs per retained model. To ensure comparability, each generated log was of the same size (number of traces) as the testing fold of the original log. For each generated log, we then compare it to the testing fold using the ELS, CFLS, EMD and MAE measures defined above. To smooth out stochastic variations, we report the mean of each of these measures across the 10 logs generated from each model.\n\n5 Results and Discussion\nTable 2 presents the evaluation results. The Event-log column identifies the evaluated log, the column Model Family refers to the type of model (DDS, LSTM, GRU). The ELS, CFLS, MAE and EMD columns present the accuracy measures.\nNote that ELS and CFLS are similarity measures (higher is better) whereas MAE and EMD are error/distance measures (lower is better). Both DDS and DL approaches gave similar results on the artificial log (P2P). This may be due to the fact that this log has a predictable behavior, which is equally well captured by both families of approaches. In three of the four real-life logs (MP, ACR, and BPI2012W), the DDS model has higher accuracy in terms of control-flow similarity, particularly in the ACR log. However, in the BPI2017W log, the DL models yielded considerably higher control-flow similarity. This can be explained by the fact that this log is much larger than the others, and DL models generally excel when fed large amounts of samples. Turning our attention to temporal similarity, we note that DL models led to the best MAE results across all event logs. An example of this can be observed in the BPI2012W log in which the best generative model obtained half the MAE than the best simulation model. In the case of EMD, there is no clear winner. All approaches are able to accurately reproduce the distribution of processing times of activities.\nThe results indicate that DDS models perform well when it comes to capturing the occurrence and order of activities (control-flow), event with smaller training datasets. However, the Deep Learning models are more accurate when it comes to capturing the temporal perspective and, as expected, they perform particularly well for the largest dataset.\nA possible explanation is that event logs of business processes (at least the ones included in this evaluation) follow to certain normative pathways that can be captured sufficiently well by automatically discovered process models. On the other hand, the waiting times in these event logs are not adequately captured by DDS models. DL models on the other hand are able to find patterns in the observed event timestamps. Since the EMD values are similar for DDS and DL models, we conclude that the differences in temporal accuracy between these two types of models stems from the fact that DL models are better able to predict the waiting times of activities (rather than the processing times). The inability for DDS models to accurately capture the waiting times can be attributed to the fact that these models rely on the assumption that the waiting times can be fully explained by the availability of resources (i.e. resource contention is the sole cause of waiting times) and that they operate under the assumption of eager resources as discussed in Section 2 (i.e. resources start an activity as soon as it is allocated to them). DL models on the other hand simply try to find the best possible fit to the observed waiting times.\nThe results of this paper are restricted to the five event-logs used for the evaluation. To obtain results with a considerable statistical significance is needed a larger volume of event logs with the required characteristics. Similarly, this work does not include all possible DL architectures applied in the context of business processes; the results are restricted to LSTM and GRU models.\n\n6 Conclusion\nIn this paper, we compared the accuracy of two approaches to discover generative models from event logs: Data-Driven Simulation (DDS) and Deep Learning (DL). The results suggest that DDS models are suitable for capturing the sequence of activities (or possibly other categorical attributes) of a process. On the other hand, DL models outperform DDS models when predicting the timing of activities, specifically the waiting times between activities.\nThis observation raises the prospect of combining these approaches into hybrid techniques that take advantage of their relative strengths. In such hybrid approaches, the DDS model would capture the control-flow perspective, while the DL model would capture the temporal dynamics, particularly waiting times. The DSS model would also provide an interpretable model that users can change in order to define \"what-if\" scenarios, e.g. a what-if scenario where an activity is removed or a new activity is added. The challenges here are: (i) how to integrate the DDS model with the DL model; and (ii) how to incorporate the information in a what-if scenario into a DL model. A possible direction to tackle the latter challenge is to adapt existing techniques to incorporate domain knowledge (e.g. the fact that an activity has been deleted) into the output of a DL model [6].\n\nReproducibiltiy package\nThe scripts and datasets required to reproduce the reported evaluation can be found at: https://github.com/AdaptiveBProcess/ DDSvsDL\n\nFootnotes:\n3: The log is provided as part of the Fluxicon Disco toolhttps://fluxicon.com/\n4: https://doi.org/10.4121/uuid:3926db30-f712-4394-aebc-75976070e91f\n5: https://doi.org/10.4121/uuid:5f3067df-f10b-45da-b98b-86ae4c7a310b\n6: https://www.win.tue.nl/bpi/doku.php?id=2017:challenge\n\nReferences:\n\n- Augusto, A., Conforti, R., Dumas, M., Rosa, M.L.: Split miner: Discovering accu- rate and simple business process models from event logs. In: 2017 IEEE Interna- tional Conference on Data Mining (ICDM). pp. 1-10. IEEE (2017)- Camargo, M., Dumas, M., Gonz\u00e1lez-Rojas, O.: Learning Accurate LSTM Models of Business Processes. In: Proceedings of BPM'2019. LNCS, vol. 168, pp. 286-302. Springer (2019)\n\n- Camargo, M., Dumas, M., Gonz\u00e1lez-Rojas, O.: Automated discovery of business process simulation models from event logs. Decis Support Syst 134, 113284 (2020)\n\n- Dumas, M., La Rosa, M., Mendling, J., Reijers, H.A.: Fundamentals of Business Process Management. Springer, second edition edn. (2018)\n\n- Evermann, J., Rehse, J.R., Fettke, P.: Predicting process behaviour using deep learning. Decis Support Syst 100, 129-140 (2017)\n\n- Francescomarino, C.D., Ghidini, C., Maggi, F.M., Petrucci, G., Yeshchenko, A.: An eye into the future: Leveraging a-priori knowledge in predictive business process monitoring. In: Proceedings of BPM'2017. Lecture Notes in Computer Science, vol. 10445, pp. 252-268. Springer (2017)\n\n- Hao, X., Zhang, G., Ma, S.: Deep Learning. Int J Semant Comput 10, 417-439 (2016)\n\n- Kuhn, H.W.: The Hungarian Method for the assignment problem. Nav Res Logist Q 2, 83-97 (1955)\n\n- Lecun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521, 436-444 (2015)\n\n- Levy, D.: Production analysis with process mining technology (2014). https://doi.org/10.4121/uuid:68726926-5ac5-4fab-b873-ee76ea412399\n\n- Lin, L., Wen, L., Wang, J.: MM-Pred: A Deep Predictive Model for Multi-attribute Event Sequence. In: Proceedings of the 2019 SIAM International Conference on Data Mining. pp. 118-126. Society for Industrial and Applied Mathematics (2019)\n\n- Martin, N., Depaire, B., Caris, A.: The Use of Process Mining in Business Process Simulation Model Construction. Bus Inf Syst Eng 58, 73-87 (2016)\n\n- Nolle, T., Seeliger, A., M\u00fchlh\u00e4user, M.: BINet: Multivariate Business Process Anomaly Detection Using Deep Learning. In: Business Process Management. BPM 2018. LNCS, vol. 11080, pp. 271-287. Springer (2018)\n\n- Rozinat, A., Mans, R.S., Song, M., van der Aalst, W.M.P.: Discovering simulation models. Inform Syst 34, 305-327 (2009)\n\n- Song, M., van der Aalst, W.M.P.: Towards comprehensive support for organiza- tional mining. Decis Support Syst 46, 300-317 (2008)\n\n- Tax, N., Teinemaa, I., van Zelst, S.J.: An interdisciplinary comparison of sequence modeling methods for next-element prediction. Softw Syst Model pp. 1619-1374 (2020)\n\n- Tax, N., Verenich, I., La Rosa, M., Dumas, M.: Predictive Business Process Moni- toring with LSTM Neural Networks. In: Advanced Information Systems Engineer- ing. CAiSE 2017. LNCS, vol. 10253, pp. 477-492. Springer (2017)\n\n- Taymouri, F., Rosa, M.L., Erfani, S., Bozorgi, Z.D., Verenich, I.: Predictive Busi- ness Process Monitoring via Generative Adversarial Nets: The Case of Next Event Prediction. In: Proceedings of BPM'2020. Springer (2020), to appear.\n\n- Wynn, M.T., Dumas, M., Fidge, C.J., ter Hofstede, A.H.M., van der Aalst, W.M.P.: Business Process Simulation for Operational Decision Support. In: Business Pro- cess Management. BPM 2007. pp. 66-77. LNCS, Springer (2008)\n\n", "annotations": {"ReferenceToTable": [{"begin": 16917, "end": 16918, "target": "#tab_0", "idx": 0}, {"begin": 22810, "end": 22811, "target": "#tab_1", "idx": 1}], "ReferenceToFootnote": [{"begin": 16244, "end": 16245, "target": "#foot_0", "idx": 0}, {"begin": 16415, "end": 16416, "target": "#foot_1", "idx": 1}, {"begin": 16692, "end": 16693, "target": "#foot_2", "idx": 2}, {"begin": 16908, "end": 16909, "target": "#foot_3", "idx": 3}], "SectionMain": [{"begin": 1000, "end": 27652, "idx": 0}], "SectionReference": [{"begin": 27940, "end": 31178, "idx": 0}], "SectionHeader": [{"begin": 0, "end": 1000, "idx": 0}], "Div": [{"begin": 98, "end": 992, "idx": 0}, {"begin": 1003, "end": 3683, "idx": 1}, {"begin": 3685, "end": 9419, "idx": 2}, {"begin": 9421, "end": 15489, "idx": 3}, {"begin": 15491, "end": 15862, "idx": 4}, {"begin": 15864, "end": 17135, "idx": 5}, {"begin": 17137, "end": 21217, "idx": 6}, {"begin": 21219, "end": 21389, "idx": 7}, {"begin": 21391, "end": 22777, "idx": 8}, {"begin": 22779, "end": 26161, "idx": 9}, {"begin": 26163, "end": 27494, "idx": 10}, {"begin": 27496, "end": 27652, "idx": 11}], "Head": [{"begin": 1003, "end": 1017, "n": "1", "idx": 0}, {"begin": 3685, "end": 3709, "n": "2", "idx": 1}, {"begin": 9421, "end": 9476, "n": "3", "idx": 2}, {"begin": 15491, "end": 15503, "n": "4", "idx": 3}, {"begin": 15864, "end": 15876, "n": "4.1", "idx": 4}, {"begin": 17137, "end": 17160, "n": "4.2", "idx": 5}, {"begin": 21219, "end": 21239, "n": "4.3", "idx": 6}, {"begin": 21391, "end": 21420, "idx": 7}, {"begin": 22779, "end": 22803, "n": "5", "idx": 8}, {"begin": 26163, "end": 26175, "n": "6", "idx": 9}, {"begin": 27496, "end": 27519, "idx": 10}], "Paragraph": [{"begin": 98, "end": 992, "idx": 0}, {"begin": 1018, "end": 1343, "idx": 1}, {"begin": 1344, "end": 1823, "idx": 2}, {"begin": 1824, "end": 2365, "idx": 3}, {"begin": 2366, "end": 2877, "idx": 4}, {"begin": 2878, "end": 3375, "idx": 5}, {"begin": 3376, "end": 3683, "idx": 6}, {"begin": 3710, "end": 4069, "idx": 7}, {"begin": 4070, "end": 5274, "idx": 8}, {"begin": 5275, "end": 5664, "idx": 9}, {"begin": 5665, "end": 6042, "idx": 10}, {"begin": 6043, "end": 6502, "idx": 11}, {"begin": 6503, "end": 6814, "idx": 12}, {"begin": 6815, "end": 7783, "idx": 13}, {"begin": 7784, "end": 8950, "idx": 14}, {"begin": 8951, "end": 9419, "idx": 15}, {"begin": 9477, "end": 9882, "idx": 16}, {"begin": 9883, "end": 10743, "idx": 17}, {"begin": 10744, "end": 11889, "idx": 18}, {"begin": 11890, "end": 12030, "idx": 19}, {"begin": 12031, "end": 14591, "idx": 20}, {"begin": 14592, "end": 15489, "idx": 21}, {"begin": 15504, "end": 15862, "idx": 22}, {"begin": 15877, "end": 15979, "idx": 23}, {"begin": 15980, "end": 16121, "idx": 24}, {"begin": 16122, "end": 16910, "idx": 25}, {"begin": 16911, "end": 17135, "idx": 26}, {"begin": 17161, "end": 19096, "idx": 27}, {"begin": 19097, "end": 19536, "idx": 28}, {"begin": 19537, "end": 20301, "idx": 29}, {"begin": 20302, "end": 21217, "idx": 30}, {"begin": 21240, "end": 21389, "idx": 31}, {"begin": 21421, "end": 22777, "idx": 32}, {"begin": 22804, "end": 23031, "idx": 33}, {"begin": 23032, "end": 24187, "idx": 34}, {"begin": 24188, "end": 24535, "idx": 35}, {"begin": 24536, "end": 25769, "idx": 36}, {"begin": 25770, "end": 26161, "idx": 37}, {"begin": 26176, "end": 26624, "idx": 38}, {"begin": 26625, "end": 27494, "idx": 39}, {"begin": 27520, "end": 27652, "idx": 40}], "ReferenceToBib": [{"begin": 1633, "end": 1637, "target": "#b12", "idx": 0}, {"begin": 1661, "end": 1665, "target": "#b16", "idx": 1}, {"begin": 1688, "end": 1691, "target": "#b2", "idx": 2}, {"begin": 2011, "end": 2015, "target": "#b11", "idx": 3}, {"begin": 2034, "end": 2037, "target": "#b2", "idx": 4}, {"begin": 2038, "end": 2041, "target": "#b13", "idx": 5}, {"begin": 2653, "end": 2656, "target": "#b4", "idx": 6}, {"begin": 2657, "end": 2660, "target": "#b10", "idx": 7}, {"begin": 2661, "end": 2664, "target": "#b16", "idx": 8}, {"begin": 2665, "end": 2668, "target": "#b17", "idx": 9}, {"begin": 2873, "end": 2876, "target": "#b1", "idx": 10}, {"begin": 3105, "end": 3109, "target": "#b15", "idx": 11}, {"begin": 4065, "end": 4068, "target": "#b3", "idx": 12}, {"begin": 4485, "end": 4488, "target": "#b3", "idx": 13}, {"begin": 5746, "end": 5750, "target": "#b11", "idx": 14}, {"begin": 5751, "end": 5754, "target": "#b13", "idx": 15}, {"begin": 6252, "end": 6256, "target": "#b11", "idx": 16}, {"begin": 6413, "end": 6417, "target": "#b18", "idx": 17}, {"begin": 6608, "end": 6612, "target": "#b13", "idx": 18}, {"begin": 6879, "end": 6882, "target": "#b2", "idx": 19}, {"begin": 7384, "end": 7387, "target": "#b0", "idx": 20}, {"begin": 8183, "end": 8187, "target": "#b14", "idx": 21}, {"begin": 9627, "end": 9630, "target": "#b1", "idx": 22}, {"begin": 9631, "end": 9633, "target": "#b4", "idx": 23}, {"begin": 9634, "end": 9637, "target": "#b16", "idx": 24}, {"begin": 10057, "end": 10060, "target": "#b6", "idx": 25}, {"begin": 10366, "end": 10369, "target": "#b8", "idx": 26}, {"begin": 10775, "end": 10778, "target": "#b4", "idx": 27}, {"begin": 11081, "end": 11085, "target": "#b10", "idx": 28}, {"begin": 11086, "end": 11089, "target": "#b17", "idx": 29}, {"begin": 11192, "end": 11196, "target": "#b16", "idx": 30}, {"begin": 11431, "end": 11435, "target": "#b15", "idx": 31}, {"begin": 11770, "end": 11774, "target": "#b12", "idx": 32}, {"begin": 11949, "end": 11952, "target": "#b1", "idx": 33}, {"begin": 15485, "end": 15488, "target": "#b1", "idx": 34}, {"begin": 16116, "end": 16120, "target": "#b9", "idx": 35}, {"begin": 18967, "end": 18970, "target": "#b7", "idx": 36}, {"begin": 20488, "end": 20491, "target": "#b2", "idx": 37}, {"begin": 27490, "end": 27493, "target": "#b5", "idx": 38}], "ReferenceString": [{"begin": 27955, "end": 28178, "id": "b0", "idx": 0}, {"begin": 28180, "end": 28350, "id": "b1", "idx": 1}, {"begin": 28354, "end": 28510, "id": "b2", "idx": 2}, {"begin": 28514, "end": 28648, "id": "b3", "idx": 3}, {"begin": 28652, "end": 28779, "id": "b4", "idx": 4}, {"begin": 28783, "end": 29063, "id": "b5", "idx": 5}, {"begin": 29067, "end": 29148, "id": "b6", "idx": 6}, {"begin": 29152, "end": 29245, "id": "b7", "idx": 7}, {"begin": 29249, "end": 29325, "id": "b8", "idx": 8}, {"begin": 29329, "end": 29463, "id": "b9", "idx": 9}, {"begin": 29467, "end": 29704, "id": "b10", "idx": 10}, {"begin": 29708, "end": 29854, "id": "b11", "idx": 11}, {"begin": 29858, "end": 30064, "id": "b12", "idx": 12}, {"begin": 30068, "end": 30187, "id": "b13", "idx": 13}, {"begin": 30191, "end": 30320, "id": "b14", "idx": 14}, {"begin": 30324, "end": 30491, "id": "b15", "idx": 15}, {"begin": 30495, "end": 30716, "id": "b16", "idx": 16}, {"begin": 30720, "end": 30952, "id": "b17", "idx": 17}, {"begin": 30956, "end": 31176, "id": "b18", "idx": 18}], "Sentence": [{"begin": 98, "end": 214, "idx": 0}, {"begin": 215, "end": 361, "idx": 1}, {"begin": 362, "end": 508, "idx": 2}, {"begin": 509, "end": 620, "idx": 3}, {"begin": 621, "end": 837, "idx": 4}, {"begin": 838, "end": 992, "idx": 5}, {"begin": 1018, "end": 1089, "idx": 6}, {"begin": 1090, "end": 1343, "idx": 7}, {"begin": 1344, "end": 1551, "idx": 8}, {"begin": 1552, "end": 1692, "idx": 9}, {"begin": 1693, "end": 1823, "idx": 10}, {"begin": 1824, "end": 1902, "idx": 11}, {"begin": 1903, "end": 2042, "idx": 12}, {"begin": 2043, "end": 2180, "idx": 13}, {"begin": 2181, "end": 2365, "idx": 14}, {"begin": 2366, "end": 2558, "idx": 15}, {"begin": 2559, "end": 2793, "idx": 16}, {"begin": 2794, "end": 2877, "idx": 17}, {"begin": 2878, "end": 3110, "idx": 18}, {"begin": 3111, "end": 3254, "idx": 19}, {"begin": 3255, "end": 3375, "idx": 20}, {"begin": 3376, "end": 3410, "idx": 21}, {"begin": 3411, "end": 3548, "idx": 22}, {"begin": 3549, "end": 3628, "idx": 23}, {"begin": 3629, "end": 3683, "idx": 24}, {"begin": 3710, "end": 4069, "idx": 25}, {"begin": 4070, "end": 4489, "idx": 26}, {"begin": 4490, "end": 5067, "idx": 27}, {"begin": 5068, "end": 5164, "idx": 28}, {"begin": 5165, "end": 5274, "idx": 29}, {"begin": 5275, "end": 5395, "idx": 30}, {"begin": 5396, "end": 5542, "idx": 31}, {"begin": 5543, "end": 5664, "idx": 32}, {"begin": 5665, "end": 5755, "idx": 33}, {"begin": 5756, "end": 5932, "idx": 34}, {"begin": 5933, "end": 5947, "idx": 35}, {"begin": 5948, "end": 6042, "idx": 36}, {"begin": 6043, "end": 6139, "idx": 37}, {"begin": 6140, "end": 6238, "idx": 38}, {"begin": 6239, "end": 6401, "idx": 39}, {"begin": 6402, "end": 6502, "idx": 40}, {"begin": 6503, "end": 6594, "idx": 41}, {"begin": 6595, "end": 6688, "idx": 42}, {"begin": 6689, "end": 6814, "idx": 43}, {"begin": 6815, "end": 6954, "idx": 44}, {"begin": 6955, "end": 7067, "idx": 45}, {"begin": 7068, "end": 7178, "idx": 46}, {"begin": 7179, "end": 7306, "idx": 47}, {"begin": 7307, "end": 7476, "idx": 48}, {"begin": 7477, "end": 7608, "idx": 49}, {"begin": 7609, "end": 7783, "idx": 50}, {"begin": 7784, "end": 7891, "idx": 51}, {"begin": 7892, "end": 8095, "idx": 52}, {"begin": 8096, "end": 8294, "idx": 53}, {"begin": 8295, "end": 8501, "idx": 54}, {"begin": 8502, "end": 8736, "idx": 55}, {"begin": 8737, "end": 8950, "idx": 56}, {"begin": 8951, "end": 9419, "idx": 57}, {"begin": 9477, "end": 9607, "idx": 58}, {"begin": 9608, "end": 9882, "idx": 59}, {"begin": 9883, "end": 10061, "idx": 60}, {"begin": 10062, "end": 10178, "idx": 61}, {"begin": 10179, "end": 10370, "idx": 62}, {"begin": 10371, "end": 10565, "idx": 63}, {"begin": 10566, "end": 10743, "idx": 64}, {"begin": 10744, "end": 10908, "idx": 65}, {"begin": 10909, "end": 11031, "idx": 66}, {"begin": 11032, "end": 11153, "idx": 67}, {"begin": 11154, "end": 11339, "idx": 68}, {"begin": 11340, "end": 11427, "idx": 69}, {"begin": 11428, "end": 11571, "idx": 70}, {"begin": 11572, "end": 11748, "idx": 71}, {"begin": 11749, "end": 11889, "idx": 72}, {"begin": 11890, "end": 12030, "idx": 73}, {"begin": 12031, "end": 12367, "idx": 74}, {"begin": 12368, "end": 12516, "idx": 75}, {"begin": 12517, "end": 12681, "idx": 76}, {"begin": 12682, "end": 12770, "idx": 77}, {"begin": 12771, "end": 12979, "idx": 78}, {"begin": 12980, "end": 13110, "idx": 79}, {"begin": 13111, "end": 13240, "idx": 80}, {"begin": 13241, "end": 13347, "idx": 81}, {"begin": 13348, "end": 13479, "idx": 82}, {"begin": 13480, "end": 13620, "idx": 83}, {"begin": 13621, "end": 13737, "idx": 84}, {"begin": 13738, "end": 13855, "idx": 85}, {"begin": 13856, "end": 14015, "idx": 86}, {"begin": 14016, "end": 14147, "idx": 87}, {"begin": 14148, "end": 14224, "idx": 88}, {"begin": 14225, "end": 14337, "idx": 89}, {"begin": 14338, "end": 14451, "idx": 90}, {"begin": 14452, "end": 14591, "idx": 91}, {"begin": 14592, "end": 14695, "idx": 92}, {"begin": 14696, "end": 14888, "idx": 93}, {"begin": 14889, "end": 14956, "idx": 94}, {"begin": 14957, "end": 15071, "idx": 95}, {"begin": 15072, "end": 15214, "idx": 96}, {"begin": 15215, "end": 15316, "idx": 97}, {"begin": 15317, "end": 15489, "idx": 98}, {"begin": 15504, "end": 15590, "idx": 99}, {"begin": 15591, "end": 15764, "idx": 100}, {"begin": 15765, "end": 15862, "idx": 101}, {"begin": 15877, "end": 15979, "idx": 102}, {"begin": 15980, "end": 16121, "idx": 103}, {"begin": 16122, "end": 16245, "idx": 104}, {"begin": 16246, "end": 16384, "idx": 105}, {"begin": 16385, "end": 16508, "idx": 106}, {"begin": 16509, "end": 16622, "idx": 107}, {"begin": 16623, "end": 16661, "idx": 108}, {"begin": 16662, "end": 16757, "idx": 109}, {"begin": 16758, "end": 16910, "idx": 110}, {"begin": 16911, "end": 16964, "idx": 111}, {"begin": 16965, "end": 17135, "idx": 112}, {"begin": 17161, "end": 17362, "idx": 113}, {"begin": 17363, "end": 17623, "idx": 114}, {"begin": 17624, "end": 17778, "idx": 115}, {"begin": 17779, "end": 17840, "idx": 116}, {"begin": 17841, "end": 17886, "idx": 117}, {"begin": 17887, "end": 17954, "idx": 118}, {"begin": 17955, "end": 18164, "idx": 119}, {"begin": 18165, "end": 18252, "idx": 120}, {"begin": 18253, "end": 18430, "idx": 121}, {"begin": 18431, "end": 18570, "idx": 122}, {"begin": 18571, "end": 18681, "idx": 123}, {"begin": 18682, "end": 18882, "idx": 124}, {"begin": 18883, "end": 18971, "idx": 125}, {"begin": 18972, "end": 19096, "idx": 126}, {"begin": 19097, "end": 19166, "idx": 127}, {"begin": 19167, "end": 19300, "idx": 128}, {"begin": 19301, "end": 19390, "idx": 129}, {"begin": 19391, "end": 19536, "idx": 130}, {"begin": 19537, "end": 19659, "idx": 131}, {"begin": 19660, "end": 19765, "idx": 132}, {"begin": 19766, "end": 19992, "idx": 133}, {"begin": 19993, "end": 20172, "idx": 134}, {"begin": 20173, "end": 20301, "idx": 135}, {"begin": 20302, "end": 20385, "idx": 136}, {"begin": 20386, "end": 20492, "idx": 137}, {"begin": 20493, "end": 20689, "idx": 138}, {"begin": 20690, "end": 20776, "idx": 139}, {"begin": 20777, "end": 20871, "idx": 140}, {"begin": 20872, "end": 21009, "idx": 141}, {"begin": 21010, "end": 21086, "idx": 142}, {"begin": 21087, "end": 21217, "idx": 143}, {"begin": 21240, "end": 21347, "idx": 144}, {"begin": 21348, "end": 21389, "idx": 145}, {"begin": 21421, "end": 21557, "idx": 146}, {"begin": 21558, "end": 21624, "idx": 147}, {"begin": 21625, "end": 21687, "idx": 148}, {"begin": 21688, "end": 21905, "idx": 149}, {"begin": 21906, "end": 22032, "idx": 150}, {"begin": 22033, "end": 22131, "idx": 151}, {"begin": 22132, "end": 22292, "idx": 152}, {"begin": 22293, "end": 22357, "idx": 153}, {"begin": 22358, "end": 22404, "idx": 154}, {"begin": 22405, "end": 22529, "idx": 155}, {"begin": 22530, "end": 22649, "idx": 156}, {"begin": 22650, "end": 22777, "idx": 157}, {"begin": 22804, "end": 22844, "idx": 158}, {"begin": 22845, "end": 22965, "idx": 159}, {"begin": 22966, "end": 23031, "idx": 160}, {"begin": 23032, "end": 23164, "idx": 161}, {"begin": 23165, "end": 23241, "idx": 162}, {"begin": 23242, "end": 23374, "idx": 163}, {"begin": 23375, "end": 23535, "idx": 164}, {"begin": 23536, "end": 23632, "idx": 165}, {"begin": 23633, "end": 23777, "idx": 166}, {"begin": 23778, "end": 23897, "idx": 167}, {"begin": 23898, "end": 24041, "idx": 168}, {"begin": 24042, "end": 24087, "idx": 169}, {"begin": 24088, "end": 24187, "idx": 170}, {"begin": 24188, "end": 24357, "idx": 171}, {"begin": 24358, "end": 24535, "idx": 172}, {"begin": 24536, "end": 24767, "idx": 173}, {"begin": 24768, "end": 24867, "idx": 174}, {"begin": 24868, "end": 24955, "idx": 175}, {"begin": 24956, "end": 25229, "idx": 176}, {"begin": 25230, "end": 25454, "idx": 177}, {"begin": 25455, "end": 25604, "idx": 178}, {"begin": 25605, "end": 25669, "idx": 179}, {"begin": 25670, "end": 25769, "idx": 180}, {"begin": 25770, "end": 25858, "idx": 181}, {"begin": 25859, "end": 25996, "idx": 182}, {"begin": 25997, "end": 26161, "idx": 183}, {"begin": 26176, "end": 26333, "idx": 184}, {"begin": 26334, "end": 26480, "idx": 185}, {"begin": 26481, "end": 26624, "idx": 186}, {"begin": 26625, "end": 26763, "idx": 187}, {"begin": 26764, "end": 26932, "idx": 188}, {"begin": 26933, "end": 27131, "idx": 189}, {"begin": 27132, "end": 27293, "idx": 190}, {"begin": 27294, "end": 27494, "idx": 191}, {"begin": 27520, "end": 27644, "idx": 192}, {"begin": 27645, "end": 27652, "idx": 193}], "ReferenceToFigure": [{"begin": 7073, "end": 7074, "target": "#fig_0", "idx": 0}, {"begin": 12687, "end": 12688, "idx": 1}, {"begin": 12776, "end": 12777, "idx": 2}, {"begin": 14894, "end": 14895, "target": "#fig_2", "idx": 3}, {"begin": 21353, "end": 21354, "idx": 4}], "Abstract": [{"begin": 88, "end": 992, "idx": 0}], "SectionFootnote": [{"begin": 27654, "end": 27938, "idx": 0}], "Footnote": [{"begin": 27665, "end": 27743, "id": "foot_0", "n": "3", "idx": 0}, {"begin": 27744, "end": 27812, "id": "foot_1", "n": "4", "idx": 1}, {"begin": 27813, "end": 27881, "id": "foot_2", "n": "5", "idx": 2}, {"begin": 27882, "end": 27938, "id": "foot_3", "n": "6", "idx": 3}]}}