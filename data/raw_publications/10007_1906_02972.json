{"text": "Variational Resampling Based Assessment of Deep Neural Networks under Distribution Shift\n\nAbstract:\nA novel variational inference based resampling framework is proposed to evaluate the robustness and generalization capability of deep learning models with respect to distribution shift. We use Auto Encoding Variational Bayes to find a latent representation of the data, on which a Variational Gaussian Mixture Model is applied to deliberately create distribution shift by dividing the dataset into different clusters. Wasserstein distance is used to characterize the extent of distribution shift between the generated data splits. We compare several popular Convolutional Neural Network (CNN) architectures and Bayesian CNN models for image classification on the Fashion-MNIST dataset, to assess their robustness and generalization behavior under the deliberately created distribution shift, as well as under random Cross Validation. Our method of creating artificial domain splits of a single dataset can also be used to establish novel model selection criteria and assessment tools in machine learning, as well as benchmark methods for domain adaptation and domain generalization approaches.\n\nMain:\n\n\n\nI. INTRODUCTION\nRecent studies have shown that deep learning methods may not generalize well beyond the training data distribution. For instance, deep learning models are vulnerable to adversarial perturbations [1], are prone to biases and unfairness [2], or may significantly but unknowingly depend on confounding variables resulting from the training data collection process [3]. In this work we focus on distribution shift, which is another important phenomenon that can have a significant negative impact on the performance of deep learning models [4]. Addressing the problems related to distribution shift is especially crucial for medical applications of machine learning [5], [6], and other high-risk application areas.\nAreas of machine learning research related to distribution shift include Transfer learning, which is the process of improving the predictive performance on a target domain by using related information from the source domain [7]. Domain Adaptation adapts the source domain distribution to the target domain distribution to improve the performance of a target learner in transfer learning . In contrast to domain adaptation, Domain Generalization is the process of utilizing data from several domains to train a system that will generalize to previously unseen domains [8].\nAlthough several domain adaptation and domain generalization benchmark datasets exist [9], they are either curated by human experts as combinations of multiple datasets with distribution shifts available a priori, or obtained through specific data manipulation techniques such as rotations [8]. Therefore, these datasets depend on domain knowledge and are restricted to specific tasks. For new applications, collecting datasets with distribution shift for evaluation of algorithms may be expensive or even intractable. Thus, to facilitate the study of distribution shift, as well as domain adaptation and domain generalization, there is a need for a general and efficient method to create benchmark datasets for evaluation of these approaches.\nFurthermore, the robustness of machine learning models to distribution shift between subsets of the same dataset or subdomains of a single domain seems to not have been studied to a sufficient extent in the past. For the various practical applications of machine learning these subsets or subdomains may also represent different sources of data, subpopulations within the target population, as well as other types of stratification, and the variability in performance of machine learning systems between them is often not considered although it is substantial in many cases.\nWhile Cross Validation is a widely used resampling technique for model selection in Machine Learning [10], [11] which generates random splits on a datasets, a resampling technique that can generate splits with distribution shift to evaluate a machine learning model does not seem to be known. Thus, inspired by the resampling technique used in Restrictive Federated Model Selection over shifted distribution [5] we propose a resampling technique to artificially create pseudo subdomains, which can serve as a benchmark method to evaluate distribution shift related problems and potential solutions.\nSpecifically, in this work we are interested in characterizing changes in model test performance under distribution shift over different subsets of the same dataset, i.e., when the feature distribution (but not the label distribution) of the test data is shifted relative to the distribution of features in the training data although both are subsets of the same dataset.\nOur major contributions are:\n\u2022 We propose a resampling framework, operating on a given dataset, which creates splits corresponding to different distributions by estimating the pseudo domain label of each instance using variational inference. We use the Wasserstein distance to quantify the amount of distribution shift created by our method. Our method can be used for the creation of benchmark datasets for domain adaptation and domain generalization.\n\nII. PREREQUISITE Auto-encoding Variational Bayes, and Variational Autoencoder (VAE) [12]:\nTo model the likelihood of data p(x), a latent variable model, characterized by the posterior p(z|x), is approximated by a variational posterior distribution q \u03c6 (z|x), where the latent variable in the variational posterior is reparameterized as z = g( , x) with an auxiliary random variable \u223c p( ) following an appropriate distribution. The conditional distribution p \u03b8 (x|z) can be modeled as a Gaussian distribution with mean and variance parameters computed from z by a decoder neural network. Evidence lower bound (ELBO) of the likelihood is optimized with respect to \u03b8 and \u03c6 using stochastic gradient descent (SGD) over the Monte Carlo estimation. As in an Auto Encoder [13] the auxiliary variable z also serves as a latent representation of an instance.\nBayesian Neural Network [14]: Different from generative representation learning methods such as VAE, which model a variational approximator to the model posterior on the hidden units, a Bayesian Neural Network builds variational models on the weights of the network, which can also be used for exploration in Reinforcement Learning [14], [15]. The negative of ELBO, which is the variational free energy F (D, \u03c6), is optimized. In particular, F (D, \u03c6) = KL(q(w|\u03c6)||p(w)) \u2212 E q [log p(D | w)], where D is the data, w is the vector of weights, \u03c6 represents the variational mean and variance parameters for the weight distribution, KL(q(w|\u03c6)||p(w)) is the KL-divergence between the prior distribution p(w) and the variational posterior q \u03c6 (w|D), and E q [log p(D | w)] is the expectation of log-likelihood under the distributional distribution. With the variational free energy F (D, \u03c6) as loss function, where weights w are implicitly represented by \u03c6, backpropagation with respect to the weights could be translated to variational parameter. Like Auto-encoding Variational Bayes, Bayes by Backprop [14] also starts from an independent noise distribution, but instead of transforming the noise together with observation data to latent units, Bayes By Backprop associates each weight with a variational mean and scale parameter to mix with the noise. Bayesian Convolutional Neural Network with Variational Inference (Bayesian CNN) [16] extends the Bayes By Backprop approach [14] to CNNs and utilize the local reparameterization trick [17]- [19] which we will elaborate in the method section.\nVariational Gaussian Mixture Model: Variational Learning of Gaussian Mixture Models (VGMM) [20] uses joint Normal-Wishart distributions for the means and inverse covariance matrices in a mixture of Gaussians, and a Dirichlet distribution for the mixing parameters. Instead of a point estimate of the mean vector, VGMM uses a Normal distribution characterized by the hypermean. VGMM result in a superior data estimation compared to simple Gaussian Mixtures.\nDistribution Shift: Let the random vector x represent the features and let the random variable y be the class label. In this work, we investigate the conditional distribution shift over p(x|y) between datasets (e.g., between the training and the test data), while the marginal distribution p(y) is shared across all datasets (cf.  [21]).\nWasserstein Distance: Wasserstein distance between two distributions p x and p y can be defined as \u03c6 W (p x , p y ) = inf \u03b3\u2208 (px,py) E (x,y)\u223c\u03b3(x,y)\n[c(x, y)] [22]- [24], where \u03b3 \u2208 (p x , p y )\nis the transportation plan or joint distribution of (x, y), with marginal distributions p x and p y respectively, and c(x, y) is the cost of moving x to y. The Wasserstein distance is calculated by taking the infimum with respect to the transportation plan \u03b3 \u2208 (p x , p y ). Wasserstein distance can be approximated to optimize Generative Adversarial Networks [25]. Compared to KL divergence, Wasserstein distance experiences no numerical problems even when the two distributions have no overlap. Hence, we use the Wasserstein distance to measure the distribution shift between two subsets of data on the latent space. t-SNE: Stochastic Neighborhood Embedding [26] uses a Gaussian density to model the conditional similarity between two points in a high dimensional space and a corresponding low dimensional embedding. The KL-divergence between the conditional similarity distributions is used as objective and is optimized with stochastic gradient descent. The t-SNE algorithm [27] extends the conditional similarity to a symmetric version by adding the conditional similarity of both directions. Furthermore, it uses a Student-t distribution instead of a Gaussian distribution in the embedding.\n\nIII. METHODS\n\n\nA. Motivation\nImage data from different sources can come from different distributions, even when the same data collection process is z x d Fig. 1. Data generation process from domains meticulously followed [28]. This phenomenon can be modeled by a directed probabilistic graphical model [29] shown in Figure 1, where the source or domain label d generates the latent representation z, which further generates the observed image x. Given an observation x, we infer the latent representation z and the domain label d as described below and given in Algorithms 1 and 2. The proposed resampling method can be regarded as a worst case analysis aiming to identify the largest possible distribution shifts that can occur when a single dataset is split into multiple folds. Another popular approach is k-fold cross validation, which splits the data randomly into k disjoint subsets (folds or splits) of equal size, and which therefore should result in subsets with the same distribution. Similarly to k-fold cross validation in this work we split the data into k subsets. However, we aim to split the dataset such that each subset follows a different conditional distribution p(x|y) of the features x given a label y, as discussed in the following.\n\nB. VGMM-VAE-CV resampling scheme\nSince high dimensional clustering is challenging, we first train a representation of the dataset using a VAE (see Section II). Instead of the observed distribution of x, for clustering we use the distribution of the latent space representation z of x, denoted by q \u03c6 (z|x). We apply a VGMM (see Section II) on the latent representation space to assign each instance to a cluster. When we cluster within subsets defined by each class label y separately, our procedure corresponds to the conditional distribution shift, which refers to a change in p(x|y), while p(y) remains shared among the clusters.\nAmong the resulting clusters, one is used for testing and the remaining clusters are used for training and validation. We use random splitting to form the training and validation sets, which therefore share the same distribution. Analogously to conventional cross validation, the train-test process is repeated with each cluster playing the role of the test dataset once. The combination of assignments to (D train D val ) D test yields a variation estimate on how good a model could generalize to D test , similar to cross validation. However, compared to conventional cross validation, our method provides a way to characterize the deep learning model's ability to generalize under distribution shift.Algorithm 1 VGMM-VAE-CV Input: dataset D, number of classes C, number of folds K for c = 1 to C do z c = vae(D c ) # train VAE on data belonging to class c d c 1 , ..., d c K = vgmm(z c ) end for D 1 , ..., D K = merge({d c k }, repeat = 1) for k = 1 to K do D test = D k T rainV alSet = D \\ D k D train , D val = randomSplit(T rainV alSet) m k = model init() for epoch = 1, 2, . . . do P erf T rain k , m k = train(D train , m k ) P erf V al k = test(D val , m k ) end for P erf T est k = test(D test , m k ) end for Algorithm 2 merge Input: repeat \u2208 {1, 2, . . .}, d c k for c = 1 to C and k = 1 to K for i = 1 to repeat do if repeat > 1 then for c = 1 to C do d c 1 , ..., d c K = Shuffle(d c 1 , ..., d c K ) end for end if for k = 1 to K do D k = C c=1 d c k end for yield D 1 , D 2 , ..., D K end for\nThe whole process is summarized in Algorithm 1, along with Algorithm 2. Algorithm 2 has an input argument repeat, which we set to 1 in Algorithm 1 for simplicity. We also only use repeat = 1 in the experiments in this work due to the limited computational resources available to us. In larger scale benchmarks the modification repeat = m > 1 in our method would be analogous to how simple k-fold cross validation compares to m-times repeated k-fold cross validation.\n\nC. Architecture of the VAE\nFollowing [30], given a single-channel input image of size 28 \u00d7 28 (see Sec. V), as the first layer the encoder uses convolution filters of size 4 \u00d7 4 with stride 2 and 64 output channels followed by a leaky ReLU activation function. The resulting activation maps go into another convolutional layer with a 128 channel output using the same filter and stride as well as batch normalization and leaky ReLU. Subsequently the results are fed into a fully connected 1024-dimensional layer followed by batch normalization and leaky ReLU. The latent variational parameter vector is chosen to be 62-dimensional and connects linearly with the layer before. After z is sampled, the decoder maps it to a fully connected layer with output dimension 1024 followed by a batch normalization layer and a ReLU activation function. It is followed by another fully connected layer with output dimensions 7 \u00d7 7 \u00d7 128, also using batch normalization and ReLU. Then a deconvolution (or transpose convolution) operation is applied resulting in a 14 \u00d7 14 \u00d7 64 dimensional output, again followed by batch normalization and ReLU. Finally, another deconvolution produces a 28 \u00d7 28 \u00d7 1 output that is followed by sigmoid activation function.\n\nD. Bayesian Neural Network\nSuppose that the predictive function of a classification neural network is solely determined by its weight vector w.p(y * | x * ; X, Y ) = w p(y | x * , w)p(w | X, Y )dw.\nTo deal with the intractable posterior distribution p(w | X, Y ), a variational posterior q \u03c6 (w), characterized by a parameter vector \u03c6, is used to approximate it. We have thatlog p(y|x) = E q(w) log p(y | w, x) \u2212 D KL (q \u03c6 (w)||p(w)) + D KL (q \u03c6 (w)||p(w | x, y)) = ELBO(\u03c6) + D KL (q \u03c6 (w)||p(w | x, y)),\nwhere we defineELBO(\u03c6) = E q(w) log p(y | w, x) \u2212 D KL (q \u03c6 (w)||p(w)).\nOptimization of ELBO(\u03c6) with respect to \u03c6 is equivalent to optimizing the KL divergence between the variational posterior q \u03c6 (w) and the posterior p(w | x, y).\nThe variational parameter \u03c6 characterizes a Gaussian distribution on the weights by q \u03c6 (w ij ) = N (\u00b5 ij , \u03c3 2 ij ), where i is the input index and j is the output index. With more complicated index conventions the following analysis can be generalized to convolution operations as well.\n1) Local reparameterization: Suppose that the weights W connecting two layers follow an isotropic Gaussian distribution, i.e., q(w ij ) = N (\u00b5 ij , \u03c3 2 ij ) as mentioned above. Given an input A the pre-activations B = AW have elements b mj = i a mi w ij , where b mj is the jth output for the mth instance in the minibatch. Each b mj follows a Gaussian distribution with mean and variance given byE(b mj ) = i a mi \u00b5 ij ,var(b mj ) = i a 2 mi \u03c3 2 ij ,= i a mi d p mi 1\u2212p w ij . If d p mi \u223c Bernoulli(1 \u2212 p), then E(b mj | W ) = i a mi w ij and var(b mj | W ) = i a 2 mi w 2 ij p 1\u2212p Thus, approximately b mj | W \u223c N ( i a mi w ij , i a 2 mi w 2 ij p 1\u2212p )\n, which is equivalent to a Gaussian dropout with dropout noise N (1, \u03b1) and \u03b1 = p 1\u2212p . Comparing with Equation ( 4) and ( 5), this is equivalent to parametrizing the variational distribution of the weights as q(w ij ) = N (\u00b5 ij , \u03b1\u00b5 2 ij ), where \u03c3 ij is replaced with \u03b1\u00b5 2 ij . To make it fully consistent with Gaussian Dropout, the prior p(w) in Equation ( 3) has to be an improper log-uniform prior so that the second term in Equation( 3) does not depend on \u00b5 ij . However, in this paper, we use a Gaussian proper prior to make it a more general Bayesian neural network. For the calculation of KL divergence instead of using an approximation formula for the improper prior, we simply use the variational Monte Carlo samples as in [14] to calculate the KL divergence as an expectation problem of the log of the likelihood ratio. In terms of architecture, we replace the ReLU to be the softplus activation function in the original CNN architecture.\n\nIV. RELATED WORK\nTransfer Learning, Domain Adaptation, Domain Generalization. As mentioned in the introduction part, many domain adaptation and domain generalization benchmark datasets are curated or combination of multiple datasets. Our proposed technique, however, offers possibility to create alternative benchmark datasets, based on only one dataset.\nRobustness and Generalization of Neural Networks. Many attention has been paid to robustness of neural networks recently. For example, Adversarial examples have been created by distorting clean images slightly and confuse a classifier. Adversarial robustness measures the worst case performance, while corruption robustness measures the classifier's average performance on image corruptions and perturbation robustness measures the prediction stability and consistency under perturbations [31]. Benchmark datasets have been created [31] for robustness of neural networks under Corruptions and Perturbations. In terms of distribution shift robustness, where models may silently fail on out-of-distribution samples, it is beneficial to predict out-of-distribution at test time [32]. In [33], it is reported that out-of-distribution dataset was assigned higher confidence, when training flow based generative models.\nIn the above works, however, distribution shift arises from either changing data or the use of multiple datasets, while, in the proposed resampling technique, we use only one dataset to deliberately generate distribution shifted splits, and the data itself is left intact.\nIn terms of generalization, measures like the margin distribution as a predictor for generalization gap is studied [34], which we find interesting to evaluate similar measures on splits of train test data created by our resampling technique.\nDisentanglement. Disentanglement tries to find latent representation of data that aligns with independent data generalization factors for interpretation and robust classification [35]. Our method does not aim at achieving disentanglement, i.e., the inferred subdomain labels do not necessarily correspond to any independent data generalization factors. However, our method could potentially testify if disentangled representations can help to overcome model performance deterioration caused by distribution shift.\n\nV. EXPERIMENTS\nWe use the Fashion-MNIST [36] data for the initial examples. Fashion-MNIST consists of 70, 000 grayscale fashion product images of size 28 \u00d7 28 pixels, which fall into 10 classes (7000 images per class). The original 60, 000 training and 10, 000 test images are combined before the application of cross validation and our resampling method discussed below. Source code and further datasets can be found at https://github.com/compstat-lmu/paper 2019 variationalResampleDistributionShift.\nWe compare our resampling method with 5-fold cross validation to demonstrate empirically that distribution shift is indeed a problem, and we investigate how different CNN models are affected by distribution shift.\n\nA. Data Splitting with Distribution Shift\nWe purposefully obtain data splits with distribution shift using the transformed latent representation from the trained VAE model by methods described in Section III (see Algorithm 1). In order to visualize the distribution shift we apply the t-SNE algorithm to the total data from all classes latent representation by training a separate VAE, then color data from each cluster from our method to represent the split, as shown in Figure 2. As a quantitative assessment we calculate the Wasserstein distances shown in Section V-E, from which it is apparent that distances between the splits resulting from our resampling technique are much larger compared to random splitting.\n\nB. Assessment of Performance Deterioration of CNN Models due to Distribution Shift\nFor the first experiment we use the well known AlexNet [37] and LeNet [38] CNN architectures to perform an image classification task on the Fashion-MNIST data as described in Section III. We also use a simple neural network with three convolutional and three fully connected layers, denoted by 3conv3fc.\nThe goal of this experiment is two-fold.  (1) We show that we can indeed deliberately subsample a given dataset to create several subsets, which are affected by distribution shift with respect to p(x|y) but roughly share a common distribution p(y) among the clusters (we confirmed this post-hoc empirically).  (2) We demonstrate that distribution shift between the training and the test data substantially reduces the classification accuracy of CNN models on the test data, and it furthermore largely increases the variability in the reported accuracy values.\nBoth the conventional 5-fold cross validation and the approach of Algorithm 1 yield five (train-validation)-test configurations each, where validation takes 20 percent of the train-validation splits randomly. Thus, each considered CNN is trained and tested five times using conventional cross-validation for data splitting, and five times using our proposed approach. All models are trained for 100 epochs, and we record the training, validation, and test accuracies. Figures 3a, 4a, and 5a show line plots of accuracy by epoch for AlexNet, LeNet, and 3conv3fc respectively, which are separated into individual panels according to the data split (training, validation, test) and data splitting procedure (conventional cross-validation and Algorithm 1). In particular, the first row of the panels in each figure shows the results from using conventional cross validation for data splitting (i.e., no distribution shift), where we see that the test accuracy is almost identical to the validation accuracy (as one would expect). The second row of the panels in each figure, however, shows that the test accuracy curves behave wildly different than the validation accuracy curves. Specifically, the test accuracy is on average substantially reduced when the data are split according to Algorithm 1, i.e., when there is a shift in the conditional feature distribution p(x|y) between the training and the test splits. Furthermore, we see that distribution shift in p(x|y) also leads to a large increase in the variance of the obtained test accuracy values. These results are also summarized in Table I.\nThus, the comparison between conventional cross validation results (where all training and test distributions are equal) and our resampling approach for data splitting clearly shows that a shift in the conditional feature distributions p(x|y) can lead to a massive deterioration in test data performance, even when the label distributions p(y) are equal.\n\nC. Bayesian CNNs under Distribution Shift\nThe Bayesian approach to deep learning uses distributions over parameters instead of point estimates to represent the model. This makes Bayesian deep neural networks more robust to overfitting [16], and suggests that they may be less affected by distribution shift. In our second experiment we investigate whether Bayesian CNNs are more robust to distribution shift introduced by our proposed resampling strategy, compared to the conventional CNNs considered in Section V-B.\nWe use the Bayesian counterparts of the same CNN architectures as considered in Section V-B, such as the Bayesian versions of AlexNet [37] and LeNet [38] introduced by [16]. Apart from the substitution of the Bayesian CNN models in place of the frequentist CNN architectures, the experiments are identical to those described in Section V-B. Figures 3b, 4b, and 5b as well as Table I show the results in the same format as described in Section V-B. While it is apparent from Figures 3b and 4b that Bayesian CNNs are less prone to overfitting to the training data than their conventional CNN counterparts, their vulnerability with respect to distribution shift seems to be about the same.\nAlthough the Bayesian Neural Network is trained with respect to the variational free energy objective, which shows better generalization to data from the same distribution compared to the frequentist approach [14], the gradients with respect to the variational parameters are still only based on the training data distribution. In future work, it would also be interesting to investigate if the expressive power of the variational distribution on the weights would be a potential factor to improve.\n\nD. Comparison of CNN models with respect to their robustness to distribution shift\nBecause under our proposed resampling approach the validation and the training data share the same distribution but the conditional feature distribution p(x|y) of the test data is shifted, the robustness of a CNN to distribution shift can be quantified by comparing the test accuracy curves to the validation accuracy curves in our experiments (see Figures 3, 4, and 5). There are different approaches to carry out such a comparison. However, for simplicity in this work we compare only the empirical mean and standard deviation values at the last epoch. Table I summarizes these values. We see that the classification accuracy on the test data reduces by about 26.0 points on average due to distribution shift. In addition, in the presence of distribution shift the standard deviation of the reported test accuracy values is about 14 times larger than the standard deviation of the accuracy values on the validation data.\nWhile the degree of performance deterioration as measured by these analyses seems to be about the same between all considered CNN models, it is conceivable that some models will be more or less affected by distribution shift, which will be reflected in the values and accuracy curves as analyzed above. Hence, our framework provides a way to quantitatively compare the robustness to distribution shift between different models.\nAs an additional point of reference, Table II contains the classification accuracies after 100 training epochs for the same CNN architectures on the original train-test split provided in the Fashion-MNIST [36] data. Note that there is no distribution shift between the training and the testing data in this case, and the training dataset is larger than in the experiments of Sections V-B and V-C.\n\nE. Computed pairwise Wasserstein distances\nWith the python package POT [24] one can compute the pairwise Wasserstein distance between two clusters of data. In Table III we computed the pairwise Wasserstein distances across the 5 clusters created based on VGMM as described in Section III, which correspond to a conditional distribution shift in p(x|y). In Table IV are computed based on random splits as in conventional cross validation. It can be clearly seen that the VGMM variant creates larger pairwise Wasserstein distances, which testifies that our proposed method generates splits of data with significant distribution shift, as intended.\n\nVI. SUMMARY AND CONCLUSION\nWe propose a new resampling technique to create pseudo subdomains over one dataset. Our resampling strategy purposefully identifies data splits with distribution shift with respect to the conditional distribution p(x|y) of features x given the label y by utilizing the latent representation of data through generative models. Variational methods are used to assign instances to the pseudo subdomains, which are represented as clusters in the latent space.\nWe use our new resampling technique to assess the robustness of deep neural networks in terms of generalization ability to distribution shift. We show that CNN models display , and data splitting procedure (\"CV\" and \"VGMM-CV\"). In the first row of panels, entitled \"CV\", the data are split randomly (conventional cross validation). In the second row of panels, entitled \"VGMM-CV\", the data are split as in Algorithm 1 leading to a conditional shift in p(x|y) between the training and the test splits. The thicker black line represents the average value across the data splits. We see that a shift in the conditional feature distribution p(x|y) of the test data leads to a reduced accuracy as well as an increased variance.\nsubstantial reductions in performance and an increase in variability under the proposed resampling technique compared to conventional cross validation. This demonstrates the severe problem that the performance of CNN models is strongly affected by changes in the conditional distribution p(x|y) even when the label distribution p(y) remains unchanged and all data originate from the same domain. In addition, we observe that this problem persists for Bayesian CNNs considered in this work, even though Bayesian CNNs otherwise are known to possess superior generalization properties at least for data from the same distribution. Possibly since the gradients with respect to the variational parameters are also based on data from the training distribution, it makes it difficult to generalize to another distribution. Our approach can be used for the evaluation of the generalization ability of deep learning models and inform model selection, alongside conventional performance evaluation approaches such as cross validation and testing on holdout data. For instance, Automatic Machine Learning (AutoML) [39] methods should also take distribution shift into account when searching for a model, where our method could easily create splits to serve within an objective function to be optimized during the AutoML process.\nThere remain some open questions and potential drawbacks , and data splitting procedure (\"CV\" and \"VGMM-CV\"). In the first row of panels, entitled \"CV\", the data are split randomly (conventional cross validation). In the second row of panels, entitled \"VGMM-CV\", the data are split as in Algorithm 1 leading to a conditional shift in p(x|y) between the training and the test splits. The thicker black line represents the average value across the data splits. We see that a shift in the conditional feature distribution p(x|y) of the test data leads to a reduced accuracy as well as an increased variance.\nof our method. It is yet unknown what model architecture or choice of hyperparameters will affect the created subdomains. Additionally, our artificially created pseudo subdomains do not necessarily correspond to real world (sub)domains, and it is not clear to what extent the artificially created distribution shift is comparable to the types of distribution shift observed between different (sub)domains in the real world.\nIn future work, methods similar to Restrictive Federated Model Selection [5] could be used to adapt to the distribution shift generated by the methods proposed in this work. In addition, it would be interesting to see new methods that not only create distribution shift, but also allow to control the extent of distribution shift by use of appropriate hyperparameters, as well as methods which could create pseudo subdomains on tasks other than classification, such as recommendation systems [40]. Furthermore, it would be interesting to see how our approach would serve as a benchmark method to evaluate different domain adaptation and domain generalization algorithms. , and data splitting procedure (\"CV\" and \"VGMM-CV\"). In the first row of panels, entitled \"CV\", the data are split randomly (conventional cross validation). In the second row of panels, entitled \"VGMM-CV\", the data are split as in Algorithm 1 leading to a conditional shift in p(x|y) between the training and the test splits. The thicker black line represents the average value across the data splits. We see that a shift in the conditional feature distribution p(x|y) of the test data leads to a reduced accuracy as well as an increased variance.\n\nFootnotes:\n\nReferences:\n\n- N. Carlini and D. Wagner, \"Towards evaluating the robustness of neural networks,\" in 2017 IEEE Symposium on Security and Privacy (SP). IEEE, 2017, pp. 39-57.- I. Chen, F. D. Johansson, and D. Sontag, \"Why Is My Classifier Discriminatory?\" in Advances in Neural Information Processing Systems 31, 2018, pp. 3539-3550.\n\n- M. A. Badgeley, J. R. Zech, L. Oakden-Rayner, B. S. Glicksberg, M. Liu, W. Gale, M. V. McConnell, B. Percha, T. M. Snyder, and J. T. Dudley, \"Deep learning predicts hip fracture using confounding patient and healthcare variables,\" npj Digital Medicine, vol. 2, no. 1, p. 31, Apr. 2019.\n\n- J. Wen, C.-N. Yu, and R. Greiner, \"Robust learning under uncertain test distributions: Relating covariate shift to model misspecification.\" in ICML, 2014, pp. 631-639.\n\n- X. Sun, A. Bommert, F. Pfisterer, J. Rahnenf\u00fchrer, M. Lang, and B. Bischl, \"High dimensional restrictive federated model selection with multi-objective bayesian optimization over shifted distributions,\" arXiv preprint arXiv:1902.08999, 2019.\n\n- B. Nestor, M. B. A. McDermott, G. Chauhan, T. Naumann, M. C. Hughes, A. Goldenberg, and M. Ghassemi, \"Rethinking clinical prediction: Why machine learning must consider year of care and feature aggregation,\" arXiv preprint arXiv:1811.12583, Nov. 2018.\n\n- K. Weiss, T. M. Khoshgoftaar, and D. Wang, \"A survey of transfer learning,\" Journal of Big data, vol. 3, no. 1, p. 9, 2016.\n\n- K. Akuzawa, Y. Iwasawa, and Y. Matsuo, \"Adversarial invariant feature learning with accuracy constraint for domain generalization,\" arXiv preprint arXiv:1904.12543, 2019.\n\n- M. Long, H. Zhu, J. Wang, and M. I. Jordan, \"Deep transfer learning with joint adaptation networks,\" in Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017, pp. 2208-2217.\n\n- I. Guyon, A. Saffari, G. Dror, and G. Cawley, \"Model selection: Beyond the bayesian/frequentist divide,\" Journal of Machine Learning Research,\n\n- D. Molchanov, A. Ashukha, and D. Vetrov, \"Variational dropout sparsifies deep neural networks,\" in Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017, pp. 2498-2507.\n\n- Y. Gal and Z. Ghahramani, \"Bayesian convolutional neural net- works with bernoulli approximate variational inference,\" arXiv preprint arXiv:1506.02158, 2015.\n\n- N. Nasios and A. G. Bors, \"Variational learning for gaussian mixture models,\" IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 36, no. 4, pp. 849-862, Aug 2006.\n\n- K. Zhang, B. Sch\u00f6lkopf, K. Muandet, and Z. Wang, \"Domain adaptation under target and conditional shift,\" in International Conference on Machine Learning, 2013, pp. 819-827.\n\n- G. Peyr, M. Cuturi, and J. Solomon, \"Gromov-wasserstein averaging of kernel and distance matrices,\" in Proceedings of The 33rd International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, M. F. Balcan and K. Q. Weinberger, Eds., vol. 48. New York, New York, USA: PMLR, 20-22 Jun 2016, pp. 2664-2672. [Online]. Available: http://proceedings.mlr.press/v48/peyre16.html\n\n- F. M\u00e9moli, \"Gromov-wasserstein distances and the metric approach to object matching,\" Foundations of computational mathematics, vol. 11, no. 4, pp. 417-487, 2011.\n\n- R. Flamary and N. Courty, \"Pot python optimal transport library,\" 2017. [Online]. Available: https://github.com/rflamary/POT\n\n- M. Arjovsky, S. Chintala, and L. Bottou, \"Wasserstein gan,\" arXiv preprint arXiv:1701.07875, 2017.\n\n- G. E. Hinton and S. T. Roweis, \"Stochastic neighbor embedding,\" in Advances in neural information processing systems, 2003, pp. 857-864.\n\n- L. v. d. Maaten and G. Hinton, \"Visualizing data using t-sne,\" Journal of machine learning research, vol. 9, no. Nov, pp. 2579-2605, 2008.\n\n- B. Recht, R. Roelofs, L. Schmidt, and V. Shankar, \"Do ImageNet Classifiers Generalize to ImageNet?\" Feb. 2019. [Online]. Available: http://arxiv.org/abs/1902.10811\n\n- D. Koller and N. Friedman, Probabilistic graphical models: principles and techniques. MIT press, 2009.\n\n- X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel, \"Infogan: Interpretable representation learning by information maximizing generative adversarial nets,\" in Advances in neural information processing systems, 2016, pp. 2172-2180.\n\n- D. Hendrycks and T. Dietterich, \"Benchmarking neural network ro- bustness to common corruptions and perturbations,\" arXiv preprint arXiv:1903.12261, 2019.\n\n- S. Liang, Y. Li, and R. Srikant, \"Enhancing the reliability of out- of-distribution image detection in neural networks,\" arXiv preprint arXiv:1706.02690, 2017.\n\n- E. Nalisnick, A. Matsukawa, Y. W. Teh, D. Gorur, and B. Lakshmi- narayanan, \"Do deep generative models know what they don't know?\" arXiv preprint arXiv:1810.09136, 2018.\n\n- Y. Jiang, D. Krishnan, H. Mobahi, and S. Bengio, \"A margin-based measure of generalization for deep networks,\" 2019. [Online]. Available: https://openreview.net/pdf?id=HJlQfnCqKX\n\n- I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner, \"beta-vae: Learning basic visual concepts with a constrained variational framework.\" ICLR, vol. 2, no. 5, p. 6, 2017.\n\n- H. Xiao, K. Rasul, and R. Vollgraf, \"Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms,\" arXiv preprint arXiv:1708.07747, 2017.\n\n- A. Krizhevsky, I. Sutskever, and G. E. Hinton, \"ImageNet Classification with Deep Convolutional Neural Networks,\" in Advances in Neural Information Processing Systems 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2012, pp. 1097- 1105.\n\n- Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, \"Gradient-based learning applied to document recognition,\" pp. 2278-2324, 1998.\n\n- X. Sun, J. Lin, and B. Bischl, \"Reinbo: Machine learning pipeline search and configuration with bayesian optimization embedded reinforcement learning,\" arXiv preprint arXiv:1904.05381, 2019.\n\n- N. Kushwaha, X. Sun, B. Singh, and O. Vyas, \"A lesson learned from pmf based approach for semantic recommender system,\" Journal of Intelligent Information Systems, vol. 50, no. 3, pp. 441-453, 2018.\n\n", "annotations": {"ReferenceToTable": [{"begin": 23896, "end": 23897, "target": "#tab_3", "idx": 0}, {"begin": 25153, "end": 25154, "target": "#tab_3", "idx": 1}, {"begin": 26603, "end": 26604, "target": "#tab_3", "idx": 2}, {"begin": 27436, "end": 27438, "target": "#tab_5", "idx": 3}, {"begin": 27956, "end": 27959, "target": "#tab_6", "idx": 4}, {"begin": 28153, "end": 28155, "target": "#tab_3", "idx": 5}], "SectionMain": [{"begin": 1201, "end": 33209, "idx": 0}], "ReferenceToFormula": [{"begin": 16782, "end": 16783, "target": "#formula_4", "idx": 0}, {"begin": 16791, "end": 16792, "target": "#formula_5", "idx": 1}, {"begin": 17026, "end": 17027, "idx": 2}, {"begin": 17108, "end": 17109, "target": "#formula_3", "idx": 3}], "SectionReference": [{"begin": 33223, "end": 39409, "idx": 0}], "SectionHeader": [{"begin": 0, "end": 1201, "idx": 0}], "Div": [{"begin": 100, "end": 1193, "idx": 0}, {"begin": 1204, "end": 5245, "idx": 1}, {"begin": 5247, "end": 9872, "idx": 2}, {"begin": 9874, "end": 9887, "idx": 3}, {"begin": 9889, "end": 11129, "idx": 4}, {"begin": 11131, "end": 13740, "idx": 5}, {"begin": 13742, "end": 14983, "idx": 6}, {"begin": 14985, "end": 17618, "idx": 7}, {"begin": 17620, "end": 19917, "idx": 8}, {"begin": 19919, "end": 20634, "idx": 9}, {"begin": 20636, "end": 21353, "idx": 10}, {"begin": 21355, "end": 24253, "idx": 11}, {"begin": 24255, "end": 25957, "idx": 12}, {"begin": 25959, "end": 27789, "idx": 13}, {"begin": 27791, "end": 28436, "idx": 14}, {"begin": 28438, "end": 33209, "idx": 15}], "Head": [{"begin": 1204, "end": 1219, "idx": 0}, {"begin": 5247, "end": 5336, "idx": 1}, {"begin": 9874, "end": 9886, "idx": 2}, {"begin": 9889, "end": 9902, "idx": 3}, {"begin": 11131, "end": 11163, "idx": 4}, {"begin": 13742, "end": 13768, "idx": 5}, {"begin": 14985, "end": 15011, "idx": 6}, {"begin": 17620, "end": 17636, "idx": 7}, {"begin": 19919, "end": 19933, "idx": 8}, {"begin": 20636, "end": 20677, "idx": 9}, {"begin": 21355, "end": 21437, "idx": 10}, {"begin": 24255, "end": 24296, "idx": 11}, {"begin": 25959, "end": 26041, "idx": 12}, {"begin": 27791, "end": 27833, "idx": 13}, {"begin": 28438, "end": 28464, "idx": 14}], "Paragraph": [{"begin": 100, "end": 1193, "idx": 0}, {"begin": 1220, "end": 1930, "idx": 1}, {"begin": 1931, "end": 2502, "idx": 2}, {"begin": 2503, "end": 3246, "idx": 3}, {"begin": 3247, "end": 3821, "idx": 4}, {"begin": 3822, "end": 4420, "idx": 5}, {"begin": 4421, "end": 4792, "idx": 6}, {"begin": 4793, "end": 4821, "idx": 7}, {"begin": 4822, "end": 5245, "idx": 8}, {"begin": 5337, "end": 6097, "idx": 9}, {"begin": 6098, "end": 7687, "idx": 10}, {"begin": 7688, "end": 8144, "idx": 11}, {"begin": 8145, "end": 8482, "idx": 12}, {"begin": 8483, "end": 8630, "idx": 13}, {"begin": 8631, "end": 8675, "idx": 14}, {"begin": 8676, "end": 9872, "idx": 15}, {"begin": 9903, "end": 11129, "idx": 16}, {"begin": 11164, "end": 11763, "idx": 17}, {"begin": 11764, "end": 12467, "idx": 18}, {"begin": 13274, "end": 13740, "idx": 19}, {"begin": 13769, "end": 14983, "idx": 20}, {"begin": 15012, "end": 15128, "idx": 21}, {"begin": 15183, "end": 15360, "idx": 22}, {"begin": 15490, "end": 15505, "idx": 23}, {"begin": 15562, "end": 15722, "idx": 24}, {"begin": 15723, "end": 16011, "idx": 25}, {"begin": 16012, "end": 16409, "idx": 26}, {"begin": 16668, "end": 17618, "idx": 27}, {"begin": 17637, "end": 17974, "idx": 28}, {"begin": 17975, "end": 18888, "idx": 29}, {"begin": 18889, "end": 19161, "idx": 30}, {"begin": 19162, "end": 19403, "idx": 31}, {"begin": 19404, "end": 19917, "idx": 32}, {"begin": 19934, "end": 20420, "idx": 33}, {"begin": 20421, "end": 20634, "idx": 34}, {"begin": 20678, "end": 21353, "idx": 35}, {"begin": 21438, "end": 21741, "idx": 36}, {"begin": 21742, "end": 22301, "idx": 37}, {"begin": 22302, "end": 23898, "idx": 38}, {"begin": 23899, "end": 24253, "idx": 39}, {"begin": 24297, "end": 24771, "idx": 40}, {"begin": 24772, "end": 25458, "idx": 41}, {"begin": 25459, "end": 25957, "idx": 42}, {"begin": 26042, "end": 26964, "idx": 43}, {"begin": 26965, "end": 27392, "idx": 44}, {"begin": 27393, "end": 27789, "idx": 45}, {"begin": 27834, "end": 28436, "idx": 46}, {"begin": 28465, "end": 28920, "idx": 47}, {"begin": 28921, "end": 29643, "idx": 48}, {"begin": 29644, "end": 30961, "idx": 49}, {"begin": 30962, "end": 31566, "idx": 50}, {"begin": 31567, "end": 31990, "idx": 51}, {"begin": 31991, "end": 33209, "idx": 52}], "ReferenceToBib": [{"begin": 1415, "end": 1418, "target": "#b0", "idx": 0}, {"begin": 1455, "end": 1458, "target": "#b1", "idx": 1}, {"begin": 1581, "end": 1584, "target": "#b2", "idx": 2}, {"begin": 1756, "end": 1759, "target": "#b3", "idx": 3}, {"begin": 1882, "end": 1885, "target": "#b4", "idx": 4}, {"begin": 1887, "end": 1890, "target": "#b5", "idx": 5}, {"begin": 2155, "end": 2158, "target": "#b6", "idx": 6}, {"begin": 2498, "end": 2501, "target": "#b7", "idx": 7}, {"begin": 2589, "end": 2592, "target": "#b8", "idx": 8}, {"begin": 2793, "end": 2796, "target": "#b7", "idx": 9}, {"begin": 3923, "end": 3927, "target": "#b9", "idx": 10}, {"begin": 3929, "end": 3933, "idx": 11}, {"begin": 4230, "end": 4233, "target": "#b4", "idx": 12}, {"begin": 6436, "end": 6440, "idx": 13}, {"begin": 7636, "end": 7640, "target": "#b11", "idx": 14}, {"begin": 7779, "end": 7783, "target": "#b12", "idx": 15}, {"begin": 8476, "end": 8480, "target": "#b13", "idx": 16}, {"begin": 8647, "end": 8651, "target": "#b16", "idx": 17}, {"begin": 9036, "end": 9040, "target": "#b17", "idx": 18}, {"begin": 9336, "end": 9340, "target": "#b18", "idx": 19}, {"begin": 9654, "end": 9658, "target": "#b19", "idx": 20}, {"begin": 10095, "end": 10099, "target": "#b20", "idx": 21}, {"begin": 10176, "end": 10180, "target": "#b21", "idx": 22}, {"begin": 13779, "end": 13783, "target": "#b22", "idx": 23}, {"begin": 17402, "end": 17406, "idx": 24}, {"begin": 18464, "end": 18468, "target": "#b23", "idx": 25}, {"begin": 18507, "end": 18511, "target": "#b23", "idx": 26}, {"begin": 18750, "end": 18754, "target": "#b24", "idx": 27}, {"begin": 18759, "end": 18763, "target": "#b25", "idx": 28}, {"begin": 19277, "end": 19281, "target": "#b26", "idx": 29}, {"begin": 19583, "end": 19587, "target": "#b27", "idx": 30}, {"begin": 19959, "end": 19963, "target": "#b28", "idx": 31}, {"begin": 20849, "end": 20861, "idx": 32}, {"begin": 21493, "end": 21497, "target": "#b29", "idx": 33}, {"begin": 21508, "end": 21512, "target": "#b30", "idx": 34}, {"begin": 21784, "end": 21787, "target": "#b0", "idx": 35}, {"begin": 22052, "end": 22055, "target": "#b1", "idx": 36}, {"begin": 24490, "end": 24494, "idx": 37}, {"begin": 24906, "end": 24910, "target": "#b29", "idx": 38}, {"begin": 24921, "end": 24925, "target": "#b30", "idx": 39}, {"begin": 24940, "end": 24944, "idx": 40}, {"begin": 27598, "end": 27602, "target": "#b28", "idx": 41}, {"begin": 27862, "end": 27866, "target": "#b16", "idx": 42}, {"begin": 30747, "end": 30751, "target": "#b31", "idx": 43}, {"begin": 32064, "end": 32067, "target": "#b4", "idx": 44}, {"begin": 32483, "end": 32487, "target": "#b32", "idx": 45}], "Sentence": [{"begin": 100, "end": 285, "idx": 0}, {"begin": 286, "end": 517, "idx": 1}, {"begin": 518, "end": 630, "idx": 2}, {"begin": 631, "end": 933, "idx": 3}, {"begin": 934, "end": 1193, "idx": 4}, {"begin": 1220, "end": 1335, "idx": 5}, {"begin": 1336, "end": 1585, "idx": 6}, {"begin": 1586, "end": 1760, "idx": 7}, {"begin": 1761, "end": 1930, "idx": 8}, {"begin": 1931, "end": 2159, "idx": 9}, {"begin": 2160, "end": 2319, "idx": 10}, {"begin": 2320, "end": 2502, "idx": 11}, {"begin": 2503, "end": 2797, "idx": 12}, {"begin": 2798, "end": 2888, "idx": 13}, {"begin": 2889, "end": 3021, "idx": 14}, {"begin": 3022, "end": 3246, "idx": 15}, {"begin": 3247, "end": 3459, "idx": 16}, {"begin": 3460, "end": 3821, "idx": 17}, {"begin": 3822, "end": 4114, "idx": 18}, {"begin": 4115, "end": 4420, "idx": 19}, {"begin": 4421, "end": 4792, "idx": 20}, {"begin": 4793, "end": 4821, "idx": 21}, {"begin": 4822, "end": 5034, "idx": 22}, {"begin": 5035, "end": 5134, "idx": 23}, {"begin": 5135, "end": 5245, "idx": 24}, {"begin": 5337, "end": 5674, "idx": 25}, {"begin": 5675, "end": 5834, "idx": 26}, {"begin": 5835, "end": 5990, "idx": 27}, {"begin": 5991, "end": 6097, "idx": 28}, {"begin": 6098, "end": 6441, "idx": 29}, {"begin": 6442, "end": 6524, "idx": 30}, {"begin": 6525, "end": 6939, "idx": 31}, {"begin": 6940, "end": 7138, "idx": 32}, {"begin": 7139, "end": 7445, "idx": 33}, {"begin": 7446, "end": 7687, "idx": 34}, {"begin": 7688, "end": 7952, "idx": 35}, {"begin": 7953, "end": 8064, "idx": 36}, {"begin": 8065, "end": 8144, "idx": 37}, {"begin": 8145, "end": 8261, "idx": 38}, {"begin": 8262, "end": 8474, "idx": 39}, {"begin": 8475, "end": 8482, "idx": 40}, {"begin": 8483, "end": 8630, "idx": 41}, {"begin": 8631, "end": 8675, "idx": 42}, {"begin": 8676, "end": 8831, "idx": 43}, {"begin": 8832, "end": 8950, "idx": 44}, {"begin": 8951, "end": 9041, "idx": 45}, {"begin": 9042, "end": 9172, "idx": 46}, {"begin": 9173, "end": 9294, "idx": 47}, {"begin": 9295, "end": 9494, "idx": 48}, {"begin": 9495, "end": 9633, "idx": 49}, {"begin": 9634, "end": 9773, "idx": 50}, {"begin": 9774, "end": 9872, "idx": 51}, {"begin": 9903, "end": 10035, "idx": 52}, {"begin": 10036, "end": 10100, "idx": 53}, {"begin": 10101, "end": 10319, "idx": 54}, {"begin": 10320, "end": 10654, "idx": 55}, {"begin": 10655, "end": 10868, "idx": 56}, {"begin": 10869, "end": 10952, "idx": 57}, {"begin": 10953, "end": 11129, "idx": 58}, {"begin": 11164, "end": 11290, "idx": 59}, {"begin": 11291, "end": 11437, "idx": 60}, {"begin": 11438, "end": 11543, "idx": 61}, {"begin": 11544, "end": 11763, "idx": 62}, {"begin": 11764, "end": 11882, "idx": 63}, {"begin": 11883, "end": 11993, "idx": 64}, {"begin": 11994, "end": 12135, "idx": 65}, {"begin": 12136, "end": 12299, "idx": 66}, {"begin": 12300, "end": 12467, "idx": 67}, {"begin": 13274, "end": 13436, "idx": 68}, {"begin": 13437, "end": 13556, "idx": 69}, {"begin": 13557, "end": 13740, "idx": 70}, {"begin": 13769, "end": 14002, "idx": 71}, {"begin": 14003, "end": 14174, "idx": 72}, {"begin": 14175, "end": 14301, "idx": 73}, {"begin": 14302, "end": 14417, "idx": 74}, {"begin": 14418, "end": 14583, "idx": 75}, {"begin": 14584, "end": 14708, "idx": 76}, {"begin": 14709, "end": 14873, "idx": 77}, {"begin": 14874, "end": 14983, "idx": 78}, {"begin": 15012, "end": 15128, "idx": 79}, {"begin": 15183, "end": 15347, "idx": 80}, {"begin": 15348, "end": 15360, "idx": 81}, {"begin": 15490, "end": 15505, "idx": 82}, {"begin": 15562, "end": 15722, "idx": 83}, {"begin": 15723, "end": 15894, "idx": 84}, {"begin": 15895, "end": 16011, "idx": 85}, {"begin": 16012, "end": 16188, "idx": 86}, {"begin": 16189, "end": 16335, "idx": 87}, {"begin": 16336, "end": 16409, "idx": 88}, {"begin": 16668, "end": 16755, "idx": 89}, {"begin": 16756, "end": 16947, "idx": 90}, {"begin": 16948, "end": 17136, "idx": 91}, {"begin": 17137, "end": 17242, "idx": 92}, {"begin": 17243, "end": 17499, "idx": 93}, {"begin": 17500, "end": 17618, "idx": 94}, {"begin": 17637, "end": 17697, "idx": 95}, {"begin": 17698, "end": 17853, "idx": 96}, {"begin": 17854, "end": 17974, "idx": 97}, {"begin": 17975, "end": 18024, "idx": 98}, {"begin": 18025, "end": 18096, "idx": 99}, {"begin": 18097, "end": 18210, "idx": 100}, {"begin": 18211, "end": 18469, "idx": 101}, {"begin": 18470, "end": 18582, "idx": 102}, {"begin": 18583, "end": 18755, "idx": 103}, {"begin": 18756, "end": 18888, "idx": 104}, {"begin": 18889, "end": 19161, "idx": 105}, {"begin": 19162, "end": 19403, "idx": 106}, {"begin": 19404, "end": 19420, "idx": 107}, {"begin": 19421, "end": 19588, "idx": 108}, {"begin": 19589, "end": 19756, "idx": 109}, {"begin": 19757, "end": 19917, "idx": 110}, {"begin": 19934, "end": 19994, "idx": 111}, {"begin": 19995, "end": 20137, "idx": 112}, {"begin": 20138, "end": 20290, "idx": 113}, {"begin": 20291, "end": 20377, "idx": 114}, {"begin": 20378, "end": 20420, "idx": 115}, {"begin": 20421, "end": 20634, "idx": 116}, {"begin": 20678, "end": 20862, "idx": 117}, {"begin": 20863, "end": 21353, "idx": 118}, {"begin": 21438, "end": 21625, "idx": 119}, {"begin": 21626, "end": 21741, "idx": 120}, {"begin": 21742, "end": 21782, "idx": 121}, {"begin": 21783, "end": 22050, "idx": 122}, {"begin": 22051, "end": 22301, "idx": 123}, {"begin": 22302, "end": 22510, "idx": 124}, {"begin": 22511, "end": 22669, "idx": 125}, {"begin": 22670, "end": 22769, "idx": 126}, {"begin": 22770, "end": 23054, "idx": 127}, {"begin": 23055, "end": 23327, "idx": 128}, {"begin": 23328, "end": 23478, "idx": 129}, {"begin": 23479, "end": 23713, "idx": 130}, {"begin": 23714, "end": 23852, "idx": 131}, {"begin": 23853, "end": 23898, "idx": 132}, {"begin": 23899, "end": 24253, "idx": 133}, {"begin": 24297, "end": 24421, "idx": 134}, {"begin": 24422, "end": 24562, "idx": 135}, {"begin": 24563, "end": 24771, "idx": 136}, {"begin": 24772, "end": 24945, "idx": 137}, {"begin": 24946, "end": 25112, "idx": 138}, {"begin": 25113, "end": 25219, "idx": 139}, {"begin": 25220, "end": 25458, "idx": 140}, {"begin": 25459, "end": 25786, "idx": 141}, {"begin": 25787, "end": 25957, "idx": 142}, {"begin": 26042, "end": 26412, "idx": 143}, {"begin": 26413, "end": 26475, "idx": 144}, {"begin": 26476, "end": 26596, "idx": 145}, {"begin": 26597, "end": 26629, "idx": 146}, {"begin": 26630, "end": 26753, "idx": 147}, {"begin": 26754, "end": 26964, "idx": 148}, {"begin": 26965, "end": 27267, "idx": 149}, {"begin": 27268, "end": 27392, "idx": 150}, {"begin": 27393, "end": 27608, "idx": 151}, {"begin": 27609, "end": 27789, "idx": 152}, {"begin": 27834, "end": 27946, "idx": 153}, {"begin": 27947, "end": 28143, "idx": 154}, {"begin": 28144, "end": 28228, "idx": 155}, {"begin": 28229, "end": 28436, "idx": 156}, {"begin": 28465, "end": 28548, "idx": 157}, {"begin": 28549, "end": 28790, "idx": 158}, {"begin": 28791, "end": 28920, "idx": 159}, {"begin": 28921, "end": 29063, "idx": 160}, {"begin": 29064, "end": 29148, "idx": 161}, {"begin": 29149, "end": 29252, "idx": 162}, {"begin": 29253, "end": 29421, "idx": 163}, {"begin": 29422, "end": 29497, "idx": 164}, {"begin": 29498, "end": 29643, "idx": 165}, {"begin": 29644, "end": 29795, "idx": 166}, {"begin": 29796, "end": 30039, "idx": 167}, {"begin": 30040, "end": 30271, "idx": 168}, {"begin": 30272, "end": 30459, "idx": 169}, {"begin": 30460, "end": 30696, "idx": 170}, {"begin": 30697, "end": 30961, "idx": 171}, {"begin": 30962, "end": 31071, "idx": 172}, {"begin": 31072, "end": 31175, "idx": 173}, {"begin": 31176, "end": 31344, "idx": 174}, {"begin": 31345, "end": 31420, "idx": 175}, {"begin": 31421, "end": 31566, "idx": 176}, {"begin": 31567, "end": 31581, "idx": 177}, {"begin": 31582, "end": 31688, "idx": 178}, {"begin": 31689, "end": 31990, "idx": 179}, {"begin": 31991, "end": 32164, "idx": 180}, {"begin": 32165, "end": 32488, "idx": 181}, {"begin": 32489, "end": 32661, "idx": 182}, {"begin": 32662, "end": 32714, "idx": 183}, {"begin": 32715, "end": 32818, "idx": 184}, {"begin": 32819, "end": 32987, "idx": 185}, {"begin": 32988, "end": 33063, "idx": 186}, {"begin": 33064, "end": 33209, "idx": 187}], "ReferenceToFigure": [{"begin": 10033, "end": 10034, "idx": 0}, {"begin": 10197, "end": 10198, "idx": 1}, {"begin": 21115, "end": 21116, "target": "#fig_2", "idx": 2}, {"begin": 22778, "end": 22784, "target": "#fig_4", "idx": 3}, {"begin": 25121, "end": 25127, "target": "#fig_4", "idx": 4}, {"begin": 25254, "end": 25263, "target": "#fig_4", "idx": 5}, {"begin": 26399, "end": 26410, "target": "#fig_5", "idx": 6}], "Abstract": [{"begin": 90, "end": 1193, "idx": 0}], "SectionFootnote": [{"begin": 33211, "end": 33221, "idx": 0}], "ReferenceString": [{"begin": 33238, "end": 33395, "id": "b0", "idx": 0}, {"begin": 33397, "end": 33554, "id": "b1", "idx": 1}, {"begin": 33558, "end": 33843, "id": "b2", "idx": 2}, {"begin": 33847, "end": 34014, "id": "b3", "idx": 3}, {"begin": 34018, "end": 34259, "id": "b4", "idx": 4}, {"begin": 34263, "end": 34514, "id": "b5", "idx": 5}, {"begin": 34518, "end": 34641, "id": "b6", "idx": 6}, {"begin": 34645, "end": 34815, "id": "b7", "idx": 7}, {"begin": 34819, "end": 35034, "id": "b8", "idx": 8}, {"begin": 35038, "end": 35180, "id": "b9", "idx": 9}, {"begin": 35184, "end": 35394, "id": "b10", "idx": 10}, {"begin": 35398, "end": 35555, "id": "b11", "idx": 11}, {"begin": 35559, "end": 35749, "id": "b12", "idx": 12}, {"begin": 35753, "end": 35925, "id": "b13", "idx": 13}, {"begin": 35929, "end": 36327, "id": "b14", "idx": 14}, {"begin": 36331, "end": 36493, "id": "b15", "idx": 15}, {"begin": 36497, "end": 36621, "id": "b16", "idx": 16}, {"begin": 36625, "end": 36723, "id": "b17", "idx": 17}, {"begin": 36727, "end": 36863, "id": "b18", "idx": 18}, {"begin": 36867, "end": 37005, "id": "b19", "idx": 19}, {"begin": 37009, "end": 37172, "id": "b20", "idx": 20}, {"begin": 37176, "end": 37278, "id": "b21", "idx": 21}, {"begin": 37282, "end": 37534, "id": "b22", "idx": 22}, {"begin": 37538, "end": 37692, "id": "b23", "idx": 23}, {"begin": 37696, "end": 37855, "id": "b24", "idx": 24}, {"begin": 37859, "end": 38028, "id": "b25", "idx": 25}, {"begin": 38032, "end": 38210, "id": "b26", "idx": 26}, {"begin": 38214, "end": 38429, "id": "b27", "idx": 27}, {"begin": 38433, "end": 38592, "id": "b28", "idx": 28}, {"begin": 38596, "end": 38880, "id": "b29", "idx": 29}, {"begin": 38884, "end": 39011, "id": "b30", "idx": 30}, {"begin": 39015, "end": 39205, "id": "b31", "idx": 31}, {"begin": 39209, "end": 39407, "id": "b32", "idx": 32}]}}