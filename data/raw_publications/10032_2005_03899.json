{"text": "Amortized Bayesian Inference for Models of Cognition\n\nAbstract:\nAs models of cognition grow in complexity and number of parameters, Bayesian inference with standard methods can become intractable, especially when the data-generating model is of unknown analytic form. Recent advances in simulationbased inference using specialized neural network architectures circumvent many previous problems of approximate Bayesian computation. Moreover, due to the properties of these special neural network estimators, the effort of training the networks via simulations amortizes over subsequent evaluations which can re-use the same network for multiple datasets and across multiple researchers. However, these methods have been largely underutilized in cognitive science and psychology so far, even though they are well suited for tackling a wide variety of modeling problems. With this work, we provide a general introduction to amortized Bayesian parameter estimation and model comparison and demonstrate the applicability of the proposed methods on a well-known class of intractable response-time models.\n\nMain:\n\n\n\nGenerative Models in Cognitive Science\nMathematical models formalize theories of cognition and enable the systematic investigation of cognitive processes through simulations and testable predictions. They enable a systematic joint analysis of behavioral and neural data, bridging a crucial gap between cognitive science and neuroscience (B. M. Turner, Forstmann, Steyvers, et al., 2019). Moreover, questions demanding a choice among competing cognitive theories can be resolved at the level of formal model comparison.\nThe generative property of such models arises from the fact that one can simulate the process of interest and study how it behaves under various conditions. More formally, consider a cognitive model M which represents a theoretically plausible, potentially noisy, process by which observable behavior x arises from an assumed cognitive system governed by hidden parameters \u03b8 and an independent source of noise \u03be \u223c p(\u03be):\nx = M (\u03b8, \u03be)\n(1) Generative models of this form have been developed in various domains throughout psychology and cognitive science, including decision making (Voss, Lerche, Mertens, & Voss, 2019), memory (Myung, Montenegro, & Pitt, 2007), reinforcement learning (Fontanesi, Gluth, Spektor, & Rieskamp, 2019), risky behavior (Stout, Busemeyer, Lin, Grant, & Bonson, 2004), to name just a few. Once a model (or a set of models) of some cognitive process of interest has been formulated, the challenge becomes to perform inference on real data. We will now briefly review the mathematical tools provided by Bayesian probability theory for parameter estimation and model comparison (Jaynes, 2003). Then, we will peruse a novel framework for performing Bayesian inference on models of cognition which are intractable with standard Bayesian methods.\n\nBayesian Parameter Estimation\nBayesian parameter estimation leverages prior knowledge about reasonable parameter ranges and integrates this information with the information provided by the data to arrive at a posterior distribution over parameters. In a Bayesian context, the posterior encodes our updated belief about plausible parameter ranges conditional on a set of N observations X := {x n } N n=1 . Bayes' rule gives us the well known analytical form of the posterior:p(\u03b8 | X) = p(X | \u03b8) p(\u03b8) p(X | \u03b8) p(\u03b8) d\u03b8 (2)\nwhere p(X | \u03b8) represents the likelihood of the parameters \u03b8 and p(\u03b8) denotes the prior, that is the distribution of \u03b8 before observing the data. The denominator is a normalizing constant usually referred to as the marginal likelihood or evidence. Note, that all distributions are also implicitly conditional on the particular generative model M .\nBased on the obtained estimate of the posterior distribution, usually in the form of random draws from the posterior, summary statistics such as posterior means or credible intervals for each parameter can be obtained. What is more, the posterior distribution can be further transformed to obtain subsequent quantities of interest, for example, the posterior predictive distribution which can be compared to the observed data for the purpose of model checking (Lynch & Western, 2004).\n\nBayesian Model Comparison\nIn many research domains, there is not a single model for a particular process, but whole classes of models instantiating different and often competing theories. Bayesian model comparison proceeds by assigning a plausibility value to each candidate model. These plausibility values (model weights, model probabilities, model predictions, etc.) can be used to guide subsequent model selection.\nTo set the stage, consider a set of J candidate models G = {M 1 , M 2 , . . . , M J }. An intuitive way to quantify plausibility is to consider the marginal likelihood of a model M given by:p(X | M ) = p(X | \u03b8, M ) p(\u03b8 | M ) d\u03b8 (3)\nwhich is also the denominator in Eq.2 (with M implicit in the previous definition). This quantity is also known as evidence, or prior predictive distribution, since the likelihood is weighted by the prior (in contrast to a posterior predictive distribution where the likelihood would be weighted by the posterior). The marginal likelihood penalizes the prior complexity of a model and thus naturally embodies the principle of Occam's razor (Jaynes, 2003). To compare two competing models, one can focus on the ratio between two marginal likelihoods, called a Bayes factor (BF):BF i j = p(X | M i ) p(X | M j ) (4)\nwhich quantifies the relative evidence of model i over model j. Alternatively, if prior information about model plausibility is available, one can consider model posteriors p(M | X) \u221d p(X | M ) p(M ) and compute the posterior odds:p(M i | X) p(M j | X) = p(X | M i ) p(X | M j ) p(M i ) p(M j )\nwhich combine the relative evidence given by the BF with prior information in the form of prior odds.\n\nModel Intractability\nIn order for cognitive models to be useful in practice, parameter estimation and model comparison should be feasible within reasonable time limits. As evident from their definitions, both Bayesian parameter estimation and model comparison depend on the likelihood function p(X | \u03b8, M ) which needs to be evaluated analytically or numerically for any triplet (M , \u03b8, X). When this is possible, standard Bayesian approaches for obtaining random draws from the posterior, such as Markov chain Monte Carlo (MCMC), or optimizing an approximate posterior, such as variational inference (VI), can be readily applied. However, when the likelihood function is not available in closed-form or too expensive to evaluate, standard methods no longer apply.\nIn fact, many interesting models from a variety of domains in cognitive science and psychology turn out to be intractable (Voss et al., 2019; B. Turner, Sederberg, & McClelland, 2016). This has precluded the wide exploration and application of these models, as researchers have often traded off complexity or neurocognitive plausibility for simplicity in order to make these models tractable. In the following, we discuss the most popular approach to inference with intractable models.\n\nSimulation-Based Inference\nSimulation-based methods leverage the generative property of mathematical models by treating a particular model as a scientific simulator from which synthetic data can be obtained given any configuration of the parameters. Simulationbased inference is common to many domains in science in general (Cranmer, Brehmer, & Louppe, 2019) and a variety of different approaches exist. These methods have also been dubbed likelihood-free, which is somewhat unfortunate, since the likelihood is implicitly defined by the generative process and sampling from the likelihood is realized through the stochastic simulator:x n \u223c p(x | \u03b8, M ) \u21d0\u21d2 x n = M (\u03b8, \u03be n ) with \u03be n \u223c p(\u03be) (6)\nDifferent simulation-based methods differ mainly with respect to how they utilize the synthetic data to perform inference on real observed data (Cranmer et al., 2019). The utility of any simulation-based method depends on multiple factors, such as asymptotic guarantees, data utilization, efficiency, scalability, and software availability.\nApproximate Bayesian computation (ABC) offers a standard set of theoretically sound methods for performing inference on intractable models (Cranmer et al., 2019). The core idea of ABC methods is to approximate the posterior by repeatedly sampling parameters from a proposal (prior) distribution and then generating a synthetic dataset by running the simulator with the sampled parameters. If the simulated dataset is sufficiently similar to an actually observed dataset, the corresponding parameters are retained as a sample from the desired posterior, otherwise rejected. However, in practice, ABC methods are notoriously inefficient and suffer from various problems, such as the curse of dimensionality or curse of inefficiency (Marin, Pudlo, Estoup, & Robert, 2018). More efficient methods employ various techniques to optimize sampling or correct potential biases.\nRecently, the scientific repertoire for simulation-based inference has been enhanced with ideas from deep learning and neural density estimation (NDE) in particular (Greenberg, Nonnenmacher, & Macke, 2019). These methods employ specialized neural network architectures which are trained with simulated data to perform efficient and accurate inference on previously intractable problems (Cranmer et al., 2019). NDE methods are rapidly developing and still largely underutilized in cognitive modeling, even though first applications to simulated (Radev, Mertens, Voss, Ardizzone, & K\u00f6the, 2020; Radev, D'Alessandro, et al., 2020) as well as actual data (Wieschen, Voss, & Radev, 2020) exist.\n\nAmortized Inference\nThe majority of simulation-based methods need to be applied to each dataset separately. This quickly becomes infeasible when multiple datasets are to be analysed and multiple candidate models are considered, since the expensive inference procedure needs to be repeated from scratch for each combination of dataset and model.  (Radev, Mertens, et al., 2020). The left panel depicts the training phase in which the summary ( f \u03b7 ) and the inference network ( f \u03c8 ) are jointly optimized to approximate the true target posterior. The right panel depicts inference with already trained networks on observed data; (b) Amortized Bayesian model comparison with evidential neural networks (Radev, D'Alessandro, et al., 2020). The left panel depicts the training phase during which the evidential network f \u03c6 is optimized to approximate the true model posteriors via a higher-order Dirichlet distribution. The right panel depicts inference with an already trained evidential network; the upfront training effort for both inference tasks is amortized over arbitrary numbers of datasets from a research domain.\nIn contrast, the concept of amortized inference refers to an approach which minimizes the cost of inference by separating the process into an expensive training (optimization) phase and a cheap inference phase which can be easily repeated for multiple datasets or models without computational overhead. Thus, the effort of training or optimization amortizes over repeated applications on multiple datasets or models. In some cases, the efficiency advantage of amortized inference becomes noticeable even for a few datasets (Radev, Mertens, et al., 2020; Radev, D'Alessandro, et al., 2020).\nThe field of amortized inference is rapidly growing and a variety of methods and concepts are currently being explored. For instance, inference compilation involves pre-training a neural network with simulations from a generative model and then using the network in combination with a probabilistic program to optimize sampling from the posterior (Le, Baydin, & Wood, 2016). The pre-paid estimation method (Mestdagh, Verdonck, Meers, Loossens, & Tuerlinckx, 2019) proceeds by creating a large grid of simulations which are reduced to summary statistics and stored on disk. Subsequent inference involves computing the nearest neighbors of an observed dataset in the pre-paid grid and interpolation. Sequential neural posterior estimation (SNPE) methods employ various iterative refinement schemes to transform a proposal distribution into the correct target posterior via expressive NDEs trained over multiple simulation rounds (Greenberg et al., 2019).\nIn line with these ideas, we recently proposed two general frameworks for amortized Bayesian parameter estimation and model comparison based on specialized neural network architectures (Radev, Mertens, et al., 2020; Radev, D'Alessandro, et al., 2020). In particular, these frameworks were designed to implement the following desirable properties:\n\u2022 Fully amortized Bayesian inference for parameter estimation and model comparison of intractable models\n\u2022 Asymptotic theoretical guarantees for sampling from the true parameter and model posteriors\n\u2022 Learning maximally informative summary statistics directly from data instead of manual selection\n\u2022 Scalability to high-dimensional problems through considerations regarding the probabilistic symmetry of the data\n\u2022 Implicit preference for simpler models based purely on generative performance\n\u2022 Online learning eliminating the need for storing large grids or reference tables\n\u2022 Parallel computations and GPU acceleration applicable to both simulations, training/optimization, and inference\nIn the following, we describe our recently developed methods parameter estimation and model comparison in turn.\n\nAmortized Parameter Estimation with Invertible Neural Networks\nRecently, we proposed a novel amortization method based on invertible neural networks (Radev, Mertens, et al., 2020), which we dubbed BayesFlow. The method relies solely on simulations from a process model in order to learn and calibrate the full posterior over all possible parameter values and observed data patterns.\nThe BayesFlow method involves two separate neural networks trained jointly. A permutation invariant summary network is responsible for reducing an entire dataset X with a variable number N of i.i.d. observations 1 into a vector of learned summary statistics. Importantly, permutation invariant networks can deal with i.i.d. sequences of variable size and preserve their probabilistic symmetry. An inference network, implemented as an invertible neural network (Radev, Mertens, et al., 2020), is responsible for approximating the true posterior of model parameters given the output of the summary network. Invertible networks can perform asymptotically exact inference and scale well from simple lowdimensional problems to high-dimensional distributions with complex dependencies. During training, model parameters and synthetic datasets are generated on the fly and neural network parameters are adjusted via joint backpropagation (see Figure 1a, left panel, for a graphical illustration of the training phase).\nGiven a model and a prior over the model parameters, the goal is thus to train a conditional invertible neural network f \u03c8 with adjustable parameters \u03c8 together with a summary network f \u03b7 with adjustable parameters \u03b7. These networks jointly learn an approximate posterior p \u03c8 (\u03b8 | f \u03b7 (X)) over the relevant parameters for arbitrary numbers of datasets and dataset sizes N, as long as they share the same data structure. To achieve this, the networks minimize the Kullback-Leibler (KL) divergence between the true and the approximate posterior:min \u03c8,\u03b7 KL p(\u03b8 | X) || p \u03c8 (\u03b8 | f \u03b7 (X))\nUtilizing the fact that we have access to the joint distribution p(\u03b8, X) = p(\u03b8) (X | \u03b8) via the simulator, we minimize the KL divergence in expectation over all possible datasets that can be generated given the prior and the model, resulting in the following optimization criterion:min \u03c8,\u03b7 E p(\u03b8,x) \u2212 log p \u03c8 (\u03b8 | f \u03b7 (X))\nIn practice, we approximate the criterion via its Monte Carlo (MC) estimate, since we can simulate theoretically infinite amounts of data and can easily evaluate p \u03c8 (\u03b8 | f \u03b7 (X)) due to our invertible architecture. In case of perfect convergence of the networks, the summary network outputs sufficient summary statistics and the inference network samples from the true posterior (Radev, Mertens, et al., 2020). Importantly, once the networks have been trained with sufficient amounts of simulated data, they can be stored and applied for inference on multiple datasets from a research domain (see Figure 1a, right panel).\n\nAmortized Model Comparison with Evidential Neural Networks\nIn another recent work (Radev, D'Alessandro, et al., 2020), we explored a framework for Bayesian model comparison on intractable models via evidential neural networks. We proposed to train a permutation invariant classifier network on simulated data from multiple models. The goal of this network is to approximate posterior model probabilities as accurately as possible. To achieve this, the network is trained to output the parameters of a higher-order probability distribution (parameterized as a Dirichlet distribution) over the model probabilities themselves, which quantifies the uncertainty in model probability estimates. Thus, for a classifier network with parameters \u03c6, the higher-order posterior distribution over model probabilities is given by:Dir(\u03c0 | \u03b1 \u03c6 (X)) = 1 B(\u03b1 \u03c6 (X)) J \u220f j=1 \u03c0 \u03b1 \u03c6 (X) j \u22121 (9)\nwhere \u03b1 \u03c6 (X) denotes the vector of concentration parameters obtained by the network for a dataset X and B(\u2022) is the multivariate beta function. The mean of this Dirichlet distribution can be used as a best estimate for the posterior model probabilities:p \u03c6 (M | X) = \u03b1 \u03c6 (X) \u2211 J j=1 \u03b1 \u03c6 (X) j (10)\nAdditionally, its variance can be interpreted as the epistemic uncertainty surrounding the actual evidence which the data provide for model comparison.\nFor training the network, we again utilize the fact that we have access to the joint distribution p(M , \u03b8, X) via simulations (see Figure 1b, left panel). Our optimization criterion is: min\u03c6 E p(M ,\u03b8,X) L p \u03c6 (M | X), M\nwhere L(\u2022,\u2022) is a strictly proper loss function (Gneiting & Raftery, 2007), M is the true model index and the data X implicitly depend on \u03b8. In practice, we approximate this expectation via draws from the joint distribution available via the simulator. Optimization of a strictly proper criterion, asymptotic convergence implies that the mean of the Dirichlet distribution represents the true model posteriors. Moreover, our simulation-based approach implicitly captures a preference for simpler models (Occam's razor), since simpler models will tend to generate more similar datasets. As a consequence, when such datasets are plausible under multiple models, the comparably simpler models will be more probable.\nAs with parameter estimation, once the evidence network has been trained on simulated data from the candidate models, it can be applied to multiple upcoming observations from a research domain (see Figure 1b, right panel).\n\nExample Applications\nIn the following, we will present two applications of amortized Bayesian parameter estimation to a recently proposed and intractable evidence accumulation model (EAM). The first illustrative application is a simulation study aimed at quantifying parameter recovery as a function of data set size. Such simulations are especially useful for planing experiments but usually too costly to perform in complex modeling scenarios. The second application is concerned with parameter estimation on real data and serves as an illustration on how researchers might utilize amortized Bayesian inference with a pre-trained density estimator in practice.\nEAMs are a popular class of models in psychology and cognitive science, as they allow a model-based analysis of response time (RT) distributions. Here, we will consider a L\u00e9vy flight model (LFM) with a non-Gaussian noise assumption (Voss et al., 2019; Wieschen et al., 2020) as an example. The L\u00e9vy flight process is driven by the following stochastic ordinary differential equation (ODE):dx c = v c dt + \u03bedt 1/\u03b1 (12) \u03be \u223c AlphaStable(\u03b1, 0, 1, 0)\nwhere dx c denotes accumulated cognitive evidence in condition c, v c denotes the average speed of information accumulation (drift), and \u03b1 controls how heavy the tails of the noise distribution are (i.e., smaller values increase the probability of outliers in the accumulation process). Further parameters of the model are: a decision threshold (a) which reflects the amount of information needed for selecting a response; a starting point (z r ) indicative of response biases; and a non-decision time (t 0 ) reflecting additive encoding and motor process. Since the relationship of the \u03b1 parameter to the standard parameters of the classical diffusion model (Ratcliff, Thapar, Gomez, & McKoon, 2004) has not been previously investigated, we focus on quantifying posterior correlations in the real data application.\n\nSimulation Example\nAs a first example, consider a simulated RT experiment with four conditions. How many trials are needed for accurate parameter recovery? To answer this question, we can simulate multiple experiments with varying number of trials per participant (N) and then compute some discrepancy between ground-truth parameters and their estimates. However, since the model is intractable, such a simulation scenario is not feasible with non-amortized methods, which would need weeks on standard machines (Voss et al., 2019). However, using the BayesFlow method (Figure 1a), we can train the networks with simulated datasets and vary the number of trials during each simulation. Such a training takes approximately one day on a standard laptop equipped with an NVIDIA R GTX1060 graphics card. Subsequent inference is then very cheap, as amortized parameter estimation on 500 simulated participants takes less than 2 seconds. We visualize the results by plotting the average R 2 metric obtained from fitting the LFM model to 300 simulated participants at different N between 50 and 1000 (see Figure 2a). Notably, recovery of the ground-truth parameters via posterior means is nearly perfect at higher trial numbers.\nAs a validation tool for visually detecting systematic biases in the approximate posteriors, we can also cheaply apply simulation-based calibration (SBC) and inspect the rank statistic of the posterior samples for uniformity (Talts, Betancourt, Simpson, Vehtari, & Gelman, 2018). Results from applying SBC to 5000 simulated participants at N = 800 are depicted in Figure 2b. Indeed, we confirm that no pronounced issues across all marginal posteriors are present.\n\nReal Data Example\nWe can also apply the same networks from the previous simulation example for fully Bayesian inference on real data. Here, we fit the LFM model to previously unpublished data from eleven participants performing a long (N = 800 per condition) lexical decision task (LDT). Since the task had a 2 \u00d7 2 design, with a factor for difficulty (hard vs. easy), and a factor for stimulus type (word vs. non-word), we can assume a different drift rate for each design cell.\nApplying the pre-trained networks, we immediately obtain samples from a full posterior over model parameters for each participant. Using the estimated posteriors, we can then test hypotheses about particular parameter values, compute individual differences, or compare means between conditions in a Bayesian way. Furthermore, we can analyze posterior correlations at an individual level and investigate task-dependent relationships between the \u03b1 parameter and other parameters (see Figure 3 for results obtained from a single participant).\nAcross participants, \u03b1 displays only small posterior correlations with drift rates as well as small posterior correlations with threshold and non-decision time parameters (mean r < 0.5 across all parameters of the standard diffusion model). These results provide first evidence that the \u03b1 parameter can indeed be decoupled from other model parameters and possibly indicates a separate decision process.\nSince the goal of this application was solely to illustrate a typical use case for amortized Bayesian inference, future research should focus on extensive external validation of the LFM model as well as proposing a neurocognitively plausible interpretation for the \u03b1 parameter.\n\nOutlook\nThe purpose of this work was to introduce the main ideas behind amortized Bayesian inference methods for simulationbased parameter estimation and model comparison. Although these methods come with promising theoretical guarantees and clear practical advantages, their utility for cognitive modeling is just beginning to be explored. Moreover, there are still many open questions and avenues for future research.\nFirst, a systematic investigation of a potential amortization gap in certain practical application seems warranted. An amortization gap refers to a drop in estimation accuracy due to the fact that we are relying on a single set of neural network parameters for solving an inference problem globally, instead of performing per-dataset optimization. Even though we have not observed such a scenario in our applications and simulations, this behavior might occur when the neural network estimators are not expressive enough to represent complex posterior distributions.\nSecond, there are still little systematic guidelines on how to best design and tune the neural network architectures so as to perform optimally across a variety of parameter estimation and model comparison tasks. Even though neural density estimation methods outperform standard ABC methods on multiple metrics and in various contexts, there is certainly room for improvement. Black-box optimization methods for hyperparameter tuning, such as Bayesian optimization or active inference (Snoek, Larochelle, & Adams, 2012), might facilitate additional performance gains and reduce potentially suboptimal architectural choices.\nFinally, user-friendly software for applying Bayesian amortization methods out-of-the-box is still largely in its infancy. Developing and maintaining such software is a crucial future goal for increasing the applicability and usability of novel simulation-based methods.\n\nConclusion\nWe hope that the inference architectures discussed in this work will spur the interest of cognitive modelers from various domains. We believe that such architectures can greatly enhance model-based analysis in cognitive science and psychology. By leaving subsidiary tractability considerations to powerful end-to-end algorithms, researchers can focus more on the task of model development and evaluation to further improve our understanding of cognitive processes.\n\nFootnotes:\n1: Note, that the i.i.d. assumption is not a necessary condition for the method to work, but used here only to simplify the discussion.\n\nReferences:\n\n- Cranmer, K., Brehmer, J., & Louppe, G. (2019). The frontier of simulation-based inference. arXiv preprint arXiv:1911.01429.- Fontanesi, L., Gluth, S., Spektor, M. S., & Rieskamp, J. (2019). A reinforcement learning diffusion decision model for value-based decisions. Psychonomic bulletin & review, 26(4), 1099-1121.\n\n- Gneiting, T., & Raftery, A. E. (2007). Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477), 359-378.\n\n- Greenberg, D. S., Nonnenmacher, M., & Macke, J. H. (2019). Automatic posterior transformation for likelihood-free in- ference. arXiv preprint arXiv:1905.07488.\n\n- Jaynes, E. T. (2003). Probability theory: The logic of science. Cambridge university press.\n\n- Le, T. A., Baydin, A. G., & Wood, F. (2016). Inference com- pilation and universal probabilistic programming. arXiv preprint arXiv:1610.09900.\n\n- Lynch, S. M., & Western, B. (2004). Bayesian posterior pre- dictive checks for complex models. Sociological methods & research, 32(3), 301-335.\n\n- Marin, J.-M., Pudlo, P., Estoup, A., & Robert, C. (2018). Likelihood-free model choice. Chapman and Hall/CRC Press Boca Raton, FL.\n\n- Mestdagh, M., Verdonck, S., Meers, K., Loossens, T., & Tuerlinckx, F. (2019). Prepaid parameter estimation without likelihoods. PLoS computational biology, 15(9), e1007181.\n\n- Myung, J. I., Montenegro, M., & Pitt, M. A. (2007). Analytic expressions for the bcdmem model of recognition memory. Journal of Mathematical Psychology, 51(3), 198-204.\n\n- Radev, S. T., D'Alessandro, M., B\u00fcrkner, P.-C., Mertens, U. K., Voss, A., & K\u00f6the, U. (2020). Amortized bayesian model comparison with evidential deep learning. arXiv preprint arXiv:2004.10629.\n\n- Radev, S. T., Mertens, U. K., Voss, A., Ardizzone, L., & K\u00f6the, U. (2020). Bayesflow: Learning complex stochas- tic models with invertible neural networks. arXiv preprint arXiv:2003.06281.\n\n- Ratcliff, R., Thapar, A., Gomez, P., & McKoon, G. (2004). A diffusion model analysis of the effects of aging in the lexical-decision task. Psychology and aging, 19(2), 278.\n\n- Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practi- cal bayesian optimization of machine learning algorithms. In Advances in neural information processing systems (pp. 2951-2959).\n\n- Stout, J. C., Busemeyer, J. R., Lin, A., Grant, S. J., & Bonson, K. R. (2004). Cognitive modeling analysis of decision- making processes in cocaine abusers. Psychonomic bulletin & review, 11(4), 742-747.\n\n- Talts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gel- man, A. (2018). Validating bayesian inference algo- rithms with simulation-based calibration. arXiv preprint arXiv:1804.06788.\n\n- Turner, B., Sederberg, P., & McClelland, J. (2016). Bayesian analysis of simulation-based models. Journal of Mathe- matical Psychology, 72, 191-199.\n\n- Turner, B. M., Forstmann, B. U., Steyvers, M., et al. (2019). Joint models of neural and behavioral data. Springer.\n\n- Voss, A., Lerche, V., Mertens, U., & Voss, J. (2019). Sequen- tial sampling models with variable boundaries and non- normal noise: A comparison of six models. Psychonomic bulletin & review, 26(3), 813-832.\n\n- Wieschen, E. M., Voss, A., & Radev, S. (2020). Jumping to conclusion? a l\u00e9vy flight model of decision making. TQMP, 16(2), 120-132.\n\n", "annotations": {"ReferenceToFootnote": [{"begin": 14166, "end": 14167, "target": "#foot_0", "idx": 0}], "SectionMain": [{"begin": 1106, "end": 26653, "idx": 0}], "SectionReference": [{"begin": 26803, "end": 30103, "idx": 0}], "SectionHeader": [{"begin": 0, "end": 1106, "idx": 0}], "Div": [{"begin": 64, "end": 1098, "idx": 0}, {"begin": 1109, "end": 2891, "idx": 1}, {"begin": 2893, "end": 4245, "idx": 2}, {"begin": 4247, "end": 5908, "idx": 3}, {"begin": 5910, "end": 7160, "idx": 4}, {"begin": 7162, "end": 9756, "idx": 5}, {"begin": 9758, "end": 13569, "idx": 6}, {"begin": 13571, "end": 16496, "idx": 7}, {"begin": 16498, "end": 18979, "idx": 8}, {"begin": 18981, "end": 20905, "idx": 9}, {"begin": 20907, "end": 22591, "idx": 10}, {"begin": 22593, "end": 24293, "idx": 11}, {"begin": 24295, "end": 26176, "idx": 12}, {"begin": 26178, "end": 26653, "idx": 13}], "Head": [{"begin": 1109, "end": 1147, "idx": 0}, {"begin": 2893, "end": 2922, "idx": 1}, {"begin": 4247, "end": 4272, "idx": 2}, {"begin": 5910, "end": 5930, "idx": 3}, {"begin": 7162, "end": 7188, "idx": 4}, {"begin": 9758, "end": 9777, "idx": 5}, {"begin": 13571, "end": 13633, "idx": 6}, {"begin": 16498, "end": 16556, "idx": 7}, {"begin": 18981, "end": 19001, "idx": 8}, {"begin": 20907, "end": 20925, "idx": 9}, {"begin": 22593, "end": 22610, "idx": 10}, {"begin": 24295, "end": 24302, "idx": 11}, {"begin": 26178, "end": 26188, "idx": 12}], "Paragraph": [{"begin": 64, "end": 1098, "idx": 0}, {"begin": 1148, "end": 1627, "idx": 1}, {"begin": 1628, "end": 2047, "idx": 2}, {"begin": 2048, "end": 2060, "idx": 3}, {"begin": 2061, "end": 2891, "idx": 4}, {"begin": 2923, "end": 3367, "idx": 5}, {"begin": 3413, "end": 3760, "idx": 6}, {"begin": 3761, "end": 4245, "idx": 7}, {"begin": 4273, "end": 4665, "idx": 8}, {"begin": 4666, "end": 4856, "idx": 9}, {"begin": 4898, "end": 5475, "idx": 10}, {"begin": 5512, "end": 5743, "idx": 11}, {"begin": 5807, "end": 5908, "idx": 12}, {"begin": 5931, "end": 6674, "idx": 13}, {"begin": 6675, "end": 7160, "idx": 14}, {"begin": 7189, "end": 7797, "idx": 15}, {"begin": 7857, "end": 8197, "idx": 16}, {"begin": 8198, "end": 9066, "idx": 17}, {"begin": 9067, "end": 9756, "idx": 18}, {"begin": 9778, "end": 10877, "idx": 19}, {"begin": 10878, "end": 11467, "idx": 20}, {"begin": 11468, "end": 12420, "idx": 21}, {"begin": 12421, "end": 12767, "idx": 22}, {"begin": 12768, "end": 12872, "idx": 23}, {"begin": 12873, "end": 12966, "idx": 24}, {"begin": 12967, "end": 13065, "idx": 25}, {"begin": 13066, "end": 13180, "idx": 26}, {"begin": 13181, "end": 13260, "idx": 27}, {"begin": 13261, "end": 13343, "idx": 28}, {"begin": 13344, "end": 13457, "idx": 29}, {"begin": 13458, "end": 13569, "idx": 30}, {"begin": 13634, "end": 13953, "idx": 31}, {"begin": 13954, "end": 14965, "idx": 32}, {"begin": 14966, "end": 15510, "idx": 33}, {"begin": 15551, "end": 15833, "idx": 34}, {"begin": 15874, "end": 16496, "idx": 35}, {"begin": 16557, "end": 17314, "idx": 36}, {"begin": 17373, "end": 17627, "idx": 37}, {"begin": 17672, "end": 17823, "idx": 38}, {"begin": 17824, "end": 18013, "idx": 39}, {"begin": 18044, "end": 18756, "idx": 40}, {"begin": 18757, "end": 18979, "idx": 41}, {"begin": 19002, "end": 19643, "idx": 42}, {"begin": 19644, "end": 20033, "idx": 43}, {"begin": 20090, "end": 20905, "idx": 44}, {"begin": 20926, "end": 22127, "idx": 45}, {"begin": 22128, "end": 22591, "idx": 46}, {"begin": 22611, "end": 23072, "idx": 47}, {"begin": 23073, "end": 23612, "idx": 48}, {"begin": 23613, "end": 24015, "idx": 49}, {"begin": 24016, "end": 24293, "idx": 50}, {"begin": 24303, "end": 24714, "idx": 51}, {"begin": 24715, "end": 25281, "idx": 52}, {"begin": 25282, "end": 25905, "idx": 53}, {"begin": 25906, "end": 26176, "idx": 54}, {"begin": 26189, "end": 26653, "idx": 55}], "ReferenceToBib": [{"begin": 1453, "end": 1495, "target": "#b17", "idx": 0}, {"begin": 2206, "end": 2243, "target": "#b18", "idx": 1}, {"begin": 2252, "end": 2285, "target": "#b9", "idx": 2}, {"begin": 2310, "end": 2355, "target": "#b1", "idx": 3}, {"begin": 2372, "end": 2418, "target": "#b14", "idx": 4}, {"begin": 2726, "end": 2740, "target": "#b4", "idx": 5}, {"begin": 4221, "end": 4244, "target": "#b6", "idx": 6}, {"begin": 5338, "end": 5352, "target": "#b4", "idx": 7}, {"begin": 6797, "end": 6816, "target": "#b18", "idx": 8}, {"begin": 6817, "end": 6858, "target": "#b16", "idx": 9}, {"begin": 7486, "end": 7520, "target": "#b0", "idx": 10}, {"begin": 8001, "end": 8023, "target": "#b0", "idx": 11}, {"begin": 8337, "end": 8359, "target": "#b0", "idx": 12}, {"begin": 8928, "end": 8966, "target": "#b7", "idx": 13}, {"begin": 9232, "end": 9272, "target": "#b3", "idx": 14}, {"begin": 9453, "end": 9475, "target": "#b0", "idx": 15}, {"begin": 9611, "end": 9659, "target": "#b11", "idx": 16}, {"begin": 9660, "end": 9694, "target": "#b10", "idx": 17}, {"begin": 9718, "end": 9749, "target": "#b19", "idx": 18}, {"begin": 10104, "end": 10134, "idx": 19}, {"begin": 10459, "end": 10494, "target": "#b10", "idx": 20}, {"begin": 11401, "end": 11431, "idx": 21}, {"begin": 11432, "end": 11466, "target": "#b10", "idx": 22}, {"begin": 11815, "end": 11841, "target": "#b5", "idx": 23}, {"begin": 11874, "end": 11931, "target": "#b8", "idx": 24}, {"begin": 12395, "end": 12419, "target": "#b3", "idx": 25}, {"begin": 12606, "end": 12636, "idx": 26}, {"begin": 12637, "end": 12671, "target": "#b10", "idx": 27}, {"begin": 13720, "end": 13750, "idx": 28}, {"begin": 14414, "end": 14444, "idx": 29}, {"begin": 16254, "end": 16284, "idx": 30}, {"begin": 16580, "end": 16615, "target": "#b10", "idx": 31}, {"begin": 18092, "end": 18118, "target": "#b2", "idx": 32}, {"begin": 19876, "end": 19895, "target": "#b18", "idx": 33}, {"begin": 19896, "end": 19918, "target": "#b19", "idx": 34}, {"begin": 20749, "end": 20790, "target": "#b12", "idx": 35}, {"begin": 21418, "end": 21437, "target": "#b18", "idx": 36}, {"begin": 22353, "end": 22406, "target": "#b15", "idx": 37}, {"begin": 25767, "end": 25801, "target": "#b13", "idx": 38}], "ReferenceString": [{"begin": 26818, "end": 26941, "id": "b0", "idx": 0}, {"begin": 26943, "end": 27133, "id": "b1", "idx": 1}, {"begin": 27137, "end": 27302, "id": "b2", "idx": 2}, {"begin": 27306, "end": 27465, "id": "b3", "idx": 3}, {"begin": 27469, "end": 27560, "id": "b4", "idx": 4}, {"begin": 27564, "end": 27706, "id": "b5", "idx": 5}, {"begin": 27710, "end": 27853, "id": "b6", "idx": 6}, {"begin": 27857, "end": 27987, "id": "b7", "idx": 7}, {"begin": 27991, "end": 28163, "id": "b8", "idx": 8}, {"begin": 28167, "end": 28335, "id": "b9", "idx": 9}, {"begin": 28339, "end": 28532, "id": "b10", "idx": 10}, {"begin": 28536, "end": 28724, "id": "b11", "idx": 11}, {"begin": 28728, "end": 28900, "id": "b12", "idx": 12}, {"begin": 28904, "end": 29089, "id": "b13", "idx": 13}, {"begin": 29093, "end": 29296, "id": "b14", "idx": 14}, {"begin": 29300, "end": 29486, "id": "b15", "idx": 15}, {"begin": 29490, "end": 29638, "id": "b16", "idx": 16}, {"begin": 29642, "end": 29757, "id": "b17", "idx": 17}, {"begin": 29761, "end": 29966, "id": "b18", "idx": 18}, {"begin": 29970, "end": 30101, "id": "b19", "idx": 19}], "Sentence": [{"begin": 64, "end": 267, "idx": 0}, {"begin": 268, "end": 430, "idx": 1}, {"begin": 431, "end": 685, "idx": 2}, {"begin": 686, "end": 867, "idx": 3}, {"begin": 868, "end": 1098, "idx": 4}, {"begin": 1148, "end": 1308, "idx": 5}, {"begin": 1309, "end": 1449, "idx": 6}, {"begin": 1450, "end": 1496, "idx": 7}, {"begin": 1497, "end": 1627, "idx": 8}, {"begin": 1628, "end": 1784, "idx": 9}, {"begin": 1785, "end": 2047, "idx": 10}, {"begin": 2048, "end": 2060, "idx": 11}, {"begin": 2061, "end": 2439, "idx": 12}, {"begin": 2440, "end": 2589, "idx": 13}, {"begin": 2590, "end": 2741, "idx": 14}, {"begin": 2742, "end": 2891, "idx": 15}, {"begin": 2923, "end": 3141, "idx": 16}, {"begin": 3142, "end": 3297, "idx": 17}, {"begin": 3298, "end": 3367, "idx": 18}, {"begin": 3413, "end": 3558, "idx": 19}, {"begin": 3559, "end": 3660, "idx": 20}, {"begin": 3661, "end": 3760, "idx": 21}, {"begin": 3761, "end": 3979, "idx": 22}, {"begin": 3980, "end": 4245, "idx": 23}, {"begin": 4273, "end": 4434, "idx": 24}, {"begin": 4435, "end": 4528, "idx": 25}, {"begin": 4529, "end": 4665, "idx": 26}, {"begin": 4666, "end": 4743, "idx": 27}, {"begin": 4744, "end": 4752, "idx": 28}, {"begin": 4753, "end": 4856, "idx": 29}, {"begin": 4898, "end": 4981, "idx": 30}, {"begin": 4982, "end": 5212, "idx": 31}, {"begin": 5213, "end": 5353, "idx": 32}, {"begin": 5354, "end": 5475, "idx": 33}, {"begin": 5512, "end": 5575, "idx": 34}, {"begin": 5576, "end": 5743, "idx": 35}, {"begin": 5807, "end": 5908, "idx": 36}, {"begin": 5931, "end": 6078, "idx": 37}, {"begin": 6079, "end": 6300, "idx": 38}, {"begin": 6301, "end": 6540, "idx": 39}, {"begin": 6541, "end": 6674, "idx": 40}, {"begin": 6675, "end": 6859, "idx": 41}, {"begin": 6860, "end": 7067, "idx": 42}, {"begin": 7068, "end": 7160, "idx": 43}, {"begin": 7189, "end": 7411, "idx": 44}, {"begin": 7412, "end": 7565, "idx": 45}, {"begin": 7566, "end": 7797, "idx": 46}, {"begin": 7857, "end": 8024, "idx": 47}, {"begin": 8025, "end": 8197, "idx": 48}, {"begin": 8198, "end": 8360, "idx": 49}, {"begin": 8361, "end": 8586, "idx": 50}, {"begin": 8587, "end": 8770, "idx": 51}, {"begin": 8771, "end": 8967, "idx": 52}, {"begin": 8968, "end": 9066, "idx": 53}, {"begin": 9067, "end": 9273, "idx": 54}, {"begin": 9274, "end": 9476, "idx": 55}, {"begin": 9477, "end": 9756, "idx": 56}, {"begin": 9778, "end": 9865, "idx": 57}, {"begin": 9866, "end": 10102, "idx": 58}, {"begin": 10103, "end": 10135, "idx": 59}, {"begin": 10136, "end": 10304, "idx": 60}, {"begin": 10305, "end": 10495, "idx": 61}, {"begin": 10496, "end": 10674, "idx": 62}, {"begin": 10675, "end": 10877, "idx": 63}, {"begin": 10878, "end": 11180, "idx": 64}, {"begin": 11181, "end": 11294, "idx": 65}, {"begin": 11295, "end": 11467, "idx": 66}, {"begin": 11468, "end": 11587, "idx": 67}, {"begin": 11588, "end": 11842, "idx": 68}, {"begin": 11843, "end": 12040, "idx": 69}, {"begin": 12041, "end": 12165, "idx": 70}, {"begin": 12166, "end": 12420, "idx": 71}, {"begin": 12421, "end": 12672, "idx": 72}, {"begin": 12673, "end": 12767, "idx": 73}, {"begin": 12768, "end": 12872, "idx": 74}, {"begin": 12873, "end": 12966, "idx": 75}, {"begin": 12967, "end": 13065, "idx": 76}, {"begin": 13066, "end": 13180, "idx": 77}, {"begin": 13181, "end": 13260, "idx": 78}, {"begin": 13261, "end": 13343, "idx": 79}, {"begin": 13344, "end": 13457, "idx": 80}, {"begin": 13458, "end": 13569, "idx": 81}, {"begin": 13634, "end": 13778, "idx": 82}, {"begin": 13779, "end": 13953, "idx": 83}, {"begin": 13954, "end": 14029, "idx": 84}, {"begin": 14030, "end": 14152, "idx": 85}, {"begin": 14153, "end": 14212, "idx": 86}, {"begin": 14213, "end": 14277, "idx": 87}, {"begin": 14278, "end": 14347, "idx": 88}, {"begin": 14348, "end": 14558, "idx": 89}, {"begin": 14559, "end": 14733, "idx": 90}, {"begin": 14734, "end": 14965, "idx": 91}, {"begin": 14966, "end": 15183, "idx": 92}, {"begin": 15184, "end": 15386, "idx": 93}, {"begin": 15387, "end": 15510, "idx": 94}, {"begin": 15551, "end": 15833, "idx": 95}, {"begin": 15874, "end": 16089, "idx": 96}, {"begin": 16090, "end": 16285, "idx": 97}, {"begin": 16286, "end": 16496, "idx": 98}, {"begin": 16557, "end": 16724, "idx": 99}, {"begin": 16725, "end": 16828, "idx": 100}, {"begin": 16829, "end": 16928, "idx": 101}, {"begin": 16929, "end": 17186, "idx": 102}, {"begin": 17187, "end": 17314, "idx": 103}, {"begin": 17373, "end": 17517, "idx": 104}, {"begin": 17518, "end": 17627, "idx": 105}, {"begin": 17672, "end": 17823, "idx": 106}, {"begin": 17824, "end": 17978, "idx": 107}, {"begin": 17979, "end": 18013, "idx": 108}, {"begin": 18044, "end": 18184, "idx": 109}, {"begin": 18185, "end": 18296, "idx": 110}, {"begin": 18297, "end": 18454, "idx": 111}, {"begin": 18455, "end": 18629, "idx": 112}, {"begin": 18630, "end": 18756, "idx": 113}, {"begin": 18757, "end": 18979, "idx": 114}, {"begin": 19002, "end": 19169, "idx": 115}, {"begin": 19170, "end": 19298, "idx": 116}, {"begin": 19299, "end": 19426, "idx": 117}, {"begin": 19427, "end": 19643, "idx": 118}, {"begin": 19644, "end": 19789, "idx": 119}, {"begin": 19790, "end": 19933, "idx": 120}, {"begin": 19934, "end": 20033, "idx": 121}, {"begin": 20090, "end": 20376, "idx": 122}, {"begin": 20377, "end": 20646, "idx": 123}, {"begin": 20647, "end": 20905, "idx": 124}, {"begin": 20926, "end": 21002, "idx": 125}, {"begin": 21003, "end": 21062, "idx": 126}, {"begin": 21063, "end": 21261, "idx": 127}, {"begin": 21262, "end": 21438, "idx": 128}, {"begin": 21439, "end": 21591, "idx": 129}, {"begin": 21592, "end": 21705, "idx": 130}, {"begin": 21706, "end": 21837, "idx": 131}, {"begin": 21838, "end": 22015, "idx": 132}, {"begin": 22016, "end": 22127, "idx": 133}, {"begin": 22128, "end": 22407, "idx": 134}, {"begin": 22408, "end": 22502, "idx": 135}, {"begin": 22503, "end": 22591, "idx": 136}, {"begin": 22611, "end": 22726, "idx": 137}, {"begin": 22727, "end": 22880, "idx": 138}, {"begin": 22881, "end": 23072, "idx": 139}, {"begin": 23073, "end": 23203, "idx": 140}, {"begin": 23204, "end": 23385, "idx": 141}, {"begin": 23386, "end": 23612, "idx": 142}, {"begin": 23613, "end": 23853, "idx": 143}, {"begin": 23854, "end": 24015, "idx": 144}, {"begin": 24016, "end": 24293, "idx": 145}, {"begin": 24303, "end": 24466, "idx": 146}, {"begin": 24467, "end": 24635, "idx": 147}, {"begin": 24636, "end": 24714, "idx": 148}, {"begin": 24715, "end": 24830, "idx": 149}, {"begin": 24831, "end": 25062, "idx": 150}, {"begin": 25063, "end": 25281, "idx": 151}, {"begin": 25282, "end": 25494, "idx": 152}, {"begin": 25495, "end": 25658, "idx": 153}, {"begin": 25659, "end": 25905, "idx": 154}, {"begin": 25906, "end": 26028, "idx": 155}, {"begin": 26029, "end": 26176, "idx": 156}, {"begin": 26189, "end": 26319, "idx": 157}, {"begin": 26320, "end": 26432, "idx": 158}, {"begin": 26433, "end": 26653, "idx": 159}], "ReferenceToFigure": [{"begin": 14897, "end": 14899, "idx": 0}, {"begin": 16479, "end": 16481, "idx": 1}, {"begin": 17962, "end": 17964, "idx": 2}, {"begin": 18962, "end": 18964, "idx": 3}, {"begin": 21483, "end": 21485, "idx": 4}, {"begin": 22011, "end": 22013, "idx": 5}, {"begin": 22499, "end": 22501, "idx": 6}, {"begin": 23562, "end": 23563, "target": "#fig_2", "idx": 7}], "Abstract": [{"begin": 54, "end": 1098, "idx": 0}], "SectionFootnote": [{"begin": 26655, "end": 26801, "idx": 0}], "Footnote": [{"begin": 26666, "end": 26801, "id": "foot_0", "n": "1", "idx": 0}]}}