{"text": "Data Bootstrapping Approaches to Improve Low Resource Abusive Language Detection for Indic Languages\n\nAbstract:\nAbusive language is a growing concern in many social media platforms. Repeated exposure to abusive speech has created physiological effects on the target users. Thus, the problem of abusive language should be addressed in all forms for online peace and safety. While extensive research exists in abusive speech detection, most studies focus on English. Recently, many smearing incidents have occurred in India, which provoked diverse forms of abusive speech in online space in various languages based on the geographic location. Therefore it is essential to deal with such malicious content. In this paper, to bridge the gap, we demonstrate a large-scale analysis of multilingual abusive speech in Indic languages. We examine different interlingual transfer mechanisms and observe the performance of various multilingual models for abusive speech detection for eight different Indic languages. We also experiment to show how robust these models are on adversarial attacks. Finally, we conduct an in-depth error analysis by looking into the models' misclassified posts across various settings. We have made our code and models public for other researchers 1 .\nCCS CONCEPTS\n\u2022 Computing methodologies \u2192 Natural language processing; \u2022 Social and professional topics \u2192 Censorship.\n\n\n1 INTRODUCTION\nSocial media platforms (such as Twitter, Facebook, etc.) have connected billions of people at different levels and allowed them to share ideas among themselves instantly. On the one hand, it has led to the exchange of thoughts and massive expansion of social networks; on the other hand, these platforms have been used to spread propaganda, violence, and abuse against users based on gender, religion, race, geographic location, etc. [11]. Not only such abusive behavior can lead to the traumatization of the victims by affecting them psychologically [37], but these can also ignite social tensions and affect the stature of the platforms which host them [36]. Further, widespread usage of such content can also have implications in the offline world: violent hate crimes, youth suicides, mass shootings, and extremist recruitment [17].\nTo mitigate the spread of such abusive content, these platforms have come up with specific guidelines 2 that need to be followed by the users of these platforms. Failure to follow these guidelines may result in the deletion of the post or suspension of the user's account. To reduce the hateful content from these platforms, they employ moderators [28] to review posts manually and keep the forum healthy and friendly. However, this moderation technique is limited by the moderators' speed, diction, ability to understand the evolution of vernacular, and familiarity with multilingual content. In addition, many moderators complain about psychological effects induced due to moderation of such abusive content [1]. Besides, due to the sheer volume and velocity of data streaming, it is an ambitious attempt to filter all the posts manually and screen out such hostile content. Thus, automatic detection of such abusive content is incredibly crucial and unavoidable.\nIt has already been eyed that Facebook actively removed a large portion of malicious content from their platform even before users flagged it 3. Nevertheless, the limitation is that these platforms can identify such detrimental content in certain major languages such as English, Spanish, etc. To that end, several studies have been performed for automated detection of abusive content, concentrating predominantly on the English language. Hence, an effort is needed to determine and mitigate such malicious content in low-resource languages.\nIn the last few years, there have been a series of incidents in India, such as smearing movements against famous political leaders 4, celebrities 5, and social media personalities, online anti-religious propaganda 6, cyber harassment 7, etc. So, to deal with such malicious content, automated systems are much required to keep the online ecosystem healthy. India has more than 1.3 billion people, having the highest number of users on Facebook 8, YouTube 9 and the third-highest number of users on Twitter 10. Besides, the country has 22 recognized languages, which are spoken in various parts of it 11. Due to the most extensive language diversity and their usage on social media, detecting such abusive content in all languages becomes challenging. There are primarily two reasons for this -annotators need to have diverse language expertise and should have knowledge in abusive content analysis.\nFurther, a recent trend on social media platforms is that people write non-English languages using English characters and switch among two or more languages in the same conversation. This phenomenon is called code-mixing (or code-switching), where linguistic units such as phrases, words, or morphemes of one language are embedded in an utterance of another language. Code-mixing allows ease of communication among speakers by furnishing a more comprehensive set of phrases and expressions. However, this has also made the task of developing NLP tools more complex, as emphasized by Chittaranjan et al. [9]. Therefore, there is a need to develop efficient models to detect abusive content in Indic languages in various settings.\nThis paper performs a large-scale analysis of multilingual abusive speech by investigating multilingual models' performance in eight different Indic languages. We address the question of data scarcity and language similarity/typology, two under-explored issues in abusive language identification. Inspired by Nag et al. [27], we explore and catalog a variety of strategies for transferring abusive language detection ability across languages, especially in the resource-rich to resource-poor direction, starting from the \"each language for itself\" (ELFI) criteria. To investigate the degree to which various transfer modes can compensate for gold training instances, we explore multiple scenarios ranging from zero-shot learning, few-shot learning, instance transfer, cross-lingual learning, etc. (more details in section 4). In summary, we observe that -\n\u2022 In ELFI style training, although m-BERT is pre-trained in more than 100 languages, MuRIL outperforms m-BERT in 7 out of 10 language types as it is pre-trained explicitly in Indian languages. \u2022 The zero-shot model transfer can be beneficial for abusive language detection when the source and the target languages belong to the same language family. For few-shot settings, AllBOne is the most effective. \u2022 The model transfer brings better performance than instance transfer (i.e., all instances of a resource-poor language are first translated to a resource-rich language and the training and predictions are done in the resource-rich language) due to the added translation error in instance transfer which reduces the overall toxicity score of an abusive post. \u2022 For low-resource languages, though synthetic silver instances are helpful in detecting abusive content up to some degree, further fine-tuning with gold target instances gives steady improvements. \u2022 Our in-depth error analysis reveals that when a post's contextual information is limited, implicit, or discriminatory features are present, the model fails to detect such an abusive post.\n\n2 RELATED WORKS 2.1 Dynamics of online abuse\nOnline hostility is a context-dependent notion intended to express hatred and threaten an individual or group based on discriminatory views. Despite the argument that hateful statements ought to be tolerated due to free speech acts, the public expression of hate speech propels the reduction of minority members, and such frequent and repetitive exposure to abusive speech could increase an individual's outgroup prejudice [35]. Real-world violent events could also lead to increased hatred in online space and vice versa [29]. With the rise of online hate, the research community has a massive responsibility to develop solutions to mitigate online hostility.\n\n2.2 Research on abusive speech\nThe concern of abusive speech has long been studied in the research community. Earlier work on abusive speech attempted to detect abusive users by using lexical, syntactic features extracted from their posts [8]. Over the past few years, research around automated hate speech detection has matured tremendously. Most of the current study consists of diverse but related works. In 2016, Zeerak Waseem and Dirk Hovy [38] contributed a dataset in which thousands of tweets were labeled with racism and sexism markers, and Davidson et al. [13] focused on distinguishing offensive from hate content on Twitter. Using this dataset, the authors examined multiple linguistic features such as character and word n-grams, POS tags, emotion lexicon, and tf-idf vectors with several classifiers such as LR, SVM, decision tree, etc. Although multiple datasets were being published, a major problem was the lack of correlation and reusable datasets across hate speech detection tasks [21]. To address this issue, Founta et al. [15] studied these inconsistencies and drew upon a robust labeling mechanism that attempts to circumvent the overlap among various forms of abusive speech. With the advent of large datasets, most academic research has moved to data-hungry complex models to improve classifier performance, including deep learning [4] and graph embedding techniques [12]. Pitsilis et al. [30], used deep learning models such as LSTMs to identify the abusive tweets in English and noticed that it was pretty effective in this task. Zhang et al. [39] fused convolutional and gated recurrent networks to enhance the classification performance and had remarkable success on 6 out of 7 datasets used. Recently, transformer based language models such as BERT are becoming immensely popular in several downstream tasks and have outperformed several deep learning models such as CNN-GRU, LSTM, etc., for detecting abusive language [5, 10].\n\n2.3 Abusive language detection in Indic languages\nIn the last few years, several shared tasks, such as Hate-Speech and Offensive Content Identification (HASOC) [25], Dravidian Lang-Tech [7] workshop, TRAC [22], etc., have been organized to develop resources, datasets, and models for abusive speech detection and multiple datasets in Indic languages such as Hindi, Marathi, Tamil, Malayalam, etc. have been made public. The HASOC [25] shared task in Indo-European languages is arguably the most well-known series of competitions. It has been consistently organized from 2019 at the Forum for Information Retrieval (FIRE). The Dravidian Lang-Tech [7] workshop focused on determining the offensive language of the code-mixed dataset in three Dravidian languages, namely, Tamil-English, Malayalam-English, and Kannada-English crawled from social media. In addition, researchers have also developed several datasets for Bengali [34], code-mixed Hindi [6], Urdu [2, 33], etc., for abusive language detection. However, a limited number of studies have been performed on the effect of zero-shot learning, few-shot learning [31, 32], instance transfer, etc. In our work, we try to fill this critical gap by studying various transfer schemes thus opening up new avenues for future research for abuse detection in Indic languages.\n\n3 DATASETS\nIn this section, we describe the datasets used in this paper. We looked into several datasets for Indic languages for abusive speech detection and attempted to gather all of them. English (En): The majority of the abusive speech datasets are available in the English language, and out of these, we select only three publicly available popular datasets. The work on automatic hate speech detection by Davidson et al. [13] made public a Twitter dataset consisting of 24k tweets. To curate the dataset, they used a set of lexicons derived from Hatebase.org 12 . Each tweet has been labeled as either hate speech, offensive or normal. Founta et al. [15] shared a large-scale Twitter dataset consisting of more than 100K tweets. Each tweet has been labeled into one of the following categories: hateful, abusive, normal, and spam. The tweets were annotated by 5-20 annotators to maintain the quality of the labels. We ignore the data points annotated as spam from our analysis. The HateXplain dataset introduced by Mathew et al. [26] is a recent addition to the hate speech research community. It contains around 20K posts categorized into three labels: hate speech, offensive, or normal. The dataset is collected from Twitter and Gab.\nHindi: For the Hindi language, we found two types of datasets: Devanagari Hindi and code-mixed Hindi. The difference between Devanagari and code-mixed is, though the semantic expression of both types of posts is almost similar, Devanagari Hindi is written using the Devanagari script while code-mixed Hindi is written using English characters. Due to differences in writing style, we treat these languages separately.\n-Devanagari Hindi (Hi): In 2019, Mandl et al. [24] released a dataset of 5.9K tweets via the HASOC shared task. The posts were labeled into one of the following classes: hate, offensive, profane and normal. The author developed the dataset by crawling tweets and comments from Twitter and Facebook. Following the previous work, in 2020, Mandl et al. [23] shared another Hindi abusive speech dataset of 3.6K.\nRecently, the author introduced another dataset [25] of 6.1K due to the huge success of the previously organized shared task. We combine all three datasets to have our final Hindi dataset. -Code-mixed Hindi (Hi-En): Bohra et al. [6] introduced the first code-mixed Hindi hate speech Twitter dataset. Each tweet has been annotated as either hate speech or non-hate speech. According to their annotation guidelines, they considered any kind of abuse as hateful. The final dataset consists of 4.5K tweets, out of which 1.6K tweets are hateful, and the remaining 2.9K are non-hateful.\nKannada (Ka-En): Chakravarthi et al. [7] released an offensive language identification dataset in Kannada-English (i.e., code-mixed Kannada). To develop the dataset, the author crawled YouTube comments in 2019. The comments are labeled into one of the following categories: not-offensive, offensive-untargeted, offensivetargeted-individual, offensive-targeted-group, offensive-targetedother, and not-in-indented-language. The final dataset consists of around 7.7K comments. We removed the data points labeled as not-in-indented-language for our analysis, which was irrelevant.\nAll the not-offensive points are assumed to be in the normal class while all the other points (except not-in-indented-language) are fused to form the abusive class. Malayalam (Ma-En): Similar to the Kannada dataset, Chakravarthi et al. [7] made public another code-mixed offensive language detection dataset in Malayalam. The dataset consists of around 20K comments, out of which around 700 comments are offensive. Mandl et al. [23] made public another code-mixed Malayalam dataset consisting 4.9K comments out of which 2.4K comments are abusive.\n\nMarathi (Mr):\nThe Marathi dataset shared by Gaikwad et al. [16] consists of 2.4K posts, among which 1.62K posts are labeled as offensive, and the remaining posts are marked as non-offensive.\nThe dataset has been curated by extracting tweets from Twitter by searching common curse words in Marathi and phrases related to politics, entertainment, and sports. The author employed six volunteer annotators who were native speakers of Marathi with ages between 20 and 25 years old and a bachelor's degree. Tamil (Ta-En): Chakravarthi et al. [7] made public another offensive language detection dataset in code-mixed Tamil. The dataset consists of 43K comments, making it one of the most extensive datasets in code-mixed Tamil. Urdu: We also found two types (actual and code-mixed) of datasets for the Urdu language.\n-Actual Urdu (Ur): For the Urdu language, we found two publicly available datasets. Akhter et al. [2]\n\n4 METHODOLOGY 4.1 Base models\nm-BERT(MB): m-BERT [14] is pre-trained on 104 languages with the largest Wikipedia utilizing a masked language modeling (MLM) objective. It is a stack of transformer encoder layers with 12 \"attention heads, \" i.e., fully connected neural networks augmented with a self-attention mechanism. m-BERT is restricted in the number of tokens it can handle (512 at max). To fine-tune m-BERT, we also add a fully connected layer with the output corresponding to the CLS token in the input. This CLS token output usually holds the representation of the sentence passed to the model. The m-BERT model has been well studied in abusive speech, has already surpassed existing baselines, and stands as a state-of-the-art. MuRIL(MU): MuRIL [19] stands for Multilingual Representations for Indian Languages and aims to improve interoperability from one language to another. This model uses a BERT base architecture pretrained from scratch utilizing the Wikipedia, Common Crawl, PMINDIA, and Dakshina corpora for 17 Indian languages and their transliterated counterparts.\n\n4.2 Interlingual transfer mechanisms\nOne of the primary interests of transformer-based models is their potential to leverage model transfer via several mechanisms. This can be especially helpful for improving the performance of learning in low-resource languages like Bengali, Hindi, Urdu, etc. We perform the following tests to evaluate the extent to which language similarity can boost transfer learning performance.\n\n4.2.1 ELFI (Each language for itself).\nWe use data from the same language for training, validation, and testing in this setting. This scenario usually occurs in the real world, where annotated (labeled) datasets are used to create classifications for a specific language. While the labeling costs are potentially high, this provides an idea of the most feasible classification performance.\n\n4.2.2 Joint training/Cross-lingual training.\nIn this technique, we combine the datasets of all the languages for training the transformerbased models. The idea is that even though the characters, words used to represent different languages vary, the contextual representation of these abusive posts is the same to good extent. In specific, we consider pre-trained embeddings of all the datapoints from all languages (inclusive of the target language) and test it on the test data of the target language. Thus, it gives an idea of whether jointly training the models can help learn a particular post's better semantic representation for determining its corresponding label.\n\n4.2.3 Model transfer.\nIn this setting, the models are trained with one language (source language) and assessed on another language (target language). In the zero-shot setting, no instances from the target language have been used while training (MTx0). In a related few-shot setting, we allow  = 32 and 64 posts per label from the available gold target instances to fine-tune the current models (trained on another language). These are called MTx32 and MTx64. Another extended variant of this model is where for a target language, we use the dataset of all other languages (combined source) to train the models and evaluate their performance on the target language. It would be the case in which we would like to deploy an abusive speech classifier for a target language directly which does not have any training instances. We name the language model as AllBOne.\n\n4.2.4 Instance transfer.\nHere we go the other way, i.e., instead of directly evaluating the model in the target language, we first translate the target language instances to the source language using Google Translate API 13 on which the model is initially fine-tuned. In the zero shot setting Ix0, no gold target instances are used. In this scenario, we can again use a few gold target language instances (by translating to source language) to fine-tune the source model further. We name them Ix32 and Ix64. As for the code-mixed instances, the translation across languages will be inaccurate; we limit this experiment to the monolingual setting only. 4.2.5 Synthetic transfer. Due to the less availability of low resource languages, in this technique, we experiment, can resource-rich language be useful if we translate them to low-resource language and build the model from scratch. To accomplish this, we translate (plentiful) gold source language (e.g., English) into the silver target language (e.g., Bengali, Hindi, etc.) instances using Google Translate API to train the model in the target language. This form of translation is widely used for model transfer; see Kozhevnikov and Titov [20]. Here, again, we can throw in zero or a few target gold instances, guiding to variations we name STx0, STx32 and STx64.\n\n4.3 Experimental setup\nAll models are assessed using the same 70:10:20 train, validation, and test split, stratified by class across the splits. For the transfer learning experiments, we use 32 and 64 training instances from each 13 https://cloud.google.com/translate class to further fine-tune the model in other languages. We make three such different random sets for each target dataset to make our evaluation more effective and report the average performance.\nAll models were coded in Python, using the Pytorch library. The models were run for 10 epoch with Adam optimizer, batch_size = 16, learning_rate = 2 \u22125 and adam_epsilon = 1 \u22128. We set the number of tokens  = 128 for the experiments. We did not perform any hyper-parameter searching due to the limitation of computational resources; besides, the stated hyper-parameters have shown stateof-the-art performance in some of the previous shared-task [5, 10]. All our results are reported on the test set. For all the experiments, we use Ryzen 9, 5 th gen 12 core processor, a Linux-based system with 64GB RAM and 16GB RTX 3080 GPU.\n\n4.4 Evaluation metric\nTo remain consistent with existing literature, we assess our models in terms of accuracy and macro F1-score. These metrics together should be able to thoroughly evaluate the classification performance in distinguishing between abusive and normal posts. For zero-shot and few-shot settings, we report only macro F1-score due to scarcity of space.\n\n5 RESULTS\n\n\n5.1 Performance of ELFI\nIn Table 2, we show the performance of each model for all the languages in terms of accuracy and macro F1 score. We observe model's performance varies from language to language. We see out of 10 language types, MuRIL (MU) outperforms m-BERT (MB) in Table 5 : Macro F1 score of MTx{32, 64} for different source and target languages. Row-wise language names represent the target language, and column-wise language names represent the source language model. The better among MB and MU is highlighted in bold. Blue denotes the best source + model pair for a target language. Blue represents the best, and green the second-best performing model per row (MU or MB). For MTx64, we show the gain added over MTx32.\n7 languages in terms of macro F1-score. Although MU was pretrained in only 17 languages (quite less compared to MB), it was specifically focused on Indian languages. We posit that this is one of the primary reasons for its prevailing superior performance over MB.\n\n5.2 Performance of joint training/cross-lingual training\nHere we investigate the importance of joint training. Even though different language has different character symbols, the main intention for creating all these datasets have been to identify abusive post. Therefore, in order to check if the dataset in one language can be useful for another language or not, we execute joint training by merging all the training language instances. In Table 3 we summarize our results. We observe for some languages, the performance improved, and for some, the performance decreased. In general, MU works better than MB as observed in case of ELFI. Furthermore, we notice the performance deviation is negligible compared to the ELFI setting. Thus, as joint training is usually more expensive in terms of computational resource usage, it is more reasonable to perform self-training in a resource-constrained environment.\n\n5.3 Performance of model transfer\n\n\n5.3.1 Performance of MTx0.\nIn Table 4, we show the performance of zero-shot model transfer outcomes across all pairs of languages. As expected, the macro F1 scores are worse compared to the ELFI setting. Further MU works better than MB.\n\u2022 Ur + MU is the most effective model when the target language is Bn; Hi + MU is the next most effective one. If Hi is the target language, Mr + MU is the most effective model followed by Ur + MU . Likewise, when Ur is the target language, Hi + MU model performs the best followed + MU . If Mr is the target language although the AllBOne + MU model performs the best, Hi + MU is the closest second. This may be explained by their membership in the Indo-Aryan language family. \u2022 The Hi + MB model performs the best for the Hi-En target language. This is possibly because of the fact that Hi-En has the same underlying semantics as that of Hi . \u2022 Ta-En + MU model is most effective for the Ka-En language.\nConversely Ka-En + MU is the best source for the Ta-En language. Besides, for the target language Ma-En, Ta-En + MB model obtains the highest performance. The effectiveness of these models is possibly because of the fact that all these languages belong to the Dravidian language family.\nOverall we observe that zero-shot abusive language detection can be useful when the source and the target languages are from the same language family. 5.3.2 Performance of MTx32 and MTx64. Table 5 illustrates the effect of allowing a small portion of available gold instances in the target language for second-stage fine-tuning. We observe adding more instances improves the overall performance in both MU and MB settings. With more target language gold instances, the deficit from ELFI continues to decrease. An additional interesting observation is that the combinations that were best in the zero-shot setting get altered in many cases here.\n\u2022 Here, both Ur + MU and Hi + MU models perform best for target language Bn. Conversely, Bn + MU is the best source for the target language Ur. \u2022 For the target languages Hi, Mr, Ka-En, and Ta-En, we observe AllBOne + MU model is the most effective. This could be due to the advantages drawn by this model from the two stage fine-tuning. While in the first stage it learns the diversity associated with the languages from different linguistic families, in the second stage it learns the target language specific intricacies from the few-shot labels provided. \u2022 Further we notice that for the target language Hi-En, En + MU model performs the best. This may be due to the Hi-En examples shown to the En + MU model as few-shots from which it is able to learn the English-Hindi switching patterns and their semantic connections. \u2022 Likewise zero-shot performance, we observe that the Ta-En + MB model achieves the best score on Ma-En. \u2022 The Mr + MB model is most effective for the target language Ur-En, followed by the Ur model. \u2022 For the target language En, similar to zero-shot performance, Hi + MU is the best source model.\nOverall we observe that in a few shot setting, the AllBOne model is the most effective.\n\n5.4 Performance of instance transfer\nIn this section, we compare the performance of instance transfer (Ix) with model transfer (MTx). Table 6 shows the performance of Ix0. We observe, unlike MTx, MB performs relatively better than MU. Although comparing Table 4 and 6, we notice MTx0 outperforms Ix0 for all the languages. We observe two reasons for the inferior performance of Ix0 -(a) while translating one language to another, translation errors are inevitable and (b) translation tones down the level abusiveness of a post. Further, we also experiment with the few-shot setup in instance transfer environment (i.e., Ix16 and Ix32). Table 7 shows the performance, which although is better than Ix0, cannot outperform the numbers obtained from the model transfer schemes (see Table 5 vs. Table 7). Overall we maintain that for abusive language detection, model transfer schemes are superior to instance transfer schemes.\n\n5.5 Performance of synthetic transfer\nHere we explore the significance of silver instances in a low-resource setting. In the scarcity of ample target instances for ELFI style training, we can leverage potentially plentiful instances from a source language, i.e., En. Table 8 shows the results. Even after using all available silver target instances, we observe that adding gold target instances gives steady improvements. This implies the worth of always having at least some gold target instances in such tasks.\n\n6 ERROR ANALYSIS\nTo delve deeper, we conduct an error analysis on both models using a small number of test data points wrongly classified by the models.\nWe examine our error from three independent directionsgeneral error, instance transfer error, and synthetic transfer error. General error: We analyze the common errors and segregate them into the following four categories.\n\u2022 The presence of discriminatory features is one of the crucial points of consideration for labeling a post abusive. We observe that models misclassify such posts where some specific words are present in the post that can be used in both abusive and non-abusive contexts. For example, the word 'nigga' in a sentence is more likely to be considered abusive, whereas African-American people use the word in a non-abusive context. For instance, in the following tweet, \"Niggas pulled up on a nigga said hey come to HR for a drug test. Homie said word bet I quit LMFAOOOO\" is predicted as abusive by the model, but its actual label is normal. On the other hand \"I play wit pussy not these niggas\" is correctly predicted abusive by the model. We see m-BERT suffers mostly for this type of error. \u2022 If the contextual information is limited in a post, models cannot predict its actual label. We observe some posts with no abusive text; however, its context makes it abusive possibly because of the presence of emoji, or attached URL. For example, the Bengali instance \"Ai maa*i tui holo akta 14 \" (Translation: You woman, you are a\n) without the emoji can be considered as non abusive; but the presence of the emojis makes it abusive. Our analysis identified that MU suffers mostly for this category of errors.\n\u2022 Implicit abusiveness is another form of an error where the model fails to capture the context due to the absence of explicit abusive content. Understanding these instances requires understanding of sarcasm, complicated reasoning skills, or background knowledge of some situations. For instance the Hindi post \"Khujliwal ko karbwakar ashabaadi bana do 14 \" (Translation: Make Khujliwal optimistic by getting it done.) is abusive toward a politician (Kejriwal) in India; nevertheless, the model fails to predict its actual label as it is sarcastic and need background knowledge about the politician. We notice MB suffers mostly for this category of errors. \u2022 Tentatively disputed annotations are another type of situation where the ground truth label is ambiguous. The context of a post can be multi-dimensional, and based on annotators' understanding, the labeling can be biased toward a specific direction. For example, the following Bengali post \"Kon kon bokach*da mile man of the match nirbachan korche. 14 \" (Translation: Which idiot-fucker is choosing Man of the Match.) has been wrongly annotated as normal, though the use of slur words makes it a clearly abusive post.\nInstance transfer error: In the case of instance transfer, where we translate the target language model to the source language model, we observe the translation affects the true semantics of the actual target posts. Usually, the translator tool reduces the toxicity score of a sentence while translating; sometimes, it cannot translate appropriately because of context-sensitive situations. Hence model performance deteriorates while predicting those instances. For example, \"Tui akta kukurer bachha 14 \" (a slur in Bengali) has been translated to \"You're a puppy\" and does not look toxic. Synthetic transfer error: A similar observation holds for synthetic transfer experiments. Here, the model is trained primarily on relatively less intense words. Hence, different kinds of abusive words/phrases get translated to either the same word or acquire some other representations. Naturally therefore the model performance degrades. For instance, when the following sentence \"Ladies and Gentlemen, Victoria Soliz has fucked up once again\" is translated to Hindi, it becomes \"Deviyon aur sajjanon, Viktoriya Solis ne ek baar phir gadbad kar di hai 14 \" (Translation: Ladies and gentlemen, Victoria Solies has messed up once again). Though the original post was abusive, the translation made the sentence less intense and could be considered as normal.\n\n7 ROBUSTNESS AGAINST ADVERSARIAL CHANGES IN THE TEXT\nObserving the exceptional performance of ELFI style training, in this section, we try to understand, even if we can build an immaculate abusive speech classification model, how robust these models are against various adversarial changes. Specifically, we propose the following six black-box 'attacks', which assumes that the attackers do not know the details of the detection algorithm, hence only creating the best possible guess to avoid exposure.\nRemove spaces: The spaces between adjacent words are removed. As the word-based language models primarily rely on tokenizing the text into a sequence of words, removing all spaces leads to a single <unk> token. Thus, finding the token boundaries would be difficult for the model. Add spaces in words: Conversely, we introduce spaces within individual words in a text, making the word unrecognizable based on characters treated as word separators.\nRemove characters from words: Here we remove the characters from words to introduce typos. These words will still be readable by a human, but the tokens are changed from the classifier's perspective.\nIntroduce special characters: Here we introduce random special characters within words to introduce typos. Swap adjacent characters: We introduce another form of typo within words by swapping adjacent characters.\n\nSwap adjacent words:\nThe transformer-based model tries to understand the underlying meaning of a sentence based on the way words are ordered. So, we swap adjacent words to change the relative ordering of words. Observations: In Figure 1, we demonstrate the performance of all the language models under various adversarial attacks for MB 15 .\nWe see the performance of all the language models drops gradually 15 Similar observations hold for MU as well.\nwith the increasing amount of adversarial attacks. Except for Hi-En, all other models exhibit robustness against adjacent word swap, which indicates that the presence of abusive words is itself a strong signal for the model to judge whether a text is abusive or not irrespective of the relative order of the words. All the language models suffer when spaces are introduced within words, making it difficult to understand the actual word boundaries for the model. Overall similar observations are found for other types of adversarial attacks, which opens up another dimension of work that needs to be addressed to strengthen the models against such adversarial attacks.\n\n8 CONCLUSION\nIn this paper, we tried to perform multilingual abusive language detection for Indic languages. We used transformer-based models to develop classifiers for abusive speech identification, using eight different languages from 14 publicly available resources. We perform several experiments for multiple languages under various settings -ELFI, zero-shot learning, few-shot learning, model transfer, instance transfer, cross-lingual learning, etc. Overall, we noticed that model transfer obtains better performance than instance transfer; further model transfer is advantageous when the source model language and target language belong to the same language family. Further in a few-shot setting the AllBOne model performs the best as it gains from both the fine-tuning stages; while in the first stage it learns universal features, in the second stage it learns language specific features. We observed for low-resource languages, though synthetic silver instances are helpful to build classifiers for abusive language detection, further fine-tuning the model with gold target instances shows steady improvements. One of the main drawbacks we observed was that the model's performance decreased against adversarial attacks. We plan to improve the existing models to make them agnostic of the adversarial attacks. Further, we plan to create datasets in other regional languages using the knowledge we obtained from our experiments.\n\nFootnotes:\n1: https://github.com/hate-alert/IndicAbusive\n2: https://help.twitter.com/en/rules-and-policies/hateful-conduct-policy\n3: https://time.com/5739688/facebook-hate-speech-languages/\n4: https://nenow.in/top-news/resign-pm-modi-trends-on-twitter-as-india-seesworst-covid-19-wave.html\n5:  5 https://www.koimoi.com/bollywood-news/sushant-singh-rajput-news-rheachakraborty-was-harassed-by-various-agencies-satish-maneshinde-demands-cbi-\n6: findings 6 https://www.news18.com/news/buzz/indians-wants-to-boycott-myntra-for-oldanti-hindu-poster-it-didnt-even-make-\n7: 4115855.html 7 https://timesofindia.indiatimes.com/city/mumbai/cyber-harassment-cases-seeupswing-in-pandemic/\n8: articleshow/88842765.cms 8 https://worldpopulationreview.com/country-rankings/\n9: facebook-users-by-country 9 https://www.globalmediainsight.com/blog\n10: /youtube-users-statistics/ 10 https://www.statista.com/statistics/242606/number-of-active-twitter\n11: -users-inselected-countries/ 11 https://www.universal-translation-services.com/recognized-languages-in-india/\n12: https://hatebase.org/\n\nReferences:\n\n- 2017. Moderators who had to view Child abuse content sue microsoft, claim- ing PTSD. https://www.theguardian.com/technology/2017/jan/11/microsoft- employees-child-abuse-lawsuit-ptsd- Muhammad Pervez Akhter, Zheng Jiangbin, Irfan Raza Naqvi, Mohammed Ab- delmajeed, and Muhammad Tariq Sadiq. 2020. Automatic detection of offensive language for urdu and roman urdu. IEEE Access 8 (2020), 91213-91226.\n\n- Maaz Amjad, Alisa Zhila, Grigori Sidorov, Andrey Labunets, Sabur Butt, Hamza Imam Amjad, Oxana Vitman, and Alexander Gelbukh. 2021. UrduThreat@ FIRE2021: Shared Track on abusive threat Identification in Urdu. In FIRE 2021: Forum for Information Retrieval Evaluation, December 13-17, 2021, India. ACM.\n\n- Pinkesh Badjatiya, Shashank Gupta, Manish Gupta, and Vasudeva Varma. 2017. Deep learning for hate speech detection in tweets. In Proceedings of the 26th international conference on World Wide Web companion. 759-760.\n\n- Somnath Banerjee, Maulindu Sarkar, Nancy Agrawal, Punyajoy Saha, and Mithun Das. 2021. Exploring Transformer Based Models to Identify Hate Speech and Offensive Content in English and Indo-Aryan Languages. arXiv preprint arXiv:2111.13974 (2021).\n\n- Aditya Bohra, Deepanshu Vijay, Vinay Singh, Syed Sarfaraz Akhtar, and Manish Shrivastava. 2018. A dataset of hindi-english code-mixed social media text for hate speech detection. In Proceedings of the second workshop on computational modeling of people's opinions, personality, and emotions in social media. 36-41.\n\n- Bharathi Raja Chakravarthi, Ruba Priyadharshini, Navya Jose, Thomas Mandl, Prasanna Kumar Kumaresan, Rahul Ponnusamy, RL Hariharan, John Philip Mc- Crae, Elizabeth Sherly, et al. 2021. Findings of the shared task on offensive language identification in Tamil, Malayalam, and Kannada. In Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages. 133-145.\n\n- Ying Chen, Yilu Zhou, Sencun Zhu, and Heng Xu. 2012. Detecting offensive language in social media to protect adolescent online safety. In 2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing. IEEE, 71-80.\n\n- Gokul Chittaranjan, Yogarshi Vyas, Kalika Bali, and Monojit Choudhury. 2014. Word-level language identification using crf: Code-switching shared task report of msr india system. In Proceedings of The First Workshop on Computational Approaches to Code Switching. 73-79.\n\n- Mithun Das, Somnath Banerjee, and Punyajoy Saha. 2021. Abusive and Threaten- ing Language Detection in Urdu using Boosting based and BERT based models: A Comparative Approach. arXiv preprint arXiv:2111.14830 (2021).\n\n- Mithun Das, Binny Mathew, Punyajoy Saha, Pawan Goyal, and Animesh Mukher- jee. 2020. Hate speech in online social media. ACM SIGWEB Newsletter Autumn (2020), 1-8.\n\n- Mithun Das, Punyajoy Saha, Ritam Dutt, Pawan Goyal, Animesh Mukherjee, and Binny Mathew. 2021. You too brutus! trapping hateful users in social media: Challenges, solutions & insights. In Proceedings of the 32nd ACM Conference on Hypertext and Social Media. 79-89.\n\n- Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. Automated hate speech detection and the problem of offensive language. In Proceedings of the International AAAI Conference on Web and Social Media, Vol. 11.\n\n- J. Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL.\n\n- Antigoni Maria Founta, Constantinos Djouvas, Despoina Chatzakou, Ilias Leon- tiadis, Jeremy Blackburn, Gianluca Stringhini, Athena Vakali, Michael Sirivianos, and Nicolas Kourtellis. 2018. Large scale crowdsourcing and characterization of twitter abusive behavior. In Twelfth International AAAI Conference on Web and Social Media.\n\n- Saurabh Sampatrao Gaikwad, Tharindu Ranasinghe, Marcos Zampieri, and Christopher Homan. 2021. Cross-lingual Offensive Language Identification for Low Resource Languages: The Case of Marathi. In Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021). 437-443.\n\n- Nicola F Johnson, R Leahy, N Johnson Restrepo, Nicolas Velasquez, Ming Zheng, P Manrique, P Devkota, and Stefan Wuchty. 2019. Hidden resilience and adaptive dynamics of the global online hate ecology. Nature 573, 7773 (2019), 261-265.\n\n- Muhammad Moin Khan, Khurram Shahzad, and Muhammad Kamran Malik. 2021. Hate Speech Detection in Roman Urdu. ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP) 20, 1 (2021), 1-19.\n\n- Simran Khanuja, Diksha Bansal, Sarvesh Mehtani, Savya Khosla, Atreyee Dey, Balaji Gopalan, Dilip Kumar Margam, Pooja Aggarwal, Rajiv Teja Nagipogu, Shachi Dave, et al. 2021. Muril: Multilingual representations for indian languages. arXiv preprint arXiv:2103.10730 (2021).\n\n- Mikhail Kozhevnikov and Ivan Titov. 2014. Cross-lingual model transfer using feature representation projection. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 579-585.\n\n- Ritesh Kumar, Atul Kr Ojha, Shervin Malmasi, and Marcos Zampieri. 2018. Bench- marking aggression identification in social media. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018). 1-11.\n\n- Ritesh Kumar, Atul Kr Ojha, Marcos Zampieri, and Shervin Malmasi. 2018. Pro- ceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018). In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018).\n\n- Thomas Mandl, Sandip Modha, Anand Kumar M, and Bharathi Raja Chakravarthi. 2020. Overview of the hasoc track at fire 2020: Hate speech and offensive lan- guage identification in tamil, malayalam, hindi, english and german. In Forum for Information Retrieval Evaluation. 29-32.\n\n- Thomas Mandl, Sandip Modha, Prasenjit Majumder, Daksh Patel, Mohana Dave, Chintak Mandlia, and Aditya Patel. 2019. Overview of the hasoc track at fire 2019: Hate speech and offensive content identification in indo-european languages. In Proceedings of the 11th forum for information retrieval evaluation. 14-17.\n\n- Thomas Mandl, Sandip Modha, Gautam Kishore Shahi, Hiren Madhu, Shrey Satapara, Prasenjit Majumder, Johannes Schaefer, Tharindu Ranasinghe, Marcos Zampieri, Durgesh Nandini, et al. 2021. Overview of the HASOC subtrack at FIRE 2021: Hate speech and offensive content identification in English and Indo-Aryan languages. arXiv preprint arXiv:2112.09301 (2021).\n\n- Binny Mathew, Punyajoy Saha, Seid Muhie Yimam, Chris Biemann, Pawan Goyal, and Animesh Mukherjee. 2021. HateXplain: A Benchmark Dataset for Explain- able Hate Speech Detection. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 14867-14875.\n\n- Arijit Nag, Bidisha Samanta, Animesh Mukherjee, Niloy Ganguly, and Soumen Chakrabarti. 2021. A Data Bootstrapping Recipe for Low-Resource Multilingual Relation Classification. In Proceedings of the 25th Conference on Computational Natural Language Learning. 575-587.\n\n- Casey Newton. 2019. The terror queue. https://www.theverge.com/2019/12/ 16/21021005/google-youtube-moderators-ptsd-accenture-violent-disturbing- content-interviews-video\n\n- Alexandra Olteanu, Carlos Castillo, Jeremy Boy, and Kush Varshney. 2018. The effect of extremist violence on hateful speech online. In Proceedings of the Inter- national AAAI Conference on Web and Social Media, Vol. 12.\n\n- Georgios K. Pitsilis, H. Ramampiaro, and H. Langseth. 2018. Detecting Offensive Language in Tweets Using Deep Learning. ArXiv abs/1801.04433 (2018).\n\n- Tharindu Ranasinghe and Marcos Zampieri. 2020. Multilingual offensive language identification with cross-lingual embeddings. arXiv preprint arXiv:2010.05324 (2020).\n\n- Tharindu Ranasinghe and Marcos Zampieri. 2021. An evaluation of multilingual offensive language identification methods for the languages of india. Information 12, 8 (2021), 306.\n\n- Hammad Rizwan, Muhammad Haroon Shakeel, and Asim Karim. 2020. Hate- speech and offensive language detection in roman Urdu. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2512-2522.\n\n- Nauros Romim, Mosahed Ahmed, Hriteshwar Talukder, and Md Saiful Islam. 2021. Hate speech detection in the bengali language: A dataset and its base- line evaluation. In Proceedings of International Joint Conference on Advances in Computational Intelligence. Springer, 457-468.\n\n- Wiktor Soral, Micha\u0142 Bilewicz, and Miko\u0142aj Winiewski. 2018. Exposure to hate speech increases prejudice through desensitization. Aggressive behavior 44, 2 (2018), 136-146.\n\n- N Statt. 2017. YouTube is facing a full-scale advertising boycott over hate speech. The Verge (2017).\n\n- Janikke Solstad Vedeler, Terje Olsen, and John Eriksen. 2019. Hate speech harms: a social justice discussion of disabled Norwegians' experiences. Disability & Society 34, 3 (2019), 368-383.\n\n- Zeerak Waseem and Dirk Hovy. 2016. Hateful symbols or hateful people? predic- tive features for hate speech detection on twitter. In Proceedings of the NAACL student research workshop. 88-93.\n\n- Ziqi Zhang, David Robinson, and Jonathan Tepper. 2018. Detecting hate speech on twitter using a convolution-gru based deep neural network. In European semantic web conference. Springer, 745-760.\n\n", "annotations": {"Abstract": [{"begin": 102, "end": 1387, "idx": 0}], "Head": [{"begin": 1271, "end": 1283, "idx": 0}, {"begin": 1390, "end": 1404, "n": "1", "idx": 1}, {"begin": 7386, "end": 7430, "n": "2", "idx": 2}, {"begin": 8093, "end": 8123, "n": "2.2", "idx": 3}, {"begin": 10052, "end": 10101, "n": "2.3", "idx": 4}, {"begin": 11374, "end": 11384, "n": "3", "idx": 5}, {"begin": 15148, "end": 15161, "idx": 6}, {"begin": 16062, "end": 16091, "n": "4", "idx": 7}, {"begin": 17147, "end": 17183, "n": "4.2", "idx": 8}, {"begin": 17567, "end": 17605, "n": "4.2.1", "idx": 9}, {"begin": 17958, "end": 18002, "n": "4.2.2", "idx": 10}, {"begin": 18632, "end": 18653, "n": "4.2.3", "idx": 11}, {"begin": 19495, "end": 19519, "n": "4.2.4", "idx": 12}, {"begin": 20815, "end": 20837, "n": "4.3", "idx": 13}, {"begin": 21906, "end": 21927, "n": "4.4", "idx": 14}, {"begin": 22275, "end": 22284, "n": "5", "idx": 15}, {"begin": 22287, "end": 22310, "n": "5.1", "idx": 16}, {"begin": 23282, "end": 23338, "n": "5.2", "idx": 17}, {"begin": 24193, "end": 24226, "n": "5.3", "idx": 18}, {"begin": 24229, "end": 24255, "n": "5.3.1", "idx": 19}, {"begin": 27315, "end": 27351, "n": "5.4", "idx": 20}, {"begin": 28239, "end": 28276, "n": "5.5", "idx": 21}, {"begin": 28753, "end": 28769, "n": "6", "idx": 22}, {"begin": 32958, "end": 33010, "n": "7", "idx": 23}, {"begin": 34322, "end": 34342, "idx": 24}, {"begin": 35445, "end": 35457, "n": "8", "idx": 25}], "ReferenceToBib": [{"begin": 1839, "end": 1843, "target": "#b10", "idx": 0}, {"begin": 1956, "end": 1960, "target": "#b36", "idx": 1}, {"begin": 2060, "end": 2064, "target": "#b35", "idx": 2}, {"begin": 2236, "end": 2240, "target": "#b16", "idx": 3}, {"begin": 2590, "end": 2594, "target": "#b27", "idx": 4}, {"begin": 2952, "end": 2955, "target": "#b0", "idx": 5}, {"begin": 5253, "end": 5256, "target": "#b8", "idx": 6}, {"begin": 5699, "end": 5703, "target": "#b26", "idx": 7}, {"begin": 7854, "end": 7858, "target": "#b34", "idx": 8}, {"begin": 7953, "end": 7957, "target": "#b28", "idx": 9}, {"begin": 8332, "end": 8335, "target": "#b7", "idx": 10}, {"begin": 8538, "end": 8542, "target": "#b37", "idx": 11}, {"begin": 8659, "end": 8663, "target": "#b12", "idx": 12}, {"begin": 9094, "end": 9098, "target": "#b20", "idx": 13}, {"begin": 9137, "end": 9141, "target": "#b14", "idx": 14}, {"begin": 9450, "end": 9453, "target": "#b3", "idx": 15}, {"begin": 9485, "end": 9489, "target": "#b11", "idx": 16}, {"begin": 9507, "end": 9511, "target": "#b29", "idx": 17}, {"begin": 9663, "end": 9667, "target": "#b38", "idx": 18}, {"begin": 10042, "end": 10045, "target": "#b4", "idx": 19}, {"begin": 10046, "end": 10049, "target": "#b9", "idx": 20}, {"begin": 10212, "end": 10216, "target": "#b24", "idx": 21}, {"begin": 10238, "end": 10241, "target": "#b6", "idx": 22}, {"begin": 10257, "end": 10261, "target": "#b21", "idx": 23}, {"begin": 10482, "end": 10486, "target": "#b24", "idx": 24}, {"begin": 10698, "end": 10701, "target": "#b6", "idx": 25}, {"begin": 10976, "end": 10980, "target": "#b33", "idx": 26}, {"begin": 10999, "end": 11002, "target": "#b5", "idx": 27}, {"begin": 11009, "end": 11012, "target": "#b1", "idx": 28}, {"begin": 11013, "end": 11016, "target": "#b32", "idx": 29}, {"begin": 11168, "end": 11172, "target": "#b30", "idx": 30}, {"begin": 11173, "end": 11176, "target": "#b31", "idx": 31}, {"begin": 11801, "end": 11805, "target": "#b12", "idx": 32}, {"begin": 12030, "end": 12034, "target": "#b14", "idx": 33}, {"begin": 12409, "end": 12413, "target": "#b25", "idx": 34}, {"begin": 13080, "end": 13084, "target": "#b23", "idx": 35}, {"begin": 13384, "end": 13388, "target": "#b22", "idx": 36}, {"begin": 13671, "end": 13674, "target": "#b5", "idx": 37}, {"begin": 14060, "end": 14063, "target": "#b6", "idx": 38}, {"begin": 14836, "end": 14839, "target": "#b6", "idx": 39}, {"begin": 15028, "end": 15032, "target": "#b22", "idx": 40}, {"begin": 15207, "end": 15211, "target": "#b15", "idx": 41}, {"begin": 15684, "end": 15687, "target": "#b6", "idx": 42}, {"begin": 16057, "end": 16060, "target": "#b1", "idx": 43}, {"begin": 16111, "end": 16115, "target": "#b13", "idx": 44}, {"begin": 16816, "end": 16820, "target": "#b18", "idx": 45}, {"begin": 20689, "end": 20693, "target": "#b19", "idx": 46}, {"begin": 21723, "end": 21726, "target": "#b4", "idx": 47}, {"begin": 21727, "end": 21730, "target": "#b9", "idx": 48}, {"begin": 37179, "end": 37180, "target": "#b4", "idx": 49}], "ReferenceToFootnote": [{"begin": 2344, "end": 2345, "target": "#foot_1", "idx": 0}, {"begin": 3350, "end": 3351, "target": "#foot_2", "idx": 1}, {"begin": 3882, "end": 3883, "target": "#foot_3", "idx": 2}, {"begin": 3897, "end": 3898, "target": "#foot_4", "idx": 3}, {"begin": 3965, "end": 3966, "target": "#foot_5", "idx": 4}, {"begin": 3985, "end": 3986, "target": "#foot_6", "idx": 5}, {"begin": 4195, "end": 4196, "target": "#foot_7", "idx": 6}, {"begin": 4206, "end": 4207, "target": "#foot_8", "idx": 7}, {"begin": 4257, "end": 4259, "target": "#foot_9", "idx": 8}, {"begin": 4351, "end": 4353, "target": "#foot_10", "idx": 9}, {"begin": 11939, "end": 11941, "target": "#foot_11", "idx": 10}], "SectionFootnote": [{"begin": 36885, "end": 37956, "idx": 0}], "ReferenceString": [{"begin": 37973, "end": 38154, "id": "b0", "idx": 0}, {"begin": 38156, "end": 38371, "id": "b1", "idx": 1}, {"begin": 38375, "end": 38675, "id": "b2", "idx": 2}, {"begin": 38679, "end": 38894, "id": "b3", "idx": 3}, {"begin": 38898, "end": 39142, "id": "b4", "idx": 4}, {"begin": 39146, "end": 39460, "id": "b5", "idx": 5}, {"begin": 39464, "end": 39854, "id": "b6", "idx": 6}, {"begin": 39858, "end": 40130, "id": "b7", "idx": 7}, {"begin": 40134, "end": 40402, "id": "b8", "idx": 8}, {"begin": 40406, "end": 40621, "id": "b9", "idx": 9}, {"begin": 40625, "end": 40787, "id": "b10", "idx": 10}, {"begin": 40791, "end": 41055, "id": "b11", "idx": 11}, {"begin": 41059, "end": 41285, "id": "b12", "idx": 12}, {"begin": 41289, "end": 41449, "id": "b13", "idx": 13}, {"begin": 41453, "end": 41783, "id": "b14", "idx": 14}, {"begin": 41787, "end": 42097, "id": "b15", "idx": 15}, {"begin": 42101, "end": 42335, "id": "b16", "idx": 16}, {"begin": 42339, "end": 42549, "id": "b17", "idx": 17}, {"begin": 42553, "end": 42824, "id": "b18", "idx": 18}, {"begin": 42828, "end": 43065, "id": "b19", "idx": 19}, {"begin": 43069, "end": 43296, "id": "b20", "idx": 20}, {"begin": 43300, "end": 43554, "id": "b21", "idx": 21}, {"begin": 43558, "end": 43834, "id": "b22", "idx": 22}, {"begin": 43838, "end": 44149, "id": "b23", "idx": 23}, {"begin": 44153, "end": 44509, "id": "b24", "idx": 24}, {"begin": 44513, "end": 44777, "id": "b25", "idx": 25}, {"begin": 44781, "end": 45047, "id": "b26", "idx": 26}, {"begin": 45051, "end": 45220, "id": "b27", "idx": 27}, {"begin": 45224, "end": 45443, "id": "b28", "idx": 28}, {"begin": 45447, "end": 45595, "id": "b29", "idx": 29}, {"begin": 45599, "end": 45763, "id": "b30", "idx": 30}, {"begin": 45767, "end": 45944, "id": "b31", "idx": 31}, {"begin": 45948, "end": 46180, "id": "b32", "idx": 32}, {"begin": 46184, "end": 46459, "id": "b33", "idx": 33}, {"begin": 46463, "end": 46634, "id": "b34", "idx": 34}, {"begin": 46638, "end": 46739, "id": "b35", "idx": 35}, {"begin": 46743, "end": 46932, "id": "b36", "idx": 36}, {"begin": 46936, "end": 47127, "id": "b37", "idx": 37}, {"begin": 47131, "end": 47325, "id": "b38", "idx": 38}], "ReferenceToTable": [{"begin": 22320, "end": 22321, "target": "#tab_2", "idx": 0}, {"begin": 22566, "end": 22567, "idx": 1}, {"begin": 23730, "end": 23731, "target": "#tab_3", "idx": 2}, {"begin": 24265, "end": 24266, "target": "#tab_4", "idx": 3}, {"begin": 25652, "end": 25653, "idx": 4}, {"begin": 27455, "end": 27456, "target": "#tab_5", "idx": 5}, {"begin": 27575, "end": 27576, "target": "#tab_4", "idx": 6}, {"begin": 27957, "end": 27958, "target": "#tab_7", "idx": 7}, {"begin": 28099, "end": 28100, "idx": 8}, {"begin": 28111, "end": 28112, "target": "#tab_7", "idx": 9}, {"begin": 28512, "end": 28513, "target": "#tab_8", "idx": 10}], "Footnote": [{"begin": 36896, "end": 36941, "id": "foot_0", "n": "1", "idx": 0}, {"begin": 36942, "end": 37014, "id": "foot_1", "n": "2", "idx": 1}, {"begin": 37015, "end": 37074, "id": "foot_2", "n": "3", "idx": 2}, {"begin": 37075, "end": 37174, "id": "foot_3", "n": "4", "idx": 3}, {"begin": 37175, "end": 37324, "id": "foot_4", "n": "5", "idx": 4}, {"begin": 37325, "end": 37448, "id": "foot_5", "n": "6", "idx": 5}, {"begin": 37449, "end": 37561, "id": "foot_6", "n": "7", "idx": 6}, {"begin": 37562, "end": 37643, "id": "foot_7", "n": "8", "idx": 7}, {"begin": 37644, "end": 37714, "id": "foot_8", "n": "9", "idx": 8}, {"begin": 37715, "end": 37816, "id": "foot_9", "n": "10", "idx": 9}, {"begin": 37817, "end": 37930, "id": "foot_10", "n": "11", "idx": 10}, {"begin": 37931, "end": 37956, "id": "foot_11", "n": "12", "idx": 11}], "Paragraph": [{"begin": 112, "end": 1270, "idx": 0}, {"begin": 1284, "end": 1387, "idx": 1}, {"begin": 1405, "end": 2241, "idx": 2}, {"begin": 2242, "end": 3207, "idx": 3}, {"begin": 3208, "end": 3750, "idx": 4}, {"begin": 3751, "end": 4649, "idx": 5}, {"begin": 4650, "end": 5378, "idx": 6}, {"begin": 5379, "end": 6234, "idx": 7}, {"begin": 6235, "end": 7384, "idx": 8}, {"begin": 7431, "end": 8091, "idx": 9}, {"begin": 8124, "end": 10050, "idx": 10}, {"begin": 10102, "end": 11372, "idx": 11}, {"begin": 11385, "end": 12615, "idx": 12}, {"begin": 12616, "end": 13033, "idx": 13}, {"begin": 13034, "end": 13441, "idx": 14}, {"begin": 13442, "end": 14022, "idx": 15}, {"begin": 14023, "end": 14599, "idx": 16}, {"begin": 14600, "end": 15146, "idx": 17}, {"begin": 15162, "end": 15338, "idx": 18}, {"begin": 15339, "end": 15958, "idx": 19}, {"begin": 15959, "end": 16060, "idx": 20}, {"begin": 16092, "end": 17145, "idx": 21}, {"begin": 17184, "end": 17565, "idx": 22}, {"begin": 17606, "end": 17956, "idx": 23}, {"begin": 18003, "end": 18630, "idx": 24}, {"begin": 18654, "end": 19493, "idx": 25}, {"begin": 19520, "end": 20813, "idx": 26}, {"begin": 20838, "end": 21278, "idx": 27}, {"begin": 21279, "end": 21904, "idx": 28}, {"begin": 21928, "end": 22273, "idx": 29}, {"begin": 22311, "end": 23016, "idx": 30}, {"begin": 23017, "end": 23280, "idx": 31}, {"begin": 23339, "end": 24191, "idx": 32}, {"begin": 24256, "end": 24465, "idx": 33}, {"begin": 24466, "end": 25169, "idx": 34}, {"begin": 25170, "end": 25456, "idx": 35}, {"begin": 25457, "end": 26101, "idx": 36}, {"begin": 26102, "end": 27225, "idx": 37}, {"begin": 27226, "end": 27313, "idx": 38}, {"begin": 27352, "end": 28237, "idx": 39}, {"begin": 28277, "end": 28751, "idx": 40}, {"begin": 28770, "end": 28905, "idx": 41}, {"begin": 28906, "end": 29128, "idx": 42}, {"begin": 29129, "end": 30253, "idx": 43}, {"begin": 30254, "end": 30432, "idx": 44}, {"begin": 30433, "end": 31609, "idx": 45}, {"begin": 31610, "end": 32956, "idx": 46}, {"begin": 33011, "end": 33460, "idx": 47}, {"begin": 33461, "end": 33907, "idx": 48}, {"begin": 33908, "end": 34107, "idx": 49}, {"begin": 34108, "end": 34320, "idx": 50}, {"begin": 34343, "end": 34663, "idx": 51}, {"begin": 34664, "end": 34774, "idx": 52}, {"begin": 34775, "end": 35443, "idx": 53}, {"begin": 35458, "end": 36883, "idx": 54}], "SectionHeader": [{"begin": 0, "end": 1387, "idx": 0}], "SectionReference": [{"begin": 37958, "end": 47327, "idx": 0}], "Sentence": [{"begin": 112, "end": 181, "idx": 0}, {"begin": 182, "end": 272, "idx": 1}, {"begin": 273, "end": 372, "idx": 2}, {"begin": 373, "end": 464, "idx": 3}, {"begin": 465, "end": 640, "idx": 4}, {"begin": 641, "end": 703, "idx": 5}, {"begin": 704, "end": 826, "idx": 6}, {"begin": 827, "end": 1005, "idx": 7}, {"begin": 1006, "end": 1084, "idx": 8}, {"begin": 1085, "end": 1204, "idx": 9}, {"begin": 1205, "end": 1270, "idx": 10}, {"begin": 1284, "end": 1387, "idx": 11}, {"begin": 1405, "end": 1575, "idx": 12}, {"begin": 1576, "end": 1844, "idx": 13}, {"begin": 1845, "end": 2065, "idx": 14}, {"begin": 2066, "end": 2241, "idx": 15}, {"begin": 2242, "end": 2403, "idx": 16}, {"begin": 2404, "end": 2514, "idx": 17}, {"begin": 2515, "end": 2660, "idx": 18}, {"begin": 2661, "end": 2835, "idx": 19}, {"begin": 2836, "end": 2956, "idx": 20}, {"begin": 2957, "end": 3118, "idx": 21}, {"begin": 3119, "end": 3207, "idx": 22}, {"begin": 3208, "end": 3352, "idx": 23}, {"begin": 3353, "end": 3501, "idx": 24}, {"begin": 3502, "end": 3647, "idx": 25}, {"begin": 3648, "end": 3750, "idx": 26}, {"begin": 3751, "end": 4107, "idx": 27}, {"begin": 4108, "end": 4260, "idx": 28}, {"begin": 4261, "end": 4354, "idx": 29}, {"begin": 4355, "end": 4501, "idx": 30}, {"begin": 4502, "end": 4649, "idx": 31}, {"begin": 4650, "end": 4832, "idx": 32}, {"begin": 4833, "end": 5017, "idx": 33}, {"begin": 5018, "end": 5140, "idx": 34}, {"begin": 5141, "end": 5257, "idx": 35}, {"begin": 5258, "end": 5378, "idx": 36}, {"begin": 5379, "end": 5538, "idx": 37}, {"begin": 5539, "end": 5675, "idx": 38}, {"begin": 5676, "end": 5943, "idx": 39}, {"begin": 5944, "end": 6204, "idx": 40}, {"begin": 6205, "end": 6234, "idx": 41}, {"begin": 6235, "end": 6427, "idx": 42}, {"begin": 6428, "end": 6584, "idx": 43}, {"begin": 6585, "end": 6638, "idx": 44}, {"begin": 6639, "end": 6996, "idx": 45}, {"begin": 6997, "end": 7194, "idx": 46}, {"begin": 7195, "end": 7384, "idx": 47}, {"begin": 7431, "end": 7571, "idx": 48}, {"begin": 7572, "end": 7859, "idx": 49}, {"begin": 7860, "end": 7958, "idx": 50}, {"begin": 7959, "end": 8091, "idx": 51}, {"begin": 8124, "end": 8202, "idx": 52}, {"begin": 8203, "end": 8336, "idx": 53}, {"begin": 8337, "end": 8435, "idx": 54}, {"begin": 8436, "end": 8500, "idx": 55}, {"begin": 8501, "end": 8729, "idx": 56}, {"begin": 8730, "end": 8943, "idx": 57}, {"begin": 8944, "end": 9099, "idx": 58}, {"begin": 9100, "end": 9292, "idx": 59}, {"begin": 9293, "end": 9490, "idx": 60}, {"begin": 9491, "end": 9649, "idx": 61}, {"begin": 9650, "end": 9814, "idx": 62}, {"begin": 9815, "end": 10050, "idx": 63}, {"begin": 10102, "end": 10471, "idx": 64}, {"begin": 10472, "end": 10581, "idx": 65}, {"begin": 10582, "end": 10673, "idx": 66}, {"begin": 10674, "end": 10901, "idx": 67}, {"begin": 10902, "end": 11055, "idx": 68}, {"begin": 11056, "end": 11201, "idx": 69}, {"begin": 11202, "end": 11372, "idx": 70}, {"begin": 11385, "end": 11446, "idx": 71}, {"begin": 11447, "end": 11564, "idx": 72}, {"begin": 11565, "end": 11737, "idx": 73}, {"begin": 11738, "end": 11861, "idx": 74}, {"begin": 11862, "end": 11941, "idx": 75}, {"begin": 11942, "end": 11943, "idx": 76}, {"begin": 11944, "end": 12015, "idx": 77}, {"begin": 12016, "end": 12108, "idx": 78}, {"begin": 12109, "end": 12210, "idx": 79}, {"begin": 12211, "end": 12294, "idx": 80}, {"begin": 12295, "end": 12357, "idx": 81}, {"begin": 12358, "end": 12473, "idx": 82}, {"begin": 12474, "end": 12568, "idx": 83}, {"begin": 12569, "end": 12615, "idx": 84}, {"begin": 12616, "end": 12717, "idx": 85}, {"begin": 12718, "end": 12959, "idx": 86}, {"begin": 12960, "end": 13033, "idx": 87}, {"begin": 13034, "end": 13145, "idx": 88}, {"begin": 13146, "end": 13240, "idx": 89}, {"begin": 13241, "end": 13332, "idx": 90}, {"begin": 13333, "end": 13441, "idx": 91}, {"begin": 13442, "end": 13567, "idx": 92}, {"begin": 13568, "end": 13630, "idx": 93}, {"begin": 13631, "end": 13741, "idx": 94}, {"begin": 13742, "end": 13813, "idx": 95}, {"begin": 13814, "end": 13901, "idx": 96}, {"begin": 13902, "end": 14022, "idx": 97}, {"begin": 14023, "end": 14164, "idx": 98}, {"begin": 14165, "end": 14233, "idx": 99}, {"begin": 14234, "end": 14444, "idx": 100}, {"begin": 14445, "end": 14496, "idx": 101}, {"begin": 14497, "end": 14599, "idx": 102}, {"begin": 14600, "end": 14764, "idx": 103}, {"begin": 14765, "end": 14921, "idx": 104}, {"begin": 14922, "end": 15014, "idx": 105}, {"begin": 15015, "end": 15146, "idx": 106}, {"begin": 15162, "end": 15338, "idx": 107}, {"begin": 15339, "end": 15504, "idx": 108}, {"begin": 15505, "end": 15648, "idx": 109}, {"begin": 15649, "end": 15765, "idx": 110}, {"begin": 15766, "end": 15869, "idx": 111}, {"begin": 15870, "end": 15958, "idx": 112}, {"begin": 15959, "end": 16042, "idx": 113}, {"begin": 16043, "end": 16060, "idx": 114}, {"begin": 16092, "end": 16228, "idx": 115}, {"begin": 16229, "end": 16381, "idx": 116}, {"begin": 16382, "end": 16454, "idx": 117}, {"begin": 16455, "end": 16572, "idx": 118}, {"begin": 16573, "end": 16664, "idx": 119}, {"begin": 16665, "end": 16798, "idx": 120}, {"begin": 16799, "end": 16948, "idx": 121}, {"begin": 16949, "end": 17145, "idx": 122}, {"begin": 17184, "end": 17310, "idx": 123}, {"begin": 17311, "end": 17441, "idx": 124}, {"begin": 17442, "end": 17565, "idx": 125}, {"begin": 17606, "end": 17695, "idx": 126}, {"begin": 17696, "end": 17838, "idx": 127}, {"begin": 17839, "end": 17956, "idx": 128}, {"begin": 18003, "end": 18108, "idx": 129}, {"begin": 18109, "end": 18284, "idx": 130}, {"begin": 18285, "end": 18461, "idx": 131}, {"begin": 18462, "end": 18630, "idx": 132}, {"begin": 18654, "end": 18781, "idx": 133}, {"begin": 18782, "end": 18883, "idx": 134}, {"begin": 18884, "end": 19056, "idx": 135}, {"begin": 19057, "end": 19090, "idx": 136}, {"begin": 19091, "end": 19296, "idx": 137}, {"begin": 19297, "end": 19454, "idx": 138}, {"begin": 19455, "end": 19493, "idx": 139}, {"begin": 19520, "end": 19762, "idx": 140}, {"begin": 19763, "end": 19827, "idx": 141}, {"begin": 19828, "end": 19974, "idx": 142}, {"begin": 19975, "end": 20002, "idx": 143}, {"begin": 20003, "end": 20146, "idx": 144}, {"begin": 20147, "end": 20172, "idx": 145}, {"begin": 20173, "end": 20379, "idx": 146}, {"begin": 20380, "end": 20602, "idx": 147}, {"begin": 20603, "end": 20694, "idx": 148}, {"begin": 20695, "end": 20813, "idx": 149}, {"begin": 20838, "end": 20959, "idx": 150}, {"begin": 20960, "end": 21082, "idx": 151}, {"begin": 21083, "end": 21139, "idx": 152}, {"begin": 21140, "end": 21278, "idx": 153}, {"begin": 21279, "end": 21338, "idx": 154}, {"begin": 21339, "end": 21455, "idx": 155}, {"begin": 21456, "end": 21511, "idx": 156}, {"begin": 21512, "end": 21731, "idx": 157}, {"begin": 21732, "end": 21777, "idx": 158}, {"begin": 21778, "end": 21904, "idx": 159}, {"begin": 21928, "end": 22036, "idx": 160}, {"begin": 22037, "end": 22180, "idx": 161}, {"begin": 22181, "end": 22273, "idx": 162}, {"begin": 22311, "end": 22423, "idx": 163}, {"begin": 22424, "end": 22488, "idx": 164}, {"begin": 22489, "end": 22642, "idx": 165}, {"begin": 22643, "end": 22765, "idx": 166}, {"begin": 22766, "end": 22816, "idx": 167}, {"begin": 22817, "end": 22881, "idx": 168}, {"begin": 22882, "end": 22970, "idx": 169}, {"begin": 22971, "end": 23016, "idx": 170}, {"begin": 23017, "end": 23056, "idx": 171}, {"begin": 23057, "end": 23182, "idx": 172}, {"begin": 23183, "end": 23280, "idx": 173}, {"begin": 23339, "end": 23392, "idx": 174}, {"begin": 23393, "end": 23543, "idx": 175}, {"begin": 23544, "end": 23720, "idx": 176}, {"begin": 23721, "end": 23757, "idx": 177}, {"begin": 23758, "end": 23855, "idx": 178}, {"begin": 23856, "end": 23920, "idx": 179}, {"begin": 23921, "end": 24013, "idx": 180}, {"begin": 24014, "end": 24191, "idx": 181}, {"begin": 24256, "end": 24359, "idx": 182}, {"begin": 24360, "end": 24432, "idx": 183}, {"begin": 24433, "end": 24465, "idx": 184}, {"begin": 24466, "end": 24575, "idx": 185}, {"begin": 24576, "end": 24663, "idx": 186}, {"begin": 24664, "end": 24753, "idx": 187}, {"begin": 24754, "end": 24864, "idx": 188}, {"begin": 24865, "end": 24941, "idx": 189}, {"begin": 24942, "end": 25010, "idx": 190}, {"begin": 25011, "end": 25108, "idx": 191}, {"begin": 25109, "end": 25169, "idx": 192}, {"begin": 25170, "end": 25234, "idx": 193}, {"begin": 25235, "end": 25324, "idx": 194}, {"begin": 25325, "end": 25456, "idx": 195}, {"begin": 25457, "end": 25607, "idx": 196}, {"begin": 25608, "end": 25613, "idx": 197}, {"begin": 25614, "end": 25645, "idx": 198}, {"begin": 25646, "end": 25785, "idx": 199}, {"begin": 25786, "end": 25879, "idx": 200}, {"begin": 25880, "end": 25966, "idx": 201}, {"begin": 25967, "end": 26101, "idx": 202}, {"begin": 26102, "end": 26178, "idx": 203}, {"begin": 26179, "end": 26351, "idx": 204}, {"begin": 26352, "end": 26439, "idx": 205}, {"begin": 26440, "end": 26660, "idx": 206}, {"begin": 26661, "end": 26749, "idx": 207}, {"begin": 26750, "end": 26927, "idx": 208}, {"begin": 26928, "end": 27032, "idx": 209}, {"begin": 27033, "end": 27127, "idx": 210}, {"begin": 27128, "end": 27225, "idx": 211}, {"begin": 27226, "end": 27313, "idx": 212}, {"begin": 27352, "end": 27448, "idx": 213}, {"begin": 27449, "end": 27486, "idx": 214}, {"begin": 27487, "end": 27549, "idx": 215}, {"begin": 27550, "end": 27637, "idx": 216}, {"begin": 27638, "end": 27842, "idx": 217}, {"begin": 27843, "end": 27950, "idx": 218}, {"begin": 27951, "end": 28114, "idx": 219}, {"begin": 28115, "end": 28237, "idx": 220}, {"begin": 28277, "end": 28356, "idx": 221}, {"begin": 28357, "end": 28505, "idx": 222}, {"begin": 28506, "end": 28532, "idx": 223}, {"begin": 28533, "end": 28660, "idx": 224}, {"begin": 28661, "end": 28751, "idx": 225}, {"begin": 28770, "end": 28905, "idx": 226}, {"begin": 28906, "end": 29029, "idx": 227}, {"begin": 29030, "end": 29128, "idx": 228}, {"begin": 29129, "end": 29245, "idx": 229}, {"begin": 29246, "end": 29400, "idx": 230}, {"begin": 29401, "end": 29556, "idx": 231}, {"begin": 29557, "end": 29660, "idx": 232}, {"begin": 29661, "end": 29767, "idx": 233}, {"begin": 29768, "end": 29866, "idx": 234}, {"begin": 29867, "end": 29919, "idx": 235}, {"begin": 29920, "end": 30013, "idx": 236}, {"begin": 30014, "end": 30155, "idx": 237}, {"begin": 30156, "end": 30253, "idx": 238}, {"begin": 30254, "end": 30356, "idx": 239}, {"begin": 30357, "end": 30432, "idx": 240}, {"begin": 30433, "end": 30576, "idx": 241}, {"begin": 30577, "end": 30715, "idx": 242}, {"begin": 30716, "end": 31032, "idx": 243}, {"begin": 31033, "end": 31089, "idx": 244}, {"begin": 31090, "end": 31197, "idx": 245}, {"begin": 31198, "end": 31341, "idx": 246}, {"begin": 31342, "end": 31443, "idx": 247}, {"begin": 31444, "end": 31609, "idx": 248}, {"begin": 31610, "end": 31825, "idx": 249}, {"begin": 31826, "end": 32000, "idx": 250}, {"begin": 32001, "end": 32071, "idx": 251}, {"begin": 32072, "end": 32199, "idx": 252}, {"begin": 32200, "end": 32289, "idx": 253}, {"begin": 32290, "end": 32360, "idx": 254}, {"begin": 32361, "end": 32486, "idx": 255}, {"begin": 32487, "end": 32538, "idx": 256}, {"begin": 32539, "end": 32836, "idx": 257}, {"begin": 32837, "end": 32956, "idx": 258}, {"begin": 33011, "end": 33248, "idx": 259}, {"begin": 33249, "end": 33460, "idx": 260}, {"begin": 33461, "end": 33522, "idx": 261}, {"begin": 33523, "end": 33671, "idx": 262}, {"begin": 33672, "end": 33740, "idx": 263}, {"begin": 33741, "end": 33907, "idx": 264}, {"begin": 33908, "end": 33998, "idx": 265}, {"begin": 33999, "end": 34107, "idx": 266}, {"begin": 34108, "end": 34214, "idx": 267}, {"begin": 34215, "end": 34320, "idx": 268}, {"begin": 34343, "end": 34463, "idx": 269}, {"begin": 34464, "end": 34532, "idx": 270}, {"begin": 34533, "end": 34663, "idx": 271}, {"begin": 34664, "end": 34774, "idx": 272}, {"begin": 34775, "end": 34825, "idx": 273}, {"begin": 34826, "end": 35089, "idx": 274}, {"begin": 35090, "end": 35237, "idx": 275}, {"begin": 35238, "end": 35443, "idx": 276}, {"begin": 35458, "end": 35553, "idx": 277}, {"begin": 35554, "end": 35714, "idx": 278}, {"begin": 35715, "end": 35901, "idx": 279}, {"begin": 35902, "end": 36118, "idx": 280}, {"begin": 36119, "end": 36343, "idx": 281}, {"begin": 36344, "end": 36566, "idx": 282}, {"begin": 36567, "end": 36676, "idx": 283}, {"begin": 36677, "end": 36765, "idx": 284}, {"begin": 36766, "end": 36883, "idx": 285}], "ReferenceToFigure": [{"begin": 34557, "end": 34558, "target": "#fig_0", "idx": 0}], "Div": [{"begin": 112, "end": 1270, "idx": 0}, {"begin": 1271, "end": 1387, "idx": 1}, {"begin": 1390, "end": 7384, "idx": 2}, {"begin": 7386, "end": 8091, "idx": 3}, {"begin": 8093, "end": 10050, "idx": 4}, {"begin": 10052, "end": 11372, "idx": 5}, {"begin": 11374, "end": 15146, "idx": 6}, {"begin": 15148, "end": 16060, "idx": 7}, {"begin": 16062, "end": 17145, "idx": 8}, {"begin": 17147, "end": 17565, "idx": 9}, {"begin": 17567, "end": 17956, "idx": 10}, {"begin": 17958, "end": 18630, "idx": 11}, {"begin": 18632, "end": 19493, "idx": 12}, {"begin": 19495, "end": 20813, "idx": 13}, {"begin": 20815, "end": 21904, "idx": 14}, {"begin": 21906, "end": 22273, "idx": 15}, {"begin": 22275, "end": 22285, "idx": 16}, {"begin": 22287, "end": 23280, "idx": 17}, {"begin": 23282, "end": 24191, "idx": 18}, {"begin": 24193, "end": 24227, "idx": 19}, {"begin": 24229, "end": 27313, "idx": 20}, {"begin": 27315, "end": 28237, "idx": 21}, {"begin": 28239, "end": 28751, "idx": 22}, {"begin": 28753, "end": 32956, "idx": 23}, {"begin": 32958, "end": 34320, "idx": 24}, {"begin": 34322, "end": 35443, "idx": 25}, {"begin": 35445, "end": 36883, "idx": 26}], "SectionMain": [{"begin": 1387, "end": 36883, "idx": 0}]}}