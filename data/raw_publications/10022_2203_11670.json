{"text": "Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation\n\nAbstract:\nBuilding models of natural language processing (NLP) is challenging in low-resource scenarios where only limited data are available. Optimization-based meta-learning algorithms achieve promising results in low-resource scenarios by adapting a well-generalized model initialization to handle new tasks. Nonetheless, these approaches suffer from the memorization overfitting issue, where the model tends to memorize the meta-training tasks while ignoring support sets when adapting to new tasks. To address this issue, we propose a memory imitation meta-learning (MemIML) method that enhances the model's reliance on support sets for task adaptation. Specifically, we introduce a task-specific memory module to store support set information and construct an imitation module to force query sets to imitate the behaviors of some representative supportset samples stored in the memory. A theoretical analysis is provided to prove the effectiveness of our method, and empirical results also demonstrate that our method outperforms competitive baselines on both text classification and generation tasks.\n\nMain:\n\n\n\n1 Introduction\nBuilding natural language processing (NLP) models in low-resource scenarios is of great importance in practical applications because labeled data are scarce. Meta-learning-based methods (Thrun and Pratt, 2012) have been commonly used in such scenarios owing to their fast adaptation ability. Notable successes have been achieved by metalearning on low-resource NLP tasks, such as multidomain sentiment classification (Yu et al., 2018; Geng et al., 2019) and personalized dialogue generation (Madotto et al., 2019; Song et al., 2020; Zheng et al., 2020).\nAmong different meta-learning approaches (Hospedales et al., 2021), optimization-based ap- * Corresponding author proaches have been widely used in various lowresource NLP scenarios (Madotto et al., 2019; Qian and Yu, 2019; Li et al., 2020; Mi et al., 2019) because they are model-agnostic and easily applicable. Concretely, optimization-based meta-learning algorithms aim to learn a well-generalized global model initialization \u03b8 that can quickly adapt to new tasks within a few steps of gradient updates. In the meta-training process, we first train \u03b8 on a support set (i.e., a few training samples of a new task i) to obtain task-specific parameters \u03b8 i . Then, we optimize \u03b8 based on the performance of \u03b8 i on a query set (i.e., another set of samples in task i).\nDespite its effectiveness, optimization-based meta-learning algorithms usually suffer from the memorization overfitting issue 1 (Yin et al., 2020; Rajendran et al., 2020), where the learned model tends to solve all the meta-training tasks by memorization, rather than learning how to quickly adapt from one task to another via support sets. This is acceptable for training process, but results in poor generalization on the meta-testing sets, because the memorized model does not have knowledge of those tasks and does not know how to utilize the base learner to learn new tasks. Hence, this issue hinders the model from capturing task-specific characteristics from support sets and thus prevents the model from adapting to distinct new tasks (Rajendran et al., 2020). For instance, in personalized dialogue generation, this implies that the dialog model cannot adapt to individual users based on short conversation histories and hence fails to generate personalized responses.\nSeveral works have been proposed to tackle the memorization overfitting issue for regression and image classification tasks. Some studies try to explicitly regularize the model parameters (Yin et al.,   1 Memorization overfitting is different from the overfitting in conventional supervised learning (Hawkins, 2004). The latter means that the model overfits to the training tasks and fails to generalize to the testing tasks. 2020; Rajendran et al., 2020), but this restricts the complexity of model initialization and reduces the model capacity. Another line of research integrates samples from support sets into the corresponding query sets via data augmentation (Yao et al., 2021). However, data augmentation on textual data may result in noisy labels or distribution shifts, which impairs the model performance (Chen et al., 2021).\nIn this paper, we address the memorization overfitting issue by enhancing the model's dependence on support sets when learning the model initialization, which forces the model to better leverage information from support sets. As an analogy, consider a young investor who has the ability to adapt to new circumstances rapidly but little memory of learned experiences, and an old investor who is experienced but refuses to be flexible. Our idea is to make the young investor adaptive to the various situations when he assesses his benefits so that he can not only take advantage of the old one's experience but also learn from the old investor how to leverage the learned experience. In this paper, the young investor stands for a standard meta-learning algorithm (e.g., MAML), which is prone to memorization overfitting, and the old investor is a memory module we integrate into the method, carrying information of support sets.\nSpecifically, we propose a Memory-Imitation Meta-Learning (MemIML) method that forces query set predictions to depend on their corresponding support sets by dynamically imitating behaviors of the latter. We therefore, introduce a memory module and an imitation module to enhance such dependence. The memory module is task-specific, storing representative information of support sets. The imitation module assists in predicting samples of query sets by dynamically imitating the memory construction. In this way, the model has to access the support set by memory imitation each time it makes a prediction on a query-set sample, hence it's no longer feasible for the model to memorize all meta tasks.\nThe contributions of this work are:\n\n2 Related Work\nMeta-Learning. Meta-Learning aims to improve the learning algorithm itself based on the previously learned experience (Thrun and Pratt, 1998; Hospedales et al., 2021). In general, there are three categories of meta-learning methods: model-based methods, (Santoro et al., 2016; Obamuyide et al., 2019) which depend on the particular model design to facilitate fast learning; metric-based methods, (Vinyals et al., 2016; Snell et al., 2017; Geng et al., 2019) which encode samples into an embedding space and classify them based on the learned distance metric; optimization-based methods (Finn et al., 2017; Mi et al., 2019) that learn a wellgeneralized model initialization which allows for fast adaptation to new tasks. For low-resource scenarios in NLP, optimization-based meta-learning methods achieved promising results on tasks such as personalized dialog generation (Madotto et al., 2019; Song et al., 2020; Tian et al., 2021), lowresource machine translation (Gu et al., 2018; Sharaf et al., 2020) and question answering (Yan et al., 2020), few-shot slot tagging (Wang et al., 2021), and so on.\nMemorization overfitting of Meta-learning. Meta-learning algorithms suffer from memorization overfitting.  Yin et al. (2020) build an information bottleneck to the model, while this approach decreases the model performance with this passive regularization.  Rajendran et al. (2020) inject random noise to the ground truth of both support and query sets, while little extra knowledge is introduced to learn a good initialization.  Yao et al. (2021) address overfitting issues by augmenting meta-training tasks through mixing up support and query sets. However, such augmentation for text needs to be based on the assumption of keeping the label and the data distribution unchanged, which is often not true in practice (Chen et al., 2021). Instead of regularization and data augmentation, we leverage the support sets information stored in the memory to augment the meta-learning.\nExternal Memory for Few-shot Learning.\nMemory mechanism has proven to be powerful for few-shot learning (Geng et al., 2019; Santoro et al., 2016; Munkhdalai et al., 2019). Current methods either refine representations stored in the memory (Ramalho and Garnelo, 2018) or refining parameters using the memory (Munkhdalai and Yu, 2017; Cai et al., 2018; Wang et al., 2020). In the NLP domain, some methods store encoded contextual information into a memory (Kaiser et al., 2017; Holla et al., 2020; Zheng et al., 2019).  Geng et al. (2019) propose a memory induction module with a dynamic routing algorithm for few-shot text classification tasks.  Munkhdalai et al. (2019) augment the model with an external memory by learning a neural memory.  Wang et al. (2021) reuse learned features stored in the memory on the few-shot slot tagging.\n\n3 Preliminaries\nWe first formulate model-agnostic meta-learning (MAML) (Finn et al., 2017). Specifically, denote the base model used in MAML as f \u03b8 and assume each task T i sampled from a task distribution p(T ) associates with a dataset D i . Each dataset D i consists of a support setD s i = {(X s j , Y s j )} N s j=1 and a query set D q i = {(X q j , Y q j )} N q j=1\n, where X and Y denote the input and ground truth of a sample, respectively. During the meta-training stage, a taskspecific (a.k.a., post-update) model f \u03b8 i is first obtained for each task T i via gradient descent over its support set D s i . Then MAML updates its initialization (a.k.a., pre-update) \u03b8 according to the performance of f \u03b8 i on the query set D q i as in Eq.1:\u03b8 * = min \u03b8 E T i \u223cp(T ) L f \u03b8 i (X q i ) , Y q i (1) s.t. \u03b8 i = \u03b8 \u2212 \u03b1\u2207 \u03b8 L (f \u03b8 (X s i ) , Y s i ) (2)\nwhere \u03b1 is the inner loop learning rate. During the meta-testing stage, the learned initialization \u03b8 * is fine-tuned on the support set D s t for task T t , and the resulting model is evaluated on the query set D q t with the post-update parameters \u03b8 t .\n\n4 Methodology\nTo alleviate the memorization overfitting issue in meta-learning, we propose MemIML, which includes a memory module and an imitation module on the grounds of a base model. The memory module is task-specific, recording the mapping behaviors between inputs and outputs of support sets for each task. The imitation module is shared across tasks and predicts values for each query-set sample by dynamically imitating the memory construction.\nThe acquired support set information leveraged by the imitation module augments the model initialization learning, enhancing the dependence of the model's task adaptation on support sets. Fig. 1 shows our model architecture.\n\n4.1 Memory Module\nWe design a memory module M i for each task T i and incorporate it in the MAML framework. In order to fully leverage information from support sets, we construct key-value pairs from support-set samples and store them in the memory module. The key is the sentence representation of a sample input from support sets obtained from an introduced key network. The corresponding value is constructed to store the information of the sample output (ground truth) as in Sec. 4.3: in NLG tasks, the value is the sentence embedding of the output sentence; in NLU tasks, the value is the one hot embedding of the class label (a scalar) of the sample. Our memory has two operations: memory writing that constructs the memory and memory reading that acquires information from memory. In the following, we elaborate on these contents in detail.\nKey Network represents a sample with a vector. Specifically, we use a frozen pre-trained BERT model (Devlin et al., 2019) as the key network. The input of the key network is the sample input sentence X s j \u2208 D s i (X q j \u2208 D q i ), and the output is the encoded representation of the first token (i.e. [CLS] token) of the sentence. The acquired representation is regarded as the key K s j for X s j (K q j for X q j ). Memory Writing constructs the memory using the information of samples in the support set D s i . For each task T i , the task-specific memory M i consists of N i memory slots (i.e. key-value pairs {K s l , V s l } N i l=1 ). To build these memory slots, we select samples from support sets and write their information into the memory. The sample selection is according to a diversity-based selection criterion (Xie et al., 2015) to ensure the diversity and representativeness of the memory content. The detailed description of this criterion is in Appendix D.\nFor each task-specific memory module M i , we adopt the diversity score as S(M i ) on the stored keys. Here, a more diverse memory gets a higher diversity score. When the memory is not full, we directly write support-set samples without selection; otherwise, we compute the diversity score of the current memory and scores after every old key-value pair is replaced with a new key-value pair. Then we replace the old pair with the new one where the replacement can maximize the diversity score. In this way, the memory we build can carry more distinguishable and representative information and efficiently utilize the storage space.\nMemory Reading obtains information from memory to enhance the meta-learning. The input is the sentence representation of the sample in query sets encoded by the key network, and the output is the memory slots similar to the query sample. Specifically, given the key representation K q j of a sample X q j \u2208 D q i , we retrieve the top N most similar slots from its task-specific memory M i . The similarity is measured based on the Euclidean distance between K q j and each key K s l in the memory slots. The retrieved key-value pairs {K s l , V s l } N l=1 act as the output of memory reading.\n\n4.2 Imitation Module\nIn order to better leverage the retrieved memory and enhance the dependence of our model on support sets, we propose an imitation module to encourage the imitation of support sets behaviors when making predictions on query sets. For each sample X q j in the query set, the inputs of the imitation module are the key K q j and its retrieved N memory slots, and the output is the predicted value V q j for X q j . To achieve the imitation, we construct a value predictor that can model the behaviors of supportset samples (i.e. key-value matching) stored in the memory. For estimating the value of each query-set sample, we conduct local adaptation on the value predictor to adapt the matching.\nIn this way, the proposed imitation module is customized for each query-set sample, which facilitates better capture of specific task information than directly using the memory reading output, especially when tasks are versatile. The reason is that the similarity measurement of previous memory reading operations is based on the fixed BERT representations, which ignores the task-specific information.\n\n4.2.1 Value Predictor\nIn MemIML, the proposed value predictor aims to build a mapping from keys to values of the memory module mentioned in Sec. 4.1. The input of the value predictor is a key obtained from the key network, and the output is the associated value.\nSpecifically, we use a two-layer fully-connected network g \u03c9 with parameters \u03c9 to build the mapping. The value predictor is learned over constructed keyvalue pairs of support sets across all tasks. Given the key K q j of a query-set sample input X q j , we can then estimate its associated value as V q j .\n\n4.2.2 Training of The Value Predictor\nTo train the value predictor, we minimize the reconstruction loss L rec \u03c9 ( V , V ) to make the predicted values as close as possible to values constructed from the ground truths of support-set samples, where L rec \u03c9 is the cross-entropy loss if the value V is a label and is the mean square loss if V is a vector.\nThe training procedure includes the global optimization shared across tasks and the local adaptation for each specific task. Specifically, we first train the value predictor with samples from support sets of all tasks. After feeding the memory reading output of a query-set sample to this network, we perform local adaptation and employ the adapted network to estimate the value for the query sample.\nGlobal Optimization. To obtain the taskindependent global parameters \u03c9, we train the value predictor over constructed keys (i.e., as inputs) and values (i.e., as outputs) from support-set samples of all tasks. The global optimization keeps updating in the whole meta-training phase.\nLocal Adaptation. To make the value predictor adaptive to each query-set sample X q j , inspired by (Sprechmann et al., 2018), we propose local adaptation that fine-tunes the global value predictor g \u03c9 to get an adapted one with parameters \u03c9 q j . The local adaptation only works when predicting X q j . Based on the initial parameters \u03c9 from the global optimization, we perform several gradient descent steps to minimize the loss L loc , which is:L loc = \u03b3 \u03c9 \u2212 \u03c9 2 2 + 1 N N l=1 L rec \u03c9 ( V s l , V s l ) (3) Here, V s l = g \u03c9(K s l ), {K s l , V s l } N l=1\nis the memory reading output of the query-set sample, and the factor \u03b3 restricts the distance between \u03c9 q j and \u03c9. Minimizing the second term encourages g \u03c9 q j to better estimate the retrieved memory values {V s l } N l=1 . Then we can acquire the locally adapted value prediction network g \u03c9 q j with parameters \u03c9 q j = arg min \u03c9 L loc (\u03c9). Given a query-sample key K q j , we can thus predict its associated value asV q j = g \u03c9 q j (K q j ),\nwhere the adapted parameters \u03c9 q j are discarded thereafter, and the model does not back-propagate through V q j . In this sense, besides the task-specific parameter \u03b8 i provided by MAML, there will also be \u03c9 q j learned from support sets specific to each query-set sample. This guarantees that the model relies more on support sets for task adaptation. Fig. 1 (right part) illustrates the mechanism of local adaptation.\n\n4.3 MemIML on NLP Applications\nIn this part, we will elaborate on two few-shot applications in NLP (i.e., text generation and text classification) to solve the memorization overfitting problem of MAML. The model structures of these applications are basically the same, except for the following three points: the base model, the way to get the value V s l stored in the memory module, and the way to leverage the output V q j of Sec. 4.2.\nPersonalized Dialogue Generation. The base model is the transformer (Vaswani et al., 2017) consisting of an encoder and a decoder. In this task, each sample consists of an input utterance and a ground truth utterance, so the value V s l stored in the memory is obtained from the ground truth utterance Y s l of a support-set sample, which is embedded by the key network followed by an LSTM (Hochreiter and Schmidhuber, 1997). This LSTM is optimized with the base model. The V q j , concatenated with the encoder outputs, serves as a new input for the decoder. Hence, we acquire the prediction of a query-set sample via \u0176 q j = Decoder([ V q j ; Encoder(X q j )]).\nMulti-domain Sentiment Classification. The base model is a BERT (Devlin et al., 2019) followed by a fully-connected network. Each sample consists of an input sentence and a sentiment label (ground truth), so the memory value V s l is the sentiment label. To leverage V q j , we interpolate it with the original output of the base model \u1ef8 q j as\u0176 q j = \u03b2 \u1ef8 q j + (1 \u2212 \u03b2) V q j (5)\nwhere \u03b2 balances \u1ef8 q j and V q j . Notice that the interpolation not only works on the prediction output but also guides the training via gradient descent based on the interpolated output. We verify the effectiveness of the interpolation in Appendix C. Mi\u2190 {< K s l , V s l >} N s l=1 # Write memory 8: \u03c9 \u2190 \u03c9 \u2212 \u03b11\u2207\u03c9L rec # Global optimization 9: \u03b8 i \u2190 \u03b8 \u2212 \u03b12\u2207 \u03b8 L base # Learn \u03b8 i in Eq. 2 10:\nfor (X q j , Y q j ) in D q i do 11:\nObtain the keys K q j for each sample X q j 12:\nRetrieve N nearest neighbors of K q j from Mi.\n13:\n\u03c9 q j \u2190 \u03c9 \u2212 \u03b13\u2207\u03c9L loc # Local adaptation 14:\nV q j = g \u03c9 q j (K q j ) # Predict memory output 15:\nPredict \u0176 q j as in Sec. 4.3 16:\nend for 17:\nend for18: Update \u03b8 \u2190 \u03b8 \u2212 \u03b14\u2207 \u03b8 T i \u223cp(T ) L base T i ,\u03b8 i ( \u0176 q , Y q )\n19: end while\n\n4.4 Theoretical Analysis\nWe theoretically investigate how our method helps to alleviate the memorization overfitting problem. Following Yin et al. (2020), we use mutual information I( \u0176 q i ; D s i |\u03b8, X q i ) to measure the level of the memorization overfitting. When the learned model ignores support sets to predict query sets, I( \u0176 q i ; D s i )|\u03b8, X q i ) = 0 occurs, which indicates the complete memorization overfitting in metalearning (Yin et al., 2020). Hence, lower mutual information means more serious memorization overfitting issues.\nWe propose a criterion similar to (Yao et al., 2021) to measure the validity of our method for tackling this problem. For a task T i = {D s i , D q i }, the criterion aims to mitigate the memorization overfitting by enhancing the model's dependence on the support set D s i , i.e. increasing the mutual information between support set and \u0176 q i as follows:I( \u0176 q i ;[D s i , M i ] | \u03b8, X q i ) > I( \u0176 q i ; D s i | \u03b8, X q i ),\nwhere M i means additional memory information we provide, which contains support sets information to augment the inference of the sample X q i in D q i . We demonstrate our method MemIML meets the above criterion (See details in Appendix A.).\n\n4.5 The Procedure of Training and Testing\nIn the meta-training phase (shown in Alg. 1), MemIML first constructs an empty memory for each task and then follows the bi-level optimization process of MAML. In the inner loop, MemIML adapts the base model initialization \u03b8 to taskspecific parameters via training on the support set. At the same time, from each support-set sample, MemIML obtains a key-value pair and determines whether to write it into the memory or not. Then, MemIML conducts the global optimization of the value predictor over these key-value pairs. In the outer loop, each sample of the query set reads the memory to retrieve the most similar memory slots. Local adaptation fine-tunes the value predictor on those retrieved slots. Next, the adapted value predictor estimates the value of each query sample and uses it to augment the learning of the model initialization. The total loss function in the inner loop is L total = L base + L rec , whereL base = L(f (X s ), Y s ) is the cross-entropy loss.\nThe procedure of meta-training and meta-testing are almost the same except that meta-testing does not optimize the learned model initialization \u03b8 and the initial parameter \u03c9 of the value predictor. For each task T t in the meta-testing phase, MemIML also adapts \u03b8 to task-specific parameters \u03b8 i in the inner-loop and constructs the task-specific memory. In the outer-loop, MemIML retrieves key-value pairs from the memory to conduct local adaptation based on the initial parameter \u03c9. The estimated value V q t from local adaptation helps the base model to infer the final output \u0176 q t .\n\n5 Experiments and Analysis\nExperiments on personalized dialogue generation and multi-domain sentiment classification verify our model on text generation and classification, respectively, where we use Persona-Chat and ARSC datasets. model over all the training tasks ignoring the speakers' personality. Fine-tune: We fine-tune the pretrained base model on the support sets of each metatesting task. MAML: We apply MAML (Madotto et al., 2019) to the base model. MR-MAML: Yin et al. ( 2020) tackle the memorization overfitting of MAML via regularization.\n\n5.1 Personalized\nMetrics. Automatic evaluation has three aspects,\n\u2022 Quality: BLEU-n (Papineni et al., 2002), CIDEr (Vedantam et al., 2015), and ROUGE (Lin, 2004) measures the n-gram matching between the generated response and ground truth. PPL (perplexity) measures the sentence fluency. \u2022 Diversity. Dist-n (Li et al., 2016) evaluates the response diversity by counting unique n-grams. \u2022 Consistency: C score (Madotto et al., 2019) measures the consistency between the generated responses and persona descriptions through a pretrained natural language inference model.\nHuman evaluation consists of Quality and Consistency. (See details in Appendix B.1).\nOverall Performance. As shown in Table 1.\nFine-tune outperforms Base Model in all metrics, which verifies that the task-specific data is helpful to its performance on specific tasks. Compared to Fine-tune, MAML behaves better on diversity and consistency but behaves worse on quality. Pretraining the base model achieves the best perplexity (lowest PPL) as shown by Base Model and Fine-tune. We analyze that it's because pretraining leads to a considerable degree of fluency in their generated utterances and is careless about each task's specific information, resulting in low consistency with tasks. Our model, MemIML, performs the best in most aspects, including quality, diversity, and task consistency. In particular, MemIML significantly improves MR-MAML in alleviating the memorization overfitting issue, suggesting that memory imitation is more effective than only regularizing model initialization.\n\n5.2 Multi-domain Sentiment Classification\nDataset. Amazon Review sentiment classification dataset (ARSC) (Yu et al., 2018) contains 69 tasks in total. Following (Geng et al., 2019), we build a 2-way 5-shot meta-learning with 57 tasks for meta-training and 12 tasks for meta-testing.\nWe conduct experiments on the ARSC (Yu et al., 2018). It contains English reviews of 23 types of Amazon products, where each product consists of three different binary classification tasks. Following Geng et al. ( 2019), we select 12 tasks from 4 domains (Books, DVD, Electronics, Kitchen) for meta-testing tasks, and the support sets of these tasks are fixed (Yu et al., 2018).\nBaselines. We compare our methods with the following baselines: Fine-tune: We fine-tune a pre-trained BERT on the support set of metatesting tasks (non-meta-learning method) as in Appendix B.2. We choose five metric-based meta-learning baselines: Matching Net (Vinyals et al., 2016), Prototypical Net (Snell et al., 2017), Proto ++, (Ren et al., 2018), Relation Net (Sung et al., 2018), and Induction Net (Geng et al., 2019). We apply an optimization-based baseline (MAML) (Finn et al., 2017) to the base model, and implement some approaches tackling the memorization overfitting problem based on MAML: MR-MAML (Yin et al., 2020), MetaMix, (Yao et al., 2021) and Meta-Aug (Rajendran et al., 2020).\nOverall Performance. Table 2 shows the performance measured by the mean accuracy of meta-testing tasks. Our model, MemIML outperforms all competing approaches including nonmeta-learning, metric-based meta-learning, and optimization-based meta-learning methods. Particularly, our model surpasses the current solutions to the memorization overfitting problem (MR-MAML, Meta-Aug, MetaMix), indicating that our method is more effective compared to regularization and textual augmentation.\n\n5.3 Memorization Overfitting Analysis\nIn Figure 2, the gaps of the losses on query sets between pre-update \u03b8 (before training on support sets)  and post-update \u03b8 i (after training on support sets) indicate the memorization overfitting problem. The gap between sky-blue and blue curves measures the memorization overfitting of meta-training (the gap between pink and red curves measures metatesting). Small loss gaps indicate a severe memorization overfitting where support sets are almost useless for task adaptation. Those loss gaps between \u03b8 and \u03b8 i collapse in MAML and MR-MAML after about 3000 steps. This indicates that the postupdate \u03b8 i barely benefits from the support set, and thus the memorization overfitting issue is severe.\nIn Figure 2 (c), MemIML has large gaps between \u03b8 and \u03b8 i , implying that \u03b8 i better leverages support sets when adapting to new tasks and thus alleviates the memorization overfitting issue.\n\n5.4 Ablation Studies\nIn Table 3, we conduct ablation studies to verify the effectiveness of each component. Removing Similarity-Search means the memory reading operation randomly outputs memory slots instead of searching for similar memory slots. This variant underperforms MemIML, indicating that similar samples stored in the memory provide more useful information to improve the model performance.\nRemoving the value predictor means directly using the memory output without a learnable network. Its results are not too bad, indicating that the memory module helps to mitigate the memorization overfitting problem. However, this usage simply aggre-gates the support set information into the query set, which is not as precise as learning the information required by the query set itself. Therefore, it is still inferior to our model. Removing Local adaptation means we only use the global value predictor to estimate the memory output. It is crucial to the value predictor since removing it from the value predictor results in an even worse performance than removing the value predictor. Besides, the significant drop in task consistency (C-score) shows that local adaptation contributes a lot to making the model adaptive to specific tasks, as it learns to adapt to each query-set sample.\n\n5.5 Analysis of Memory Operations\nMemory Size. In Table 4 and 5 Number of Neighbors. We also investigate the effects of different numbers of neighbors for the model performance in Table 4 and Table 5. In both datasets, the model performs better with a larger number of neighbors. However, when the number of neighbors is too large, the model retrieves some dissimilar slots from the memory module. These dissimilar slots bring much noise, which makes the predictions of query samples inaccurate.\n\n5.6 Case Study\nWe present two generated cases in personalized dialog in Table. 6. Base Model, Fine-tune, and MAML generate general responses with little useful information or responses that are not consistent with the personality of personas. MR-MAML generates irrelevant responses to the dialogue context. Our model not only responds coherently to the dialog history but also caters to the persona descriptions of each user.\n\n6 Conclusion\nIn this paper, we tackle the memorization overfitting problem of meta-learning for text classification and generation applications. We propose MemIML to enhance the dependence of the model on the support sets for task adaptation. MemIML introduces a memory module storing the information of support sets, and propose an imitation module to better leverage the support set information by imitating the behaviors of the memory. Both empirical and theoretical results demonstrate that our method MemIML effectively alleviates the memorization overfitting problem.\n\n7 Ethical Considerations\nThe\n\nA Validity of Memory Imitation Strategy\nProof of inequality in Eqn. 6. We check the validity of memory imitation by examining whether the criterion in Section 4.4 is met. We check the increase of mutual information between predictions of query sets with the provided support-set information after augmented with the memory information M.I( \u0176 q ; [D s , M]|\u03b8, X q ) \u2212 I( \u0176 q ; D s |\u03b8, X q ) = H( \u0176 q |\u03b8, X q ) \u2212 H( \u0176 q |D s , M, \u03b8, X q ) \u2212 H( \u0176 q |\u03b8, X q ) + H( \u0176 q |D s , \u03b8, X q ) = \u2212 H( \u0176 q |X q , X s , Y s , M, \u03b8) + H( \u0176 q |X q , X s , Y s , \u03b8).\nFor short, we use notation Z = (X q , X s , Y s , \u03b8) to denote a set of variables. Then we can rewrite (7) as\u2212 H( \u0176 q |Z, M) + H( \u0176 q |Z) = E \u0176 q ,Z,M log p( \u0176 q |Z, M) \u2212 E \u0176 q ,Z log p( \u0176 q |Z) .\nNote that trivially, we have E M [1] = 1, so we getE \u0176 q ,Z p( \u0176 q |Z) = E \u0176 q ,Z,M p( \u0176 q |Z)\nsince p( \u0176 q , Z) does not rely on the variable M. Hence, we can just write E \u0176 q ,Z,M as E for short.\nThen the equation (7) will become to E[log p( \u0176 q |Z, M)] \u2212 E[log p( \u0176 q |Z)]\n= E[log p( \u0176 q |M, Z) p( \u0176 q |Z) ] = \u0176 q ,M,Z p(Z)p( \u0176 q , M|Z) log p( \u0176 q , M|Z)p( \u0176 q |Z)p(M|Z) = E Z [KL(p(M, \u0176 q |Z)||p( \u0176 q |Z)p(M|Z))]\n> 0\nwhere the last inequality holds due to \u0176 q is dependent on M.\nWe also investigate that memory imitation improves the learning of model initialization via another criterion I(\u03b8; [D q , M]|D q ) > 0 following Yao et al. (2021). This criterion guarantees that the additional memory knowledge contributes to updating the initialization in the outer loop. Since all the meta-training tasks satisfy this criterion, the generalization ability of the model initialization improves.\nProof. I(\u03b8; [D q , M]|D q ) = H(\u03b8|D q ) \u2212 H(\u03b8|D q , M) = E[\u2212 log P (\u03b8|D q )] + E[log p([\u03b8|D q , M)])] = E[log p(\u03b8|D q , M) p(\u03b8|D q ) ] > 0\n\nB Experimental Details\nB.1 Personalized Dialogue Generation Experimental Setup. We implement our model based on the transformer (Dehghani et al., 2018; Vaswani et al., 2017) with pre-trained Glove embedding (Pennington et al., 2014) following (Madotto et al., 2019). The hidden dimensions of the LSTM unit are set to 1024. We set the number of neighbors N = 10 and the number of local adaptation steps L = 20. We follow all other hyperparameter settings in Madotto et al. (2019) : we use SGD for the inner loop training and Adam for the outer loop update with learning rates 0.01 and 0.0003, respectively. We set batch size as 16 and use beam search with beam size 5.\nHuman Evaluation We conduct human evaluation following Song et al. (2020) considering two aspects Quality and Consistency where five welleducated volunteers annotate 250 generated responses for each model. The annotators score each response from two aspects: Quality and Consistency in a 3-point scale: 2 for good, 1 for fair, and 0 for bad. Quality measures coherence, fluency, and informativeness. Consistency measures the task consistency between the generated responses and the person's persona description.\n\nB.2 Multi-domain Sentiment Classification\nExperimental Setup. We utilize a BERT (Devlin et al., 2019) as the encoder. We fine-tune the off-the-shelf pre-trained BERT on the masked language modeling task following (Dopierre et al., 2021) as it greatly improves embeddings' quality (Sun et al., 2019). The fine-tuned BERT is then used as the initialization for all few-shot models. We use Adam (Kingma and Ba, 2015) optimizer for both inner and outer loop update with learning rate 2e \u22125 and 1e \u22125 respectively, and we set \u03b2 = 0.2 in Eqn. 5, the number of neighbors N = 20 and the number of local adaptation steps L = 5.\n\nC Effectiveness of the Interpolation\nTo measure whether MemIML improves the learned model initialization, we add an experiment that does not incorporate the memory module during meta-testing (i.e., \u03b2 = 1 in Eq. 5) for the multi-domain sentiment classification task.\n\nD Diversity-selection Criterion\n\n\nFootnotes:\n2: (Kj, K h ) = arccos( K j \u2022K h K j 2 K h 2 )\n\nReferences:\n\n- Qi Cai, Yingwei Pan, Ting Yao, Chenggang Yan, and Tao Mei. 2018. Memory matching networks for one- shot image recognition. In Proceedings of the IEEE conference on computer vision and pattern recogni- tion, pages 4080-4088.- Jiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal, and Diyi Yang. 2021. An empirical survey of data augmentation for limited data learning in nlp. arXiv e-prints, pages arXiv-2106.\n\n- Mostafa Dehghani, Stephan Gouws, Oriol Vinyals, Jakob Uszkoreit, and Lukasz Kaiser. 2018. Univer- sal transformers. In International Conference on Learning Representations.\n\n- Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understand- ing. In NAACL-HLT (1).\n\n- Thomas Dopierre, Christophe Gravier, and Wilfried Logerais. 2021. A neural few-shot text classifica- tion reality check. In Proceedings of the 16th Con- ference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 935-943.\n\n- Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In International Conference on Ma- chine Learning, pages 1126-1135. PMLR.\n\n- Ruiying Geng, Binhua Li, Yongbin Li, Xiaodan Zhu, Ping Jian, and Jian Sun. 2019. Induction networks for few-shot text classification. In Proceedings of the 2019 Conference on Empirical Methods in Nat- ural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3904-3913.\n\n- Jiatao Gu, Yong Wang, Yun Chen, Victor OK Li, and Kyunghyun Cho. 2018. Meta-learning for low- resource neural machine translation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3622-3631.\n\n- Douglas M Hawkins. 2004. The problem of overfitting. Journal of chemical information and computer sci- ences, 44(1):1-12.\n\n- Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural Computation, 9(8):1735-1780.\n\n- Nithin Holla, Pushkar Mishra, Helen Yannakoudakis, and Ekaterina Shutova. 2020. Learning to learn to disambiguate: Meta-learning for few-shot word sense disambiguation. In Findings of the Associa- tion for Computational Linguistics: EMNLP 2020, pages 4517-4533.\n\n- Timothy M Hospedales, Antreas Antoniou, Paul Mi- caelli, and Amos J. Storkey. 2021. Meta-learning in neural networks: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, pages 1- 1.\n\n- \u0141ukasz Kaiser, Ofir Nachum, Aurko Roy, and Samy Bengio. 2017. Learning to remember rare events. arXiv preprint arXiv:1703.03129.\n\n- Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In ICLR (Poster).\n\n- Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and William B Dolan. 2016. A diversity-promoting objective function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, pages 110-119.\n\n- Rumeng Li, Xun Wang, and Hong Yu. 2020. Metamt, a meta learning method leveraging multiple domain data for low resource machine translation. In Pro- ceedings of the AAAI Conference on Artificial Intel- ligence, volume 34, pages 8245-8252.\n\n- Chin-Yew Lin. 2004. ROUGE: A package for auto- matic evaluation of summaries. In Text Summariza- tion Branches Out, pages 74-81, Barcelona, Spain. Association for Computational Linguistics.\n\n- Andrea Madotto, Zhaojiang Lin, Chien-Sheng Wu, and Pascale Fung. 2019. Personalizing dialogue agents via meta-learning. In Proceedings of the 57th An- nual Meeting of the Association for Computational Linguistics, pages 5454-5459.\n\n- Fei Mi, Minlie Huang, Jiyong Zhang, and Boi Faltings. 2019. Meta-learning for low-resource natural lan- guage generation in task-oriented dialogue systems. arXiv preprint arXiv:1905.05644.\n\n- Tsendsuren Munkhdalai, Alessandro Sordoni, TONG WANG, and Adam Trischler. 2019. Metalearned neural memory. Advances in Neural Information Processing Systems, 32:13331-13342.\n\n- Tsendsuren Munkhdalai and Hong Yu. 2017. Meta networks. In International Conference on Machine Learning, pages 2554-2563. PMLR.\n\n- Abiola Obamuyide, Andreas Vlachos, et al. 2019. Meta-learning improves lifelong relation extraction.\n\n- Kishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. Bleu: a method for automatic eval- uation of machine translation. In Proceedings of the 40th annual meeting of the Association for Compu- tational Linguistics, pages 311-318.\n\n- Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word rep- resentation. In Proceedings of the 2014 conference on empirical methods in natural language process- ing (EMNLP), pages 1532-1543.\n\n- Kun Qian and Zhou Yu. 2019. Domain adaptive dialog generation via meta learning. In Proceedings of the 57th Annual Meeting of the Association for Compu- tational Linguistics, pages 2639-2649.\n\n- Janarthanan Rajendran, Alexander Irpan, and Eric Jang. 2020. Meta-learning requires meta-augmentation. Advances in Neural Information Processing Systems, 33:5705-5715.\n\n- Tiago Ramalho and Marta Garnelo. 2018. Adaptive posterior learning: few-shot learning with a surprise- based memory module. In International Conference on Learning Representations.\n\n- Mengye Ren, Eleni Triantafillou, Sachin Ravi, Jake Snell, Kevin Swersky, Joshua B Tenenbaum, Hugo Larochelle, and Richard S Zemel. 2018. Meta- learning for semi-supervised few-shot classification. In International Conference on Learning Represen- tations.\n\n- Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. 2016. Meta- learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850. PMLR.\n\n- Amr Sharaf, Hany Hassan, and Hal Daum\u00e9 III. 2020. Meta-learning for few-shot nmt adaptation. In NGT@ ACL.\n\n- Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for few-shot learning. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 4080-4090.\n\n- Yiping Song, Zequn Liu, Wei Bi, Rui Yan, and Ming Zhang. 2020. Learning to customize model struc- tures for few-shot dialogue generation tasks. In Pro- ceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 5832- 5841.\n\n- Pablo Sprechmann, Siddhant M Jayakumar, Jack W Rae, Alexander Pritzel, Adria Puigdomenech Badia, Benigno Uria, Oriol Vinyals, Demis Hassabis, Raz- van Pascanu, and Charles Blundell. 2018. Memory- based parameter adaptation. In International Con- ference on Learning Representations.\n\n- Chi Sun, Xipeng Qiu, Yige Xu, and Xuanjing Huang. 2019. How to fine-tune bert for text classification? In China National Conference on Chinese Computa- tional Linguistics, pages 194-206. Springer.\n\n- Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip HS Torr, and Timothy M Hospedales. 2018. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1199-1208.\n\n- S. Thrun and L. Pratt. 1998. Learning to Learn: Intro- duction and Overview. Learning to Learn: Introduc- tion and Overview.\n\n- Sebastian Thrun and Lorien Pratt. 2012. Learning to learn. Springer Science & Business Media.\n\n- Zhiliang Tian, Wei Bi, Zihan Zhang, Dongkyu Lee, Yiping Song, and Nevin L Zhang. 2021. Learning from my friends: Few-shot personalized conversa- tion systems via social networks. In Proceedings of the AAAI Conference on Artificial Intelligence, vol- ume 35, pages 13907-13915.\n\n- Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information pro- cessing systems, pages 5998-6008.\n\n- Ramakrishna Vedantam, C. Lawrence Zitnick, and Devi Parikh. 2015. Cider: Consensus-based image description evaluation. In CVPR, pages 4566-4575. IEEE Computer Society.\n\n- Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. 2016. Matching networks for one shot learning. Advances in neural information processing systems, 29:3630-3638.\n\n- Hongru Wang, Zezhong Wang, Gabriel Pui Cheong Fung, and Kam-Fai Wong. 2021. Mcml: A novel memory-based contrastive meta-learning method for few shot slot tagging. arXiv preprint arXiv:2108.11635.\n\n- Yaqing Wang, Quanming Yao, James T. Kwok, and Li- onel M. Ni. 2020. Generalizing from a few exam- ples: A survey on few-shot learning. ACM Comput. Surv., 53(3).\n\n- Pengtao Xie, Yuntian Deng, and Eric Xing. 2015. Di- versifying restricted boltzmann machine for docu- ment modeling. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1315-1324.\n\n- Ming Yan, Hao Zhang, Di Jin, and Joey Tianyi Zhou. 2020. Multi-source meta transfer for low resource multiple-choice question answering. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7331-7341, On- line. Association for Computational Linguistics.\n\n- Huaxiu Yao, Long-Kai Huang, Linjun Zhang, Ying Wei, Li Tian, James Zou, Junzhou Huang, et al. 2021. Improving generalization in meta-learning via task augmentation. In International Conference on Ma- chine Learning, pages 11887-11897. PMLR.\n\n- Mingzhang Yin, George Tucker, Mingyuan Zhou, Sergey Levine, and Chelsea Finn. 2020. Meta- learning without memorization. In International Conference on Learning Representations.\n\n- Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng, Gerald Tesauro, Haoyu Wang, and Bowen Zhou. 2018. Diverse few-shot text clas- sification with multiple metrics. In Proceedings of\n\n", "annotations": {"ReferenceToTable": [{"begin": 24170, "end": 24171, "target": "#tab_1", "idx": 0}, {"begin": 26427, "end": 26428, "target": "#tab_2", "idx": 1}, {"begin": 27844, "end": 27845, "target": "#tab_3", "idx": 2}, {"begin": 29163, "end": 29170, "target": "#tab_5", "idx": 3}, {"begin": 29293, "end": 29306, "target": "#tab_5", "idx": 4}, {"begin": 29681, "end": 29682, "idx": 5}], "SectionMain": [{"begin": 1213, "end": 34517, "idx": 0}], "ReferenceToFormula": [{"begin": 23405, "end": 23409, "idx": 0}, {"begin": 25537, "end": 25541, "idx": 1}], "SectionReference": [{"begin": 34578, "end": 44406, "idx": 0}], "SectionHeader": [{"begin": 0, "end": 1213, "idx": 0}], "Div": [{"begin": 108, "end": 1205, "idx": 0}, {"begin": 1216, "end": 6029, "idx": 1}, {"begin": 6031, "end": 8860, "idx": 2}, {"begin": 8862, "end": 9968, "idx": 3}, {"begin": 9970, "end": 10646, "idx": 4}, {"begin": 10648, "end": 13702, "idx": 5}, {"begin": 13704, "end": 14820, "idx": 6}, {"begin": 14822, "end": 15391, "idx": 7}, {"begin": 15393, "end": 17855, "idx": 8}, {"begin": 17857, "end": 20098, "idx": 9}, {"begin": 20100, "end": 21316, "idx": 10}, {"begin": 21318, "end": 22921, "idx": 11}, {"begin": 22923, "end": 23474, "idx": 12}, {"begin": 23476, "end": 25038, "idx": 13}, {"begin": 25040, "end": 26884, "idx": 14}, {"begin": 26886, "end": 27812, "idx": 15}, {"begin": 27814, "end": 29105, "idx": 16}, {"begin": 29107, "end": 29602, "idx": 17}, {"begin": 29604, "end": 30029, "idx": 18}, {"begin": 30031, "end": 30604, "idx": 19}, {"begin": 30606, "end": 30634, "idx": 20}, {"begin": 30636, "end": 32415, "idx": 21}, {"begin": 32417, "end": 33596, "idx": 22}, {"begin": 33598, "end": 34216, "idx": 23}, {"begin": 34218, "end": 34483, "idx": 24}, {"begin": 34485, "end": 34517, "idx": 25}], "Head": [{"begin": 1216, "end": 1230, "n": "1", "idx": 0}, {"begin": 6031, "end": 6045, "n": "2", "idx": 1}, {"begin": 8862, "end": 8877, "n": "3", "idx": 2}, {"begin": 9970, "end": 9983, "n": "4", "idx": 3}, {"begin": 10648, "end": 10665, "n": "4.1", "idx": 4}, {"begin": 13704, "end": 13724, "n": "4.2", "idx": 5}, {"begin": 14822, "end": 14843, "n": "4.2.1", "idx": 6}, {"begin": 15393, "end": 15430, "n": "4.2.2", "idx": 7}, {"begin": 17857, "end": 17887, "n": "4.3", "idx": 8}, {"begin": 20100, "end": 20124, "n": "4.4", "idx": 9}, {"begin": 21318, "end": 21359, "n": "4.5", "idx": 10}, {"begin": 22923, "end": 22949, "n": "5", "idx": 11}, {"begin": 23476, "end": 23492, "n": "5.1", "idx": 12}, {"begin": 25040, "end": 25081, "n": "5.2", "idx": 13}, {"begin": 26886, "end": 26923, "n": "5.3", "idx": 14}, {"begin": 27814, "end": 27834, "n": "5.4", "idx": 15}, {"begin": 29107, "end": 29140, "n": "5.5", "idx": 16}, {"begin": 29604, "end": 29618, "n": "5.6", "idx": 17}, {"begin": 30031, "end": 30043, "n": "6", "idx": 18}, {"begin": 30606, "end": 30630, "n": "7", "idx": 19}, {"begin": 30636, "end": 30675, "idx": 20}, {"begin": 32417, "end": 32439, "idx": 21}, {"begin": 33598, "end": 33639, "idx": 22}, {"begin": 34218, "end": 34254, "idx": 23}, {"begin": 34485, "end": 34516, "idx": 24}], "Paragraph": [{"begin": 108, "end": 1205, "idx": 0}, {"begin": 1231, "end": 1784, "idx": 1}, {"begin": 1785, "end": 2552, "idx": 2}, {"begin": 2553, "end": 3530, "idx": 3}, {"begin": 3531, "end": 4366, "idx": 4}, {"begin": 4367, "end": 5294, "idx": 5}, {"begin": 5295, "end": 5993, "idx": 6}, {"begin": 5994, "end": 6029, "idx": 7}, {"begin": 6046, "end": 7146, "idx": 8}, {"begin": 7147, "end": 8025, "idx": 9}, {"begin": 8026, "end": 8064, "idx": 10}, {"begin": 8065, "end": 8860, "idx": 11}, {"begin": 8878, "end": 9148, "idx": 12}, {"begin": 9234, "end": 9610, "idx": 13}, {"begin": 9714, "end": 9968, "idx": 14}, {"begin": 9984, "end": 10421, "idx": 15}, {"begin": 10422, "end": 10646, "idx": 16}, {"begin": 10666, "end": 11495, "idx": 17}, {"begin": 11496, "end": 12474, "idx": 18}, {"begin": 12475, "end": 13107, "idx": 19}, {"begin": 13108, "end": 13702, "idx": 20}, {"begin": 13725, "end": 14417, "idx": 21}, {"begin": 14418, "end": 14820, "idx": 22}, {"begin": 14844, "end": 15084, "idx": 23}, {"begin": 15085, "end": 15391, "idx": 24}, {"begin": 15431, "end": 15745, "idx": 25}, {"begin": 15746, "end": 16146, "idx": 26}, {"begin": 16147, "end": 16429, "idx": 27}, {"begin": 16430, "end": 16878, "idx": 28}, {"begin": 16990, "end": 17409, "idx": 29}, {"begin": 17435, "end": 17855, "idx": 30}, {"begin": 17888, "end": 18294, "idx": 31}, {"begin": 18295, "end": 18958, "idx": 32}, {"begin": 18959, "end": 19303, "idx": 33}, {"begin": 19339, "end": 19594, "idx": 34}, {"begin": 19733, "end": 19769, "idx": 35}, {"begin": 19770, "end": 19817, "idx": 36}, {"begin": 19818, "end": 19864, "idx": 37}, {"begin": 19865, "end": 19868, "idx": 38}, {"begin": 19869, "end": 19913, "idx": 39}, {"begin": 19914, "end": 19966, "idx": 40}, {"begin": 19967, "end": 19999, "idx": 41}, {"begin": 20000, "end": 20011, "idx": 42}, {"begin": 20012, "end": 20019, "idx": 43}, {"begin": 20085, "end": 20098, "idx": 44}, {"begin": 20125, "end": 20646, "idx": 45}, {"begin": 20647, "end": 21003, "idx": 46}, {"begin": 21074, "end": 21316, "idx": 47}, {"begin": 21360, "end": 22280, "idx": 48}, {"begin": 22334, "end": 22921, "idx": 49}, {"begin": 22950, "end": 23474, "idx": 50}, {"begin": 23493, "end": 23541, "idx": 51}, {"begin": 23542, "end": 24045, "idx": 52}, {"begin": 24046, "end": 24130, "idx": 53}, {"begin": 24131, "end": 24172, "idx": 54}, {"begin": 24173, "end": 25038, "idx": 55}, {"begin": 25082, "end": 25322, "idx": 56}, {"begin": 25323, "end": 25701, "idx": 57}, {"begin": 25702, "end": 26399, "idx": 58}, {"begin": 26400, "end": 26884, "idx": 59}, {"begin": 26924, "end": 27622, "idx": 60}, {"begin": 27623, "end": 27812, "idx": 61}, {"begin": 27835, "end": 28214, "idx": 62}, {"begin": 28215, "end": 29105, "idx": 63}, {"begin": 29141, "end": 29602, "idx": 64}, {"begin": 29619, "end": 30029, "idx": 65}, {"begin": 30044, "end": 30604, "idx": 66}, {"begin": 30631, "end": 30634, "idx": 67}, {"begin": 30676, "end": 30973, "idx": 68}, {"begin": 31185, "end": 31294, "idx": 69}, {"begin": 31382, "end": 31433, "idx": 70}, {"begin": 31477, "end": 31579, "idx": 71}, {"begin": 31580, "end": 31657, "idx": 72}, {"begin": 31658, "end": 31739, "idx": 73}, {"begin": 31799, "end": 31802, "idx": 74}, {"begin": 31803, "end": 31864, "idx": 75}, {"begin": 31865, "end": 32276, "idx": 76}, {"begin": 32277, "end": 32415, "idx": 77}, {"begin": 32440, "end": 33084, "idx": 78}, {"begin": 33085, "end": 33596, "idx": 79}, {"begin": 33640, "end": 34216, "idx": 80}, {"begin": 34255, "end": 34483, "idx": 81}], "ReferenceToBib": [{"begin": 1417, "end": 1440, "target": "#b36", "idx": 0}, {"begin": 1648, "end": 1665, "target": "#b47", "idx": 1}, {"begin": 1666, "end": 1684, "target": "#b6", "idx": 2}, {"begin": 1722, "end": 1744, "target": "#b17", "idx": 3}, {"begin": 1745, "end": 1763, "target": "#b31", "idx": 4}, {"begin": 1764, "end": 1783, "idx": 5}, {"begin": 1826, "end": 1851, "target": "#b11", "idx": 6}, {"begin": 1967, "end": 1989, "target": "#b17", "idx": 7}, {"begin": 1990, "end": 2008, "target": "#b24", "idx": 8}, {"begin": 2009, "end": 2025, "target": "#b15", "idx": 9}, {"begin": 2026, "end": 2042, "target": "#b18", "idx": 10}, {"begin": 2681, "end": 2699, "target": "#b46", "idx": 11}, {"begin": 2700, "end": 2723, "target": "#b25", "idx": 12}, {"begin": 3296, "end": 3320, "target": "#b25", "idx": 13}, {"begin": 3831, "end": 3846, "target": "#b8", "idx": 14}, {"begin": 3963, "end": 3986, "target": "#b25", "idx": 15}, {"begin": 4196, "end": 4214, "target": "#b45", "idx": 16}, {"begin": 4346, "end": 4365, "target": "#b1", "idx": 17}, {"begin": 6164, "end": 6187, "target": "#b35", "idx": 18}, {"begin": 6188, "end": 6212, "target": "#b11", "idx": 19}, {"begin": 6300, "end": 6322, "target": "#b28", "idx": 20}, {"begin": 6323, "end": 6346, "target": "#b21", "idx": 21}, {"begin": 6442, "end": 6464, "target": "#b40", "idx": 22}, {"begin": 6465, "end": 6484, "target": "#b30", "idx": 23}, {"begin": 6485, "end": 6503, "target": "#b6", "idx": 24}, {"begin": 6632, "end": 6651, "target": "#b5", "idx": 25}, {"begin": 6652, "end": 6668, "target": "#b18", "idx": 26}, {"begin": 6917, "end": 6939, "target": "#b17", "idx": 27}, {"begin": 6940, "end": 6958, "target": "#b31", "idx": 28}, {"begin": 6959, "end": 6977, "target": "#b37", "idx": 29}, {"begin": 7011, "end": 7028, "target": "#b7", "idx": 30}, {"begin": 7029, "end": 7049, "target": "#b29", "idx": 31}, {"begin": 7073, "end": 7091, "target": "#b44", "idx": 32}, {"begin": 7115, "end": 7134, "target": "#b41", "idx": 33}, {"begin": 7254, "end": 7271, "target": "#b46", "idx": 34}, {"begin": 7405, "end": 7428, "target": "#b25", "idx": 35}, {"begin": 7577, "end": 7594, "target": "#b45", "idx": 36}, {"begin": 7864, "end": 7883, "target": "#b1", "idx": 37}, {"begin": 8130, "end": 8149, "target": "#b6", "idx": 38}, {"begin": 8150, "end": 8171, "target": "#b28", "idx": 39}, {"begin": 8172, "end": 8196, "target": "#b19", "idx": 40}, {"begin": 8265, "end": 8292, "target": "#b26", "idx": 41}, {"begin": 8333, "end": 8358, "target": "#b20", "idx": 42}, {"begin": 8359, "end": 8376, "target": "#b0", "idx": 43}, {"begin": 8377, "end": 8395, "target": "#b42", "idx": 44}, {"begin": 8480, "end": 8501, "target": "#b12", "idx": 45}, {"begin": 8502, "end": 8521, "target": "#b10", "idx": 46}, {"begin": 8522, "end": 8541, "idx": 47}, {"begin": 8544, "end": 8562, "target": "#b6", "idx": 48}, {"begin": 8671, "end": 8695, "target": "#b19", "idx": 49}, {"begin": 8768, "end": 8786, "target": "#b41", "idx": 50}, {"begin": 8933, "end": 8952, "target": "#b5", "idx": 51}, {"begin": 11596, "end": 11617, "target": "#b3", "idx": 52}, {"begin": 12325, "end": 12343, "target": "#b43", "idx": 53}, {"begin": 16530, "end": 16555, "target": "#b32", "idx": 54}, {"begin": 18363, "end": 18385, "target": "#b38", "idx": 55}, {"begin": 18685, "end": 18719, "target": "#b9", "idx": 56}, {"begin": 19023, "end": 19044, "target": "#b3", "idx": 57}, {"begin": 20236, "end": 20253, "target": "#b46", "idx": 58}, {"begin": 20543, "end": 20561, "target": "#b46", "idx": 59}, {"begin": 20681, "end": 20699, "target": "#b45", "idx": 60}, {"begin": 23341, "end": 23363, "target": "#b17", "idx": 61}, {"begin": 23560, "end": 23582, "target": "#b22", "idx": 62}, {"begin": 23582, "end": 23614, "idx": 63}, {"begin": 23626, "end": 23637, "target": "#b16", "idx": 64}, {"begin": 23784, "end": 23801, "target": "#b14", "idx": 65}, {"begin": 23886, "end": 23908, "target": "#b17", "idx": 66}, {"begin": 25145, "end": 25162, "target": "#b47", "idx": 67}, {"begin": 25201, "end": 25220, "target": "#b6", "idx": 68}, {"begin": 25358, "end": 25375, "target": "#b47", "idx": 69}, {"begin": 25683, "end": 25700, "target": "#b47", "idx": 70}, {"begin": 25962, "end": 25984, "target": "#b40", "idx": 71}, {"begin": 26003, "end": 26023, "target": "#b30", "idx": 72}, {"begin": 26035, "end": 26053, "target": "#b27", "idx": 73}, {"begin": 26068, "end": 26087, "target": "#b34", "idx": 74}, {"begin": 26107, "end": 26126, "target": "#b6", "idx": 75}, {"begin": 26175, "end": 26194, "target": "#b5", "idx": 76}, {"begin": 26313, "end": 26331, "target": "#b46", "idx": 77}, {"begin": 26342, "end": 26360, "target": "#b45", "idx": 78}, {"begin": 26374, "end": 26398, "target": "#b25", "idx": 79}, {"begin": 32010, "end": 32027, "target": "#b45", "idx": 80}, {"begin": 32545, "end": 32568, "target": "#b2", "idx": 81}, {"begin": 32569, "end": 32590, "target": "#b38", "idx": 82}, {"begin": 32624, "end": 32649, "target": "#b23", "idx": 83}, {"begin": 32660, "end": 32682, "target": "#b17", "idx": 84}, {"begin": 32874, "end": 32895, "target": "#b17", "idx": 85}, {"begin": 33140, "end": 33158, "target": "#b31", "idx": 86}, {"begin": 33678, "end": 33699, "target": "#b3", "idx": 87}, {"begin": 33811, "end": 33834, "target": "#b4", "idx": 88}, {"begin": 33878, "end": 33896, "target": "#b33", "idx": 89}], "ReferenceString": [{"begin": 34593, "end": 34816, "id": "b0", "idx": 0}, {"begin": 34818, "end": 34998, "id": "b1", "idx": 1}, {"begin": 35002, "end": 35174, "id": "b2", "idx": 2}, {"begin": 35178, "end": 35351, "id": "b3", "idx": 3}, {"begin": 35355, "end": 35617, "id": "b4", "idx": 4}, {"begin": 35621, "end": 35815, "id": "b5", "idx": 5}, {"begin": 35819, "end": 36151, "id": "b6", "idx": 6}, {"begin": 36155, "end": 36393, "id": "b7", "idx": 7}, {"begin": 36397, "end": 36518, "id": "b8", "idx": 8}, {"begin": 36522, "end": 36627, "id": "b9", "idx": 9}, {"begin": 36631, "end": 36892, "id": "b10", "idx": 10}, {"begin": 36896, "end": 37099, "id": "b11", "idx": 11}, {"begin": 37103, "end": 37231, "id": "b12", "idx": 12}, {"begin": 37235, "end": 37334, "id": "b13", "idx": 13}, {"begin": 37338, "end": 37656, "id": "b14", "idx": 14}, {"begin": 37660, "end": 37898, "id": "b15", "idx": 15}, {"begin": 37902, "end": 38091, "id": "b16", "idx": 16}, {"begin": 38095, "end": 38325, "id": "b17", "idx": 17}, {"begin": 38329, "end": 38517, "id": "b18", "idx": 18}, {"begin": 38521, "end": 38694, "id": "b19", "idx": 19}, {"begin": 38698, "end": 38825, "id": "b20", "idx": 20}, {"begin": 38829, "end": 38929, "id": "b21", "idx": 21}, {"begin": 38933, "end": 39175, "id": "b22", "idx": 22}, {"begin": 39179, "end": 39414, "id": "b23", "idx": 23}, {"begin": 39418, "end": 39609, "id": "b24", "idx": 24}, {"begin": 39613, "end": 39780, "id": "b25", "idx": 25}, {"begin": 39784, "end": 39964, "id": "b26", "idx": 26}, {"begin": 39968, "end": 40223, "id": "b27", "idx": 27}, {"begin": 40227, "end": 40446, "id": "b28", "idx": 28}, {"begin": 40450, "end": 40555, "id": "b29", "idx": 29}, {"begin": 40559, "end": 40766, "id": "b30", "idx": 30}, {"begin": 40770, "end": 41027, "id": "b31", "idx": 31}, {"begin": 41031, "end": 41313, "id": "b32", "idx": 32}, {"begin": 41317, "end": 41513, "id": "b33", "idx": 33}, {"begin": 41517, "end": 41771, "id": "b34", "idx": 34}, {"begin": 41775, "end": 41899, "id": "b35", "idx": 35}, {"begin": 41903, "end": 41996, "id": "b36", "idx": 36}, {"begin": 42000, "end": 42276, "id": "b37", "idx": 37}, {"begin": 42280, "end": 42510, "id": "b38", "idx": 38}, {"begin": 42514, "end": 42681, "id": "b39", "idx": 39}, {"begin": 42685, "end": 42870, "id": "b40", "idx": 40}, {"begin": 42874, "end": 43069, "id": "b41", "idx": 41}, {"begin": 43073, "end": 43233, "id": "b42", "idx": 42}, {"begin": 43237, "end": 43473, "id": "b43", "idx": 43}, {"begin": 43477, "end": 43775, "id": "b44", "idx": 44}, {"begin": 43779, "end": 44019, "id": "b45", "idx": 45}, {"begin": 44023, "end": 44200, "id": "b46", "idx": 46}, {"begin": 44204, "end": 44404, "id": "b47", "idx": 47}], "Sentence": [{"begin": 108, "end": 240, "idx": 0}, {"begin": 241, "end": 409, "idx": 1}, {"begin": 410, "end": 601, "idx": 2}, {"begin": 602, "end": 756, "idx": 3}, {"begin": 757, "end": 989, "idx": 4}, {"begin": 990, "end": 1205, "idx": 5}, {"begin": 1231, "end": 1388, "idx": 6}, {"begin": 1389, "end": 1522, "idx": 7}, {"begin": 1523, "end": 1784, "idx": 8}, {"begin": 1785, "end": 2097, "idx": 9}, {"begin": 2098, "end": 2291, "idx": 10}, {"begin": 2292, "end": 2443, "idx": 11}, {"begin": 2444, "end": 2552, "idx": 12}, {"begin": 2553, "end": 2893, "idx": 13}, {"begin": 2894, "end": 3132, "idx": 14}, {"begin": 3133, "end": 3321, "idx": 15}, {"begin": 3322, "end": 3530, "idx": 16}, {"begin": 3531, "end": 3655, "idx": 17}, {"begin": 3656, "end": 3847, "idx": 18}, {"begin": 3848, "end": 3956, "idx": 19}, {"begin": 3957, "end": 4077, "idx": 20}, {"begin": 4078, "end": 4215, "idx": 21}, {"begin": 4216, "end": 4366, "idx": 22}, {"begin": 4367, "end": 4592, "idx": 23}, {"begin": 4593, "end": 4800, "idx": 24}, {"begin": 4801, "end": 5048, "idx": 25}, {"begin": 5049, "end": 5294, "idx": 26}, {"begin": 5295, "end": 5498, "idx": 27}, {"begin": 5499, "end": 5590, "idx": 28}, {"begin": 5591, "end": 5678, "idx": 29}, {"begin": 5679, "end": 5793, "idx": 30}, {"begin": 5794, "end": 5993, "idx": 31}, {"begin": 5994, "end": 6029, "idx": 32}, {"begin": 6046, "end": 6060, "idx": 33}, {"begin": 6061, "end": 6213, "idx": 34}, {"begin": 6214, "end": 6765, "idx": 35}, {"begin": 6766, "end": 7146, "idx": 36}, {"begin": 7147, "end": 7189, "idx": 37}, {"begin": 7190, "end": 7252, "idx": 38}, {"begin": 7253, "end": 7403, "idx": 39}, {"begin": 7404, "end": 7575, "idx": 40}, {"begin": 7576, "end": 7697, "idx": 41}, {"begin": 7698, "end": 7884, "idx": 42}, {"begin": 7885, "end": 8025, "idx": 43}, {"begin": 8026, "end": 8064, "idx": 44}, {"begin": 8065, "end": 8197, "idx": 45}, {"begin": 8198, "end": 8396, "idx": 46}, {"begin": 8397, "end": 8542, "idx": 47}, {"begin": 8543, "end": 8669, "idx": 48}, {"begin": 8670, "end": 8766, "idx": 49}, {"begin": 8767, "end": 8860, "idx": 50}, {"begin": 8878, "end": 8953, "idx": 51}, {"begin": 8954, "end": 9105, "idx": 52}, {"begin": 9106, "end": 9148, "idx": 53}, {"begin": 9234, "end": 9310, "idx": 54}, {"begin": 9311, "end": 9477, "idx": 55}, {"begin": 9478, "end": 9610, "idx": 56}, {"begin": 9714, "end": 9754, "idx": 57}, {"begin": 9755, "end": 9968, "idx": 58}, {"begin": 9984, "end": 10155, "idx": 59}, {"begin": 10156, "end": 10281, "idx": 60}, {"begin": 10282, "end": 10421, "idx": 61}, {"begin": 10422, "end": 10609, "idx": 62}, {"begin": 10610, "end": 10646, "idx": 63}, {"begin": 10666, "end": 10755, "idx": 64}, {"begin": 10756, "end": 10904, "idx": 65}, {"begin": 10905, "end": 11020, "idx": 66}, {"begin": 11021, "end": 11131, "idx": 67}, {"begin": 11132, "end": 11304, "idx": 68}, {"begin": 11305, "end": 11435, "idx": 69}, {"begin": 11436, "end": 11495, "idx": 70}, {"begin": 11496, "end": 11542, "idx": 71}, {"begin": 11543, "end": 11637, "idx": 72}, {"begin": 11638, "end": 11797, "idx": 73}, {"begin": 11798, "end": 11827, "idx": 74}, {"begin": 11828, "end": 11914, "idx": 75}, {"begin": 11915, "end": 12011, "idx": 76}, {"begin": 12012, "end": 12095, "idx": 77}, {"begin": 12096, "end": 12139, "idx": 78}, {"begin": 12140, "end": 12249, "idx": 79}, {"begin": 12250, "end": 12413, "idx": 80}, {"begin": 12414, "end": 12474, "idx": 81}, {"begin": 12475, "end": 12577, "idx": 82}, {"begin": 12578, "end": 12636, "idx": 83}, {"begin": 12637, "end": 12867, "idx": 84}, {"begin": 12868, "end": 12969, "idx": 85}, {"begin": 12970, "end": 13107, "idx": 86}, {"begin": 13108, "end": 13184, "idx": 87}, {"begin": 13185, "end": 13345, "idx": 88}, {"begin": 13346, "end": 13499, "idx": 89}, {"begin": 13500, "end": 13612, "idx": 90}, {"begin": 13613, "end": 13702, "idx": 91}, {"begin": 13725, "end": 13953, "idx": 92}, {"begin": 13954, "end": 14136, "idx": 93}, {"begin": 14137, "end": 14250, "idx": 94}, {"begin": 14251, "end": 14292, "idx": 95}, {"begin": 14293, "end": 14417, "idx": 96}, {"begin": 14418, "end": 14647, "idx": 97}, {"begin": 14648, "end": 14820, "idx": 98}, {"begin": 14844, "end": 14966, "idx": 99}, {"begin": 14967, "end": 14971, "idx": 100}, {"begin": 14972, "end": 15084, "idx": 101}, {"begin": 15085, "end": 15185, "idx": 102}, {"begin": 15186, "end": 15282, "idx": 103}, {"begin": 15283, "end": 15391, "idx": 104}, {"begin": 15431, "end": 15745, "idx": 105}, {"begin": 15746, "end": 15870, "idx": 106}, {"begin": 15871, "end": 15964, "idx": 107}, {"begin": 15965, "end": 16146, "idx": 108}, {"begin": 16147, "end": 16167, "idx": 109}, {"begin": 16168, "end": 16356, "idx": 110}, {"begin": 16357, "end": 16429, "idx": 111}, {"begin": 16430, "end": 16447, "idx": 112}, {"begin": 16448, "end": 16677, "idx": 113}, {"begin": 16678, "end": 16733, "idx": 114}, {"begin": 16734, "end": 16878, "idx": 115}, {"begin": 16990, "end": 17104, "idx": 116}, {"begin": 17105, "end": 17214, "idx": 117}, {"begin": 17215, "end": 17332, "idx": 118}, {"begin": 17333, "end": 17409, "idx": 119}, {"begin": 17435, "end": 17549, "idx": 120}, {"begin": 17550, "end": 17708, "idx": 121}, {"begin": 17709, "end": 17788, "idx": 122}, {"begin": 17789, "end": 17855, "idx": 123}, {"begin": 17888, "end": 18058, "idx": 124}, {"begin": 18059, "end": 18289, "idx": 125}, {"begin": 18290, "end": 18294, "idx": 126}, {"begin": 18295, "end": 18328, "idx": 127}, {"begin": 18329, "end": 18425, "idx": 128}, {"begin": 18426, "end": 18720, "idx": 129}, {"begin": 18721, "end": 18764, "idx": 130}, {"begin": 18765, "end": 18854, "idx": 131}, {"begin": 18855, "end": 18958, "idx": 132}, {"begin": 18959, "end": 18997, "idx": 133}, {"begin": 18998, "end": 19083, "idx": 134}, {"begin": 19084, "end": 19213, "idx": 135}, {"begin": 19214, "end": 19303, "idx": 136}, {"begin": 19339, "end": 19373, "idx": 137}, {"begin": 19374, "end": 19527, "idx": 138}, {"begin": 19528, "end": 19594, "idx": 139}, {"begin": 19733, "end": 19769, "idx": 140}, {"begin": 19770, "end": 19817, "idx": 141}, {"begin": 19818, "end": 19864, "idx": 142}, {"begin": 19865, "end": 19868, "idx": 143}, {"begin": 19869, "end": 19913, "idx": 144}, {"begin": 19914, "end": 19966, "idx": 145}, {"begin": 19967, "end": 19991, "idx": 146}, {"begin": 19992, "end": 19999, "idx": 147}, {"begin": 20000, "end": 20011, "idx": 148}, {"begin": 20012, "end": 20019, "idx": 149}, {"begin": 20085, "end": 20098, "idx": 150}, {"begin": 20125, "end": 20225, "idx": 151}, {"begin": 20226, "end": 20363, "idx": 152}, {"begin": 20364, "end": 20562, "idx": 153}, {"begin": 20563, "end": 20646, "idx": 154}, {"begin": 20647, "end": 20764, "idx": 155}, {"begin": 20765, "end": 21003, "idx": 156}, {"begin": 21074, "end": 21227, "idx": 157}, {"begin": 21228, "end": 21316, "idx": 158}, {"begin": 21360, "end": 21401, "idx": 159}, {"begin": 21402, "end": 21519, "idx": 160}, {"begin": 21520, "end": 21644, "idx": 161}, {"begin": 21645, "end": 21783, "idx": 162}, {"begin": 21784, "end": 21880, "idx": 163}, {"begin": 21881, "end": 21988, "idx": 164}, {"begin": 21989, "end": 22062, "idx": 165}, {"begin": 22063, "end": 22202, "idx": 166}, {"begin": 22203, "end": 22280, "idx": 167}, {"begin": 22334, "end": 22531, "idx": 168}, {"begin": 22532, "end": 22688, "idx": 169}, {"begin": 22689, "end": 22818, "idx": 170}, {"begin": 22819, "end": 22921, "idx": 171}, {"begin": 22950, "end": 23154, "idx": 172}, {"begin": 23155, "end": 23224, "idx": 173}, {"begin": 23225, "end": 23320, "idx": 174}, {"begin": 23321, "end": 23382, "idx": 175}, {"begin": 23383, "end": 23474, "idx": 176}, {"begin": 23493, "end": 23501, "idx": 177}, {"begin": 23502, "end": 23541, "idx": 178}, {"begin": 23542, "end": 23715, "idx": 179}, {"begin": 23716, "end": 23763, "idx": 180}, {"begin": 23764, "end": 23776, "idx": 181}, {"begin": 23777, "end": 23862, "idx": 182}, {"begin": 23863, "end": 24045, "idx": 183}, {"begin": 24046, "end": 24099, "idx": 184}, {"begin": 24100, "end": 24130, "idx": 185}, {"begin": 24131, "end": 24151, "idx": 186}, {"begin": 24152, "end": 24172, "idx": 187}, {"begin": 24173, "end": 24313, "idx": 188}, {"begin": 24314, "end": 24415, "idx": 189}, {"begin": 24416, "end": 24522, "idx": 190}, {"begin": 24523, "end": 24732, "idx": 191}, {"begin": 24733, "end": 24838, "idx": 192}, {"begin": 24839, "end": 25038, "idx": 193}, {"begin": 25082, "end": 25090, "idx": 194}, {"begin": 25091, "end": 25190, "idx": 195}, {"begin": 25191, "end": 25322, "idx": 196}, {"begin": 25323, "end": 25376, "idx": 197}, {"begin": 25377, "end": 25512, "idx": 198}, {"begin": 25513, "end": 25701, "idx": 199}, {"begin": 25702, "end": 25712, "idx": 200}, {"begin": 25713, "end": 25895, "idx": 201}, {"begin": 25896, "end": 26127, "idx": 202}, {"begin": 26128, "end": 26399, "idx": 203}, {"begin": 26400, "end": 26420, "idx": 204}, {"begin": 26421, "end": 26503, "idx": 205}, {"begin": 26504, "end": 26660, "idx": 206}, {"begin": 26661, "end": 26884, "idx": 207}, {"begin": 26924, "end": 27129, "idx": 208}, {"begin": 27130, "end": 27285, "idx": 209}, {"begin": 27286, "end": 27403, "idx": 210}, {"begin": 27404, "end": 27490, "idx": 211}, {"begin": 27491, "end": 27622, "idx": 212}, {"begin": 27623, "end": 27812, "idx": 213}, {"begin": 27835, "end": 27921, "idx": 214}, {"begin": 27922, "end": 28060, "idx": 215}, {"begin": 28061, "end": 28214, "idx": 216}, {"begin": 28215, "end": 28311, "idx": 217}, {"begin": 28312, "end": 28430, "idx": 218}, {"begin": 28431, "end": 28603, "idx": 219}, {"begin": 28604, "end": 28649, "idx": 220}, {"begin": 28650, "end": 28751, "idx": 221}, {"begin": 28752, "end": 28903, "idx": 222}, {"begin": 28904, "end": 29105, "idx": 223}, {"begin": 29141, "end": 29153, "idx": 224}, {"begin": 29154, "end": 29191, "idx": 225}, {"begin": 29192, "end": 29307, "idx": 226}, {"begin": 29308, "end": 29386, "idx": 227}, {"begin": 29387, "end": 29504, "idx": 228}, {"begin": 29505, "end": 29602, "idx": 229}, {"begin": 29619, "end": 29682, "idx": 230}, {"begin": 29683, "end": 29846, "idx": 231}, {"begin": 29847, "end": 29910, "idx": 232}, {"begin": 29911, "end": 30029, "idx": 233}, {"begin": 30044, "end": 30175, "idx": 234}, {"begin": 30176, "end": 30273, "idx": 235}, {"begin": 30274, "end": 30469, "idx": 236}, {"begin": 30470, "end": 30604, "idx": 237}, {"begin": 30631, "end": 30634, "idx": 238}, {"begin": 30676, "end": 30706, "idx": 239}, {"begin": 30707, "end": 30806, "idx": 240}, {"begin": 30807, "end": 30973, "idx": 241}, {"begin": 31185, "end": 31267, "idx": 242}, {"begin": 31268, "end": 31294, "idx": 243}, {"begin": 31382, "end": 31433, "idx": 244}, {"begin": 31477, "end": 31579, "idx": 245}, {"begin": 31580, "end": 31657, "idx": 246}, {"begin": 31658, "end": 31739, "idx": 247}, {"begin": 31799, "end": 31802, "idx": 248}, {"begin": 31803, "end": 31864, "idx": 249}, {"begin": 31865, "end": 32028, "idx": 250}, {"begin": 32029, "end": 32153, "idx": 251}, {"begin": 32154, "end": 32276, "idx": 252}, {"begin": 32277, "end": 32283, "idx": 253}, {"begin": 32284, "end": 32415, "idx": 254}, {"begin": 32440, "end": 32496, "idx": 255}, {"begin": 32497, "end": 32683, "idx": 256}, {"begin": 32684, "end": 32739, "idx": 257}, {"begin": 32740, "end": 32826, "idx": 258}, {"begin": 32827, "end": 33022, "idx": 259}, {"begin": 33023, "end": 33084, "idx": 260}, {"begin": 33085, "end": 33290, "idx": 261}, {"begin": 33291, "end": 33426, "idx": 262}, {"begin": 33427, "end": 33484, "idx": 263}, {"begin": 33485, "end": 33596, "idx": 264}, {"begin": 33640, "end": 33659, "idx": 265}, {"begin": 33660, "end": 33715, "idx": 266}, {"begin": 33716, "end": 33897, "idx": 267}, {"begin": 33898, "end": 33977, "idx": 268}, {"begin": 33978, "end": 34216, "idx": 269}, {"begin": 34255, "end": 34483, "idx": 270}], "ReferenceToFigure": [{"begin": 10615, "end": 10616, "target": "#fig_0", "idx": 0}, {"begin": 17794, "end": 17795, "target": "#fig_0", "idx": 1}, {"begin": 26934, "end": 26935, "target": "#fig_2", "idx": 2}, {"begin": 27633, "end": 27634, "target": "#fig_2", "idx": 3}], "Abstract": [{"begin": 98, "end": 1205, "idx": 0}], "SectionFootnote": [{"begin": 34519, "end": 34576, "idx": 0}], "Footnote": [{"begin": 34530, "end": 34576, "id": "foot_0", "n": "2", "idx": 0}]}}