{"text": "Adversarial and Contrastive Variational Autoencoder for Sequential Recommendation\n\nAbstract:\nSequential recommendation as an emerging topic has attracted increasing attention due to its important practical significance. Models based on deep learning and attention mechanism have achieved good performance in sequential recommendation. Recently, the generative models based on Variational Autoencoder (VAE) have shown the unique advantage in collaborative filtering. In particular, the sequential VAE model as a recurrent version of VAE can effectively capture temporal dependencies among items in user sequence and perform sequential recommendation. However, VAE-based models suffer from a common limitation that the representational ability of the obtained approximate posterior distribution is limited, resulting in lower quality of generated samples. This is especially true for generating sequences. To solve the above problem, in this work, we propose a novel method called Adversarial and Contrastive Variational Autoencoder (ACVAE) for sequential recommendation. Specifically, we first introduce the adversarial training for sequence generation under the Adversarial Variational Bayes (AVB) framework, which enables our model to generate high-quality latent variables. Then, we employ the contrastive loss. The latent variables will be able to learn more personalized and salient characteristics by minimizing the contrastive loss. Besides, when encoding the sequence, we apply a recurrent and convolutional structure to capture global and local relationships in the sequence. Finally, we conduct extensive experiments on four real-world datasets. The experimental results show that our proposed ACVAE model outperforms other state-of-the-art methods.\nCCS CONCEPTS\n\u2022 Information systems \u2192 Recommender systems.\n\nMain:\n\n\n\n1 INTRODUCTION\nWith the rapid development of web technology, the amount of data is growing explosively, and we have to face massive information every day. The recommender systems (RSs) as an important tool to alleviate information overload can generate a personalized recommendation list for different users.\nThe core recommendation method in RSs is collaborative filtering (CF). Matrix decomposition [13] is the most representative approach in CF, which decomposes the observed matrix into two low-rank matrices of users and items. Temporal dynamic as one of the classic problems in RSs has always attracted attention. Traditional CF methods such as matrix decomposition calculates user's temporal dynamic interest by introducing time segments, but it usually leads to inaccurate prediction results because it fails to capture the changes in dependencies between items over time. The appearance of sequential recommender systems (SRSs) brings a significant improvement in alleviating this problem. SRSs aim to find potential patterns and the dependencies of items in the sequence, and understand user's time-varying interest behind the sequence of his interacted items in order to accurately make next-item recommendation. Different from conventional RSs, SRSs consider the sequential context by taking the prior sequential interactions into account, which effectively models users' dynamic preference and items' popularity [26].\nIn order to process the sequence information for SRSs, lots of methods are proposed to capture the sequential patterns. The Factorizing Personalized Markov Chain (FPMC) [18] uses Markov chain to obtain the information of previous items. Although FPMC is able to make recommendations using sequence information, long-term sequence information can not be captured due to the constraints of Markov chain. Because of the powerful learning ability of neural networks, recurrent neural networks (RNN) based method such as LSTM [27] can be utilized in capturing long-term information, which greatly improves the performance of SRSs. Besides, attention mechanism is widely used in recent models such as SASRec [11] and BERT4Rec [23]. Compared with RNN-based models, attentionbased models achieve better prediction results because of its ability in capturing global dependencies.\nGenerative Adversarial Network (GAN) [2] and Variational Autoenoder (VAE) [14] as two powerful generative models have been successfully applied in RSs. Based on VAE, the sequential VAE (SVAE) [20] model employs a recursive implementation of standard VAE encoder to capture temporal features of items. SVAE has shown good predicting results with the powerful capability of sequence reconstruction. With a sequence of items as the input data, the model can generate \"next-k\" items that are most likely to be chosen by users. However, we argue that the encoder of SVAE has significant limitations, resulting in obtaining low quality of approximate posterior distribution. The deep learning information bottleneck theory reveals that the essence of deep learning is to eliminate useless information and leave real effective information [1]. When applying VAE to generate sequences, we hope to get high-quality latent variables containing sufficient information so that the decoder can use it to generate high-quality samples. Besides, we hope that the latent variables sampled for different users can reflect obvious differences in order to construct \"personalized\" user sequences.\nFor the above motivation, in this paper, we propose Adversarial and Contrastive Variational Autoencoder (ACVAE), which has made several improvements to VAE model for sequential recommendation. This new model tries to reduce the unnecessary dependency constraints on latent variables and allow the model to learn more personalized and effective user characteristics, which can be reflected in two aspects: 1) different dimensions in the latent variables, 2) different latent variables between different users. Within one latent variable, the different dimensions should have low relevance. In this way, the information contained in each dimension in the latent variable will be unique and more representative. Between different users, their corresponding latent variables should have a certain difference, so that the latent variables will have more personalized and salient information. In this work, we find that Adversarial Variational Bayes (AVB) plays an important role in reducing the relevance of various dimensions of latent variables. Thus we introduce AVB into sequential recommendation, which brings the latent variables a more flexible approximate posterior distribution and enhances the independence of different dimensions. Then, we introduce a contrastive learning method for VAE model to assist the training of the encoder, which brings more personalized and salient characteristics of users to the latent variables. Finally, for the task of sequential recommendation, we add a special convolutional layer which can improve the RNN-based encoder in capturing local information between adjacent items. This enables the encoder to learn effective local dependencies in the input sequences. The main contributions of our work are as follows:\n\u2022 We propose to introduce adversarial learning under the AVB framework for sequential recommendation, which brings a closer approximate posterior distribution to the true distribution for sequential VAE model and reduces the correlation between different dimensions of latent variables. \u2022 We introduce contrastive learning to VAE model and utilize contrastive loss to learn the distinctive users' characteristics.\nThe optimization of contrastive loss ensures the personalized and salient characteristics of different users. \u2022 We leverage a convolutional layer to strengthen the connections between adjacent items in the inference model, which helps to better capture short-term relationships in the sequence.\n\n2 RELATED WORK 2.1 Sequential Recommendation\nSequential recommendation performs next-item prediction according to users' historical interactions. Conventional collaborative filtering methods for recommendation usually fail to capture the dependencies of items in the sequence. Therefore, they are not suitable for sequential recommendation scenarios. Caser [24] firstly uses a vertical and a horizontal Convolutional Neural Network (CNN) to capture the local sequence information. In order to describe users' dynamic preference and items' popularity over time, FPMC [18] introduces Markov chains to capture the dependency of the previous item. Following FPMC, higher-order Markov chain [3] is used in learning high-order sequential dependencies. Besides, some models that learn long-term sequential dependencies use LSTM [27] and GRU [5]. Hierarchical structures are also used for improving the performance of sequential recommendation. For example, Parallel RNN [6] brings both the user-item interactions and meta data together. RCNN [28] combines recurrent layer and convolutional layer together to mine short-term sequential patterns. Attention mechanism is a popular technology recently. SASRec [11] brings self-attention into SRSs and BERT4Rec [23] employs BERT model to learn bidirectional item dependencies for sequential recommendation. Hierarchical attention network [29] is used for capturing both long-term and short-term sequence information.\n\n2.2 VAE for Recommendation\nVariational Autoencoder [12, 19] learns the approximate posterior of latent variables under the variational inference framework. There are also some variants of VAE, such as -VAE [7] which learns disentangled representations and DVAE [10] which is similar to denoising autoencoder. The encoded user preference variables (i.e., the latent variables) in variational autoencoder can be used in generating the distribution of recommended items. Mult-VAE [14] is a representative method of using VAE for recommendation. Based on Mult-VAE, SVAE [20] takes in a sequence of items with sequential dependencies, and processes it with the GRU network and finally outputs probability distribution of candidate items. CVRCF [22] employs a recurrent neural network and includes both user and item features in variational inference. MacridVAE [15] employs VAE to learn disentangled representations that can enhance robustness. RecVAE [21] proposes a new composite prior for training based on alternating updates to enhance performance.\n\n2.3 Adversarial Learning\nAdversarial learning has been successfully utilized in some models like APR [4]. GAN-based models such as IRGAN [25], CFGAN [2] can be used for recommendation. SeqGAN [30] uses GAN to generate sequences. Adversarial Variational Bayes [16] unifies GAN and VAE, which allows us to obtain a closer approximate posterior to the real posterior in VAE. VAEGAN [31] introduces AVB to train VAE and utilizes GAN for implicit variational inference, which provides a better approximation to the posterior and maximum likelihood assignment. To sum up, there is still a lack of research work in applying adversarial learning in sequential recommendation.\n\n3 THE METHOD\nIn this section, we first introduce the formulation of the sequential recommendation problem, then present our proposed method -Adversarial and Contrastive Autoencoder for Sequential Recommendation (ACVAE). Figure 1 shows the structure of our proposed ACVAE. There are three main parts in ACVAE: contrast part, encoder part and adversary part. Original users' interaction sequence  is input to the encoder consists of RNN-CNN layers and noise function after embedding. The output of the encoder is , which is then input into the decoder, discriminator and adversary. The adversary receives inputs (, ) and (,  \u2032 ), where  \u2032 is sampled from normal Gaussian distribution. The discriminator receives inputs (, ) and (, z), where z is the latent variable  after shuffled.\n\n3.1 Problem Formulation\nIn this paper, U = { 1 ,  Mult-VAE [14] introduces VAE model into collaborative filtering. In Mult-VAE, the generative model generates the distribution of the all items  ( x ) from a latent variable   sampled from a normal Gaussian distribution through a function   which can be implemented with neural network. When making recommendations, x is sampled from multinomial distribution with the distribution  ( x ).\nIn the task of sequential recommendation, the modeling of the temporal dependencies between items is very important. The temporal dependencies can be modeled by a conditional probability. For a certain timestep , the sequential model predicts the ( +1)-th item according to the items numbering from 1 to , and the conditional probability of the sequential model is  ( , +1 | , [1: ] ). Mult-VAE fails to model temporal order of items, but SVAE as a recursive version of VAE is proposed to capture the time dependence of the sequence. SVAE generates the target  , for latent variable  , at every timestep :\ud835\udc9b \ud835\udc62,\ud835\udc61 \u223c N (0, \ud835\udc70 |\ud835\udc9b \ud835\udc62,\ud835\udc61 | ) \ud835\udf0b \ud835\udf03 (\ud835\udc9b \ud835\udc62,\ud835\udc61 ) \u223c exp(\ud835\udc53 \ud835\udf03 (\ud835\udc9b \ud835\udc62,\ud835\udc61 )) \ud835\udc99 \ud835\udc62,\ud835\udc61 \u223c \ud835\udc40\ud835\udc62\ud835\udc59\ud835\udc61\ud835\udc56 (1, \ud835\udf0b \ud835\udf03 (\ud835\udc9b \ud835\udc62,\ud835\udc61 ))\nwhere N denotes the Gaussian distribution,   denotes a function (usually a neural network) with parameter  and   is the distribution function of   after softmax. The generated  , is sampled from multinomial distribution.\nAs for the inference model, we can obtain the approximate posterior distribution of latent variable  , according to the previous items  , [1: ] by the encoder. The approximate posterior distribution   ( , [1:  ] | , [1:  ] ) can be factorized as:  Then, the target sequence   can be generated by the decoder\ud835\udc44 \ud835\udf19 (\ud835\udc9b \ud835\udc62, [1:\ud835\udc47 \ud835\udc62 ] |\ud835\udc99 \ud835\udc62, [1:\ud835\udc47 \ud835\udc62 ] ) = \ud835\udc47 \ud835\udc62 \ud835\udc61 =1 \ud835\udc5e \ud835\udf19 (\ud835\udc67 \ud835\udc62,\ud835\udc61 |\ud835\udc99 \ud835\udc62, [1:\ud835\udc61 ] )\ud835\udc43 \ud835\udf03 (\ud835\udc99 \ud835\udc62, [2:\ud835\udc47 \ud835\udc62 +1] |\ud835\udc9b \ud835\udc62, [1:\ud835\udc47 \ud835\udc62 ] ): \ud835\udc43 (x \ud835\udc62 , \ud835\udc9b \ud835\udc62 ) = \ud835\udc43 \ud835\udf03 (\ud835\udc99 \ud835\udc62, [2:\ud835\udc47 \ud835\udc62 +1] |\ud835\udc9b \ud835\udc62, [1:\ud835\udc47 \ud835\udc62 ] )\ud835\udc44 \ud835\udf19 (\ud835\udc9b \ud835\udc62, [1:\ud835\udc47 \ud835\udc62 ] ) = \ud835\udc47 \ud835\udc62 \ud835\udc61 =1 \ud835\udc5d \ud835\udf03 (\ud835\udc65 \ud835\udc62,\ud835\udc61 +1 |\ud835\udc67 \ud835\udc62,\ud835\udc61 )\ud835\udc5e \ud835\udf19 (\ud835\udc67 \ud835\udc62,\ud835\udc61 )\nin which the output x is sampled from multinomial distribution.\n\n3.3 Adversarial Learning for Sequential VAE\nIn this section, we will first introduce the shortcomings of the traditional VAE models and show the important role of AVB in inferring latent variables with small correlation between different dimensions in VAE. Then, the AVB approach is proposed to improve the quality of latent variables for sequential recommendation.\n\n3.3.1 Shortcomings of Traditional VAE Models.\nThe traditional VAE does sampling from the Gaussian distribution for the approximate posterior distribution   in the inference model, and thus leading to limited representational ability of latent variables. AVB has shown that the representational ability can be improved by inferring the latent variables in a flexible black box with adversarial training [16]. However, this is not the only difference between VAE and AVB. We use the following simple example to illustrate the problem. Consider a 2-dim latent variable  sampled from N (,  2 ), where  and  are the outputs of a special neural network, which always outputs either [\u22121, \u22121] or [1, 1] with equal probability for  and constant values for . This is regarded as the fake data, which has strong correlation between the two dimensions. Then, consider the  of real data is the discrete uniform distribution of {\u22121, 1} \u00d7 {\u22121, 1} and the real  is also sampled from Gaussian distribution, and thus the two dimensions are independent. Since in VAE, the common approach for calculating KL divergence is simply calculating KL( (|)|| ()), where  () is the prior distribution N (0,  ) and  (|) is the approximate posterior distribution. Each dimension of  is conditional independent. In this example, the KL divergence for the real and fake data are the same, since they share the same  and  2 . So the KL divergence can not distinguish the real and fake data (Figure 2(a)). However, if we input the real and fake data into an discriminator  which is a simple fully connected neural network, it shows different answers for these two kinds of sampled points (Figure 2 (b)).\nThe above example demonstrates that in some cases, discriminator may have certain advantages in judging the correlation of sampled dimensions compared with normal VAE. We will further show the influence of AVB on the correlation between different dimensions of latent variables in the experiment. This independence allows latent variables to capture more representative and disentangled characteristics of different users in recommendation. On the other hand, for sequential VAE models, encoder is supposed to capture the new information at each timestep to model the users' characteristics that change over time more accurately. The change of users' interest at different time may be subtle, which puts forward higher requirements for the expressiveness of the latent variables. AVB exploits the method of adversarial learning to increase the diversity of the distribution of latent variables and reducing the correlation of different dimensions between latent variables. That's why AVB is a suitable choice for our sequential VAE model.\n\n3.3.2 Adversarial Sequential Variational Bayes.\nBecause of the reasons above, we introduce adversarial learning into the sequential model and train the model in the framework of Adversarial Variational Bayes (AVB). AVB enables us to use complex inference models for VAE with adversarial learning, which generates diverse probability distributions that are close to the true posterior distribution. Sequential VAE performs maximum-likelihood training of variational evidence lower bound to estimate the intractable marginal log-likelihood E   \u223c D () log   (  ). For a single user , we have:log \ud835\udc43 \ud835\udf03 ( x\ud835\udc62 ) \u2265 E \ud835\udc9b \ud835\udc62 \u223c\ud835\udc44 \ud835\udf19 (\ud835\udc9b \ud835\udc62 |\ud835\udc99 \ud835\udc62 ) log \ud835\udc43 \ud835\udf03 ( x\ud835\udc62 |\ud835\udc9b \ud835\udc62 ) \u2212 KL(\ud835\udc44 \ud835\udf19 (\ud835\udc9b \ud835\udc62 |\ud835\udc99 \ud835\udc62 )||\ud835\udc43 (\ud835\udc9b \ud835\udc62 )) = \ud835\udc47 \ud835\udc62 \u2211\ufe01 \ud835\udc61 =1 [E \ud835\udc9b \ud835\udc62,\ud835\udc61 \u223c\ud835\udc5e \ud835\udf19 (\ud835\udc9b \ud835\udc62,\ud835\udc61 |\ud835\udc99 \ud835\udc62,[1:\ud835\udc61 ] ) log \ud835\udc5d \ud835\udf03 (\ud835\udc99 \ud835\udc62,\ud835\udc61 +1 |\ud835\udc9b \ud835\udc62,\ud835\udc61 ) \u2212 KL(\ud835\udc5e \ud835\udf19 (\ud835\udc9b \ud835\udc62,\ud835\udc61 |\ud835\udc99 \ud835\udc62, [1:\ud835\udc61 ] )||\ud835\udc5d (\ud835\udc9b \ud835\udc62,\ud835\udc61 ))] (4)\nwhere  is the data distribution and ,  stand for the parameters of generative and inference model respectively. The right side of the equation ( 4) is called the evidence lower bound (ELBO).\nOur goal is to optimize the marginal log-likelihood of   . However, it is usually difficult to calculate directly because the parameter  relies on   (  |  ). To solve this problem, we change the AVB term of objective function to:max \ud835\udf03,\ud835\udf19 \ud835\udc47 \ud835\udc62 \u2211\ufe01 \ud835\udc61 =1 E \ud835\udc99 \ud835\udc62,\ud835\udc61 \u223c\ud835\udc5d D (\ud835\udc99 \ud835\udc62,\ud835\udc61 ) [E \ud835\udc9b \ud835\udc62,\ud835\udc61 \u223c\ud835\udc5e \ud835\udf19 (\ud835\udc9b \ud835\udc62,\ud835\udc61 |\ud835\udc99 \ud835\udc62,[1:\ud835\udc61 ] ) log \ud835\udc5d \ud835\udf03 (\ud835\udc99 \ud835\udc62,\ud835\udc61 +1 |\ud835\udc9b \ud835\udc62,\ud835\udc61 ) \u2212 KL(\ud835\udc5e \ud835\udf19 (\ud835\udc9b \ud835\udc62,\ud835\udc61 |\ud835\udc99 \ud835\udc62, [1:\ud835\udc61 ] )||\ud835\udc5d (\ud835\udc9b \ud835\udc62,\ud835\udc61 ))]max \u03a8 \ud835\udc47 \ud835\udc62 \u2211\ufe01 \ud835\udc61 =1 [E \ud835\udc99 \ud835\udc62 \u223c\ud835\udc43 D (\ud835\udc99 \ud835\udc62 ) E \ud835\udc9b \ud835\udc62 \u223c\ud835\udc44 \ud835\udf19 (\ud835\udc9b \ud835\udc62 |\ud835\udc99 \ud835\udc62 ) log(\ud835\udf0e (\ud835\udc47 \u03a8 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udc62 ) (\ud835\udc61 ) )) + E \ud835\udc99 \ud835\udc62 \u223c\ud835\udc43 D (\ud835\udc99 \ud835\udc62 ) E \ud835\udc9b \ud835\udc62 \u223c\ud835\udc43 (\ud835\udc9b \ud835\udc62 ) log(1 \u2212 \ud835\udf0e (\ud835\udc47 \u03a8 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udc62 ) (\ud835\udc61 ) ))]\nwhere  () = (1 + e \u2212 ) \u22121 is the sigmoid function, and \u03a8 denotes the parameters of the discriminative network  \u03a8 (  ,   ). When equation ( 7) achieves its maximum, the optimal discriminative network  * (  ,   ) would be:\ud835\udc47 * (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udc62 ) (\ud835\udc61 ) = log \ud835\udc5e \ud835\udf19 (\ud835\udc9b \ud835\udc62,\ud835\udc61 |\ud835\udc99 \ud835\udc62,\ud835\udc61 ) \u2212 log \ud835\udc5d (\ud835\udc9b \ud835\udc62,\ud835\udc61 )\nSubstitute it into the previous AVB term of the objective function and the expression can be written as:max \ud835\udf03,\ud835\udf19 \ud835\udc47 \ud835\udc62 \u2211\ufe01 \ud835\udc61 =1 E \ud835\udc99 \ud835\udc62,\ud835\udc61 \u223c\ud835\udc5d D (\ud835\udc99 \ud835\udc62,\ud835\udc61 ) E \ud835\udc9b \ud835\udc62,\ud835\udc61 \u223c\ud835\udc5e \ud835\udf19 (\ud835\udc9b \ud835\udc62,\ud835\udc61 |\ud835\udc99 \ud835\udc62,\ud835\udc61 ) [ log \ud835\udc5d \ud835\udf03 (\ud835\udc99 \ud835\udc62,\ud835\udc61 +1 |\ud835\udc9b \ud835\udc62,\ud835\udc61 ) \u2212 \ud835\udc47 * \u03a8 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udc62 ) (\ud835\udc61 ) ]\nIn practice, we usually consider the reparameterization trick [12] so that parameters in this step can be optimized in the back propagation. Specifically, following [31], we define a non-linear function   (, ) =  1 (  ( 2 (), )), where  1 and  2 denote the functions in the encoder and   denotes the \"add \" function (this part will be described in detail in Section 3.4). Both  are sampled from Gaussian distribution. Thus we can infer a flexible distribution with our proposed encoder by using the reparameterization trick. So finally, the AVB term of the objective function can be written as:max \ud835\udf03,\ud835\udf19 \ud835\udc47 \ud835\udc62 \u2211\ufe01 \ud835\udc61 =1 E \ud835\udc99 \ud835\udc62,\ud835\udc61 \u223c\ud835\udc5d D (\ud835\udc99 \ud835\udc62,\ud835\udc61 ) E \ud835\udf16\u223cN (0,I) [log \ud835\udc43 \ud835\udf03 (\ud835\udc99 \ud835\udc62,\ud835\udc61 +1 |\ud835\udc9b \ud835\udf19 (\ud835\udc99 \ud835\udc62, [1:\ud835\udc61 ] , \ud835\udf50)) \u2212\ud835\udc47 * \u03a8 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udf19 (\ud835\udc99 \ud835\udc62 , \ud835\udf50)) (\ud835\udc61 ) ]\nDuring training, we hope both of the objectives (both equation ( 7) and ( 10)) can get to their optimal values. However, they show the contrast tendency in optimizing any one of them. That is to say, one tends to get worse with the other closer to its optimal value. So we need alternate training in order to optimize both of them.\n\n3.4 Encoder Structure\nIn order to bring sequential information for latent variables in AC-VAE, we need a powerful encoder to capture potential temporal dependencies between items. In SVAE, a recurrent layer is employed to capture the dependencies between the current item and its previous ones. Although long-term sequence dependencies can be captured by RNN units like GRU or LSTM, local relationship between adjacent items may be ignored. In order to enhance the local relationship, we design a special convolutional layer combined with RNN as the encoder.\nwhere  () = log(1 + exp()) is the softplus function.\n3.4.2 CNN Layer. After the RNN layer, a convolutional layer is used to capture local features in the sequences in our model, where the collection of hidden states  , in RNN will serve as the input of our convolutional layer. As shown in figure 1, a vertical CNN filter covers certain adjacent items in the user sequence, and convolves in the sequence to get local features. Before convolution, the \"add \" function  \u2032 , =   ( , , ) is applied to the output  , , which brings noise to the encoder of AVB. Then we define the filter   \u2208 R \u00d71 . During convolution, the filter   moves on the plane of size   \u00d7  in both horizontal and vertical directions. In order to make the input  \u2032 , and the output  , correspond to each other on timestep , we add several zeropadding rows. If the filter's bottom reached ( + 1)-th row when it is generating the -th output, the ( + 1)-th item's information would be revealed to the -th item, which results in label leakage. Therefore, we add all the zero-padding rows before our real data. As a result, we get the output matrix of the CNN layer  , .\n\n3.4.3 Fully Connected\nLayer. Finally, we use a fully connected network to transform the output of the CNN layer to the latent variable .\ud835\udc9b \ud835\udc62,\ud835\udc61 = \ud835\udf09 (\ud835\udc84 \ud835\udc62,\ud835\udc61 ) \u2022 \ud835\udc7e + \ud835\udc83\nwhere  denotes the weight of the full connected layer and  denotes the bias.\n\n3.5 Contrastive Learning\nIn sequential recommendation, the sequences of different users may be relatively similar, which makes it difficult for the model to analyze the user's unique personalized characteristics. The decoder is required to be able to reconstruct the input in original VAE model. However, this goal turns to be even more difficult [8, 17] when a whole sequence needs to be accurately reconstructed in SVAE. If the only goal of the model is to reconstruct the sequence, some truly effective and salient user's personalized information may be ignored. Here we to introduce contrastive learning to help train the sequential VAE model, which can also improve the \"individuation\" of latent variables.\n\n3.5.1 Contrastive Loss.\nWe hope that the latent variables can obtain more effective and salient information about user 's input   in our ACVAE model. In order to capture users' salient features, we learn the contrastive loss by employing a contrastive discriminator   to compare the latent variables of different users.\nHere In order to make   to be able to distinguish the latent variables of different users, we need to find another term of the objective function which can measure the relationship between  and . Here, we define the contrastive loss L , as follow:L \ud835\udf14,\ud835\udf19 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udc62 ) = \u2212 \ud835\udc47 \ud835\udc62 \u2211\ufe01 \ud835\udc61 =1 [E \ud835\udc9b \ud835\udc62 \u223c\ud835\udc44 \ud835\udf19 (\ud835\udc9b \ud835\udc62 |\ud835\udc99 \ud835\udc62 ) log(\ud835\udf0e (\ud835\udc3a \ud835\udf14 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udc62 ) (\ud835\udc61 ) )) + E \ud835\udc9b \ud835\udc62 \u2032 \u223c\ud835\udc44 \ud835\udf19 ( z\ud835\udc62 |\ud835\udc99 \ud835\udc96 \u2032 ) log(\ud835\udf0e (1 \u2212 \ud835\udc3a \ud835\udf14 (\ud835\udc99 \ud835\udc62 \u2032 , \ud835\udc9b \ud835\udc62 ) (\ud835\udc61 ) ))]\nWhen minimizing the contrastive loss L , (  ,   ), the discriminator   can better distinguish the positive matches and negative matches. The latent variables inferred by the encoder will obtain more salient and personalized information of different users.\n\n3.5.2 Optimization.\nThe optimization goal of contrastive learning part is minimizing the contrastive loss term of the objective function by optimizing  and . Since the encoder and the discriminator   are both optimizing the contrastive term of the objective function, we do not need additional alternate training process. Thus this term can be simply added to the original term of the objective function in variational autoencoder when optimizing the parameters in the encoder.\n\n3.6 Objective Functions\nOverall, the whole objective functions of our proposed ACVAE for user  are as follows:max \ud835\udf19,\ud835\udf03,\ud835\udf14 \ud835\udc47 \ud835\udc62 \u2211\ufe01 \ud835\udc61 =1 E \ud835\udc99 \ud835\udc62,\ud835\udc61 \u223c\ud835\udc5d D (\ud835\udc99 \ud835\udc62,\ud835\udc61 ) E \ud835\udf50\u223cN (0,I) [log \ud835\udc43 \ud835\udf03 (\ud835\udc99 \ud835\udc62,\ud835\udc61 +1 |\ud835\udc9b \ud835\udf19 (\ud835\udc99 \ud835\udc62, [1:\ud835\udc61 ] , \ud835\udf50)) \u2212 \ud835\udefc \u2022 \ud835\udc47 * \u03a8 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udf19 (\ud835\udc99 \ud835\udc62 , \ud835\udf50)) (\ud835\udc61 ) \u2212 \ud835\udefd \u2022 L \ud835\udf14,\ud835\udf19 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udf19 (\ud835\udc99 \ud835\udc62 , \ud835\udf16)) (\ud835\udc61 ) ], max \u03a8 \ud835\udc47 \ud835\udc62 \u2211\ufe01 \ud835\udc61 =1 [E \ud835\udc99 \ud835\udc62 \u223c\ud835\udc43 D (\ud835\udc99 \ud835\udc62 ) E \ud835\udf50\u223cN (0,I) log(\ud835\udf0e (\ud835\udc47 \u03a8 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udf19 (\ud835\udc99 \ud835\udc62 , \ud835\udf50)) (\ud835\udc61 ) )) + E \ud835\udc99 \ud835\udc62 \u223c\ud835\udc43 D (\ud835\udc99 \ud835\udc62 ) E \ud835\udc9b \ud835\udc62 \u223c\ud835\udc43 (\ud835\udc9b \ud835\udc62 ) log(1 \u2212 \ud835\udf0e (\ud835\udc47 \u03a8 (\ud835\udc99 \ud835\udc62 , \ud835\udc9b \ud835\udc62 ) (\ud835\udc61 ) ))]\nwhere  and  are hyper-parameters controlling the weight of the discriminative and contrastive terms respectively. The pseudo code of our algorithm is shown in Algorithm 1, where  is a hyperparameter representing the learning rate.\n\n4 EXPERIMENTS 4.1 Datasets\nWe evaluate our model on the following datasets, which are widely used in evaluating the performance of recommender system.\n\u2022 MovieLens Latest (ML-latest) 1 : MovieLens Latest is a widely used dataset which contains the latest movie ratings with detailed timestamps. Ratings range from 1 to 5. \u2022 MovieLens 1m (ML-1m) 2 : This is a widely used dataset which contains 1 million ratings with detailed timestamps and rating level from 1 to 5. \u2022 MovieLens 10m (ML-10m) 3 : This is a larger version of ML-1m, which contains 10 million movie ratings by the users. \u2022 Yelp 4 : Yelp contains businesses, reviews and user data including ratings and timestamps. We use a subset of the review data of it, which contains detailed review information since 2018.\nAll the datasets are preprocessed following the similar approach in SVAE [20]. First, we only consider the interactions with rating score strictly larger than 3 as positive interactions on the datasets with rating values range from 1 to 5. Then, we remove the users interacted less than 5 times, as well as the items interacted less than 5 times. Since in our model, we only need the information of implicit feedback, the detailed numeric rating numbers are all set to 1. The unused item labels are ignored and all of the ratings or purchases are treated as interactions. Table 1 shows the statistics of our preprocessed datasets. We can see that these datasets' sizes and the average length of sequences differ significantly. The ML-10m dataset contains the most records while the ML-latest dataset contains the least records. And the average length of ML-latest, ML-1m and ML-10m are far more than that of Yelp. It enables us to further explore each model's performances on datasets of different sizes and different average lengths of sequences.\n\n4.2 Baselines\nIn order to evaluate the performance of our model, we take some models for recommendation as baselines, including the traditional approach according to popularity, RNN-based methods, attentionbased method, adversarial learning method and VAE methods. This is a brief introduction of these methods:\n\u2022 POP: POP is a simple recommendation algorithm. It sorts by the number of user interactions and always recommends the ones with highest popularity. \u2022 FPMC [18] : FPMC combines matrix factorization and markov chains together to recommend the items. \u2022 Caser [24] : Caser uses horizontal and vertical CNN to capture the information. \u2022 GRU4Rec + [5]: GRU4Rec + uses GRU and new loss functions for session based recommendation. \u2022 BERT4Rec [23] : BERT4Rec employs BERT model, which trains the model by predicting the masked items with a bidirectional self-attention network. \u2022 CFGAN [2] : CFGAN uses a GAN structure to generate user's purchase vector. \u2022 Mult-VAE [14] : Mult-VAE uses a multinomial likelihood for variational autoencoder to improve the performance. \u2022 SVAE [20] : Sequential variational autoencoder uses GRU and variational autoencoder to generate the target sequence.\n\n4.3 Training Details\nWe implement ACVAE with PyTorch. For POP, FPMC, GRU4Rec + , CFGAN and Caser, we use the code in the NeuRec 5 algorithm library.\nFor SVAE, we use the code provided by the author. For Mult-VAE and BERT4Rec, we implement them with PyTorch following the original code.\nThe ACVAE model includes an embedding layer of size 128, a GRU layer of size 100, and the latent variables of size 64. A residual structure is added to the the convolutional layer in the encoder to prevent degradation of the gradient. Since the length of the item sequences of different users are not the same, we set several fixed sequence lengths  for each datasets to gather different sequences in one batch. If the length of the sequence is larger than , then we only keep the last  items. If the length is smaller than , we pad zeros to the end of item sequence. In our experiments, we use Adam optimizer with  = 1.0 \u00d7 10 \u22124 and weight decay  2 = 1.0 \u00d7 10 \u22122 for VAE and SGD optimizer with  = 5.0 \u00d7 10 \u22124 and  2 = 1.0 \u00d7 10 \u22121 for  \u03a8 and   . The settings of  and  have an impact on the experimental results, which will be further explored in Section 4.7.\nFor the sake of fairness, we set the embedding size to 128 for the models with neural network in the baselines except FPMC (embedding size equals to 64) for its poor performance when embedding size equals to 128. To make the model converge, the models are trained for 300 epochs on ML-latest, 200 epochs on ML-1m, 100 epochs on ML-10m and 40 epochs on Yelp. The source code of ACVAE is available on GitHub 6.\n\n4.4 Evaluation Metrics\nThe goal of our proposed method is predicting the next item that will be picked by the user. For each user, we split the interact sequence by 8:2 for training and testing respectively. After training, the users' training sets are used as test input and the output of last item will be taken as prediction.\nWe use some of the widely used metrics to evaluate the performance of our model for recommendation. We evaluate the metrics for top- item recommendation.\n\u2022 Recall: Recall ratio of the ground truth item.\n\n\ud835\udc45\ud835\udc52\ud835\udc50\ud835\udc4e\ud835\udc59\ud835\udc59@\ud835\udc58 =\n\n\n\ud835\udc3b\ud835\udc56\ud835\udc61\ud835\udc60@\ud835\udc58 |\ud835\udc3f|\nwhere  denotes the relevant items in the test dataset. \u2022 NDCG: Normalized Discounted Cumulative Gain. considers not only how many hits are recommended, but also the position the hits locates in top-k recommendation.\nThe more the hits are and the closer the hits are to the top, the higher the score of   will be.\ud835\udc41 \ud835\udc37\ud835\udc36\ud835\udc3a@\ud835\udc58 = \ud835\udc37\ud835\udc36\ud835\udc3a@\ud835\udc58 \ud835\udc3c\ud835\udc37\ud835\udc36\ud835\udc3a@\ud835\udc58 = \ud835\udc58 \ud835\udc56=1 1 log 2 (\ud835\udc56+1) |\ud835\udc3f | \ud835\udc56=1 1 log 2 (\ud835\udc56+1)\nwhere  =  where   denotes the rank of the first hit in the prediction list. ML-latest Recall@5 NDCG@5 MRR@5 Recall@10 NDCG@10 MRR@10 Recall@20 NDCG@20 MRR@20 POP 0.\n\nML-1m\nRecall@5 NDCG@5 MRR@5 Recall@10 NDCG@10 MRR@10 Recall@20 NDCG@20 MRR@ Compared with the VAE models (i.e., SVAE and Mult-VAE), our model has a significant improvement. That's because our model employs AVB and contrastive loss, which brings significant improvement to the inference of latent variables in sequential recommendation.\nCompared with deep learning based methods Caser and GRU4Rec + , our model achieves significant improvement. On the one hand, it shows powerful predictive ability of generative models, on the other hand, it also shows that the combination of RNN and CNN may bring improvements. In CFGAN, it employs a GAN structure to generate fake purchase vectors. Although it has generative capabilities, it is not suitable for sequential recommendation, the dynamic changes of user interests can not be captured.\nCompared with BERT4Rec, although ACVAE only considers the unidirectional information, it does not utilize the global attention mechanism, it still achieves better results. It indicates that for sequence-oriented generative models, obtaining high-quality latent variables is the key to achieving good results.\nIt is worth noting that SVAE has achieved the best except ACVAE in most of the datasets. However, in datasets with fewer users (e.g. ML-latest), FPMC performs better than SVAE. It shows that traditional methods are still valid on some datasets. In datasets with short average sequence length (e.g. Yelp), BERT4Rec and Mult-VAE perform well, it shows that these two methods are competitive in sequential recommendation with short sequence length.\n\n4.6 Ablation Study\nApart from making comparison with other models, we also perform ablation study on our own model to investigate the effectiveness of different components. We choose Recall@10 as the evaluation metric. We disable the key parts of our model (without contrastive loss, without AVB, without CNN layer) in turn, and test the performance on four datasets. Figure 3 (a), 3(b), 3(c) and 3(d) show the results. We can observe that training curves are smooth, and ACVAE with full components performs best, it shows the effectiveness of all the three components and each of them contributes to the result.\n\n4.6.1 Study of AVB.\nFor the model without AVB, we remove the adversary  \u03a8 without changing the structure of encoder. The results of the model without AVB is worse than the results of ACVAE in all of the metrics shown in figure 3. The possible reason is that the adversary can effectively regularize the latent variables, which improves the generation ability of latent variables.\nIn addition, we measure the correlation coefficients of the various dimensions of the latent variables on four datasets. Since the correlation coefficients are in the form of matrix, we need to transform it into a scalar in order to evaluate the correlation in a more intuitive way. The diagonal elements in the correlation coefficient matrix are all one and the other elements represent the correlation between different elements. So we use the following formula to get a specific value to measure the correlation:\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc5f = \u2211\ufe01 \ud835\udc56 \u2211\ufe01 \ud835\udc57 \ud835\udc50 2 \ud835\udc56 \ud835\udc57\nwhere    is the element of the matrix  \u2212  and  denotes the correlation coefficient matrix and  denotes the identity matrix. Figure 4 shows the change of value  on four datasets. The result shows that in all of the four datasets, the correlation coefficient of using AVB is lower than that of not using AVB. This demonstrates the important role of AVB in reducing the correlation of different dimensions of latent variables.\n\n4.6.2 Study of Contrastive Loss.\nTo verify the effectiveness of contrastive loss, we set  to 0, which disables the contrastive loss term without affecting the training of the VAE model. From figure 3, we observe that contrastive loss brings ACVAE better performance in most of the datasets. This shows that the contrastive loss can further enhance the generalization ability of the model by minimizing contrastive loss. 4.6.3 Study of CNN Layer. We compare the training results with and without CNN. Fully connected layers are used to replace the original CNN layer. We can find that, compared with the model without CNN layers, ACVAE achieves better results. The reason is that CNN layer helps further capture the local information of the items.\n\n4.7 Impact of Hyper-parameters\nIn order to investigate the influence of the hyper-parameters (i.e. and ) in the objective function, we perform a grid search strategy to test the impact on ML-1M dataset. We choose Recall@10 and NDCG@10 as evaluation metrics. The results are shown in Figure 5 According to [7], higher  values will result in stronger constraint on the latent variables. Therefore, we set the value of  between 0 \u223c 0.2 based on experience. Figure 5 shows the highest evaluation results during training of RC@10 and NDCG@10. We can find that both RC@10 and NDCG@10 reach the highest values when  = 0.05 and then go down. The reason for this result is that adversarial learning can bring certain constraints to latent variables to prevent overfitting, but too large weight of  will lead to over-regularization and reduce the effect.\n\n4.7.2 Impact of \ud835\udefd.\nTo study the impact of contrastive learning, we test the hyper-parameter  determining the weight of contrastive loss in the range of {0.0, 0.05, 0.1, 0.2, 0.3, 0.5, 1.0}. We can observe that the contrastive loss term can bring positive effect for the results, the results are best when  = 0.5. It is worth noticing that when  = 0.0, using contrastive loss term will greatly improve the results, because without the KL term, the model will rely on the contrastive loss for learning.\n\n5 CONCLUSION\nIn this paper, we focus on the shortcomings in the VAE models for sequential recommendation, especially the quality of the inferred latent variables. These shortcomings have largely limited the ability of latent variables in the VAE model in expressing the sequential information with users' unique preferences. We propose a novel sequential recommendation model ACVAE to enhance the encoder. We introduce adversarial learning via AVB framework to sequential recommendation, which reduces the relevance between different dimensions in latent variables. We also employ contrastive learning into VAE, which brings the model better generalization by minimizing contrastive loss. Besides, we add a special convolutional layer in the encoder after recurrent layer to further capture the shortterm information in the sequence. Experiments demonstrate that our proposed ACVAE model achieves considerable performance improvement compared with state-of-the-art models.\n\nFootnotes:\n1: https://grouplens.org/datasets/movielens\n2: https://grouplens.org/datasets/movielens\n3: https://grouplens.org/datasets/movielens\n4: https://www.yelp.com/dataset\n5: https://github.com/wubinzzu/NeuRec\n6: https://github.com/ACVAE/ACVAE-PyTorch\n\nReferences:\n\n- Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. 2016. Deep variational information bottleneck. arXiv preprint arXiv:1612.00410 (2016).- Dong-Kyu Chae, Jin-Soo Kang, Sang-Wook Kim, and Jung-Tae Lee. 2018. Cfgan: A generic collaborative filtering framework based on generative adversarial networks. In Proceedings of the 27th ACM international conference on information and knowledge management. 137-146.\n\n- Ruining He and Julian McAuley. 2016. Fusing similarity models with markov chains for sparse sequential recommendation. In 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 191-200.\n\n- Xiangnan He, Zhankui He, Xiaoyu Du, and Tat-Seng Chua. 2018. Adversarial personalized ranking for recommendation. In The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. 355-364.\n\n- Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).\n\n- Bal\u00e1zs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos Tikk. 2016. Parallel recurrent neural network architectures for feature-rich session-based recommendations. In Proceedings of the 10th ACM conference on recommender systems. 241-248.\n\n- Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2016. beta-vae: Learning basic visual concepts with a constrained variational framework. (2016).\n\n- R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. 2018. Learning deep represen- tations by mutual information estimation and maximization. arXiv preprint arXiv:1808.06670 (2018).\n\n- Ferenc Husz\u00e1r. 2017. Variational inference using implicit distributions. arXiv preprint arXiv:1702.08235 (2017).\n\n- Daniel Im Im, Sungjin Ahn, Roland Memisevic, and Yoshua Bengio. 2017. De- noising criterion for variational auto-encoding framework. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 31.\n\n- Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom- mendation. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 197-206.\n\n- Diederik P. Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. In 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings.\n\n- Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech- niques for recommender systems. Computer 42, 8 (2009), 30-37.\n\n- Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018. Variational autoencoders for collaborative filtering. In Proceedings of the 2018 World Wide Web Conference. 689-698.\n\n- Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learn- ing disentangled representations for recommendation. In Advances in Neural Information Processing Systems. 5711-5722.\n\n- Lars M. Mescheder, Sebastian Nowozin, and Andreas Geiger. 2017. Adversarial Variational Bayes: Unifying Variational Autoencoders and Generative Adversarial Networks. In Proceedings of the 34th International Conference on Machine Learning. 2391-2400.\n\n- Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748 (2018).\n\n- Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor- izing personalized markov chains for next-basket recommendation. In Proceedings of the 19th international conference on World wide web. 811-820.\n\n- Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochas- tic backpropagation and approximate inference in deep generative models. In International conference on machine learning. PMLR, 1278-1286.\n\n- Noveen Sachdeva, Giuseppe Manco, Ettore Ritacco, and Vikram Pudi. 2019. Se- quential variational autoencoders for collaborative filtering. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining. 600-608.\n\n- Ilya Shenbin, Anton Alekseev, Elena Tutubalina, Valentin Malykh, and Sergey I Nikolenko. 2020. RecVAE: A New Variational Autoencoder for Top-N Recommen- dations with Implicit Feedback. In Proceedings of the 13th International Conference on Web Search and Data Mining. 528-536.\n\n- Qingquan Song, Shiyu Chang, and Xia Hu. 2019. Coupled Variational Recurrent Collaborative Filtering. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 335-343.\n\n- Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep- resentations from transformer. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 1441-1450.\n\n- Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommenda- tion via convolutional sequence embedding. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 565-573.\n\n- Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng Zhang, and Dell Zhang. 2017. Irgan: A minimax game for unifying generative and discriminative information retrieval models. In Proceedings of the 40th In- ternational ACM SIGIR conference on Research and Development in Information Retrieval. 515-524.\n\n- Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z. Sheng, and Mehmet A. Orgun. 2019. Sequential Recommender Systems: Challenges, Progress and Prospects. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence. 6332-6338.\n\n- Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. 2017. Recurrent recommender networks. In Proceedings of the tenth ACM international conference on web search and data mining. 495-503.\n\n- Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Jiajie Xu, Victor S Sheng S. Sheng, Zhiming Cui, Xiaofang Zhou, and Hui Xiong. 2019. Recurrent convolutional neu- ral network for sequential recommendation. In The World Wide Web Conference. 3398-3404.\n\n- Haochao Ying, Fuzhen Zhuang, Fuzheng Zhang, Yanchi Liu, Guandong Xu, Xing Xie, Hui Xiong, and Jian Wu. 2018. Sequential recommender system based on hierarchical attention network. In IJCAI International Joint Conference on Artificial Intelligence.\n\n- Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2017. Seqgan: Sequence generative adversarial nets with policy gradient. In Thirty-first AAAI conference on artificial intelligence.\n\n- Xianwen Yu, Xiaoning Zhang, Yang Cao, and Min Xia. 2019. VAEGAN: A Collab- orative Filtering Framework based on Adversarial Variational Autoencoders.. In IJCAI. 4206-4212.\n\n", "annotations": {"ReferenceToTable": [{"begin": 26026, "end": 26027, "target": "#tab_5", "idx": 0}], "ReferenceToFootnote": [{"begin": 24856, "end": 24857, "target": "#foot_0", "idx": 0}, {"begin": 25018, "end": 25019, "target": "#foot_1", "idx": 1}, {"begin": 25165, "end": 25166, "target": "#foot_2", "idx": 2}, {"begin": 25265, "end": 25266, "target": "#foot_3", "idx": 3}, {"begin": 27817, "end": 27818, "target": "#foot_4", "idx": 4}, {"begin": 29240, "end": 29241, "target": "#foot_5", "idx": 5}], "SectionMain": [{"begin": 1824, "end": 36965, "idx": 0}], "ReferenceToFormula": [{"begin": 17715, "end": 17716, "idx": 0}, {"begin": 18442, "end": 18443, "target": "#formula_5", "idx": 1}, {"begin": 19612, "end": 19613, "target": "#formula_5", "idx": 2}, {"begin": 19621, "end": 19623, "target": "#formula_8", "idx": 3}], "SectionReference": [{"begin": 37223, "end": 44021, "idx": 0}], "SectionHeader": [{"begin": 0, "end": 1824, "idx": 0}], "Div": [{"begin": 93, "end": 1758, "idx": 0}, {"begin": 1759, "end": 1816, "idx": 1}, {"begin": 1827, "end": 7769, "idx": 2}, {"begin": 7771, "end": 9225, "idx": 3}, {"begin": 9227, "end": 10275, "idx": 4}, {"begin": 10277, "end": 10944, "idx": 5}, {"begin": 10946, "end": 11726, "idx": 6}, {"begin": 11728, "end": 13686, "idx": 7}, {"begin": 13688, "end": 14053, "idx": 8}, {"begin": 14055, "end": 16762, "idx": 9}, {"begin": 16764, "end": 19878, "idx": 10}, {"begin": 19880, "end": 21571, "idx": 11}, {"begin": 21573, "end": 21812, "idx": 12}, {"begin": 21814, "end": 22525, "idx": 13}, {"begin": 22527, "end": 23508, "idx": 14}, {"begin": 23510, "end": 23987, "idx": 15}, {"begin": 23989, "end": 24672, "idx": 16}, {"begin": 24674, "end": 26495, "idx": 17}, {"begin": 26497, "end": 27687, "idx": 18}, {"begin": 27689, "end": 29242, "idx": 19}, {"begin": 29244, "end": 29775, "idx": 20}, {"begin": 29777, "end": 29788, "idx": 21}, {"begin": 29790, "end": 30345, "idx": 22}, {"begin": 30347, "end": 31936, "idx": 23}, {"begin": 31938, "end": 32550, "idx": 24}, {"begin": 32552, "end": 33895, "idx": 25}, {"begin": 33897, "end": 34643, "idx": 26}, {"begin": 34645, "end": 35489, "idx": 27}, {"begin": 35491, "end": 35991, "idx": 28}, {"begin": 35993, "end": 36965, "idx": 29}], "Head": [{"begin": 1759, "end": 1771, "idx": 0}, {"begin": 1827, "end": 1841, "n": "1", "idx": 1}, {"begin": 7771, "end": 7815, "n": "2", "idx": 2}, {"begin": 9227, "end": 9253, "n": "2.2", "idx": 3}, {"begin": 10277, "end": 10301, "n": "2.3", "idx": 4}, {"begin": 10946, "end": 10958, "n": "3", "idx": 5}, {"begin": 11728, "end": 11751, "n": "3.1", "idx": 6}, {"begin": 13688, "end": 13731, "n": "3.3", "idx": 7}, {"begin": 14055, "end": 14100, "n": "3.3.1", "idx": 8}, {"begin": 16764, "end": 16811, "n": "3.3.2", "idx": 9}, {"begin": 19880, "end": 19901, "n": "3.4", "idx": 10}, {"begin": 21573, "end": 21594, "n": "3.4.3", "idx": 11}, {"begin": 21814, "end": 21838, "n": "3.5", "idx": 12}, {"begin": 22527, "end": 22550, "n": "3.5.1", "idx": 13}, {"begin": 23510, "end": 23529, "n": "3.5.2", "idx": 14}, {"begin": 23989, "end": 24012, "n": "3.6", "idx": 15}, {"begin": 24674, "end": 24700, "n": "4", "idx": 16}, {"begin": 26497, "end": 26510, "n": "4.2", "idx": 17}, {"begin": 27689, "end": 27709, "n": "4.3", "idx": 18}, {"begin": 29244, "end": 29266, "n": "4.4", "idx": 19}, {"begin": 29777, "end": 29787, "idx": 20}, {"begin": 29790, "end": 29800, "idx": 21}, {"begin": 30347, "end": 30352, "idx": 22}, {"begin": 31938, "end": 31956, "n": "4.6", "idx": 23}, {"begin": 32552, "end": 32571, "n": "4.6.1", "idx": 24}, {"begin": 33897, "end": 33929, "n": "4.6.2", "idx": 25}, {"begin": 34645, "end": 34675, "n": "4.7", "idx": 26}, {"begin": 35491, "end": 35509, "n": "4.7.2", "idx": 27}, {"begin": 35993, "end": 36005, "n": "5", "idx": 28}], "Paragraph": [{"begin": 93, "end": 1758, "idx": 0}, {"begin": 1772, "end": 1816, "idx": 1}, {"begin": 1842, "end": 2135, "idx": 2}, {"begin": 2136, "end": 3257, "idx": 3}, {"begin": 3258, "end": 4128, "idx": 4}, {"begin": 4129, "end": 5306, "idx": 5}, {"begin": 5307, "end": 7060, "idx": 6}, {"begin": 7061, "end": 7474, "idx": 7}, {"begin": 7475, "end": 7769, "idx": 8}, {"begin": 7816, "end": 9225, "idx": 9}, {"begin": 9254, "end": 10275, "idx": 10}, {"begin": 10302, "end": 10944, "idx": 11}, {"begin": 10959, "end": 11726, "idx": 12}, {"begin": 11752, "end": 12165, "idx": 13}, {"begin": 12166, "end": 12771, "idx": 14}, {"begin": 12863, "end": 13083, "idx": 15}, {"begin": 13084, "end": 13391, "idx": 16}, {"begin": 13623, "end": 13686, "idx": 17}, {"begin": 13732, "end": 14053, "idx": 18}, {"begin": 14101, "end": 15723, "idx": 19}, {"begin": 15724, "end": 16762, "idx": 20}, {"begin": 16812, "end": 17353, "idx": 21}, {"begin": 17570, "end": 17760, "idx": 22}, {"begin": 17761, "end": 17990, "idx": 23}, {"begin": 18303, "end": 18523, "idx": 24}, {"begin": 18588, "end": 18692, "idx": 25}, {"begin": 18820, "end": 19414, "idx": 26}, {"begin": 19547, "end": 19878, "idx": 27}, {"begin": 19902, "end": 20438, "idx": 28}, {"begin": 20439, "end": 20491, "idx": 29}, {"begin": 20492, "end": 21571, "idx": 30}, {"begin": 21595, "end": 21709, "idx": 31}, {"begin": 21736, "end": 21812, "idx": 32}, {"begin": 21839, "end": 22525, "idx": 33}, {"begin": 22551, "end": 22846, "idx": 34}, {"begin": 22847, "end": 23094, "idx": 35}, {"begin": 23253, "end": 23508, "idx": 36}, {"begin": 23530, "end": 23987, "idx": 37}, {"begin": 24013, "end": 24099, "idx": 38}, {"begin": 24442, "end": 24672, "idx": 39}, {"begin": 24701, "end": 24824, "idx": 40}, {"begin": 24825, "end": 25447, "idx": 41}, {"begin": 25448, "end": 26495, "idx": 42}, {"begin": 26511, "end": 26808, "idx": 43}, {"begin": 26809, "end": 27687, "idx": 44}, {"begin": 27710, "end": 27837, "idx": 45}, {"begin": 27838, "end": 27974, "idx": 46}, {"begin": 27975, "end": 28833, "idx": 47}, {"begin": 28834, "end": 29242, "idx": 48}, {"begin": 29267, "end": 29572, "idx": 49}, {"begin": 29573, "end": 29726, "idx": 50}, {"begin": 29727, "end": 29775, "idx": 51}, {"begin": 29801, "end": 30016, "idx": 52}, {"begin": 30017, "end": 30113, "idx": 53}, {"begin": 30181, "end": 30345, "idx": 54}, {"begin": 30353, "end": 30682, "idx": 55}, {"begin": 30683, "end": 31181, "idx": 56}, {"begin": 31182, "end": 31490, "idx": 57}, {"begin": 31491, "end": 31936, "idx": 58}, {"begin": 31957, "end": 32550, "idx": 59}, {"begin": 32572, "end": 32931, "idx": 60}, {"begin": 32932, "end": 33447, "idx": 61}, {"begin": 33472, "end": 33895, "idx": 62}, {"begin": 33930, "end": 34643, "idx": 63}, {"begin": 34676, "end": 35489, "idx": 64}, {"begin": 35510, "end": 35991, "idx": 65}, {"begin": 36006, "end": 36965, "idx": 66}], "ReferenceToBib": [{"begin": 2228, "end": 2232, "target": "#b12", "idx": 0}, {"begin": 3252, "end": 3256, "target": "#b25", "idx": 1}, {"begin": 3427, "end": 3431, "target": "#b17", "idx": 2}, {"begin": 3779, "end": 3783, "target": "#b26", "idx": 3}, {"begin": 3960, "end": 3964, "target": "#b10", "idx": 4}, {"begin": 3978, "end": 3982, "target": "#b22", "idx": 5}, {"begin": 4166, "end": 4169, "target": "#b1", "idx": 6}, {"begin": 4203, "end": 4207, "target": "#b13", "idx": 7}, {"begin": 4321, "end": 4325, "target": "#b19", "idx": 8}, {"begin": 4961, "end": 4964, "target": "#b0", "idx": 9}, {"begin": 8128, "end": 8132, "target": "#b23", "idx": 10}, {"begin": 8337, "end": 8341, "target": "#b17", "idx": 11}, {"begin": 8457, "end": 8460, "target": "#b2", "idx": 12}, {"begin": 8592, "end": 8596, "target": "#b26", "idx": 13}, {"begin": 8605, "end": 8608, "target": "#b4", "idx": 14}, {"begin": 8734, "end": 8737, "target": "#b5", "idx": 15}, {"begin": 8806, "end": 8810, "target": "#b27", "idx": 16}, {"begin": 8970, "end": 8974, "target": "#b10", "idx": 17}, {"begin": 9020, "end": 9024, "target": "#b22", "idx": 18}, {"begin": 9147, "end": 9151, "target": "#b28", "idx": 19}, {"begin": 9278, "end": 9282, "target": "#b11", "idx": 20}, {"begin": 9283, "end": 9286, "target": "#b18", "idx": 21}, {"begin": 9433, "end": 9436, "target": "#b6", "idx": 22}, {"begin": 9488, "end": 9492, "target": "#b9", "idx": 23}, {"begin": 9704, "end": 9708, "target": "#b13", "idx": 24}, {"begin": 9793, "end": 9797, "target": "#b19", "idx": 25}, {"begin": 9966, "end": 9970, "target": "#b21", "idx": 26}, {"begin": 10083, "end": 10087, "target": "#b14", "idx": 27}, {"begin": 10174, "end": 10178, "target": "#b20", "idx": 28}, {"begin": 10378, "end": 10381, "target": "#b3", "idx": 29}, {"begin": 10414, "end": 10418, "target": "#b24", "idx": 30}, {"begin": 10426, "end": 10429, "target": "#b1", "idx": 31}, {"begin": 10469, "end": 10473, "target": "#b29", "idx": 32}, {"begin": 10536, "end": 10540, "target": "#b15", "idx": 33}, {"begin": 10656, "end": 10660, "target": "#b30", "idx": 34}, {"begin": 11787, "end": 11791, "target": "#b13", "idx": 35}, {"begin": 14457, "end": 14461, "target": "#b15", "idx": 36}, {"begin": 18882, "end": 18886, "target": "#b11", "idx": 37}, {"begin": 18985, "end": 18989, "target": "#b30", "idx": 38}, {"begin": 22161, "end": 22164, "target": "#b7", "idx": 39}, {"begin": 22165, "end": 22168, "target": "#b16", "idx": 40}, {"begin": 25521, "end": 25525, "target": "#b19", "idx": 41}, {"begin": 26965, "end": 26969, "target": "#b17", "idx": 42}, {"begin": 27066, "end": 27070, "target": "#b23", "idx": 43}, {"begin": 27244, "end": 27248, "target": "#b22", "idx": 44}, {"begin": 27387, "end": 27390, "target": "#b1", "idx": 45}, {"begin": 27467, "end": 27471, "target": "#b13", "idx": 46}, {"begin": 27576, "end": 27580, "target": "#b19", "idx": 47}, {"begin": 34950, "end": 34953, "target": "#b6", "idx": 48}], "ReferenceString": [{"begin": 37238, "end": 37391, "id": "b0", "idx": 0}, {"begin": 37393, "end": 37659, "id": "b1", "idx": 1}, {"begin": 37663, "end": 37862, "id": "b2", "idx": 2}, {"begin": 37866, "end": 38087, "id": "b3", "idx": 3}, {"begin": 38091, "end": 38273, "id": "b4", "idx": 4}, {"begin": 38277, "end": 38529, "id": "b5", "idx": 5}, {"begin": 38533, "end": 38763, "id": "b6", "idx": 6}, {"begin": 38767, "end": 39013, "id": "b7", "idx": 7}, {"begin": 39017, "end": 39129, "id": "b8", "idx": 8}, {"begin": 39133, "end": 39340, "id": "b9", "idx": 9}, {"begin": 39344, "end": 39505, "id": "b10", "idx": 10}, {"begin": 39509, "end": 39723, "id": "b11", "idx": 11}, {"begin": 39727, "end": 39868, "id": "b12", "idx": 12}, {"begin": 39872, "end": 40061, "id": "b13", "idx": 13}, {"begin": 40065, "end": 40258, "id": "b14", "idx": 14}, {"begin": 40262, "end": 40511, "id": "b15", "idx": 15}, {"begin": 40515, "end": 40669, "id": "b16", "idx": 16}, {"begin": 40673, "end": 40897, "id": "b17", "idx": 17}, {"begin": 40901, "end": 41113, "id": "b18", "idx": 18}, {"begin": 41117, "end": 41354, "id": "b19", "idx": 19}, {"begin": 41358, "end": 41634, "id": "b20", "idx": 20}, {"begin": 41638, "end": 41848, "id": "b21", "idx": 21}, {"begin": 41852, "end": 42141, "id": "b22", "idx": 22}, {"begin": 42145, "end": 42359, "id": "b23", "idx": 23}, {"begin": 42363, "end": 42687, "id": "b24", "idx": 24}, {"begin": 42691, "end": 42954, "id": "b25", "idx": 25}, {"begin": 42958, "end": 43163, "id": "b26", "idx": 26}, {"begin": 43167, "end": 43409, "id": "b27", "idx": 27}, {"begin": 43413, "end": 43660, "id": "b28", "idx": 28}, {"begin": 43664, "end": 43844, "id": "b29", "idx": 29}, {"begin": 43848, "end": 44019, "id": "b30", "idx": 30}], "Sentence": [{"begin": 93, "end": 219, "idx": 0}, {"begin": 220, "end": 334, "idx": 1}, {"begin": 335, "end": 465, "idx": 2}, {"begin": 466, "end": 649, "idx": 3}, {"begin": 650, "end": 853, "idx": 4}, {"begin": 854, "end": 903, "idx": 5}, {"begin": 904, "end": 1069, "idx": 6}, {"begin": 1070, "end": 1275, "idx": 7}, {"begin": 1276, "end": 1313, "idx": 8}, {"begin": 1314, "end": 1438, "idx": 9}, {"begin": 1439, "end": 1583, "idx": 10}, {"begin": 1584, "end": 1654, "idx": 11}, {"begin": 1655, "end": 1758, "idx": 12}, {"begin": 1772, "end": 1816, "idx": 13}, {"begin": 1842, "end": 1981, "idx": 14}, {"begin": 1982, "end": 2135, "idx": 15}, {"begin": 2136, "end": 2206, "idx": 16}, {"begin": 2207, "end": 2359, "idx": 17}, {"begin": 2360, "end": 2446, "idx": 18}, {"begin": 2447, "end": 2707, "idx": 19}, {"begin": 2708, "end": 2825, "idx": 20}, {"begin": 2826, "end": 3050, "idx": 21}, {"begin": 3051, "end": 3257, "idx": 22}, {"begin": 3258, "end": 3377, "idx": 23}, {"begin": 3378, "end": 3494, "idx": 24}, {"begin": 3495, "end": 3659, "idx": 25}, {"begin": 3660, "end": 3883, "idx": 26}, {"begin": 3884, "end": 3983, "idx": 27}, {"begin": 3984, "end": 4128, "idx": 28}, {"begin": 4129, "end": 4280, "idx": 29}, {"begin": 4281, "end": 4429, "idx": 30}, {"begin": 4430, "end": 4525, "idx": 31}, {"begin": 4526, "end": 4651, "idx": 32}, {"begin": 4652, "end": 4797, "idx": 33}, {"begin": 4798, "end": 4965, "idx": 34}, {"begin": 4966, "end": 5150, "idx": 35}, {"begin": 5151, "end": 5306, "idx": 36}, {"begin": 5307, "end": 5499, "idx": 37}, {"begin": 5500, "end": 5815, "idx": 38}, {"begin": 5816, "end": 5895, "idx": 39}, {"begin": 5896, "end": 6015, "idx": 40}, {"begin": 6016, "end": 6193, "idx": 41}, {"begin": 6194, "end": 6349, "idx": 42}, {"begin": 6350, "end": 6543, "idx": 43}, {"begin": 6544, "end": 6738, "idx": 44}, {"begin": 6739, "end": 6922, "idx": 45}, {"begin": 6923, "end": 7009, "idx": 46}, {"begin": 7010, "end": 7060, "idx": 47}, {"begin": 7061, "end": 7347, "idx": 48}, {"begin": 7348, "end": 7474, "idx": 49}, {"begin": 7475, "end": 7584, "idx": 50}, {"begin": 7585, "end": 7769, "idx": 51}, {"begin": 7816, "end": 7916, "idx": 52}, {"begin": 7917, "end": 8047, "idx": 53}, {"begin": 8048, "end": 8121, "idx": 54}, {"begin": 8122, "end": 8251, "idx": 55}, {"begin": 8252, "end": 8414, "idx": 56}, {"begin": 8415, "end": 8516, "idx": 57}, {"begin": 8517, "end": 8609, "idx": 58}, {"begin": 8610, "end": 8707, "idx": 59}, {"begin": 8708, "end": 8800, "idx": 60}, {"begin": 8801, "end": 8908, "idx": 61}, {"begin": 8909, "end": 8962, "idx": 62}, {"begin": 8963, "end": 9115, "idx": 63}, {"begin": 9116, "end": 9225, "idx": 64}, {"begin": 9254, "end": 9382, "idx": 65}, {"begin": 9383, "end": 9535, "idx": 66}, {"begin": 9536, "end": 9694, "idx": 67}, {"begin": 9695, "end": 9768, "idx": 68}, {"begin": 9769, "end": 9959, "idx": 69}, {"begin": 9960, "end": 10072, "idx": 70}, {"begin": 10073, "end": 10166, "idx": 71}, {"begin": 10167, "end": 10275, "idx": 72}, {"begin": 10302, "end": 10382, "idx": 73}, {"begin": 10383, "end": 10461, "idx": 74}, {"begin": 10462, "end": 10505, "idx": 75}, {"begin": 10506, "end": 10648, "idx": 76}, {"begin": 10649, "end": 10831, "idx": 77}, {"begin": 10832, "end": 10944, "idx": 78}, {"begin": 10959, "end": 11165, "idx": 79}, {"begin": 11166, "end": 11217, "idx": 80}, {"begin": 11218, "end": 11302, "idx": 81}, {"begin": 11303, "end": 11427, "idx": 82}, {"begin": 11428, "end": 11525, "idx": 83}, {"begin": 11526, "end": 11628, "idx": 84}, {"begin": 11629, "end": 11726, "idx": 85}, {"begin": 11752, "end": 11842, "idx": 86}, {"begin": 11843, "end": 12063, "idx": 87}, {"begin": 12064, "end": 12165, "idx": 88}, {"begin": 12166, "end": 12282, "idx": 89}, {"begin": 12283, "end": 12353, "idx": 90}, {"begin": 12354, "end": 12551, "idx": 91}, {"begin": 12552, "end": 12699, "idx": 92}, {"begin": 12700, "end": 12771, "idx": 93}, {"begin": 12863, "end": 13024, "idx": 94}, {"begin": 13025, "end": 13083, "idx": 95}, {"begin": 13084, "end": 13243, "idx": 96}, {"begin": 13244, "end": 13391, "idx": 97}, {"begin": 13623, "end": 13686, "idx": 98}, {"begin": 13732, "end": 13944, "idx": 99}, {"begin": 13945, "end": 14053, "idx": 100}, {"begin": 14101, "end": 14308, "idx": 101}, {"begin": 14309, "end": 14462, "idx": 102}, {"begin": 14463, "end": 14524, "idx": 103}, {"begin": 14525, "end": 14587, "idx": 104}, {"begin": 14588, "end": 14803, "idx": 105}, {"begin": 14804, "end": 14895, "idx": 106}, {"begin": 14896, "end": 15089, "idx": 107}, {"begin": 15090, "end": 15287, "idx": 108}, {"begin": 15288, "end": 15334, "idx": 109}, {"begin": 15335, "end": 15446, "idx": 110}, {"begin": 15447, "end": 15525, "idx": 111}, {"begin": 15526, "end": 15723, "idx": 112}, {"begin": 15724, "end": 15891, "idx": 113}, {"begin": 15892, "end": 16020, "idx": 114}, {"begin": 16021, "end": 16164, "idx": 115}, {"begin": 16165, "end": 16353, "idx": 116}, {"begin": 16354, "end": 16503, "idx": 117}, {"begin": 16504, "end": 16696, "idx": 118}, {"begin": 16697, "end": 16762, "idx": 119}, {"begin": 16812, "end": 16978, "idx": 120}, {"begin": 16979, "end": 17161, "idx": 121}, {"begin": 17162, "end": 17324, "idx": 122}, {"begin": 17325, "end": 17353, "idx": 123}, {"begin": 17570, "end": 17681, "idx": 124}, {"begin": 17682, "end": 17760, "idx": 125}, {"begin": 17761, "end": 17819, "idx": 126}, {"begin": 17820, "end": 17918, "idx": 127}, {"begin": 17919, "end": 17990, "idx": 128}, {"begin": 18303, "end": 18425, "idx": 129}, {"begin": 18426, "end": 18523, "idx": 130}, {"begin": 18588, "end": 18692, "idx": 131}, {"begin": 18820, "end": 18960, "idx": 132}, {"begin": 18961, "end": 19191, "idx": 133}, {"begin": 19192, "end": 19237, "idx": 134}, {"begin": 19238, "end": 19344, "idx": 135}, {"begin": 19345, "end": 19414, "idx": 136}, {"begin": 19547, "end": 19658, "idx": 137}, {"begin": 19659, "end": 19730, "idx": 138}, {"begin": 19731, "end": 19813, "idx": 139}, {"begin": 19814, "end": 19878, "idx": 140}, {"begin": 19902, "end": 20059, "idx": 141}, {"begin": 20060, "end": 20174, "idx": 142}, {"begin": 20175, "end": 20320, "idx": 143}, {"begin": 20321, "end": 20438, "idx": 144}, {"begin": 20439, "end": 20491, "idx": 145}, {"begin": 20492, "end": 20497, "idx": 146}, {"begin": 20498, "end": 20508, "idx": 147}, {"begin": 20509, "end": 20716, "idx": 148}, {"begin": 20717, "end": 20865, "idx": 149}, {"begin": 20866, "end": 20994, "idx": 150}, {"begin": 20995, "end": 21031, "idx": 151}, {"begin": 21032, "end": 21140, "idx": 152}, {"begin": 21141, "end": 21262, "idx": 153}, {"begin": 21263, "end": 21445, "idx": 154}, {"begin": 21446, "end": 21511, "idx": 155}, {"begin": 21512, "end": 21571, "idx": 156}, {"begin": 21595, "end": 21601, "idx": 157}, {"begin": 21602, "end": 21709, "idx": 158}, {"begin": 21736, "end": 21812, "idx": 159}, {"begin": 21839, "end": 22026, "idx": 160}, {"begin": 22027, "end": 22109, "idx": 161}, {"begin": 22110, "end": 22236, "idx": 162}, {"begin": 22237, "end": 22379, "idx": 163}, {"begin": 22380, "end": 22525, "idx": 164}, {"begin": 22551, "end": 22676, "idx": 165}, {"begin": 22677, "end": 22846, "idx": 166}, {"begin": 22847, "end": 23042, "idx": 167}, {"begin": 23043, "end": 23094, "idx": 168}, {"begin": 23253, "end": 23389, "idx": 169}, {"begin": 23390, "end": 23508, "idx": 170}, {"begin": 23530, "end": 23667, "idx": 171}, {"begin": 23668, "end": 23831, "idx": 172}, {"begin": 23832, "end": 23987, "idx": 173}, {"begin": 24013, "end": 24099, "idx": 174}, {"begin": 24442, "end": 24555, "idx": 175}, {"begin": 24556, "end": 24672, "idx": 176}, {"begin": 24701, "end": 24824, "idx": 177}, {"begin": 24825, "end": 24967, "idx": 178}, {"begin": 24968, "end": 25257, "idx": 179}, {"begin": 25258, "end": 25350, "idx": 180}, {"begin": 25351, "end": 25447, "idx": 181}, {"begin": 25448, "end": 25526, "idx": 182}, {"begin": 25527, "end": 25687, "idx": 183}, {"begin": 25688, "end": 25794, "idx": 184}, {"begin": 25795, "end": 25919, "idx": 185}, {"begin": 25920, "end": 26019, "idx": 186}, {"begin": 26020, "end": 26078, "idx": 187}, {"begin": 26079, "end": 26174, "idx": 188}, {"begin": 26175, "end": 26275, "idx": 189}, {"begin": 26276, "end": 26361, "idx": 190}, {"begin": 26362, "end": 26495, "idx": 191}, {"begin": 26511, "end": 26761, "idx": 192}, {"begin": 26762, "end": 26808, "idx": 193}, {"begin": 26809, "end": 26857, "idx": 194}, {"begin": 26858, "end": 26957, "idx": 195}, {"begin": 26958, "end": 27057, "idx": 196}, {"begin": 27058, "end": 27139, "idx": 197}, {"begin": 27140, "end": 27232, "idx": 198}, {"begin": 27233, "end": 27378, "idx": 199}, {"begin": 27379, "end": 27455, "idx": 200}, {"begin": 27456, "end": 27568, "idx": 201}, {"begin": 27569, "end": 27687, "idx": 202}, {"begin": 27710, "end": 27742, "idx": 203}, {"begin": 27743, "end": 27837, "idx": 204}, {"begin": 27838, "end": 27887, "idx": 205}, {"begin": 27888, "end": 27974, "idx": 206}, {"begin": 27975, "end": 28093, "idx": 207}, {"begin": 28094, "end": 28209, "idx": 208}, {"begin": 28210, "end": 28386, "idx": 209}, {"begin": 28387, "end": 28468, "idx": 210}, {"begin": 28469, "end": 28542, "idx": 211}, {"begin": 28543, "end": 28720, "idx": 212}, {"begin": 28721, "end": 28833, "idx": 213}, {"begin": 28834, "end": 29046, "idx": 214}, {"begin": 29047, "end": 29191, "idx": 215}, {"begin": 29192, "end": 29242, "idx": 216}, {"begin": 29267, "end": 29359, "idx": 217}, {"begin": 29360, "end": 29451, "idx": 218}, {"begin": 29452, "end": 29572, "idx": 219}, {"begin": 29573, "end": 29672, "idx": 220}, {"begin": 29673, "end": 29726, "idx": 221}, {"begin": 29727, "end": 29775, "idx": 222}, {"begin": 29801, "end": 29855, "idx": 223}, {"begin": 29856, "end": 29902, "idx": 224}, {"begin": 29903, "end": 30016, "idx": 225}, {"begin": 30017, "end": 30113, "idx": 226}, {"begin": 30181, "end": 30256, "idx": 227}, {"begin": 30257, "end": 30345, "idx": 228}, {"begin": 30353, "end": 30519, "idx": 229}, {"begin": 30520, "end": 30682, "idx": 230}, {"begin": 30683, "end": 30790, "idx": 231}, {"begin": 30791, "end": 30959, "idx": 232}, {"begin": 30960, "end": 31031, "idx": 233}, {"begin": 31032, "end": 31181, "idx": 234}, {"begin": 31182, "end": 31353, "idx": 235}, {"begin": 31354, "end": 31490, "idx": 236}, {"begin": 31491, "end": 31579, "idx": 237}, {"begin": 31580, "end": 31623, "idx": 238}, {"begin": 31624, "end": 31667, "idx": 239}, {"begin": 31668, "end": 31735, "idx": 240}, {"begin": 31736, "end": 31788, "idx": 241}, {"begin": 31789, "end": 31936, "idx": 242}, {"begin": 31957, "end": 32110, "idx": 243}, {"begin": 32111, "end": 32156, "idx": 244}, {"begin": 32157, "end": 32305, "idx": 245}, {"begin": 32306, "end": 32357, "idx": 246}, {"begin": 32358, "end": 32550, "idx": 247}, {"begin": 32572, "end": 32668, "idx": 248}, {"begin": 32669, "end": 32931, "idx": 249}, {"begin": 32932, "end": 33052, "idx": 250}, {"begin": 33053, "end": 33214, "idx": 251}, {"begin": 33215, "end": 33363, "idx": 252}, {"begin": 33364, "end": 33447, "idx": 253}, {"begin": 33472, "end": 33595, "idx": 254}, {"begin": 33596, "end": 33649, "idx": 255}, {"begin": 33650, "end": 33778, "idx": 256}, {"begin": 33779, "end": 33895, "idx": 257}, {"begin": 33930, "end": 34082, "idx": 258}, {"begin": 34083, "end": 34187, "idx": 259}, {"begin": 34188, "end": 34316, "idx": 260}, {"begin": 34317, "end": 34322, "idx": 261}, {"begin": 34323, "end": 34342, "idx": 262}, {"begin": 34343, "end": 34396, "idx": 263}, {"begin": 34397, "end": 34463, "idx": 264}, {"begin": 34464, "end": 34556, "idx": 265}, {"begin": 34557, "end": 34643, "idx": 266}, {"begin": 34676, "end": 34743, "idx": 267}, {"begin": 34744, "end": 34847, "idx": 268}, {"begin": 34848, "end": 34902, "idx": 269}, {"begin": 34903, "end": 35029, "idx": 270}, {"begin": 35030, "end": 35098, "idx": 271}, {"begin": 35099, "end": 35182, "idx": 272}, {"begin": 35183, "end": 35278, "idx": 273}, {"begin": 35279, "end": 35489, "idx": 274}, {"begin": 35510, "end": 35680, "idx": 275}, {"begin": 35681, "end": 35803, "idx": 276}, {"begin": 35804, "end": 35991, "idx": 277}, {"begin": 36006, "end": 36155, "idx": 278}, {"begin": 36156, "end": 36317, "idx": 279}, {"begin": 36318, "end": 36398, "idx": 280}, {"begin": 36399, "end": 36558, "idx": 281}, {"begin": 36559, "end": 36681, "idx": 282}, {"begin": 36682, "end": 36826, "idx": 283}, {"begin": 36827, "end": 36965, "idx": 284}], "ReferenceToFigure": [{"begin": 11173, "end": 11174, "idx": 0}, {"begin": 15519, "end": 15523, "target": "#fig_1", "idx": 1}, {"begin": 15716, "end": 15717, "target": "#fig_1", "idx": 2}, {"begin": 20736, "end": 20737, "idx": 3}, {"begin": 32313, "end": 32314, "target": "#fig_4", "idx": 4}, {"begin": 32779, "end": 32780, "target": "#fig_4", "idx": 5}, {"begin": 33603, "end": 33604, "target": "#fig_5", "idx": 6}, {"begin": 34095, "end": 34096, "target": "#fig_4", "idx": 7}, {"begin": 34935, "end": 34936, "target": "#fig_8", "idx": 8}, {"begin": 35106, "end": 35107, "target": "#fig_8", "idx": 9}], "Abstract": [{"begin": 83, "end": 1816, "idx": 0}], "SectionFootnote": [{"begin": 36967, "end": 37221, "idx": 0}], "Footnote": [{"begin": 36978, "end": 37021, "id": "foot_0", "n": "1", "idx": 0}, {"begin": 37022, "end": 37065, "id": "foot_1", "n": "2", "idx": 1}, {"begin": 37066, "end": 37109, "id": "foot_2", "n": "3", "idx": 2}, {"begin": 37110, "end": 37141, "id": "foot_3", "n": "4", "idx": 3}, {"begin": 37142, "end": 37179, "id": "foot_4", "n": "5", "idx": 4}, {"begin": 37180, "end": 37221, "id": "foot_5", "n": "6", "idx": 5}]}}