{"text": "Predictive Modeling of Periodic Behavior for Human-Robot Symbiotic Walking\n\nAbstract:\nWe propose in this paper Periodic Interaction Primitives -a probabilistic framework that can be used to learn compact models of periodic behavior. Our approach extends existing formulations of Interaction Primitives to periodic movement regimes, i.e., walking. We show that this model is particularly well-suited for learning data-driven, customized models of human walking, which can then be used for generating predictions over future states or for inferring latent, biomechanical variables. We also demonstrate how the same framework can be used to learn controllers for a robotic prosthesis using an imitation learning approach. Results in experiments with human participants indicate that Periodic Interaction Primitives efficiently generate predictions and ankle angle control signals for a robotic prosthetic ankle, with MAE of 2.21 \u2022 in 0.0008s per inference. Performance degrades gracefully in the presence of noise or sensor fall outs. Compared to alternatives, this algorithm functions 20 times faster and performed 4.5 times more accurately on test subjects.\n\nMain:\n\n\n\nI. INTRODUCTION\nWalking is a critical motor skill which is at the center of human mobility and independence. Healthy human adults on average walk several thousand steps per day seemingly without any effort and with substantial grace and fluency to their movements. However, for many millions of people [1] affected by musculoskeletal disorders, amputations, neurologic pathologies, or other health-related issues walking is a daily struggle or even completely out of reach [2], [3]. Modern assistive robotics technology (e.g. an exoskeleton, orthotic or prosthetic) has the potential to change the lives of people affected by such conditions for the better, by replacing missing, or augmenting existing capabilities. However, methodologies are needed that allow robots to generate periodic actions that seamlessly blend with those of the human user [4].\nIn particular, such assistive robots need to be able to anticipate future kinematic states of the human partner given current sensor readings of their walking gait [5], thereby providing a window of opportunity for decisionmaking and control. In addition to predicting kinematics, it is suggested that assistive devices also take biomechanical and ergonomic ramifications on the human body into account [6]. Considering that different walking gaits result in varying magnitudes in internal stresses being applied to the human Fig. 1. PIP is used to learn a realtime, closed-loop controller for symbiotic walking by analyzing and predicting sensor values, as well as control signals.\nmusculoskeletal system; it is important that assistive robots can generate estimates of biomechanical variables in a rapid and predictive fashion to avoid overexertion, injury, or even serious chronic diseases such as osteoarthritis (OA) [7]. Inverse dynamics [8] techniques can generate accurate estimates of internal biomechanical variables, but are generally slow and non-predictive in nature. In addition, they often require information from high-fidelity sensors, usually motion capture and an instrumented treadmill with force plates, which is typically not available outside of controlled laboratory environments. Hence, other methods are needed to be used in non-clinical settings with low-fidelity sensors and can run on devices with limited computational power.\nTherefore we propose Periodic Interaction Primitives (PIP) -an extension to interaction primitives (IP) [9]. PIP is a data-driven approach to the predictive modeling of periodic behavior for human-robot symbiotic walking, i.e., effortless walking with an intelligent prosthesis, exoskeleton, or other assistive device. Once trained, a PIP can be used for anticipating the future states of the human user, such as kinematics from observed sensors, and inferring latent, unobserved variables, for instance internal biomechanical variables or external prosthesis or exoskeleton control without the further necessity of a motion capture system or additional biomechanical model. These features are achieved, by correlating at runtime, the information captured from multiple sensors with corresponding biomechanical or control parameters which are incorporated during the training process. PIP is differentiated from previous interaction primitives in three ways.  (1) We tie the statistical processes of IP to a periodic domain through the use of von Mises basis functions and provide analytical formulations of partial derivatives with respect to phase.  (2) In concert with periodicity modifications, PIP incorporates a novel phase estimation method which is effective in tightly-coupled or symbiotic systems which exhibit periodic phase behavior.  (3) We describe a data augmentation scheme that allows PIPs to infer unobservable, biomechanical information through latent variable estimation.\n\nII. RELATED WORK\nEarly work on control involving prosthetics and exoskeletons has primarily focused on the control aspects of the human robot system [10]. Controllers have been successfully developed for both transtibial [11] and transfemoral [12] applications. Extensions have also been made, which provide control parameters for a variety of common terrains such as navigating slopes [13] or stairs [14]. While these methods have been shown to produce robust and stable controllers, there are a number of downsides. First, these control systems are entirely reactive to the human subject. Second, they must be closely tuned to match each individuals walking gait.\nIn contrast, data-driven approaches to the probabilistic modeling of HRI often leverage hidden Markov models [15] [16] [17], which are well-suited for the joint inference problems commonly encountered in interaction. However, they often require a discretization of the state space and suffer from computational overhead too large to be feasibly placed onto the low-power microprocessors that prosthetic devices require.\nOne method that overcomes some of these limitations is called Probabilistic Movement Primitives (ProMP) [18], [19]. As a probabilistic formulation of the Movement Primitivies concept, this method uses a stochastic feedback controller to reproduce learned trajectory distributions, both stroke based and rhythmic, with predefined phase progression. By incorporating a probabilistic framework (utilizing the demonstration variance) ProMPs allow for greater flexibility in trajectory reproduction than deterministic methods.\nIn order to increase flexibility and accuracy even further Interaction Primitives were proposed, as a learning from demonstration method in which a joint probability distribution is created over the parameterized models of two interacting agents. By incorporating the full joint trajectory distribution IPs enable the inference of all modeled parameters based on a sample set of observed parameters. This approach has proven capable in several different scenarios [20] [21] [22] [23] [24]. However while potential for rhythmic behaviors has been proposed before, careful management of basis functions as well as modifications to phase estimation must be made to to take periodicity into account. Additionally, these methods do not yet address the problem of inferring temporal position in highly dynamic tightly coupled periodic systems; where the behavior of the human influences the behavior of the robot and vice versa. Instead they utilize methods such as dynamic time warping (DTW) to help determine the correct phase of the system for interaction, which are too computationally demanding to be used in run in real-time on assistive devices. This type of symbiosis between the human and robot, where there is constant reaction and interaction, necessitates new methods of quantifying and modeling interactions.\n\nIII. PREDICTIVE MODELING WITH PERIODIC INTERACTION PRIMITIVES\nThe approach proposed in this paper focuses on probabilistic modeling and inference of periodic behavior during walking. The main goal is to learn a predictive model that relates current multimodal sensor readings to future states of the human during the walking gait. In contrast to previous modeling approaches, we simultaneously predict: (a) observable sensor values, (b) unobservable biomechanical data, as well as potentially (c) control values for a prosthesis, exoskeleton or other assistive device.\nAs an overview of the algorithm presented in this paper; first a data set is collected which represents typical variations in sensor readings during walking. The data set is then augmented with biomechanical information from the subject via tools such as OpenSim [25] or Vicon Nexus [26], as well as control signals for which action an assistive device or prosthesis should take at each timestep. The final step of the learning process is to train the predictive model, which extracts and efficiently represents the correlations and dynamics inherent in the data. The goal of PIP is to represent the reciprocal coupling between observed data (sensor values), unobservable data (extracted biomechanical parameters), and control variables (angular control value for a prosthetic ankle), instead of an analytical formulation of the dynamics.\n\nA. Training: Data Collection and Data Augmentation\nOne benefit of PIP is that variables which are not observed though the sensors such as: joint torques, muscle lengths, metabolic power consumption, or mechanical work can be inferred. We accomplish this by incorporating the internal biomechanical variables and their distributions w.r.t. time directly into our predictive models; in the following manner.\nEach user performs a walking action spanning multiple gait cycles which produces a time series of sensor measurements. This time series is subdivided into a set of N individual demonstrations, each representing a single gait cycle, [y 1 , . . . , y Tn ] \u2208 R Ds\u00d7Tn , such that D s is the total number of degrees of freedom from all sensors and T n is the number of observations for the n-th demonstration.\nGiven the set of individual demonstrations, the trajectories of unobservable variables [m 1 , . . . , m Tn ] \u2208 R Dm\u00d7Tn , such that D m is total number of degrees of freedom for all unobservable variables, is calculated using a desired analysis tool. The original sensor observations are then augmented such that Y 1:t = [y t , m t ] \u2208 R D forms the new state representation of the human at every time step, whereD = D s + D m .\nThe objective of this approach is to turn the estimation of internal variables into a function approximation problem which will run significantly faster and will work even when variables are missing. By incorporating unobservable variables into the training process, we can later leverage the PIP framework to infer internal loads using observable variables alone.\n\nB. Training: Learning a Periodic Interaction Primitive\nProbabilistically, the objective of PIP is to infer estimates of the future states of both the observed and non-observed variables \u0176 t+1:T , given observations of the human Y 1:t :p( \u0176 t+1:T |Y 1:t ).\nThis requires us to define a state transition model for each degree of freedom along with an observation model relating the unobservable variables to the observed variables based on our set of training demonstrations. As previously established [21], we can simplify this process significantly by first transforming our state representation into a latent space via basis function decomposition. That is, we want to find a vector of coefficients w d for each degree of freedom 0 \u2264 d < D such that y d t = \u03a6 \u03c6(t) w d + y for all observations in the training demonstrations, where\u03a6 \u03c6(t) \u2208 R B d \u00d71 is a vector of B d basis functions, w d \u2208 R B d \u00d71 , and y is i.i.d. Gaussian noise.\nThis decomposition accomplishes three goals: a) it produces a time-invariant state w d for each DOF, allowing inference of all past and future values from a single state value, b) it captures the dynamics of each DOF over time, eliminating the need for an explicit transition function, and c) it allows for correlation between different DOFs. A necessary component of the above decomposition is the introduction of a temporal dependence for the basis functions on a relative phase function \u03c6(t) \u2208 [0, 100], or for notational simplicity \u03c6. Utilizing phase decouples the relative progress of an interaction from its absolute length, thus preserving the shape of a trajectory across temporal speeds and allows for the efficient calculation of the values for a DOF for an entire interaction: Y d 1:P = [\u03a6 w d ] where \u03a6 = [\u03a6 0 , . . . , \u03a6 100 ] \u2208 R B\u00d7P . P here represents the number of sampled points for the trajectory and has the additional benefit of acting as a smoothing function. We succinctly represent all DOFs in our state representation by concatenating them into a single weight vector:w = [w 0 , . . . , w D ] \u2208 R 1\u00d7B with B = D d B d .\nBy its very nature walking is a periodic action and biomechanical analyses have therefore shown that gait cycles can be quantitatively described by phase plane evaluations [27]. So as to truly capture the periodic nature of our state variables, we must choose an appropriate basis function which operates over a cyclical domain. This is in contrast to prior work in IPs which employ Gaussian basis functions for trajectories with distinct start and end points. In this work, we utilize the von Mises function, an approximation of the wrapped normal distribution over the domain of the unit circle:\u03c8 \u00b5 (\u03c6) = e \u03bacos(\u03b1(\u03c6\u2212\u00b5)) 2\u03c0I 0 (\u03ba) ,\nwhere \u00b5 lies in the interval [0, 2\u03c0] and specifies the center of the basis function, \u03b1 is 2\u03c0/100 (required to transform the phase into [0, 2\u03c0]), \u03ba is a measure of inverse variance, and I 0 is the modified Bessel function of order zero.\n\nC. Inference: Phase Detection\nWith the basis space fully defined, we re-formulate our probabilistic objective from (1) asp(w t |Y 1:t , w 0 ) \u221d p(y t |w t )p(w t |Y 1:t\u22121 , w 0 ). (3)\nIntuitively, the goal is to infer the state of the interaction w t given t observations of the human and a prior estimate of the state, w 0 . However, without knowing the phase values associated with the observations Y 1:t we cannot apply a correction to our estimate, and so we must first estimate the phase \u03c6 for each observation y t . As part of the training process we create a low dimensional manifold, or subspace, encompassing the phase and observed variables. The created manifold allows for the efficient projection of observations onto the manifold so as to determine the corresponding phase.\nBefore we can construct this manifold model, we must first temporally align the demonstration gait cycles. This is required as gaits are nonlinearly warped in time through variations in walking speed, incline, and other environmental and biomechanical factors. According to existing analyses on complex joint movements, there are quantitative relationships between the positions of the knee, tibia, and ankle with respect to the phase plane. In this work, we exploit these relationships to temporally align our demonstrations through measurements of the angular position, angular velocity, and angular acceleration of the tibia. While the position and velocity are directly observed, the acceleration is not. Instead it is computed through the partial derivative of the linear combination of basis functions with respect to the phase:\u2202 B d b \u03c8 b (\u03c6)w d b \u2202\u03c6 = B d b w d b \u2202\u03c8 b (\u03c6) \u2202\u03c6 (4) = B d b w d b \u03ba sin(\u03b1(\u00b5 b \u2212 \u03c6))e \u03ba cos(\u03b1(\u00b5 b \u2212\u03c6)) 2\u03c0I o (\u03ba) ,\nwhere d corresponds to the tibia angular velocity DOF.\nTemporal alignment is performed with dynamic time warping (DTW) [28], in which the distance between two demonstrations u and v is computed as a cost matrix C. The optimal alignment can be found as the minimum path through the cost matrix,C p * (u, v) = min L l=1 c(u n l , v m l ) ,\nwhere the cost function c(\u2022) is the sum of the Euclidean distances between angular positions, velocities, and accelerations. Since we wish to align all demonstrated trajectories, the full set of trajectories are temporally aligned creating an approximately optimal time alignment between all demonstrations. We assume that all aligned demonstrations lie over the phase interval [0, 100], such that the first time step is 0 and the last is 100. Finally, we discretize the data over two dimensions -E angular position states and F angular velocity states -and assign each discrete state a phase value determined via the nearest neighbor in the set of aligned trajectories. This creates an E \u00d7 F lookup table, in the subspace or manifold, that can be queried quickly to approximate phase from angular position and velocity. We denote the lookup function L(y t ) which accepts an observation from which the angular position and velocity are projected onto the table and the resulting phase \u03c6 is returned.\n\nD. Inference: Generating Predictions and Controls\nIn order to evaluate the posterior probability of (3), we utilize a full state linear estimator, i.e. Kalman filter, to recursively apply Gaussian conditioning to a matrix of basis weights. Which evaluates the state prediction density as,p(w t |Y 1:t\u22121 , w 0 ) = p(w t |w t\u22121 )p(w t\u22121 |Y 1:t\u22121 , w 0 )dw t\u22121\nFor tractability, we make the assumption that the posterior state densities are normally distributed, that is, p(w t |Y 1:t , w 0 ) = N (\u00b5 t , \u03a3 t ). Additionally, because our state has been transformed into a time-invariant representation, we no longer have a meaningful state transition function in time. That is, p(w t |Y 1:t\u22121 , w 0 ) = p(w t\u22121 |Y 1:t\u22121 , w 0 ). The observation function, h(\u2022), is simply the linear combination of weighted basis functions as described in Sec. III-B and the observation matrix H is defined as:H t = \uf8ee \uf8ef \uf8f0 \u03a6 \u03c6 . . . 0 . . . . . . . . . 0 . . . \u03a6 \u03c6 \uf8f9 \uf8fa \uf8fb .\nThe standard update equations for the calculation of the posterior density follow:K t = \u03a3 t\u22121 H t (H t \u03a3 t\u22121 H t + R t ) \u22121 , () \u00b5 t = \u00b5 t\u22121 + K t (y t \u2212 H t \u00b5 t\u22121 ),\u03a3 t = (I \u2212 K t H t )\u03a3 t\u22121 ,\nwhere K is the Kalman gain matrix which controls how heavily we update our state estimate based on the observed measurement while taking into account the measurement noise matrix R t . While the observation matrix given here includes both the observed and controlled DOFs, in practice only the observed DOFs are considered. This can be orchestrated by either setting the entries corresponding to the controlled DOFs to zero in H t , or regularizing them with artificial noise in R t . Future trajectories for any degree of freedom d, including the controlled ones, can be trivially calculated with Y d1:P = [\u03a6 \u00b5 d t ]\n. The initial estimate, p(w 0 ) = N (\u00b5 0 , \u03a3 0 ), is determined from the set of basis weights generated from the demonstrations, where \u00b5 0 is the sample mean and \u03a3 0 is the sample covariance.\nThe PIP algorithm is shown in its entirety in Fig. 2. At the first time step, the previous state estimate is given as \u00b5 0 Periodic Interaction Primitives Input: L(\u2022): phase lookup function, \u00b5 t\u22121 \u2208 R 1\u00d7B : prior distribution mean, \u03a3 t\u22121 \u2208 R B\u00d7B : prior distribution uncertainty, y t \u2208 R 1\u00d7Ds : sensor observations at t.\n\nOutput:\n\u0176 Ds 1:P \u2208 R P \u00d7Ds : inferred states of D s observed variables, \u0176 Dm 1:P \u2208 R P \u00d7Dm : inferred states of D m unobservable variables, \u00b5 t : the updated state mean, \u03a3 t : the updated state uncertainty. 1) Estimate phase \u03c6 using trained lookup function:\u03c6 = L(y t ).\n2) Compute the Kalman gain matrix:K t = \u03a3 t\u22121 H t (H t \u03a3 t\u22121 H t + R) \u22121 .\n3) Incorporate observations into the state estimate:\u00b5 t = \u00b5 t\u22121 + K t (y t \u2212 H t \u00b5 t\u22121 ), \u03a3 t = (I \u2212 K t H t )\u03a3 t\u22121 .\n4) Predict the past, present, and future states of all observed and unobserved state variables:\u0176 d 1:P = [\u03a6 w d ] for 0 < d < D. 5)\nOutput the observed states, unobservable states, and posterior distribution:\u0176 Ds 1:P , \u0176 Dm 1:P , \u00b5 t , \u03a3 t .\nFig. 2. Periodic Interaction Primitives and \u03a3 0 . In subsequent steps, the updated state estimate is used as the prior.\n\nIV. EXPERIMENTAL SETUP\n\n\nA. Data Collection\nData collection was performed in a human subject study approved by the Institutional Review Board at Arizona State University. Five participants were fitted with smart shoes, IMUs and retroreflective markers for a VICON motion capture system with 10 cameras. Four IMU devices, one on each shank and one on each femur output 9DOF inertial data as well as angular position from a proprietary embedded sensor fusion algorithm. The smart shoes measure ground reaction forces at four points: heel, first metatarsal joint, fourth metatarsal joint and toe, through silicone tubes which are wound into air bladders, placed in the soles of the shoes, and connected to barometric pressure sensors. To collect biomechanical data, each participant was asked to walk on an instrumented treadmill at 5 different speeds from 0.5m/s to 1.3m/s for 2 min at each speed in a single trial. Motion Capture marker positions and ground reaction force data was collected on the subjects and processed with the common commercially available biomechanics model: Vicon PlugInGait model (version 2) in Vicon Nexus software [26] to calculate joint angles (angles between skeletal links), forces (reflected force from one skeletal link to another), and moments (torque between skeletal links). The entire learning process from raw data to testable model output takes approximately 3 minutes. Subjects were divided into two groups three subjects for training and two for testing. Ten consecutive strides from each subject were removed from the full data set as holdout data for testing and model evaluation.\n\nB. Experiment 1: Predictive Capabilities\nThe first experiment evaluates the inference and prediction capabilities of the introduced PIP method by assessing: (a) the accuracy of the estimated phase variable when the subjects are walking at different speeds, and (b) the prediction quality of the learned models on observed variables. Fig. 3 shows an example of the PIP phase detection method as compared to the common method of dynamic time warping, with the phase manifold on the left plot and the detected phase on the right plot. The phase manifold illustrates how each point in the space is directly associated with a specific phase value, when individual observations occur, phase is directly estimated through the use of a 2D lookup function. This leads to a very accurate phase detection which works over a large range of walking speeds. The common phase detection method of Dynamic Time Warping is further compared against the PIP phase detection method to show that the PIP phase detection method is more accurate as it lacks the temporal disturbances commonly present in DTW. During this experiment the inference time of each phase detection method was collected and it was found that the PIP method is significantly faster requiring 0.0004 seconds average vs 0.008 seconds average for DTW.\nTable I shows the mean absolute error (MAE) for prediction of sensor values via a PIP in the top section, using the joint model from all training subjects data, tested on each subject individually. We can see for example that the error on predicting the shank is in the range 1 \u2022 to 3 \u2022 , hence yielding accurate predictions for all participants. The shank velocity is at approximately 15 \u2022 . This may appear substantial, however, the prediction error amounts to a deviation of approximately 1.5%. In addition, all predictions of the foot pressure are lower than 30 mBar and are therefore also of high accuracy.\nFig. 4 shows the predictions for the shank angle and the smart shoe heel pressure. The red shaded area highlights the sensor readings, which have been used for conditioning, which generates the predictions starting at 0.25 seconds and ending at 1.4 seconds. For both variables, the PIP predictions (blue) accurately match the ground truth values (black). However, higher uncertainty in heel pressure persists during the swing phase, likely due to the variability in shoe pressure, resulting from air decompressing when lifting the heel.\nTable II shows how general the model is as well as a comparison to ProMP via. the errors present when tested with: PIP on the three training subjects, PIP two test subjects, and a ProMP model on two test subjects.\n\nC. Experiment 2: Latent Variable Estimation\nThe second experiment aims at evaluating how accurately the method predicts latent unobservable variables, e.g., biomechanical information that was added to the collected data during the data augmentation step (see Sec. III-A). Fig. 5 depicts the ground truth knee force along with the predicted values of the knee force as inferred via the PIP. The bottom section of Table (I) shows the kinematic and biomechanical variables that are inferred using this technique, namely ankle and knee: moments, forces and angles; along with the MAE for each subject. It is critical to note here, that the ground truth was obtained from the data augmentation process and therefore not composed of direct sensor measurements. Still,  Besides prediction accuracy, a critical aspect when using machine learning components on an assistive device is safety. It is important that predictions degrade gracefully (meaning minimal deterioration of the prediction accuracy) with noisy or missing sensor data. Fig. 5 shows an example for the graceful degradation as exhibited during inference in PIP, where sensors start failing one after the other. In the first section of the figure, all sensors are observed when making predictions. As sensors fail the uncertainty of the prediction grows and that the prediction accuracy slightly decreases. However, in general, the plot of the prediction trajectory still largely follows the ground truth.\n\nD. Experiment 3: Learning Control with PIPs\nThe last experiment evaluates the ability of PIPs to generate control signals for a powered lower limb prosthesis along with predictions. More specifically, we investigated if ankle angles from a healthy walking gait can be imitated and reproduced when wearing the active prosthesis using PIP. Each participant was asked to wear the SpringActive 6. Ankle angle when no prosthetic was worn (black), when using the SpringActive control software (yellow), and when using PIP inference (blue).\nOdyssey prosthesis [29], a battery powered lower limb prosthesis 1. Imitation of the subjects walking gait is achieved by inferring in real-time the (unobservable) ankle angle and sending it to the prosthesis for execution.\nFig. 6 depicts the ankle angle that resulted from this experiment. The black line is an example of ankle angle when no prosthesis is worn. Ankle angles recorded when the prosthesis was used in conjunction with both PIP in blue and the commercial control software originally shipped with the SpringActive Odyssey in yellow, with three example strides of each. It can be seen that while PIP closely tracks the expected ankle angle, the commercial control software substantially deviates from how the participant would naturally move. A ProMP controller was not compared against in this experiment, since the high ankle angle error seen in Table II would possibly make this controller unsafe.\n\nV. CONCLUSION\nIn this paper, we proposed Periodic Interaction Primitives, a probabilistic framework that can be used to learn compact models of periodic behavior in symbiotic systems. PIP facilitates prediction of future states of walking, as well as generation of control signals for assistive devices through its integrated phase estimation process. Most notably this approach extends Interaction Primitives to latent variables which are either unobservable or hard to measure in practice. For example, when collecting training data, we recorded motion capture readings to calculate offline biomechanical data such as ankle angles and internal forces of the subjects; but did not require additional motion capture readings at runtime. Instead, we use other low-cost sensors to estimate the biomechanical variables at each time-step.\nResults in experiments with human participants indicate that Periodic Interaction Primitives efficiently generates predictions and ankle angle control signals for a robotic prosthetic ankle, even of subjects that the model was not trained on, with MAE of 2.21 \u2022 in 0.0008s per inference. Even on devices with limited compute power it is expected that inference rates of 1000Hz can easily be achieved. Compared to ProMP, with MAE of 10.10 \u2022 in 0.0169s per inference which is too slow and inaccurate for use with a robotic prosthetic. Furthermore it was shown that performance degrades gracefully in the presence of noise or sensor fall outs. This work shows that the approach can quickly generate predictive models and controls using a purely data-driven methodology.\n\nFootnotes:\n\nReferences:\n\n- K. Ziegler-Graham, E. J. MacKenzie, P. L. Ephraim, T. G. Travison, and R. Brookmeyer, \"Estimating the prevalence of limb loss in the united states: 2005 to 2050,\" Archives of physical medicine and rehabilitation, vol. 89, no. 3, pp. 422-429, 2008.- A. Medhat, P. M. Huber, and M. A. Medhat, \"Factors that influence the level of activities in persons with lower extremity amputation,\" Rehabilitation Nursing, vol. 15, no. 1, pp. 13-18, 1990.\n\n- R. BUZGOV \u00c1, M. BUZGA, and J. KRISTIN \u00cdKOV \u00c1, \"Whoqol: Assessment of quality of life in patients after lower limb amputation.\" Acta Medica Martiniana, vol. 9, no. 1, 2009.\n\n- R. Weir, \"The great divide-the human-machine interface. issues in the control of prostheses, manipulators, and other human machine systems,\" in 2003 IEEE 29th Annual Proceedings of Bioengineering Conference. IEEE, 2003, pp. 275-276.\n\n- G. K. Klute, C. Kantor, C. Darrouzet, H. Wild, S. Wilkinson, S. Iveljic, and G. Creasey, \"Lower-limb amputee needs assessment using multi- stakeholder focus-group approach.\" Journal of Rehabilitation Research & Development, vol. 46, no. 3, 2009.\n\n- D. C. Morgenroth, A. D. Segal, K. E. Zelik, J. M. Czerniecki, G. K. Klute, P. G. Adamczyk, M. S. Orendurff, M. E. Hahn, S. H. Collins, and A. D. Kuo, \"The effect of prosthetic foot push-off on mechanical loading associated with knee osteoarthritis in lower extremity amputees,\" Gait & posture, vol. 34, no. 4, pp. 502-507, 2011.\n\n- D. C. Morgenroth, A. C. Gellhorn, and P. Suri, \"Osteoarthritis in the disabled population: A mechanical perspective,\" PM&R, vol. 4, no. 5, pp. S20 -S27, 2012, osteoarthritis. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S1934148212000263\n\n- G. Robertson, G. Caldwell, J. Hamill, G. Kamen, and S. Whittlesey, Research methods in biomechanics, 2E. Human Kinetics, 2013.\n\n- H. B. Amor, G. Neumann, S. Kamthe, O. Kroemer, and J. Peters, \"Interaction primitives for human-robot cooperation tasks,\" in 2014 IEEE international conference on robotics and automation (ICRA).\n\n- M. R. Tucker, J. Olivier, A. Pagel, H. Bleuler, M. Bouri, O. Lambercy, J. del R Mill\u00e1n, R. Riener, H. Vallery, and R. Gassert, \"Control strategies for active lower extremity prosthetics and orthotics: a review,\" Journal of neuroengineering and rehabilitation, vol. 12, no. 1, p. 1, 2015.\n\n- S. K. Au, J. Weber, and H. Herr, \"Powered ankle-foot prosthesis im- proves walking metabolic economy,\" IEEE Transactions on Robotics, vol. 25, no. 1, pp. 51-66, 2009.\n\n- F. Sup, H. A. Varol, J. Mitchell, T. J. Withrow, and M. Goldfarb, \"Pre- liminary evaluations of a self-contained anthropomorphic transfemoral prosthesis,\" IEEE/ASME Transactions on mechatronics, vol. 14, no. 6, pp. 667-676, 2009.\n\n- F. Sup, H. A. Varol, and M. Goldfarb, \"Upslope walking with a powered knee and ankle prosthesis: initial results with an amputee subject,\" IEEE transactions on neural systems and rehabilitation engineering, vol. 19, no. 1, pp. 71-78, 2010.\n\n- S. Au, M. Berniker, and H. Herr, \"Powered ankle-foot prosthesis to assist level-ground and stair-descent gaits,\" Neural Networks, vol. 21, no. 4, pp. 654-666, 2008.\n\n- L. R. Rabiner, \"A tutorial on hidden markov models and selected applications in speech recognition,\" Proceedings of the IEEE, vol. 77, no. 2, pp. 257-286, Feb 1989.\n\n- D. Lee and Y. Nakamura, \"Mimesis model from partial observations for a humanoid robot,\" The International Journal of Robotics Re- search, vol. 29, no. 1, pp. 60-80, 2010.\n\n- L. Rozo, J. Silv\u00e9rio, S. Calinon, and D. G. Caldwell, \"Learning controllers for reactive and proactive behaviors in human-robot col- laboration,\" Frontiers in Robotics and AI, vol. 3, no. 30, pp. 1-11, June 2016, specialty Section Robotic Control Systems.\n\n- A. Paraschos, C. Daniel, J. R. Peters, and G. Neumann, \"Probabilistic movement primitives,\" in Advances in neural information processing systems, 2013, pp. 2616-2624.\n\n- O. Dermy, A. Paraschos, M. Ewerton, J. Peters, F. Charpillet, and S. Ivaldi, \"Prediction of intention during interaction with icub with probabilistic movement primitives,\" Frontiers in Robotics and AI, vol. 4, p. 45, 2017.\n\n- Y. Cui, J. Poon, J. V. Miro, K. Yamazaki, K. Sugimoto, and T. Mat- subara, \"Environment-adaptive interaction primitives through visual context for human-robot motor skill learning,\" Autonomous Robots, Aug 2018.\n\n- J. Campbell and H. B. Amor, \"Bayesian interaction primitives: A slam approach to human-robot interaction,\" in Conference on Robot Learning, 2017, pp. 379-387.\n\n- O. S. Oguz, Z. Zhou, and D. Wollherr, \"A hybrid framework for understanding and predicting human reaching motions,\" Frontiers in Robotics and AI, vol. 5, p. 27, 2018.\n\n- L. Chen, H. Wu, S. Duan, Y. Guan, and J. Rojas, \"Learning human- robot collaboration insights through the integration of muscle activity in interaction motion models,\" in 2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids), Nov 2017, pp. 491- 496.\n\n- M. Ewerton, G. Neumann, R. Lioutikov, H. B. Amor, J. Peters, and G. Maeda, \"Learning multiple collaborative tasks with a mixture of interaction primitives,\" in 2015 IEEE International Conference on Robotics and Automation (ICRA), May 2015, pp. 1535-1542.\n\n- S. L. Delp, F. C. Anderson, A. S. Arnold, P. Loan, A. Habib, C. T. John, E. Guendelman, and D. G. Thelen, \"Opensim: open-source software to create and analyze dynamic simulations of movement,\" IEEE transactions on biomedical engineering, vol. 54, no. 11, pp. 1940-1950, 2007.\n\n- Vicon, \"Plug-in gait model details.\" [Online]. Available: https://www. vicon.com/downloads/documentation/plug-in-gait-model-details\n\n- A. McMillan, A. Pulver, D. Collier, and D. B. Williams, \"Sagittal and frontal plane joint mechanics throughout the stance phase of walking in adolescents who are obese,\" Gait & posture, vol. 32, no. 2, pp. 263-268, 2010.\n\n- Dynamic Time Warping. Berlin, Heidelberg: Springer Berlin Heidelberg, 2007, pp. 69-84. [Online]. Available: https://doi.org/10. 1007/978-3-540-74048-3 4\n\n- M. Grimmer, M. Holgate, R. Holgate, A. Boehler, J. Ward, K. Hollan- der, T. Sugar, and A. Seyfarth, \"A powered prosthetic ankle joint for walking and running,\" Biomedical engineering online, vol. 15, no. 3, p. 141, 2016.\n\n", "annotations": {"ReferenceToTable": [{"begin": 22965, "end": 22966, "idx": 0}, {"begin": 24114, "end": 24116, "idx": 1}, {"begin": 27188, "end": 27190, "idx": 2}], "SectionMain": [{"begin": 1164, "end": 28837, "idx": 0}], "SectionReference": [{"begin": 28851, "end": 35094, "idx": 0}], "SectionHeader": [{"begin": 0, "end": 1164, "idx": 0}], "Div": [{"begin": 86, "end": 1156, "idx": 0}, {"begin": 1167, "end": 4967, "idx": 1}, {"begin": 4969, "end": 7892, "idx": 2}, {"begin": 7894, "end": 9301, "idx": 3}, {"begin": 9303, "end": 10906, "idx": 4}, {"begin": 10908, "end": 13857, "idx": 5}, {"begin": 13859, "end": 16934, "idx": 6}, {"begin": 16936, "end": 19209, "idx": 7}, {"begin": 19211, "end": 20035, "idx": 8}, {"begin": 20037, "end": 20060, "idx": 9}, {"begin": 20062, "end": 21657, "idx": 10}, {"begin": 21659, "end": 24321, "idx": 11}, {"begin": 24323, "end": 25785, "idx": 12}, {"begin": 25787, "end": 27234, "idx": 13}, {"begin": 27236, "end": 28837, "idx": 14}], "Head": [{"begin": 1167, "end": 1182, "idx": 0}, {"begin": 4969, "end": 4985, "idx": 1}, {"begin": 7894, "end": 7955, "idx": 2}, {"begin": 9303, "end": 9353, "idx": 3}, {"begin": 10908, "end": 10962, "idx": 4}, {"begin": 13859, "end": 13888, "idx": 5}, {"begin": 16936, "end": 16985, "idx": 6}, {"begin": 19211, "end": 19218, "idx": 7}, {"begin": 20037, "end": 20059, "idx": 8}, {"begin": 20062, "end": 20080, "idx": 9}, {"begin": 21659, "end": 21699, "idx": 10}, {"begin": 24323, "end": 24366, "idx": 11}, {"begin": 25787, "end": 25830, "idx": 12}, {"begin": 27236, "end": 27249, "idx": 13}], "Paragraph": [{"begin": 86, "end": 1156, "idx": 0}, {"begin": 1183, "end": 2020, "idx": 1}, {"begin": 2021, "end": 2703, "idx": 2}, {"begin": 2704, "end": 3475, "idx": 3}, {"begin": 3476, "end": 4967, "idx": 4}, {"begin": 4986, "end": 5634, "idx": 5}, {"begin": 5635, "end": 6054, "idx": 6}, {"begin": 6055, "end": 6576, "idx": 7}, {"begin": 6577, "end": 7892, "idx": 8}, {"begin": 7956, "end": 8462, "idx": 9}, {"begin": 8463, "end": 9301, "idx": 10}, {"begin": 9354, "end": 9708, "idx": 11}, {"begin": 9709, "end": 10113, "idx": 12}, {"begin": 10114, "end": 10526, "idx": 13}, {"begin": 10542, "end": 10906, "idx": 14}, {"begin": 10963, "end": 11143, "idx": 15}, {"begin": 11164, "end": 11740, "idx": 16}, {"begin": 11843, "end": 12936, "idx": 17}, {"begin": 12988, "end": 13585, "idx": 18}, {"begin": 13622, "end": 13857, "idx": 19}, {"begin": 13889, "end": 13980, "idx": 20}, {"begin": 14043, "end": 14645, "idx": 21}, {"begin": 14646, "end": 15480, "idx": 22}, {"begin": 15596, "end": 15650, "idx": 23}, {"begin": 15651, "end": 15889, "idx": 24}, {"begin": 15934, "end": 16934, "idx": 25}, {"begin": 16986, "end": 17224, "idx": 26}, {"begin": 17294, "end": 17824, "idx": 27}, {"begin": 17886, "end": 17968, "idx": 28}, {"begin": 18080, "end": 18681, "idx": 29}, {"begin": 18698, "end": 18889, "idx": 30}, {"begin": 18890, "end": 19209, "idx": 31}, {"begin": 19219, "end": 19468, "idx": 32}, {"begin": 19481, "end": 19515, "idx": 33}, {"begin": 19556, "end": 19608, "idx": 34}, {"begin": 19674, "end": 19769, "idx": 35}, {"begin": 19806, "end": 19882, "idx": 36}, {"begin": 19916, "end": 20035, "idx": 37}, {"begin": 20081, "end": 21657, "idx": 38}, {"begin": 21700, "end": 22958, "idx": 39}, {"begin": 22959, "end": 23570, "idx": 40}, {"begin": 23571, "end": 24107, "idx": 41}, {"begin": 24108, "end": 24321, "idx": 42}, {"begin": 24367, "end": 25785, "idx": 43}, {"begin": 25831, "end": 26320, "idx": 44}, {"begin": 26321, "end": 26544, "idx": 45}, {"begin": 26545, "end": 27234, "idx": 46}, {"begin": 27250, "end": 28070, "idx": 47}, {"begin": 28071, "end": 28837, "idx": 48}], "ReferenceToBib": [{"begin": 1469, "end": 1472, "target": "#b0", "idx": 0}, {"begin": 1640, "end": 1643, "target": "#b1", "idx": 1}, {"begin": 1645, "end": 1648, "target": "#b2", "idx": 2}, {"begin": 2016, "end": 2019, "target": "#b3", "idx": 3}, {"begin": 2185, "end": 2188, "target": "#b4", "idx": 4}, {"begin": 2424, "end": 2427, "target": "#b5", "idx": 5}, {"begin": 2942, "end": 2945, "target": "#b6", "idx": 6}, {"begin": 2964, "end": 2967, "target": "#b7", "idx": 7}, {"begin": 3580, "end": 3583, "target": "#b8", "idx": 8}, {"begin": 4436, "end": 4439, "target": "#b0", "idx": 9}, {"begin": 4628, "end": 4631, "target": "#b1", "idx": 10}, {"begin": 4823, "end": 4826, "target": "#b2", "idx": 11}, {"begin": 5118, "end": 5122, "target": "#b9", "idx": 12}, {"begin": 5190, "end": 5194, "target": "#b10", "idx": 13}, {"begin": 5212, "end": 5216, "target": "#b11", "idx": 14}, {"begin": 5355, "end": 5359, "target": "#b12", "idx": 15}, {"begin": 5370, "end": 5374, "target": "#b13", "idx": 16}, {"begin": 5744, "end": 5748, "target": "#b14", "idx": 17}, {"begin": 5749, "end": 5753, "target": "#b15", "idx": 18}, {"begin": 5754, "end": 5758, "target": "#b16", "idx": 19}, {"begin": 6159, "end": 6163, "target": "#b17", "idx": 20}, {"begin": 6165, "end": 6169, "target": "#b18", "idx": 21}, {"begin": 7041, "end": 7045, "target": "#b19", "idx": 22}, {"begin": 7046, "end": 7050, "target": "#b20", "idx": 23}, {"begin": 7051, "end": 7055, "target": "#b21", "idx": 24}, {"begin": 7056, "end": 7060, "target": "#b22", "idx": 25}, {"begin": 7061, "end": 7065, "target": "#b23", "idx": 26}, {"begin": 8726, "end": 8730, "target": "#b24", "idx": 27}, {"begin": 8746, "end": 8750, "target": "#b25", "idx": 28}, {"begin": 11408, "end": 11412, "target": "#b20", "idx": 29}, {"begin": 13160, "end": 13164, "target": "#b26", "idx": 30}, {"begin": 15715, "end": 15719, "target": "#b27", "idx": 31}, {"begin": 21176, "end": 21180, "target": "#b25", "idx": 32}, {"begin": 26340, "end": 26344, "target": "#b28", "idx": 33}], "Sentence": [{"begin": 86, "end": 232, "idx": 0}, {"begin": 233, "end": 346, "idx": 1}, {"begin": 347, "end": 579, "idx": 2}, {"begin": 580, "end": 718, "idx": 3}, {"begin": 719, "end": 953, "idx": 4}, {"begin": 954, "end": 1031, "idx": 5}, {"begin": 1032, "end": 1156, "idx": 6}, {"begin": 1183, "end": 1275, "idx": 7}, {"begin": 1276, "end": 1431, "idx": 8}, {"begin": 1432, "end": 1649, "idx": 9}, {"begin": 1650, "end": 1883, "idx": 10}, {"begin": 1884, "end": 2020, "idx": 11}, {"begin": 2021, "end": 2263, "idx": 12}, {"begin": 2264, "end": 2428, "idx": 13}, {"begin": 2429, "end": 2554, "idx": 14}, {"begin": 2555, "end": 2703, "idx": 15}, {"begin": 2704, "end": 2946, "idx": 16}, {"begin": 2947, "end": 3100, "idx": 17}, {"begin": 3101, "end": 3324, "idx": 18}, {"begin": 3325, "end": 3475, "idx": 19}, {"begin": 3476, "end": 3584, "idx": 20}, {"begin": 3585, "end": 3794, "idx": 21}, {"begin": 3795, "end": 4150, "idx": 22}, {"begin": 4151, "end": 4360, "idx": 23}, {"begin": 4361, "end": 4434, "idx": 24}, {"begin": 4435, "end": 4626, "idx": 25}, {"begin": 4627, "end": 4821, "idx": 26}, {"begin": 4822, "end": 4967, "idx": 27}, {"begin": 4986, "end": 5123, "idx": 28}, {"begin": 5124, "end": 5230, "idx": 29}, {"begin": 5231, "end": 5375, "idx": 30}, {"begin": 5376, "end": 5486, "idx": 31}, {"begin": 5487, "end": 5559, "idx": 32}, {"begin": 5560, "end": 5634, "idx": 33}, {"begin": 5635, "end": 5851, "idx": 34}, {"begin": 5852, "end": 6054, "idx": 35}, {"begin": 6055, "end": 6170, "idx": 36}, {"begin": 6171, "end": 6402, "idx": 37}, {"begin": 6403, "end": 6576, "idx": 38}, {"begin": 6577, "end": 6823, "idx": 39}, {"begin": 6824, "end": 6976, "idx": 40}, {"begin": 6977, "end": 7272, "idx": 41}, {"begin": 7273, "end": 7499, "idx": 42}, {"begin": 7500, "end": 7723, "idx": 43}, {"begin": 7724, "end": 7892, "idx": 44}, {"begin": 7956, "end": 8076, "idx": 45}, {"begin": 8077, "end": 8224, "idx": 46}, {"begin": 8225, "end": 8462, "idx": 47}, {"begin": 8463, "end": 8620, "idx": 48}, {"begin": 8621, "end": 8859, "idx": 49}, {"begin": 8860, "end": 9026, "idx": 50}, {"begin": 9027, "end": 9301, "idx": 51}, {"begin": 9354, "end": 9537, "idx": 52}, {"begin": 9538, "end": 9641, "idx": 53}, {"begin": 9642, "end": 9708, "idx": 54}, {"begin": 9709, "end": 9827, "idx": 55}, {"begin": 9828, "end": 9953, "idx": 56}, {"begin": 9954, "end": 10113, "idx": 57}, {"begin": 10114, "end": 10213, "idx": 58}, {"begin": 10214, "end": 10363, "idx": 59}, {"begin": 10364, "end": 10526, "idx": 60}, {"begin": 10542, "end": 10741, "idx": 61}, {"begin": 10742, "end": 10906, "idx": 62}, {"begin": 10963, "end": 11143, "idx": 63}, {"begin": 11164, "end": 11381, "idx": 64}, {"begin": 11382, "end": 11557, "idx": 65}, {"begin": 11558, "end": 11740, "idx": 66}, {"begin": 11843, "end": 12185, "idx": 67}, {"begin": 12186, "end": 12381, "idx": 68}, {"begin": 12382, "end": 12672, "idx": 69}, {"begin": 12673, "end": 12692, "idx": 70}, {"begin": 12693, "end": 12824, "idx": 71}, {"begin": 12825, "end": 12936, "idx": 72}, {"begin": 12988, "end": 13165, "idx": 73}, {"begin": 13166, "end": 13316, "idx": 74}, {"begin": 13317, "end": 13448, "idx": 75}, {"begin": 13449, "end": 13585, "idx": 76}, {"begin": 13622, "end": 13857, "idx": 77}, {"begin": 13889, "end": 13980, "idx": 78}, {"begin": 14043, "end": 14184, "idx": 79}, {"begin": 14185, "end": 14380, "idx": 80}, {"begin": 14381, "end": 14510, "idx": 81}, {"begin": 14511, "end": 14645, "idx": 82}, {"begin": 14646, "end": 14752, "idx": 83}, {"begin": 14753, "end": 14906, "idx": 84}, {"begin": 14907, "end": 15087, "idx": 85}, {"begin": 15088, "end": 15274, "idx": 86}, {"begin": 15275, "end": 15354, "idx": 87}, {"begin": 15355, "end": 15480, "idx": 88}, {"begin": 15596, "end": 15650, "idx": 89}, {"begin": 15651, "end": 15889, "idx": 90}, {"begin": 15934, "end": 16058, "idx": 91}, {"begin": 16059, "end": 16241, "idx": 92}, {"begin": 16242, "end": 16377, "idx": 93}, {"begin": 16378, "end": 16604, "idx": 94}, {"begin": 16605, "end": 16754, "idx": 95}, {"begin": 16755, "end": 16934, "idx": 96}, {"begin": 16986, "end": 17087, "idx": 97}, {"begin": 17088, "end": 17175, "idx": 98}, {"begin": 17176, "end": 17224, "idx": 99}, {"begin": 17294, "end": 17443, "idx": 100}, {"begin": 17444, "end": 17600, "idx": 101}, {"begin": 17601, "end": 17660, "idx": 102}, {"begin": 17661, "end": 17774, "idx": 103}, {"begin": 17775, "end": 17824, "idx": 104}, {"begin": 17886, "end": 17968, "idx": 105}, {"begin": 18080, "end": 18264, "idx": 106}, {"begin": 18265, "end": 18403, "idx": 107}, {"begin": 18404, "end": 18564, "idx": 108}, {"begin": 18565, "end": 18681, "idx": 109}, {"begin": 18698, "end": 18889, "idx": 110}, {"begin": 18890, "end": 19209, "idx": 111}, {"begin": 19219, "end": 19417, "idx": 112}, {"begin": 19418, "end": 19468, "idx": 113}, {"begin": 19481, "end": 19515, "idx": 114}, {"begin": 19556, "end": 19608, "idx": 115}, {"begin": 19674, "end": 19769, "idx": 116}, {"begin": 19806, "end": 19882, "idx": 117}, {"begin": 19916, "end": 19965, "idx": 118}, {"begin": 19966, "end": 20035, "idx": 119}, {"begin": 20081, "end": 20207, "idx": 120}, {"begin": 20208, "end": 20339, "idx": 121}, {"begin": 20340, "end": 20504, "idx": 122}, {"begin": 20505, "end": 20768, "idx": 123}, {"begin": 20769, "end": 20950, "idx": 124}, {"begin": 20951, "end": 21344, "idx": 125}, {"begin": 21345, "end": 21442, "idx": 126}, {"begin": 21443, "end": 21529, "idx": 127}, {"begin": 21530, "end": 21657, "idx": 128}, {"begin": 21700, "end": 21991, "idx": 129}, {"begin": 21992, "end": 22190, "idx": 130}, {"begin": 22191, "end": 22406, "idx": 131}, {"begin": 22407, "end": 22502, "idx": 132}, {"begin": 22503, "end": 22743, "idx": 133}, {"begin": 22744, "end": 22958, "idx": 134}, {"begin": 22959, "end": 23156, "idx": 135}, {"begin": 23157, "end": 23305, "idx": 136}, {"begin": 23306, "end": 23351, "idx": 137}, {"begin": 23352, "end": 23456, "idx": 138}, {"begin": 23457, "end": 23570, "idx": 139}, {"begin": 23571, "end": 23653, "idx": 140}, {"begin": 23654, "end": 23828, "idx": 141}, {"begin": 23829, "end": 23925, "idx": 142}, {"begin": 23926, "end": 24107, "idx": 143}, {"begin": 24108, "end": 24321, "idx": 144}, {"begin": 24367, "end": 24594, "idx": 145}, {"begin": 24595, "end": 24712, "idx": 146}, {"begin": 24713, "end": 24920, "idx": 147}, {"begin": 24921, "end": 25077, "idx": 148}, {"begin": 25078, "end": 25205, "idx": 149}, {"begin": 25206, "end": 25351, "idx": 150}, {"begin": 25352, "end": 25491, "idx": 151}, {"begin": 25492, "end": 25577, "idx": 152}, {"begin": 25578, "end": 25686, "idx": 153}, {"begin": 25687, "end": 25785, "idx": 154}, {"begin": 25831, "end": 25968, "idx": 155}, {"begin": 25969, "end": 26124, "idx": 156}, {"begin": 26125, "end": 26320, "idx": 157}, {"begin": 26321, "end": 26544, "idx": 158}, {"begin": 26545, "end": 26611, "idx": 159}, {"begin": 26612, "end": 26683, "idx": 160}, {"begin": 26684, "end": 26903, "idx": 161}, {"begin": 26904, "end": 27076, "idx": 162}, {"begin": 27077, "end": 27234, "idx": 163}, {"begin": 27250, "end": 27419, "idx": 164}, {"begin": 27420, "end": 27587, "idx": 165}, {"begin": 27588, "end": 27727, "idx": 166}, {"begin": 27728, "end": 27972, "idx": 167}, {"begin": 27973, "end": 28070, "idx": 168}, {"begin": 28071, "end": 28358, "idx": 169}, {"begin": 28359, "end": 28471, "idx": 170}, {"begin": 28472, "end": 28603, "idx": 171}, {"begin": 28604, "end": 28711, "idx": 172}, {"begin": 28712, "end": 28837, "idx": 173}], "ReferenceToFigure": [{"begin": 2552, "end": 2553, "idx": 0}, {"begin": 18941, "end": 18942, "idx": 1}, {"begin": 19921, "end": 19922, "idx": 2}, {"begin": 21997, "end": 21998, "idx": 3}, {"begin": 23576, "end": 23577, "idx": 4}, {"begin": 24600, "end": 24601, "target": "#fig_1", "idx": 5}, {"begin": 25357, "end": 25358, "target": "#fig_1", "idx": 6}, {"begin": 26177, "end": 26178, "idx": 7}, {"begin": 26550, "end": 26551, "idx": 8}], "Abstract": [{"begin": 76, "end": 1156, "idx": 0}], "SectionFootnote": [{"begin": 28839, "end": 28849, "idx": 0}], "ReferenceString": [{"begin": 28866, "end": 29113, "id": "b0", "idx": 0}, {"begin": 29115, "end": 29306, "id": "b1", "idx": 1}, {"begin": 29310, "end": 29481, "id": "b2", "idx": 2}, {"begin": 29485, "end": 29717, "id": "b3", "idx": 3}, {"begin": 29721, "end": 29966, "id": "b4", "idx": 4}, {"begin": 29970, "end": 30298, "id": "b5", "idx": 5}, {"begin": 30302, "end": 30564, "id": "b6", "idx": 6}, {"begin": 30568, "end": 30694, "id": "b7", "idx": 7}, {"begin": 30698, "end": 30892, "id": "b8", "idx": 8}, {"begin": 30896, "end": 31183, "id": "b9", "idx": 9}, {"begin": 31187, "end": 31353, "id": "b10", "idx": 10}, {"begin": 31357, "end": 31586, "id": "b11", "idx": 11}, {"begin": 31590, "end": 31829, "id": "b12", "idx": 12}, {"begin": 31833, "end": 31997, "id": "b13", "idx": 13}, {"begin": 32001, "end": 32165, "id": "b14", "idx": 14}, {"begin": 32169, "end": 32339, "id": "b15", "idx": 15}, {"begin": 32343, "end": 32598, "id": "b16", "idx": 16}, {"begin": 32602, "end": 32768, "id": "b17", "idx": 17}, {"begin": 32772, "end": 32994, "id": "b18", "idx": 18}, {"begin": 32998, "end": 33208, "id": "b19", "idx": 19}, {"begin": 33212, "end": 33370, "id": "b20", "idx": 20}, {"begin": 33374, "end": 33540, "id": "b21", "idx": 21}, {"begin": 33544, "end": 33816, "id": "b22", "idx": 22}, {"begin": 33820, "end": 34074, "id": "b23", "idx": 23}, {"begin": 34078, "end": 34353, "id": "b24", "idx": 24}, {"begin": 34357, "end": 34488, "id": "b25", "idx": 25}, {"begin": 34492, "end": 34712, "id": "b26", "idx": 26}, {"begin": 34716, "end": 34868, "id": "b27", "idx": 27}, {"begin": 34872, "end": 35092, "id": "b28", "idx": 28}]}}