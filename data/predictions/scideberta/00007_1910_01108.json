{"text": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\n\nAbstract:\nAs Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-theedge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller generalpurpose language representation model, called DistilBERT, which can then be finetuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.\n\n\n1 Introduction\nThe last two years have seen the rise of Transfer Learning approaches in Natural Language Processing (NLP) with large-scale pre-trained language models becoming a basic tool in many NLP tasks [Devlin et al., 2018, Radford et al., 2019, Liu et al., 2019]. While these models lead to significant improvement, they often have several hundred million parameters and current research 1 on pre-trained models indicates that training even larger models still leads to better performances on downstream tasks.\nThe trend toward bigger models raises several concerns. First is the environmental cost of exponentially scaling these models' computational requirements as mentioned in Schwartz et al. [2019], Strubell et al. [2019]. Second, while operating these models on-device in real-time has the potential to enable novel and interesting language processing applications, the growing computational and memory requirements of these models may hamper wide adoption.\nIn this paper, we show that it is possible to reach similar performances on many downstream-tasks using much smaller language models pre-trained with knowledge distillation, resulting in models that are lighter and faster at inference time, while also requiring a smaller computational training budget. Our general-purpose pre-trained models can be fine-tuned with good performances on several downstream tasks, keeping the flexibility of larger models. We also show that our compressed models are small enough to run on the edge, e.g. on mobile devices.\nUsing a triple loss, we show that a 40% smaller Transformer (Vaswani et al. [2017]) pre-trained through distillation via the supervision of a bigger Transformer language model can achieve similar performance on a variety of downstream tasks, while being 60% faster at inference time. Further ablation studies indicate that all the components of the triple loss are important for best performances.\nWe have made the trained weights available along with the training code in the Transformers 2 library from HuggingFace [Wolf et al., 2019].\n\n2 Knowledge distillation\nKnowledge distillation [Bucila et al., 2006, Hinton et al., 2015] is a compression technique in which a compact model -the student -is trained to reproduce the behaviour of a larger model -the teacheror an ensemble of models.\nIn supervised learning, a classification model is generally trained to predict an instance class by maximizing the estimated probability of gold labels. A standard training objective thus involves minimizing the cross-entropy between the model's predicted distribution and the one-hot empirical distribution of training labels. A model performing well on the training set will predict an output distribution with high probability on the correct class and with near-zero probabilities on other classes. But some of these \"near-zero\" probabilities are larger than others and reflect, in part, the generalization capabilities of the model and how well it will perform on the test set 3.\nTraining loss The student is trained with a distillation loss over the soft target probabilities of the teacher: L ce = i t i * log(s i ) where t i (resp. s i ) is a probability estimated by the teacher (resp. the student). This objective results in a rich training signal by leveraging the full teacher distribution. Following Hinton et al. [2015] we used a softmax-temperature:p i = exp(zi/T ) j exp(zj /T )\nwhere T controls the smoothness of the output distribution and z i is the model score for the class i. The same temperature T is applied to the student and the teacher at training time, while at inference, T is set to 1 to recover a standard softmax.\nThe final training objective is a linear combination of the distillation loss L ce with the supervised training loss, in our case the masked language modeling loss L mlm [Devlin et al., 2018]. We found it beneficial to add a cosine embedding loss (L cos ) which will tend to align the directions of the student and teacher hidden states vectors.\n3 DistilBERT: a distilled version of BERT Student architecture In the present work, the student -DistilBERT -has the same general architecture as BERT. The token-type embeddings and the pooler are removed while the number of layers is reduced by a factor of 2. Most of the operations used in the Transformer architecture (linear layer and layer normalisation) are highly optimized in modern linear algebra frameworks and our investigations showed that variations on the last dimension of the tensor (hidden size dimension) have a smaller impact on computation efficiency (for a fixed parameters budget) than variations on other factors like the number of layers. Thus we focus on reducing the number of layers.\n\nStudent initialization\nIn addition to the previously described optimization and architectural choices, an important element in our training procedure is to find the right initialization for the sub-network to converge. Taking advantage of the common dimensionality between teacher and student networks, we initialize the student from the teacher by taking one layer out of two.\n\nData and compute power\nWe train DistilBERT on the same corpus as the original BERT model: a concatenation of English Wikipedia and Toronto Book Corpus [Zhu et al., 2015]. DistilBERT was trained on 8 16GB V100 GPUs for approximately 90 hours. For the sake of comparison, the RoBERTa model [Liu et al., 2019] required 1 day of training on 1024 32GB V100.\n\n4 Experiments\nGeneral Language Understanding We assess the language understanding and generalization capabilities of DistilBERT on the General Language Understanding Evaluation (GLUE) benchmark [Wang et al., 2018], a collection of 9 datasets for evaluating natural language understanding systems. We report scores on the development sets for each task by fine-tuning DistilBERT without the use of ensembling or multi-tasking scheme for fine-tuning (which are mostly orthogonal to the present work). We compare the results to the baseline provided by the authors of GLUE: an ELMo (Peters et al. [2018]) encoder followed by two BiLSTMs. 4 he results on each of the 9 tasks are showed on Table 1 along with the macro-score (average of individual scores). Among the 9 tasks, DistilBERT is always on par or improving over the ELMo baseline (up to 19 points of accuracy on STS-B). DistilBERT also compares surprisingly well to BERT, retaining 97% of the performance with 40% fewer parameters.\n\n4.1 Downstream task benchmark\nDownstream tasks We further study the performances of DistilBERT on several downstream tasks under efficient inference constraints: a classification task (IMDb sentiment classification - Maas et al. [2011]) and a question answering task (SQuAD v1.1 -Rajpurkar et al. [2016]).\nAs shown in Table 2, DistilBERT is only 0.6% point behind BERT in test accuracy on the IMDb benchmark while being 40% smaller. On SQuAD, DistilBERT is within 3.9 points of the full BERT.\nWe also studied whether we could add another step of distillation during the adaptation phase by fine-tuning DistilBERT on SQuAD using a BERT model previously fine-tuned on SQuAD as a\n\nAblation\nVariation on GLUE macro-score\u2205 -L cos -L mlm -2.96 L ce -\u2205 -L mlm -1.46 L ce -L cos -\u2205\n-0.31 Triple loss + random weights initialization -3.69\nteacher for an additional term in the loss (knowledge distillation). In this setting, there are thus two successive steps of distillation, one during the pre-training phase and one during the adaptation phase.\nIn this case, we were able to reach interesting performances given the size of the model: 79.8 F1 and 70.4 EM, i.e. within 3 points of the full model.\n\nSize and inference speed\nTo further investigate the speed-up/size trade-off of DistilBERT, we compare (in Table 3) the number of parameters of each model along with the inference time needed to do a full pass on the STS-B development set on CPU (Intel Xeon E5-2690 v3 Haswell @2.9GHz) using a batch size of 1. DistilBERT has 40% fewer parameters than BERT and is 60% faster than BERT.\nOn device computation We studied whether DistilBERT could be used for on-the-edge applications by building a mobile application for question answering. We compare the average inference time on a recent smartphone (iPhone 7 Plus) against our previously trained question answering model based on BERT-base. Excluding the tokenization step, DistilBERT is 71% faster than BERT, and the whole model weighs 207 MB (which could be further reduced with quantization). Our code is available 5.\n\n4.2 Ablation study\nIn this section, we investigate the influence of various components of the triple loss and the student initialization on the performances of the distilled model. We report the macro-score on GLUE. Table 4 presents the deltas with the full triple loss: removing the Masked Language Modeling loss has little impact while the two distillation losses account for a large portion of the performance.\n\n5 Related work\nTask-specific distillation Most of the prior works focus on building task-specific distillation setups.  Tang et al. [2019] transfer fine-tune classification model BERT to an LSTM-based classifier.  Chatterjee [2019] distill BERT model fine-tuned on SQuAD in a smaller Transformer model previously initialized from BERT. In the present work, we found it beneficial to use a general-purpose pre-training distillation rather than a task-specific distillation.  Turc et al. [2019] use the original pretraining objective to train smaller student, then fine-tuned via distillation. As shown in the ablation study, we found it beneficial to leverage the teacher's knowledge to pre-train with additional distillation signal.\nMulti-distillation Yang et al. [2019] combine the knowledge of an ensemble of teachers using multi-task learning to regularize the distillation. The authors apply Multi-Task Knowledge Distillation to learn a compact question answering model from a set of large question answering models. An application of multi-distillation is multi-linguality: Tsai et al. [2019] adopts a similar approach to us by pre-training a multilingual model from scratch solely through distillation. However, as shown in the ablation study, leveraging the teacher's knowledge with initialization and additional losses leads to substantial gains.\nOther compression techniques have been studied to compress large models. Recent developments in weights pruning reveal that it is possible to remove some heads in the self-attention at test time without significantly degrading the performance Michel et al. [2019]. Some layers can be reduced to one head. A separate line of study leverages quantization to derive smaller models (Gupta et al. [2015]). Pruning and quantization are orthogonal to the present work.\n\n6 Conclusion and future work\nWe introduced DistilBERT, a general-purpose pre-trained version of BERT, 40% smaller, 60% faster, that retains 97% of the language understanding capabilities. We showed that a general-purpose language model can be successfully trained with distillation and analyzed the various components with an ablation study. We further demonstrated that DistilBERT is a compelling option for edge applications.\n\nFootnotes:\n1: See for instance the recently released MegatronLM (https://nv-adlr.github.io/MegatronLM) EMC^2: 5th Edition Co-located with NeurIPS'19\n2: https://github.com/huggingface/transformers\n3: E.g. BERT-base's predictions for a masked token in \"I think this is the beginning of a beautiful [MASK]\" comprise two high probability tokens (day and life) and a long tail of valid predictions (future, story, world. . . ).\n4: We use jiant [Wang et al., 2019] to compute the baseline.\n5: https://github.com/huggingface/swift-coreml-transformers\n\nReferences:\n\n- Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In NAACL-HLT, 2018.- Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.\n\n- Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar S. Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke S. Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. ArXiv, abs/1907.11692, 2019.\n\n- Roy Schwartz, Jesse Dodge, Noah A. Smith, and Oren Etzioni. Green ai. ArXiv, abs/1907.10597, 2019.\n\n- Emma Strubell, Ananya Ganesh, and Andrew McCallum. Energy and policy considerations for deep learning in nlp. In ACL, 2019.\n\n- Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NIPS, 2017.\n\n- Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, and Jamie Brew. Transformers: State-of-the-art natural language processing, 2019.\n\n- Cristian Bucila, Rich Caruana, and Alexandru Niculescu-Mizil. Model compression. In KDD, 2006.\n\n- Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the knowledge in a neural network. ArXiv, abs/1503.02531, 2015.\n\n- Yukun Zhu, Ryan Kiros, Richard S. Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. 2015 IEEE International Conference on Computer Vision (ICCV), pages 19-27, 2015.\n\n- Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. In ICLR, 2018.\n\n- Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. In NAACL, 2018.\n\n- Alex Wang, Ian F. Tenney, Yada Pruksachatkun, Katherin Yu, Jan Hula, Patrick Xia, Raghu Pappagari, Shuning Jin, R. Thomas McCoy, Roma Patel, Yinghui Huang, Jason Phang, Edouard Grave, Najoung Kim, Phu Mon Htut, Thibault F'evry, Berlin Chen, Nikita Nangia, Haokun Liu, Anhad Mohananey, Shikha Bordia, Nicolas Patry, Ellie Pavlick, and Samuel R. Bowman. jiant 1.1: A software toolkit for research on general-purpose text understanding models. http://jiant.info/, 2019.\n\n- Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. Learning word vectors for sentiment analysis. In ACL, 2011.\n\n- Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100, 000+ questions for machine comprehension of text. In EMNLP, 2016.\n\n- Raphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga Vechtomova, and Jimmy Lin. Distilling task-specific knowledge from bert into simple neural networks. ArXiv, abs/1903.12136, 2019.\n\n- Debajyoti Chatterjee. Making neural machine reading comprehension faster. ArXiv, abs/1904.00796, 2019.\n\n- Iulia Turc, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Well-read students learn better: The impact of student initialization on knowledge distillation. ArXiv, abs/1908.08962, 2019.\n\n- Ze Yang, Linjun Shou, Ming Gong, Wutao Lin, and Daxin Jiang. Model compression with multi-task knowledge distillation for web-scale question answering system. ArXiv, abs/1904.09636, 2019.\n\n- Henry Tsai, Jason Riesa, Melvin Johnson, Naveen Arivazhagan, Xin Li, and Amelia Archer. Small and practical bert models for sequence labeling. In EMNLP-IJCNLP, 2019.\n\n- Paul Michel, Omer Levy, and Graham Neubig. Are sixteen heads really better than one? In NeurIPS, 2019.\n\n- Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan. Deep learning with limited numerical precision. In ICML, 2015.\n\n", "annotations": {"Abstract": [{"begin": 79, "end": 1252, "idx": 0}], "Head": [{"begin": 1255, "end": 1269, "n": "1", "idx": 0}, {"begin": 3320, "end": 3344, "n": "2", "idx": 1}, {"begin": 5974, "end": 5996, "idx": 2}, {"begin": 6353, "end": 6375, "idx": 3}, {"begin": 6707, "end": 6720, "n": "4", "idx": 4}, {"begin": 7695, "end": 7724, "n": "4.1", "idx": 5}, {"begin": 8373, "end": 8381, "idx": 6}, {"begin": 8887, "end": 8911, "idx": 7}, {"begin": 9758, "end": 9776, "n": "4.2", "idx": 8}, {"begin": 10173, "end": 10187, "n": "5", "idx": 9}, {"begin": 11991, "end": 12019, "n": "6", "idx": 10}], "ReferenceToBib": [{"begin": 1462, "end": 1482, "target": "#b0", "idx": 0}, {"begin": 1482, "end": 1504, "target": "#b1", "idx": 1}, {"begin": 1504, "end": 1523, "idx": 2}, {"begin": 1942, "end": 1964, "target": "#b3", "idx": 3}, {"begin": 1966, "end": 1988, "target": "#b4", "idx": 4}, {"begin": 2841, "end": 2863, "target": "#b5", "idx": 5}, {"begin": 3298, "end": 3317, "target": "#b6", "idx": 6}, {"begin": 3368, "end": 3388, "target": "#b7", "idx": 7}, {"begin": 3388, "end": 3409, "target": "#b8", "idx": 8}, {"begin": 4583, "end": 4603, "target": "#b8", "idx": 9}, {"begin": 5086, "end": 5107, "target": "#b0", "idx": 10}, {"begin": 6504, "end": 6522, "target": "#b9", "idx": 11}, {"begin": 6641, "end": 6659, "target": "#b2", "idx": 12}, {"begin": 6901, "end": 6920, "target": "#b10", "idx": 13}, {"begin": 7286, "end": 7307, "target": "#b11", "idx": 14}, {"begin": 7912, "end": 7930, "target": "#b13", "idx": 15}, {"begin": 7962, "end": 7998, "idx": 16}, {"begin": 10293, "end": 10311, "target": "#b15", "idx": 17}, {"begin": 10387, "end": 10404, "target": "#b16", "idx": 18}, {"begin": 10647, "end": 10665, "target": "#b17", "idx": 19}, {"begin": 10925, "end": 10943, "target": "#b18", "idx": 20}, {"begin": 11252, "end": 11270, "target": "#b19", "idx": 21}, {"begin": 11771, "end": 11791, "target": "#b20", "idx": 22}, {"begin": 11906, "end": 11926, "target": "#b21", "idx": 23}, {"begin": 12859, "end": 12878, "target": "#b12", "idx": 24}], "ReferenceToFootnote": [{"begin": 1649, "end": 1650, "target": "#foot_0", "idx": 0}, {"begin": 3271, "end": 3272, "target": "#foot_1", "idx": 1}, {"begin": 4252, "end": 4253, "target": "#foot_2", "idx": 2}, {"begin": 7342, "end": 7343, "target": "#foot_3", "idx": 3}, {"begin": 9754, "end": 9755, "target": "#foot_4", "idx": 4}], "SectionFootnote": [{"begin": 12420, "end": 12963, "idx": 0}], "ReferenceString": [{"begin": 12980, "end": 13147, "id": "b0", "idx": 0}, {"begin": 13149, "end": 13292, "id": "b1", "idx": 1}, {"begin": 13296, "end": 13523, "id": "b2", "idx": 2}, {"begin": 13527, "end": 13625, "id": "b3", "idx": 3}, {"begin": 13629, "end": 13752, "id": "b4", "idx": 4}, {"begin": 13756, "end": 13923, "id": "b5", "idx": 5}, {"begin": 13927, "end": 14154, "id": "b6", "idx": 6}, {"begin": 14158, "end": 14252, "id": "b7", "idx": 7}, {"begin": 14256, "end": 14383, "id": "b8", "idx": 8}, {"begin": 14387, "end": 14686, "id": "b9", "idx": 9}, {"begin": 14690, "end": 14880, "id": "b10", "idx": 10}, {"begin": 14884, "end": 15054, "id": "b11", "idx": 11}, {"begin": 15058, "end": 15524, "id": "b12", "idx": 12}, {"begin": 15528, "end": 15683, "id": "b13", "idx": 13}, {"begin": 15687, "end": 15831, "id": "b14", "idx": 14}, {"begin": 15835, "end": 16014, "id": "b15", "idx": 15}, {"begin": 16018, "end": 16120, "id": "b16", "idx": 16}, {"begin": 16124, "end": 16313, "id": "b17", "idx": 17}, {"begin": 16317, "end": 16504, "id": "b18", "idx": 18}, {"begin": 16508, "end": 16673, "id": "b19", "idx": 19}, {"begin": 16677, "end": 16779, "id": "b20", "idx": 20}, {"begin": 16783, "end": 16920, "id": "b21", "idx": 21}], "ReferenceToTable": [{"begin": 7398, "end": 7399, "target": "#tab_0", "idx": 0}, {"begin": 8019, "end": 8020, "idx": 1}, {"begin": 8999, "end": 9000, "idx": 2}, {"begin": 9980, "end": 9981, "target": "#tab_1", "idx": 3}], "Footnote": [{"begin": 12431, "end": 12568, "id": "foot_0", "n": "1", "idx": 0}, {"begin": 12569, "end": 12615, "id": "foot_1", "n": "2", "idx": 1}, {"begin": 12616, "end": 12842, "id": "foot_2", "n": "3", "idx": 2}, {"begin": 12843, "end": 12903, "id": "foot_3", "n": "4", "idx": 3}, {"begin": 12904, "end": 12963, "id": "foot_4", "n": "5", "idx": 4}], "Paragraph": [{"begin": 89, "end": 1252, "idx": 0}, {"begin": 1270, "end": 1771, "idx": 1}, {"begin": 1772, "end": 2225, "idx": 2}, {"begin": 2226, "end": 2780, "idx": 3}, {"begin": 2781, "end": 3178, "idx": 4}, {"begin": 3179, "end": 3318, "idx": 5}, {"begin": 3345, "end": 3570, "idx": 6}, {"begin": 3571, "end": 4254, "idx": 7}, {"begin": 4255, "end": 4634, "idx": 8}, {"begin": 4665, "end": 4915, "idx": 9}, {"begin": 4916, "end": 5261, "idx": 10}, {"begin": 5262, "end": 5972, "idx": 11}, {"begin": 5997, "end": 6351, "idx": 12}, {"begin": 6376, "end": 6705, "idx": 13}, {"begin": 6721, "end": 7693, "idx": 14}, {"begin": 7725, "end": 8000, "idx": 15}, {"begin": 8001, "end": 8187, "idx": 16}, {"begin": 8188, "end": 8371, "idx": 17}, {"begin": 8382, "end": 8411, "idx": 18}, {"begin": 8469, "end": 8524, "idx": 19}, {"begin": 8525, "end": 8734, "idx": 20}, {"begin": 8735, "end": 8885, "idx": 21}, {"begin": 8912, "end": 9271, "idx": 22}, {"begin": 9272, "end": 9756, "idx": 23}, {"begin": 9777, "end": 10171, "idx": 24}, {"begin": 10188, "end": 10905, "idx": 25}, {"begin": 10906, "end": 11527, "idx": 26}, {"begin": 11528, "end": 11989, "idx": 27}, {"begin": 12020, "end": 12418, "idx": 28}], "SectionHeader": [{"begin": 0, "end": 1252, "idx": 0}], "SectionReference": [{"begin": 12965, "end": 16922, "idx": 0}], "Sentence": [{"begin": 89, "end": 339, "idx": 0}, {"begin": 340, "end": 567, "idx": 1}, {"begin": 568, "end": 883, "idx": 2}, {"begin": 884, "end": 1059, "idx": 3}, {"begin": 1060, "end": 1252, "idx": 4}, {"begin": 1270, "end": 1524, "idx": 5}, {"begin": 1525, "end": 1771, "idx": 6}, {"begin": 1772, "end": 1827, "idx": 7}, {"begin": 1828, "end": 1989, "idx": 8}, {"begin": 1990, "end": 2225, "idx": 9}, {"begin": 2226, "end": 2528, "idx": 10}, {"begin": 2529, "end": 2679, "idx": 11}, {"begin": 2680, "end": 2780, "idx": 12}, {"begin": 2781, "end": 3064, "idx": 13}, {"begin": 3065, "end": 3178, "idx": 14}, {"begin": 3179, "end": 3318, "idx": 15}, {"begin": 3345, "end": 3570, "idx": 16}, {"begin": 3571, "end": 3723, "idx": 17}, {"begin": 3724, "end": 3898, "idx": 18}, {"begin": 3899, "end": 4072, "idx": 19}, {"begin": 4073, "end": 4254, "idx": 20}, {"begin": 4255, "end": 4409, "idx": 21}, {"begin": 4410, "end": 4464, "idx": 22}, {"begin": 4465, "end": 4478, "idx": 23}, {"begin": 4479, "end": 4572, "idx": 24}, {"begin": 4573, "end": 4634, "idx": 25}, {"begin": 4665, "end": 4767, "idx": 26}, {"begin": 4768, "end": 4915, "idx": 27}, {"begin": 4916, "end": 5108, "idx": 28}, {"begin": 5109, "end": 5261, "idx": 29}, {"begin": 5262, "end": 5413, "idx": 30}, {"begin": 5414, "end": 5924, "idx": 31}, {"begin": 5925, "end": 5972, "idx": 32}, {"begin": 5997, "end": 6192, "idx": 33}, {"begin": 6193, "end": 6351, "idx": 34}, {"begin": 6376, "end": 6523, "idx": 35}, {"begin": 6524, "end": 6594, "idx": 36}, {"begin": 6595, "end": 6705, "idx": 37}, {"begin": 6721, "end": 7003, "idx": 38}, {"begin": 7004, "end": 7205, "idx": 39}, {"begin": 7206, "end": 7343, "idx": 40}, {"begin": 7344, "end": 7458, "idx": 41}, {"begin": 7459, "end": 7581, "idx": 42}, {"begin": 7582, "end": 7693, "idx": 43}, {"begin": 7725, "end": 8000, "idx": 44}, {"begin": 8001, "end": 8127, "idx": 45}, {"begin": 8128, "end": 8187, "idx": 46}, {"begin": 8188, "end": 8371, "idx": 47}, {"begin": 8382, "end": 8411, "idx": 48}, {"begin": 8469, "end": 8524, "idx": 49}, {"begin": 8525, "end": 8593, "idx": 50}, {"begin": 8594, "end": 8734, "idx": 51}, {"begin": 8735, "end": 8885, "idx": 52}, {"begin": 8912, "end": 9271, "idx": 53}, {"begin": 9272, "end": 9423, "idx": 54}, {"begin": 9424, "end": 9576, "idx": 55}, {"begin": 9577, "end": 9731, "idx": 56}, {"begin": 9732, "end": 9756, "idx": 57}, {"begin": 9777, "end": 9938, "idx": 58}, {"begin": 9939, "end": 9973, "idx": 59}, {"begin": 9974, "end": 10171, "idx": 60}, {"begin": 10188, "end": 10291, "idx": 61}, {"begin": 10292, "end": 10385, "idx": 62}, {"begin": 10386, "end": 10508, "idx": 63}, {"begin": 10509, "end": 10645, "idx": 64}, {"begin": 10646, "end": 10764, "idx": 65}, {"begin": 10765, "end": 10905, "idx": 66}, {"begin": 10906, "end": 11050, "idx": 67}, {"begin": 11051, "end": 11193, "idx": 68}, {"begin": 11194, "end": 11381, "idx": 69}, {"begin": 11382, "end": 11527, "idx": 70}, {"begin": 11528, "end": 11600, "idx": 71}, {"begin": 11601, "end": 11792, "idx": 72}, {"begin": 11793, "end": 11832, "idx": 73}, {"begin": 11833, "end": 11928, "idx": 74}, {"begin": 11929, "end": 11989, "idx": 75}, {"begin": 12020, "end": 12178, "idx": 76}, {"begin": 12179, "end": 12332, "idx": 77}, {"begin": 12333, "end": 12418, "idx": 78}], "Div": [{"begin": 89, "end": 1252, "idx": 0}, {"begin": 1255, "end": 3318, "idx": 1}, {"begin": 3320, "end": 5972, "idx": 2}, {"begin": 5974, "end": 6351, "idx": 3}, {"begin": 6353, "end": 6705, "idx": 4}, {"begin": 6707, "end": 7693, "idx": 5}, {"begin": 7695, "end": 8371, "idx": 6}, {"begin": 8373, "end": 8885, "idx": 7}, {"begin": 8887, "end": 9756, "idx": 8}, {"begin": 9758, "end": 10171, "idx": 9}, {"begin": 10173, "end": 11989, "idx": 10}, {"begin": 11991, "end": 12418, "idx": 11}], "SectionMain": [{"begin": 1252, "end": 12418, "idx": 0}], "ScholarlyEntity": [{"label": "Method", "begin": 91, "end": 109, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120Transfer", "\u0120Learning"], "seq_scores": [0.9735642075538635, 0.9703211784362793], "text": " Transfer Learning", "score": 0.9719426929950714, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 376, "end": 386, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120pre", "-", "train"], "seq_scores": [0.8585531115531921, 0.841521680355072, 0.8170231580734253], "text": " pre-train", "score": 0.8390326499938965, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 449, "end": 460, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9947457313537598, 0.9960913062095642, 0.9967881441116333, 0.9967363476753235], "text": " DistilBERT", "score": 0.9960903823375702, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 613, "end": 626, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120dist", "illation"], "seq_scores": [0.9399943947792053, 0.986764669418335], "text": " distillation", "score": 0.9633795320987701, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 673, "end": 696, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120knowledge", "\u0120dist", "illation"], "seq_scores": [0.9838136434555054, 0.9948276877403259, 0.994232714176178], "text": " knowledge distillation", "score": 0.990958015124003, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 703, "end": 726, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120pre", "-", "training", "\u0120phase"], "seq_scores": [0.8299826383590698, 0.8176774978637695, 0.9442304968833923, 0.942396879196167, 0.7289888262748718], "text": " the pre-training phase", "score": 0.8526552677154541, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 779, "end": 784, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9938563704490662, 0.9940462112426758], "text": " BERT", "score": 0.993951290845871, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 948, "end": 961, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120pre", "-", "training"], "seq_scores": [0.9164271950721741, 0.9466508030891418, 0.9446722269058228], "text": " pre-training", "score": 0.9359167416890463, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 975, "end": 989, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120a", "\u0120triple", "\u0120loss"], "seq_scores": [0.6341907382011414, 0.6728998422622681, 0.8939381241798401], "text": " a triple loss", "score": 0.7336762348810831, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 999, "end": 1017, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120language", "\u0120modeling"], "seq_scores": [0.9636780023574829, 0.9873368144035339], "text": " language modeling", "score": 0.9755074083805084, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1018, "end": 1031, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120dist", "illation"], "seq_scores": [0.9304198026657104, 0.9919993281364441], "text": " distillation", "score": 0.9612095654010773, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1035, "end": 1058, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120cos", "ine", "-", "distance", "\u0120losses"], "seq_scores": [0.9548234343528748, 0.9776197671890259, 0.977600634098053, 0.9793749451637268, 0.9344652891159058], "text": " cosine-distance losses", "score": 0.9647768139839172, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1111, "end": 1121, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120pre", "-", "train"], "seq_scores": [0.7741522192955017, 0.7261799573898315, 0.687099814414978], "text": " pre-train", "score": 0.7291439970334371, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1161, "end": 1184, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120on", "-", "device", "\u0120comput", "ations"], "seq_scores": [0.6256495118141174, 0.8198876976966858, 0.8185898065567017, 0.6863025426864624, 0.604198694229126], "text": " on-device computations", "score": 0.7109256505966186, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 114, "end": 145, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120large", "-", "scale", "\u0120pre", "-", "trained", "\u0120models"], "seq_scores": [0.9847416281700134, 0.9965752959251404, 0.9971494078636169, 0.9948257803916931, 0.9974650144577026, 0.997121274471283, 0.9963200092315674], "text": " large-scale pre-trained models", "score": 0.9948854872158596, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 216, "end": 235, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120these", "\u0120large", "\u0120models"], "seq_scores": [0.6593292355537415, 0.7405228018760681, 0.9835077524185181], "text": " these large models", "score": 0.7944532632827759, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 386, "end": 441, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120smaller", "\u0120general", "purpose", "\u0120language", "\u0120representation", "\u0120model"], "seq_scores": [0.9928481578826904, 0.9958594441413879, 0.9951655864715576, 0.9971669316291809, 0.997308611869812, 0.9976443648338318, 0.9967670440673828], "text": " a smaller generalpurpose language representation model", "score": 0.9961085915565491, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 542, "end": 566, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120its", "\u0120larger", "\u0120counterparts"], "seq_scores": [0.6790081858634949, 0.7874599099159241, 0.6535558700561523], "text": " its larger counterparts", "score": 0.7066746552785238, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 639, "end": 660, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120task", "-", "specific", "\u0120models"], "seq_scores": [0.9696163535118103, 0.9873742461204529, 0.9876662492752075, 0.9840620160102844], "text": " task-specific models", "score": 0.9821797162294388, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 927, "end": 941, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120larger", "\u0120models"], "seq_scores": [0.9797315001487732, 0.9920254349708557], "text": " larger models", "score": 0.9858784675598145, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 1059, "end": 1097, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120Our", "\u0120smaller", ",", "\u0120faster", "\u0120and", "\u0120lighter", "\u0120model"], "seq_scores": [0.9567224979400635, 0.9810309410095215, 0.9668144583702087, 0.9821494221687317, 0.9546339511871338, 0.9813235402107239, 0.9830498099327087], "text": " Our smaller, faster and lighter model", "score": 0.9722463744027274, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1310, "end": 1328, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120Transfer", "\u0120Learning"], "seq_scores": [0.9678492546081543, 0.9658966064453125], "text": " Transfer Learning", "score": 0.9668729305267334, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1463, "end": 1482, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Dev", "lin", "\u0120et", "\u0120al", ".,", "\u01202018"], "seq_scores": [0.9984741806983948, 0.9975330829620361, 0.997747004032135, 0.9977720379829407, 0.9972557425498962, 0.9970665574073792], "text": "Devlin et al., 2018", "score": 0.9976414342721304, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1483, "end": 1504, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Rad", "ford", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9979554414749146, 0.9971231818199158, 0.9973887801170349, 0.9974802136421204, 0.9970979690551758, 0.9971342086791992], "text": " Radford et al., 2019", "score": 0.9973632991313934, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1505, "end": 1522, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Liu", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9972932934761047, 0.9973758459091187, 0.9976859092712402, 0.9975798726081848, 0.9976746439933777], "text": " Liu et al., 2019", "score": 0.9975219130516052, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1687, "end": 1696, "seq_label": ["B-Method"], "seq_token": ["\u0120training"], "seq_scores": [0.6060637831687927], "text": " training", "score": 0.6060637831687927, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 1381, "end": 1421, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120large", "-", "scale", "\u0120pre", "-", "trained", "\u0120language", "\u0120models"], "seq_scores": [0.9929149150848389, 0.9975395202636719, 0.9978936314582825, 0.9959374666213989, 0.9982795715332031, 0.9980998635292053, 0.995496392250061, 0.9983289837837219], "text": " large-scale pre-trained language models", "score": 0.9968112930655479, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 1530, "end": 1543, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120these", "\u0120models"], "seq_scores": [0.98615962266922, 0.9912213087081909], "text": " these models", "score": 0.9886904656887054, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 1653, "end": 1672, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120pre", "-", "trained", "\u0120models"], "seq_scores": [0.9888973832130432, 0.9972223043441772, 0.9972437620162964, 0.996405839920044], "text": " pre-trained models", "score": 0.9949423223733902, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 1696, "end": 1715, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120even", "\u0120larger", "\u0120models"], "seq_scores": [0.9404619336128235, 0.8261428475379944, 0.9902082085609436], "text": " even larger models", "score": 0.9189376632372538, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1941, "end": 1965, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Schwartz", "\u0120et", "\u0120al", ".", "\u0120[", "2019", "],"], "seq_scores": [0.9958058595657349, 0.998938262462616, 0.9991000890731812, 0.9987918734550476, 0.9968709349632263, 0.9983375072479248, 0.9574692249298096], "text": " Schwartz et al. [2019],", "score": 0.9921876788139343, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1965, "end": 1989, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Str", "ub", "ell", "\u0120et", "\u0120al", ".", "\u0120[", "2019", "]."], "seq_scores": [0.9971843361854553, 0.9986587762832642, 0.9989854693412781, 0.9991273283958435, 0.999113142490387, 0.9989855885505676, 0.9975234866142273, 0.9985203146934509, 0.9916690587997437], "text": " Strubell et al. [2019].", "score": 0.997751944594913, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 1788, "end": 1802, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120bigger", "\u0120models"], "seq_scores": [0.9325396418571472, 0.8744522929191589], "text": " bigger models", "score": 0.9034959673881531, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2013, "end": 2026, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120these", "\u0120models"], "seq_scores": [0.8231321573257446, 0.8308103084564209], "text": " these models", "score": 0.8269712328910828, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2186, "end": 2199, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120these", "\u0120models"], "seq_scores": [0.8680220246315002, 0.841346800327301], "text": " these models", "score": 0.8546844124794006, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2358, "end": 2362, "seq_label": ["B-Method"], "seq_token": ["\u0120pre"], "seq_scores": [0.6458635926246643], "text": " pre", "score": 0.6458635926246643, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2375, "end": 2398, "seq_label": ["I-Method", "B-Method", "I-Method", "I-Method"], "seq_token": ["trained", "\u0120knowledge", "\u0120dist", "illation"], "seq_scores": [0.5334817171096802, 0.9881346225738525, 0.9934343099594116, 0.9931281805038452], "text": " knowledge distillation", "score": 0.8770447075366974, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2574, "end": 2585, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120fine", "-", "tun", "ed"], "seq_scores": [0.8134989738464355, 0.7567980289459229, 0.7375043034553528, 0.6716732382774353], "text": " fine-tuned", "score": 0.7448686361312866, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2329, "end": 2358, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120much", "\u0120smaller", "\u0120language", "\u0120models"], "seq_scores": [0.9762200117111206, 0.9905380010604858, 0.9920926690101624, 0.9971531629562378], "text": " much smaller language models", "score": 0.9890009611845016, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2412, "end": 2419, "seq_label": ["B-MLModelGeneric"], "seq_token": ["\u0120models"], "seq_scores": [0.9596075415611267], "text": " models", "score": 0.9596075415611267, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2528, "end": 2567, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120Our", "\u0120general", "-", "purpose", "\u0120pre", "-", "trained", "\u0120models"], "seq_scores": [0.9743688106536865, 0.9517448544502258, 0.9970918893814087, 0.9970665574073792, 0.9959756731987, 0.9972918629646301, 0.9974653720855713, 0.9972423315048218], "text": " Our general-purpose pre-trained models", "score": 0.9885309189558029, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2664, "end": 2678, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120larger", "\u0120models"], "seq_scores": [0.9836958646774292, 0.9894318580627441], "text": " larger models", "score": 0.9865638613700867, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2697, "end": 2719, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120our", "\u0120compressed", "\u0120models"], "seq_scores": [0.9813355207443237, 0.9852411150932312, 0.9949058294296265], "text": " our compressed models", "score": 0.9871608217557272, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 2828, "end": 2840, "seq_label": ["I-Method", "I-Method", "B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120triple", "\u0120loss", "\u0120Trans", "former"], "seq_scores": [0.5171992182731628, 0.85920250415802, 0.8242387175559998, 0.934272825717926], "text": " Transformer", "score": 0.7837283164262772, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2842, "end": 2864, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["V", "as", "w", "ani", "\u0120et", "\u0120al", ".", "\u0120[", "2017", "])"], "seq_scores": [0.9974843263626099, 0.9976599216461182, 0.9983162879943848, 0.9984086155891418, 0.9985920786857605, 0.9985713958740234, 0.9985097050666809, 0.99779212474823, 0.9980031847953796, 0.8974483609199524], "text": "Vaswani et al. [2017])", "score": 0.9880786001682281, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2864, "end": 2868, "seq_label": ["B-Method"], "seq_token": ["\u0120pre"], "seq_scores": [0.5530598759651184], "text": " pre", "score": 0.5530598759651184, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2884, "end": 2897, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120dist", "illation"], "seq_scores": [0.9596433043479919, 0.974777340888977], "text": " distillation", "score": 0.9672103226184845, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 2929, "end": 2941, "seq_label": ["I-Method", "B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120supervision", "\u0120Trans", "former"], "seq_scores": [0.5861793160438538, 0.8919734358787537, 0.9112457036972046], "text": " Transformer", "score": 0.7964661518732706, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2814, "end": 2843, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u012040", "%", "\u0120smaller", "\u0120Trans", "former", "\u0120(", "V"], "seq_scores": [0.991154670715332, 0.9938063621520996, 0.9941498041152954, 0.9960028529167175, 0.9951550960540771, 0.9938719272613525, 0.8836173415184021, 0.5426834225654602], "text": " a 40% smaller Transformer (V", "score": 0.9238051846623421, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2920, "end": 2956, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120bigger", "\u0120Trans", "former", "\u0120language", "\u0120model"], "seq_scores": [0.9777804017066956, 0.9897645711898804, 0.9876824021339417, 0.9962285757064819, 0.9960747957229614, 0.9958374500274658], "text": " a bigger Transformer language model", "score": 0.9905613660812378, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 3257, "end": 3280, "seq_label": ["B-ModelArchitecture", "I-Method", "I-Method"], "seq_token": ["\u0120Transformers", "\u01202", "\u0120library"], "seq_scores": [0.4784858524799347, 0.36365506052970886, 0.5761883854866028], "text": " Transformers 2 library", "score": 0.4727764328320821, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3285, "end": 3297, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Hug", "ging", "Face"], "seq_scores": [0.8994483351707458, 0.931020975112915, 0.9125057458877563], "text": " HuggingFace", "score": 0.9143250187238058, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3299, "end": 3316, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Wolf", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.993586003780365, 0.9908303022384644, 0.9893653392791748, 0.9852306246757507, 0.9823516011238098], "text": "Wolf et al., 2019", "score": 0.988272774219513, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3345, "end": 3367, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["Know", "ledge", "\u0120dist", "illation"], "seq_scores": [0.9888933300971985, 0.9957143664360046, 0.9962039589881897, 0.9946541786193848], "text": "Knowledge distillation", "score": 0.9938664585351944, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3369, "end": 3388, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["B", "uc", "ila", "\u0120et", "\u0120al", ".,", "\u01202006"], "seq_scores": [0.996692419052124, 0.9792566299438477, 0.9815424084663391, 0.9894796013832092, 0.9894698858261108, 0.9864338636398315, 0.9834218621253967], "text": "Bucila et al., 2006", "score": 0.9866138100624084, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3389, "end": 3409, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120H", "inton", "\u0120et", "\u0120al", ".,", "\u01202015"], "seq_scores": [0.996012806892395, 0.9887597560882568, 0.992922306060791, 0.9929348826408386, 0.9918602108955383, 0.990983247756958], "text": " Hinton et al., 2015", "score": 0.9922455350557963, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3413, "end": 3427, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120a", "\u0120compression"], "seq_scores": [0.6585937738418579, 0.4912286102771759], "text": " a compression", "score": 0.5749111920595169, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3446, "end": 3462, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120compact", "\u0120model"], "seq_scores": [0.9889049530029297, 0.9930612444877625, 0.9934626817703247], "text": " a compact model", "score": 0.991809626420339, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3464, "end": 3475, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["the", "\u0120student"], "seq_scores": [0.653897762298584, 0.9546417593955994], "text": "the student", "score": 0.8042697608470917, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3517, "end": 3532, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120larger", "\u0120model"], "seq_scores": [0.9804649353027344, 0.99162358045578, 0.9915995597839355], "text": " a larger model", "score": 0.9878960251808167, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3534, "end": 3545, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["the", "\u0120teacher"], "seq_scores": [0.6551327705383301, 0.9703609943389893], "text": "the teacher", "score": 0.8127468824386597, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3547, "end": 3569, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120an", "\u0120ensemble", "\u0120of", "\u0120models"], "seq_scores": [0.9053959250450134, 0.967151403427124, 0.9691956043243408, 0.9910658001899719], "text": " an ensemble of models", "score": 0.9582021832466125, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3573, "end": 3593, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120supervised", "\u0120learning"], "seq_scores": [0.9642987251281738, 0.9645692706108093], "text": " supervised learning", "score": 0.9644339978694916, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3594, "end": 3617, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120classification", "\u0120model"], "seq_scores": [0.9884361028671265, 0.9889059066772461, 0.9908567667007446], "text": " a classification model", "score": 0.9893995920817057, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3898, "end": 3906, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120A", "\u0120model"], "seq_scores": [0.9812301397323608, 0.9825526475906372], "text": " A model", "score": 0.981891393661499, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3925, "end": 3942, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", "\u0120set"], "seq_scores": [0.9906837940216064, 0.9914529323577881, 0.989038348197937], "text": " the training set", "score": 0.9903916915257772, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4196, "end": 4206, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9763633012771606, 0.9752117991447449], "text": " the model", "score": 0.9757875502109528, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4238, "end": 4251, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120test", "\u0120set"], "seq_scores": [0.9857910871505737, 0.9857726693153381, 0.9760589599609375], "text": " the test set", "score": 0.9825409054756165, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 4296, "end": 4316, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120a", "\u0120dist", "illation", "\u0120loss"], "seq_scores": [0.8679103851318359, 0.8822884559631348, 0.9383675456047058, 0.8693670034408569], "text": " a distillation loss", "score": 0.8894833475351334, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 4582, "end": 4603, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120H", "inton", "\u0120et", "\u0120al", ".", "\u0120[", "2015", "]"], "seq_scores": [0.9667763113975525, 0.9930511713027954, 0.9971888661384583, 0.9978435039520264, 0.9977626800537109, 0.9963106513023376, 0.997211754322052, 0.9955708384513855], "text": " Hinton et al. [2015]", "score": 0.9927144721150398, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4268, "end": 4280, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120The", "\u0120student"], "seq_scores": [0.9885873794555664, 0.9826479554176331], "text": " The student", "score": 0.9856176674365997, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4354, "end": 4366, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120teacher"], "seq_scores": [0.9595282673835754, 0.9520312547683716], "text": " the teacher", "score": 0.9557797610759735, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4445, "end": 4457, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120teacher"], "seq_scores": [0.9078794121742249, 0.9398891925811768], "text": " the teacher", "score": 0.9238843023777008, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4464, "end": 4476, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120student"], "seq_scores": [0.8752955198287964, 0.9723806381225586], "text": " the student", "score": 0.9238380789756775, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4804, "end": 4832, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120student", "\u0120and", "\u0120the", "\u0120teacher"], "seq_scores": [0.9921594858169556, 0.9929084777832031, 0.9528269171714783, 0.6894001960754395, 0.9924431443214417], "text": " the student and the teacher", "score": 0.9239476442337036, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 4971, "end": 4998, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120dist", "illation", "\u0120loss", "\u0120L", "\u0120ce"], "seq_scores": [0.7920458912849426, 0.8326625227928162, 0.9307019114494324, 0.8371946811676025, 0.4447196125984192, 0.8764042854309082], "text": " the distillation loss L ce", "score": 0.7856214841206869, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5003, "end": 5032, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120supervised", "\u0120training", "\u0120loss"], "seq_scores": [0.5644387602806091, 0.6876243352890015, 0.8719163537025452, 0.7108493447303772], "text": " the supervised training loss", "score": 0.7087071985006332, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5049, "end": 5085, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120masked", "\u0120language", "\u0120modeling", "\u0120loss", "\u0120L", "\u0120ml", "m"], "seq_scores": [0.6924585103988647, 0.9826827049255371, 0.9801085591316223, 0.8410964608192444, 0.384663850069046, 0.9138247966766357, 0.9244845509529114], "text": " masked language modeling loss L mlm", "score": 0.8170456332819802, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 5087, "end": 5106, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Dev", "lin", "\u0120et", "\u0120al", ".,", "\u01202018"], "seq_scores": [0.9972237348556519, 0.9936760067939758, 0.9953325390815735, 0.9953384399414062, 0.9940739274024963, 0.9934727549552917], "text": "Devlin et al., 2018", "score": 0.9948529005050659, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5138, "end": 5140, "seq_label": ["B-Method"], "seq_token": ["\u0120a"], "seq_scores": [0.591794490814209], "text": " a", "score": 0.591794490814209, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5140, "end": 5162, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120cos", "ine", "\u0120embed", "ding", "\u0120loss"], "seq_scores": [0.5900374054908752, 0.9728599786758423, 0.9661872982978821, 0.9582223296165466, 0.8494241833686829], "text": " cosine embedding loss", "score": 0.8673462390899658, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 5263, "end": 5274, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9950036406517029, 0.9965446591377258, 0.9971681237220764, 0.9972665309906006], "text": " DistilBERT", "score": 0.9964957386255264, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 5298, "end": 5303, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9925214648246765, 0.9953349232673645], "text": " BERT", "score": 0.9939281940460205, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 5359, "end": 5369, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["Dist", "il", "BER", "T"], "seq_scores": [0.9963764548301697, 0.996849000453949, 0.9974386692047119, 0.9973872303962708], "text": "DistilBERT", "score": 0.9970128387212753, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 5407, "end": 5412, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9956623911857605, 0.9964535236358643], "text": " BERT", "score": 0.9960579574108124, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5413, "end": 5439, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120The", "\u0120token", "-", "type", "\u0120embed", "d", "ings"], "seq_scores": [0.6732457280158997, 0.531294584274292, 0.9862072467803955, 0.9884074330329895, 0.9848094582557678, 0.9780201315879822, 0.9714780449867249], "text": " The token-type embeddings", "score": 0.8733518038477216, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5443, "end": 5454, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120pool", "er"], "seq_scores": [0.6909273266792297, 0.838069498538971, 0.8033149242401123], "text": " the pooler", "score": 0.7774372498194376, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 5557, "end": 5569, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120Trans", "former"], "seq_scores": [0.7221328616142273, 0.9714695811271667], "text": " Transformer", "score": 0.846801221370697, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5584, "end": 5596, "seq_label": ["B-Method", "I-Method"], "seq_token": ["linear", "\u0120layer"], "seq_scores": [0.6176090240478516, 0.686273455619812], "text": "linear layer", "score": 0.6519412398338318, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5600, "end": 5620, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120layer", "\u0120normal", "isation"], "seq_scores": [0.6740660667419434, 0.8587101697921753, 0.844711184501648], "text": " layer normalisation", "score": 0.7924958070119222, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5275, "end": 5298, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120distilled", "\u0120version", "\u0120of"], "seq_scores": [0.9466166496276855, 0.935278594493866, 0.7986543774604797, 0.6872860789299011], "text": " a distilled version of", "score": 0.8419589251279831, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5345, "end": 5357, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120student"], "seq_scores": [0.9838113188743591, 0.9844055771827698], "text": " the student", "score": 0.9841084480285645, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6163, "end": 6179, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120sub", "-", "network"], "seq_scores": [0.8896968960762024, 0.8080681562423706, 0.7335944175720215, 0.7068476676940918], "text": " the sub-network", "score": 0.7845517843961716, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6246, "end": 6275, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120teacher", "\u0120and", "\u0120student", "\u0120networks"], "seq_scores": [0.9928747415542603, 0.9910043478012085, 0.9904333353042603, 0.9944460391998291], "text": " teacher and student networks", "score": 0.9921896159648895, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6290, "end": 6302, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120student"], "seq_scores": [0.9928874373435974, 0.9949638843536377], "text": " the student", "score": 0.9939256608486176, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6307, "end": 6319, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120teacher"], "seq_scores": [0.9877786040306091, 0.9929706454277039], "text": " the teacher", "score": 0.9903746247291565, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 6384, "end": 6395, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.991852343082428, 0.9951047897338867, 0.9959279894828796, 0.9960196614265442], "text": " DistilBERT", "score": 0.9947261959314346, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 6430, "end": 6435, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9855464696884155, 0.9935044050216675], "text": " BERT", "score": 0.9895254373550415, "type": "ScholarlyEntity"}, {"label": "Datasource", "begin": 6461, "end": 6479, "seq_label": ["B-Datasource", "I-Datasource"], "seq_token": ["\u0120English", "\u0120Wikipedia"], "seq_scores": [0.6541741490364075, 0.6222492456436157], "text": " English Wikipedia", "score": 0.6382116973400116, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 6483, "end": 6503, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120Toronto", "\u0120Book", "\u0120Corpus"], "seq_scores": [0.761322557926178, 0.8497112989425659, 0.7979907393455505], "text": " Toronto Book Corpus", "score": 0.8030081987380981, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6505, "end": 6521, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Z", "hu", "\u0120et", "\u0120al", ".,", "\u01202015"], "seq_scores": [0.9982956051826477, 0.9977307915687561, 0.9981957077980042, 0.9982736110687256, 0.997943103313446, 0.9978110194206238], "text": "Zhu et al., 2015", "score": 0.9980416397253672, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 6523, "end": 6534, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9901946187019348, 0.9931560158729553, 0.9939163327217102, 0.9941173791885376], "text": " DistilBERT", "score": 0.9928460866212845, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 6626, "end": 6634, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9778550863265991, 0.9894837737083435, 0.9920008182525635], "text": " RoBERTa", "score": 0.9864465594291687, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6642, "end": 6658, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["L", "iu", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9984195232391357, 0.9972952008247375, 0.9981814622879028, 0.9980568289756775, 0.9977834820747375, 0.9973776340484619], "text": "Liu et al., 2019", "score": 0.9978523552417755, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 6398, "end": 6414, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120same", "\u0120corpus"], "seq_scores": [0.97749924659729, 0.970256507396698, 0.9910345673561096], "text": " the same corpus", "score": 0.9795967737833658, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 6442, "end": 6461, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120a", "\u0120conc", "aten", "ation", "\u0120of"], "seq_scores": [0.891217052936554, 0.8842726945877075, 0.848781168460846, 0.7430478930473328, 0.5303223133087158], "text": " a concatenation of", "score": 0.7795282244682312, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 6461, "end": 6479, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120English", "\u0120Wikipedia"], "seq_scores": [0.5395585894584656, 0.9503623247146606], "text": " English Wikipedia", "score": 0.7449604570865631, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 6721, "end": 6751, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["General", "\u0120Language", "\u0120Understanding"], "seq_scores": [0.9774245023727417, 0.9873628616333008, 0.9728400111198425], "text": "General Language Understanding", "score": 0.9792091250419617, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 6765, "end": 6788, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120language", "\u0120understanding"], "seq_scores": [0.9099432826042175, 0.9716169238090515], "text": " language understanding", "score": 0.9407801032066345, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 6792, "end": 6807, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120general", "ization"], "seq_scores": [0.5222949385643005, 0.9730556607246399], "text": " generalization", "score": 0.7476752996444702, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 6823, "end": 6834, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9924197793006897, 0.9950307607650757, 0.9956538677215576, 0.995442271232605], "text": " DistilBERT", "score": 0.994636669754982, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 6841, "end": 6883, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120General", "\u0120Language", "\u0120Understanding", "\u0120Evaluation"], "seq_scores": [0.9862031936645508, 0.9844949841499329, 0.9834575653076172, 0.9793031811714172], "text": " General Language Understanding Evaluation", "score": 0.9833647310733795, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 6885, "end": 6889, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["GL", "UE"], "seq_scores": [0.9897105097770691, 0.9920684099197388], "text": "GLUE", "score": 0.9908894598484039, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6902, "end": 6919, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["W", "ang", "\u0120et", "\u0120al", ".,", "\u01202018"], "seq_scores": [0.9978530406951904, 0.9966403245925903, 0.9978359341621399, 0.9978905320167542, 0.9975720047950745, 0.997194766998291], "text": "Wang et al., 2018", "score": 0.9974977672100067, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7061, "end": 7073, "seq_label": ["I-Task", "B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120understanding", "\u0120fine", "-", "tun", "ing"], "seq_scores": [0.4995029866695404, 0.9454317688941956, 0.9491905570030212, 0.9556174874305725, 0.9190847873687744], "text": " fine-tuning", "score": 0.8537655174732208, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7073, "end": 7084, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9880160689353943, 0.9945433139801025, 0.9953606724739075, 0.9950920343399048], "text": " DistilBERT", "score": 0.9932530224323273, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7103, "end": 7114, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120en", "semb", "ling"], "seq_scores": [0.947900652885437, 0.9855152368545532, 0.9871377944946289], "text": " ensembling", "score": 0.973517894744873, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7117, "end": 7138, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120multi", "-", "t", "asking", "\u0120scheme"], "seq_scores": [0.8223420977592468, 0.9870713353157043, 0.9857890009880066, 0.9857468605041504, 0.9150551557540894], "text": " multi-tasking scheme", "score": 0.9392008900642395, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7142, "end": 7154, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120fine", "-", "tun", "ing"], "seq_scores": [0.9702319502830505, 0.9823948740959167, 0.9800726175308228, 0.9822694063186646], "text": " fine-tuning", "score": 0.9787422120571136, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 7271, "end": 7276, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120GL", "UE"], "seq_scores": [0.987907350063324, 0.9858237504959106], "text": " GLUE", "score": 0.9868655502796173, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7280, "end": 7285, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120EL", "Mo"], "seq_scores": [0.6071968078613281, 0.8538062572479248], "text": " ELMo", "score": 0.7305015325546265, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7287, "end": 7306, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["P", "eters", "\u0120et", "\u0120al", ".", "\u0120[", "2018"], "seq_scores": [0.9966358542442322, 0.9967999458312988, 0.9978848099708557, 0.9977763295173645, 0.997142493724823, 0.994502067565918, 0.9955303072929382], "text": "Peters et al. [2018", "score": 0.9966102583067757, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 7308, "end": 7316, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120enc", "oder"], "seq_scores": [0.7387280464172363, 0.8933165669441223], "text": " encoder", "score": 0.8160223066806793, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 7332, "end": 7340, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120Bi", "L", "ST", "Ms"], "seq_scores": [0.8103576302528381, 0.9470541477203369, 0.9216691851615906, 0.9447298645973206], "text": " BiLSTMs", "score": 0.9059527069330215, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7477, "end": 7488, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9938350915908813, 0.9958152174949646, 0.9964367151260376, 0.9964697360992432], "text": " DistilBERT", "score": 0.9956391900777817, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7527, "end": 7532, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120EL", "Mo"], "seq_scores": [0.9689333438873291, 0.9845830202102661], "text": " ELMo", "score": 0.9767581820487976, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 7573, "end": 7579, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120ST", "S", "-", "B"], "seq_scores": [0.9732599258422852, 0.9745809435844421, 0.9760624766349792, 0.9782163500785828], "text": " STS-B", "score": 0.9755299240350723, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7581, "end": 7592, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9943566918373108, 0.995987594127655, 0.9965590834617615, 0.9964097142219543], "text": " DistilBERT", "score": 0.9958282709121704, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7627, "end": 7632, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9923892617225647, 0.9949643611907959], "text": " BERT", "score": 0.9936768114566803, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 6921, "end": 6948, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120a", "\u0120collection", "\u0120of", "\u01209", "\u0120datasets"], "seq_scores": [0.8652132749557495, 0.941632866859436, 0.7732924222946167, 0.5465677976608276, 0.9966950416564941], "text": " a collection of 9 datasets", "score": 0.8246802806854248, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 7023, "end": 7044, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120development", "\u0120sets"], "seq_scores": [0.9899284243583679, 0.9956747889518738, 0.9942635893821716], "text": " the development sets", "score": 0.9932889342308044, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7231, "end": 7244, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120baseline"], "seq_scores": [0.781482458114624, 0.7941825985908508], "text": " the baseline", "score": 0.7878325283527374, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 7464, "end": 7476, "seq_label": ["I-MLModelGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["L", "\u01209", "\u0120tasks", "\u0120the", "\u01209", "\u0120tasks"], "seq_scores": [0.5331154465675354, 0.6804683208465576, 0.6897609829902649, 0.5387284755706787, 0.684897243976593, 0.5634095668792725], "text": " the 9 tasks", "score": 0.615063339471817, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7523, "end": 7541, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120EL", "Mo", "\u0120baseline"], "seq_scores": [0.8030579686164856, 0.8864708542823792, 0.8154799938201904, 0.899493396282196], "text": " the ELMo baseline", "score": 0.8511255532503128, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7778, "end": 7789, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9909829497337341, 0.9951708912849426, 0.9955600500106812, 0.9956509470939636], "text": " DistilBERT", "score": 0.9943412095308304, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 7858, "end": 7873, "seq_label": ["B-Task"], "seq_token": ["\u0120classification"], "seq_scores": [0.9590076804161072], "text": " classification", "score": 0.9590076804161072, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 7880, "end": 7909, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["IM", "Db", "\u0120sentiment", "\u0120classification"], "seq_scores": [0.9819075465202332, 0.9924494028091431, 0.8973278999328613, 0.9619930386543274], "text": "IMDb sentiment classification", "score": 0.9584194719791412, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7911, "end": 7931, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ma", "as", "\u0120et", "\u0120al", ".", "\u0120[", "2011", "])"], "seq_scores": [0.9971466660499573, 0.9983415603637695, 0.9989979863166809, 0.9990027546882629, 0.9987689852714539, 0.997562050819397, 0.9985966086387634, 0.8571321964263916], "text": " Maas et al. [2011])", "score": 0.9806936010718346, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 7937, "end": 7956, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120question", "\u0120answering"], "seq_scores": [0.9808195233345032, 0.9908576607704163], "text": " question answering", "score": 0.9858385920524597, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 7963, "end": 7973, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset", "I-Dataset", "I-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["S", "Qu", "AD", "\u0120v", "1", ".", "1"], "seq_scores": [0.9923869371414185, 0.9950113296508789, 0.9947482943534851, 0.9899463057518005, 0.9926626682281494, 0.9900772571563721, 0.9895811080932617], "text": "SQuAD v1.1", "score": 0.9920591286250523, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7975, "end": 8000, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["R", "aj", "pur", "kar", "\u0120et", "\u0120al", ".", "\u0120[", "2016", "])."], "seq_scores": [0.9973067045211792, 0.998132050037384, 0.9989091157913208, 0.9989663362503052, 0.9990031123161316, 0.9988641738891602, 0.9984915256500244, 0.9973342418670654, 0.998184859752655, 0.9022977352142334], "text": "Rajpurkar et al. [2016]).", "score": 0.988748985528946, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8021, "end": 8032, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9921284914016724, 0.9947565793991089, 0.9949179887771606, 0.9948456287384033], "text": " DistilBERT", "score": 0.9941621720790863, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8058, "end": 8063, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9855684638023376, 0.9868713617324829], "text": " BERT", "score": 0.9862199127674103, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 8087, "end": 8092, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120IM", "Db"], "seq_scores": [0.9391413927078247, 0.9462374448776245], "text": " IMDb", "score": 0.9426894187927246, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 8130, "end": 8136, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120S", "Qu", "AD"], "seq_scores": [0.9938072562217712, 0.9930907487869263, 0.9920725226402283], "text": " SQuAD", "score": 0.9929901758829752, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8137, "end": 8148, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9911894798278809, 0.9943205118179321, 0.9946117401123047, 0.9943742752075195], "text": " DistilBERT", "score": 0.9936240017414093, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8181, "end": 8186, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.959909200668335, 0.9749387502670288], "text": " BERT", "score": 0.9674239754676819, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8240, "end": 8253, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120dist", "illation"], "seq_scores": [0.6997533440589905, 0.9887455105781555], "text": " distillation", "score": 0.844249427318573, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8260, "end": 8281, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120adaptation", "\u0120phase"], "seq_scores": [0.6958458423614502, 0.7370790839195251, 0.4840489625930786], "text": " the adaptation phase", "score": 0.6389912962913513, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8284, "end": 8296, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120fine", "-", "tun", "ing"], "seq_scores": [0.8318698406219482, 0.8849351406097412, 0.9100397229194641, 0.8388733863830566], "text": " fine-tuning", "score": 0.8664295226335526, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8296, "end": 8307, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9849581718444824, 0.9955497980117798, 0.9959250688552856, 0.9951465725898743], "text": " DistilBERT", "score": 0.9928949028253555, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 8310, "end": 8316, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120S", "Qu", "AD"], "seq_scores": [0.989599347114563, 0.9942388534545898, 0.994106650352478], "text": " SQuAD", "score": 0.9926482836405436, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8324, "end": 8329, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9915930032730103, 0.9946095943450928], "text": " BERT", "score": 0.9931012988090515, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 8360, "end": 8366, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120S", "Qu", "AD"], "seq_scores": [0.9893409609794617, 0.9935593605041504, 0.9935584664344788], "text": " SQuAD", "score": 0.9921529293060303, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 8322, "end": 8335, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120B", "ERT", "\u0120model"], "seq_scores": [0.7895415425300598, 0.7585623264312744, 0.7551726698875427, 0.7769181728363037], "text": " a BERT model", "score": 0.7700486779212952, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 8394, "end": 8399, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120GL", "UE"], "seq_scores": [0.9828028082847595, 0.9859716296195984], "text": " GLUE", "score": 0.984387218952179, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8569, "end": 8591, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["knowledge", "\u0120dist", "illation"], "seq_scores": [0.9917368292808533, 0.9936941266059875, 0.9928576946258545], "text": "knowledge distillation", "score": 0.9927628835042318, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8649, "end": 8662, "seq_label": ["I-Method", "I-Method", "B-Method", "I-Method"], "seq_token": ["\u0120successive", "\u0120steps", "\u0120dist", "illation"], "seq_scores": [0.5871294140815735, 0.5560204982757568, 0.8835979104042053, 0.9614771008491516], "text": " distillation", "score": 0.7470562309026718, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8674, "end": 8697, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120pre", "-", "training", "\u0120phase"], "seq_scores": [0.8556263446807861, 0.9585685729980469, 0.9554319977760315, 0.9612405896186829, 0.7907183170318604], "text": " the pre-training phase", "score": 0.9043171644210816, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8712, "end": 8733, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120adaptation", "\u0120phase"], "seq_scores": [0.8399352431297302, 0.8942013382911682, 0.5839768648147583], "text": " the adaptation phase", "score": 0.7727044820785522, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 8813, "end": 8823, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9852069020271301, 0.9697611927986145], "text": " the model", "score": 0.9774840474128723, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 8869, "end": 8884, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120full", "\u0120model"], "seq_scores": [0.9926707744598389, 0.9900173544883728, 0.9933313727378845], "text": " the full model", "score": 0.9920065005620321, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8965, "end": 8976, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9942662119865417, 0.9954879879951477, 0.9963602423667908, 0.9960814118385315], "text": " DistilBERT", "score": 0.9955489635467529, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 9102, "end": 9108, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120ST", "S", "-", "B"], "seq_scores": [0.9825106263160706, 0.9923600554466248, 0.9889909029006958, 0.9899901151657104], "text": " STS-B", "score": 0.9884629249572754, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9196, "end": 9207, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9946451187133789, 0.9956860542297363, 0.996775209903717, 0.996543824672699], "text": " DistilBERT", "score": 0.9959125518798828, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9237, "end": 9242, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9944133162498474, 0.9962838292121887], "text": " BERT", "score": 0.9953485727310181, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9265, "end": 9270, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9941667318344116, 0.9954895377159119], "text": " BERT", "score": 0.9948281347751617, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9029, "end": 9040, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120each", "\u0120model"], "seq_scores": [0.9485808610916138, 0.9435632824897766], "text": " each model", "score": 0.9460720717906952, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 9098, "end": 9124, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120ST", "S", "-", "B", "\u0120development", "\u0120set"], "seq_scores": [0.8469977378845215, 0.926139235496521, 0.9291306734085083, 0.9365960955619812, 0.9432569742202759, 0.971384584903717, 0.9794797301292419], "text": " the STS-B development set", "score": 0.9332835759435382, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9312, "end": 9323, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9917027354240417, 0.9946789741516113, 0.9952653646469116, 0.9943506717681885], "text": " DistilBERT", "score": 0.9939994364976883, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 9403, "end": 9422, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120question", "\u0120answering"], "seq_scores": [0.9694772958755493, 0.9681743383407593], "text": " question answering", "score": 0.9688258171081543, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 9531, "end": 9550, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120question", "\u0120answering"], "seq_scores": [0.8060414791107178, 0.7655755281448364], "text": " question answering", "score": 0.7858085036277771, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9565, "end": 9575, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "base"], "seq_scores": [0.9898966550827026, 0.990723192691803, 0.9834717512130737, 0.9873914122581482], "text": " BERT-base", "score": 0.9878707528114319, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9609, "end": 9620, "seq_label": ["I-Method", "I-Method", "B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120token", "ization", "\u0120Dist", "il", "BER", "T"], "seq_scores": [0.5275194048881531, 0.9267011284828186, 0.9942185878753662, 0.9960799813270569, 0.9968710541725159, 0.9966332316398621], "text": " DistilBERT", "score": 0.9063372313976288, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9639, "end": 9644, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9944002032279968, 0.9956347346305847], "text": " BERT", "score": 0.9950174689292908, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9508, "end": 9556, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120our", "\u0120previously", "\u0120trained", "\u0120question", "\u0120answering", "\u0120model"], "seq_scores": [0.9920624494552612, 0.994244396686554, 0.9964678287506104, 0.9925751686096191, 0.9962285757064819, 0.9968438148498535], "text": " our previously trained question answering model", "score": 0.99473703900973, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9649, "end": 9665, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120whole", "\u0120model"], "seq_scores": [0.9884893298149109, 0.9935809373855591, 0.9943114519119263], "text": " the whole model", "score": 0.9921272397041321, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9847, "end": 9863, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120triple", "\u0120loss"], "seq_scores": [0.751080334186554, 0.8518766164779663, 0.9099940061569214], "text": " the triple loss", "score": 0.8376503189404806, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9867, "end": 9894, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120student", "\u0120initialization"], "seq_scores": [0.676100492477417, 0.7825961112976074, 0.9213518500328064], "text": " the student initialization", "score": 0.7933494846026102, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 9967, "end": 9972, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120GL", "UE"], "seq_scores": [0.9904609322547913, 0.9898766875267029], "text": " GLUE", "score": 0.9901688098907471, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10006, "end": 10027, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120full", "\u0120triple", "\u0120loss"], "seq_scores": [0.687966525554657, 0.7895087599754333, 0.9678632020950317, 0.9535740613937378], "text": " the full triple loss", "score": 0.849728137254715, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10041, "end": 10071, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Mask", "ed", "\u0120Language", "\u0120Model", "ing", "\u0120loss"], "seq_scores": [0.5795998573303223, 0.9869562387466431, 0.986035943031311, 0.984882652759552, 0.9808979630470276, 0.8910081386566162], "text": " Masked Language Modeling loss", "score": 0.9015634655952454, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10095, "end": 10123, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120two", "\u0120dist", "illation", "\u0120losses"], "seq_scores": [0.5763726234436035, 0.752852737903595, 0.8656771183013916, 0.9251424670219421, 0.8440096974372864], "text": " the two distillation losses", "score": 0.7928109288215637, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9917, "end": 9937, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120distilled", "\u0120model"], "seq_scores": [0.9929244518280029, 0.9940252900123596, 0.9947585463523865], "text": " the distilled model", "score": 0.9939027627309164, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10188, "end": 10214, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["Task", "-", "specific", "\u0120dist", "illation"], "seq_scores": [0.993777871131897, 0.9960098266601562, 0.9967706203460693, 0.9969622492790222, 0.996032178401947], "text": "Task-specific distillation", "score": 0.9959105491638184, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10256, "end": 10290, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120task", "-", "specific", "\u0120dist", "illation", "\u0120setups"], "seq_scores": [0.9824474453926086, 0.9933138489723206, 0.9936180114746094, 0.9935230016708374, 0.9916656613349915, 0.6941301822662354], "text": " task-specific distillation setups", "score": 0.9414496918519338, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 10292, "end": 10311, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Tang", "\u0120et", "\u0120al", ".", "\u0120[", "2019", "]"], "seq_scores": [0.9935603141784668, 0.998649537563324, 0.9989581108093262, 0.9985641837120056, 0.9973800778388977, 0.9976693987846375, 0.9878501296043396], "text": " Tang et al. [2019]", "score": 0.9960902503558567, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 10351, "end": 10356, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9928552508354187, 0.994734525680542], "text": " BERT", "score": 0.9937948882579803, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 10362, "end": 10373, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120L", "ST", "M", "-", "based"], "seq_scores": [0.6198228001594543, 0.7530324459075928, 0.7661809921264648, 0.6541244983673096, 0.5581511855125427], "text": " LSTM-based", "score": 0.6702623844146729, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 10386, "end": 10404, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ch", "atter", "jee", "\u0120[", "2019", "]"], "seq_scores": [0.9945683479309082, 0.9984222650527954, 0.9989182949066162, 0.9977693557739258, 0.9980493783950806, 0.9886123538017273], "text": " Chatterjee [2019]", "score": 0.9960566659768423, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 10412, "end": 10417, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9936150312423706, 0.9947519898414612], "text": " BERT", "score": 0.9941835105419159, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 10437, "end": 10443, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120S", "Qu", "AD"], "seq_scores": [0.9921597838401794, 0.9909150004386902, 0.9897936582565308], "text": " SQuAD", "score": 0.9909561475118002, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 10456, "end": 10468, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120Trans", "former"], "seq_scores": [0.7496468424797058, 0.8580664992332458], "text": " Transformer", "score": 0.8038566708564758, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 10502, "end": 10507, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9945900440216064, 0.9947563409805298], "text": " BERT", "score": 0.9946731925010681, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10559, "end": 10561, "seq_label": ["B-Method"], "seq_token": ["\u0120a"], "seq_scores": [0.6081403493881226], "text": " a", "score": 0.6081403493881226, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10561, "end": 10603, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120general", "-", "purpose", "\u0120pre", "-", "training", "\u0120dist", "illation"], "seq_scores": [0.640974223613739, 0.9946388602256775, 0.9955437779426575, 0.9902032613754272, 0.9958199262619019, 0.9959241151809692, 0.9933103322982788, 0.9920371770858765], "text": " general-purpose pre-training distillation", "score": 0.949806459248066, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10615, "end": 10617, "seq_label": ["B-Method"], "seq_token": ["\u0120a"], "seq_scores": [0.5616725087165833], "text": " a", "score": 0.5616725087165833, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10617, "end": 10644, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120task", "-", "specific", "\u0120dist", "illation"], "seq_scores": [0.6958626508712769, 0.9957512617111206, 0.9961079955101013, 0.9961584210395813, 0.9952660799026489], "text": " task-specific distillation", "score": 0.9358292818069458, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 10646, "end": 10665, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Tur", "c", "\u0120et", "\u0120al", ".", "\u0120[", "2019", "]"], "seq_scores": [0.9957461953163147, 0.9981154203414917, 0.9988231062889099, 0.9989515542984009, 0.9985248446464539, 0.9964183568954468, 0.9974740147590637, 0.986707329750061], "text": " Turc et al. [2019]", "score": 0.9963451027870178, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10669, "end": 10704, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120original", "\u0120pret", "raining", "\u0120objective"], "seq_scores": [0.6818845868110657, 0.8782529234886169, 0.6926313042640686, 0.943112850189209, 0.7167656421661377], "text": " the original pretraining objective", "score": 0.7825294613838196, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10750, "end": 10763, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120dist", "illation"], "seq_scores": [0.9849908947944641, 0.9889772534370422], "text": " distillation", "score": 0.9869840741157532, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10858, "end": 10868, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120pre", "-", "train"], "seq_scores": [0.7959108948707581, 0.6754052639007568, 0.7102188467979431], "text": " pre-train", "score": 0.7271783351898193, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10873, "end": 10904, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120additional", "\u0120dist", "illation", "\u0120signal"], "seq_scores": [0.7697770595550537, 0.7745155692100525, 0.9548102617263794, 0.7923716902732849], "text": " additional distillation signal", "score": 0.8228686451911926, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10330, "end": 10351, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120classification", "\u0120model"], "seq_scores": [0.9497436285018921, 0.956104040145874], "text": " classification model", "score": 0.9529238343238831, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10359, "end": 10384, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120an", "\u0120L", "ST", "M", "-", "based", "\u0120class", "ifier"], "seq_scores": [0.951835036277771, 0.9580188989639282, 0.9977239966392517, 0.9974179267883301, 0.9971946477890015, 0.9974822402000427, 0.9967014193534851, 0.9973215460777283], "text": " an LSTM-based classifier", "score": 0.9867119640111923, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10412, "end": 10423, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120B", "ERT", "\u0120model"], "seq_scores": [0.7877374291419983, 0.8333322405815125, 0.7787428498268127], "text": " BERT model", "score": 0.7999375065167745, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10446, "end": 10474, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120smaller", "\u0120Trans", "former", "\u0120model"], "seq_scores": [0.9644838571548462, 0.9857690930366516, 0.9890167713165283, 0.9922473430633545, 0.988835871219635], "text": " a smaller Transformer model", "score": 0.9840705871582032, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10713, "end": 10729, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120smaller", "\u0120student"], "seq_scores": [0.9906032681465149, 0.9941745400428772], "text": " smaller student", "score": 0.992388904094696, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10831, "end": 10843, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120teacher"], "seq_scores": [0.5402507781982422, 0.7448626756668091], "text": " the teacher", "score": 0.6425567269325256, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10906, "end": 10924, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["Multi", "-", "dist", "illation"], "seq_scores": [0.9939765930175781, 0.9965985417366028, 0.996933102607727, 0.9963998794555664], "text": "Multi-distillation", "score": 0.9959770292043686, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 10924, "end": 10943, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Yang", "\u0120et", "\u0120al", ".", "\u0120[", "2019", "]"], "seq_scores": [0.9809897541999817, 0.996724545955658, 0.9982923865318298, 0.9974983334541321, 0.9968359470367432, 0.997660756111145, 0.9935570359230042], "text": " Yang et al. [2019]", "score": 0.9945083941732135, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10998, "end": 11018, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120multi", "-", "task", "\u0120learning"], "seq_scores": [0.9915223121643066, 0.9943526983261108, 0.9947677850723267, 0.9943698048591614], "text": " multi-task learning", "score": 0.9937531501054764, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11021, "end": 11029, "seq_label": ["B-Method"], "seq_token": ["\u0120regular"], "seq_scores": [0.6831273436546326], "text": " regular", "score": 0.6831273436546326, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11032, "end": 11049, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120dist", "illation"], "seq_scores": [0.551112174987793, 0.9310269951820374, 0.9843463897705078], "text": " the distillation", "score": 0.822161853313446, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11068, "end": 11102, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Multi", "-", "Task", "\u0120Knowledge", "\u0120Dist", "illation"], "seq_scores": [0.9894258975982666, 0.9961112141609192, 0.9970501661300659, 0.9968683123588562, 0.9966399669647217, 0.9960022568702698], "text": " Multi-Task Knowledge Distillation", "score": 0.9953496356805166, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 11121, "end": 11140, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120question", "\u0120answering"], "seq_scores": [0.7242693901062012, 0.8720108270645142], "text": " question answering", "score": 0.7981401085853577, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 11166, "end": 11185, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120question", "\u0120answering"], "seq_scores": [0.5326406955718994, 0.6879774332046509], "text": " question answering", "score": 0.6103090643882751, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11211, "end": 11230, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120multi", "-", "dist", "illation"], "seq_scores": [0.991838276386261, 0.9967838525772095, 0.9967710375785828, 0.9962893724441528], "text": " multi-distillation", "score": 0.9954206347465515, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11233, "end": 11250, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120multi", "-", "ling", "uality"], "seq_scores": [0.5606891512870789, 0.6199635863304138, 0.5973601937294006, 0.5209736824035645], "text": " multi-linguality", "score": 0.5747466534376144, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 11251, "end": 11270, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ts", "ai", "\u0120et", "\u0120al", ".", "\u0120[", "2019", "]"], "seq_scores": [0.987255334854126, 0.9976025223731995, 0.9983736276626587, 0.998678982257843, 0.9969003200531006, 0.9940313696861267, 0.9975428581237793, 0.985276997089386], "text": " Tsai et al. [2019]", "score": 0.9944577515125275, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11305, "end": 11318, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120pre", "-", "training"], "seq_scores": [0.9537042379379272, 0.9623477458953857, 0.9488372206687927], "text": " pre-training", "score": 0.9549630681673685, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11367, "end": 11380, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120dist", "illation"], "seq_scores": [0.9852815270423889, 0.9867010712623596], "text": " distillation", "score": 0.9859912991523743, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11462, "end": 11477, "seq_label": ["I-Method", "I-Method", "I-Method", "B-Method"], "seq_token": ["\u0120teacher", "'s", "\u0120knowledge", "\u0120initialization"], "seq_scores": [0.6311859488487244, 0.5830942988395691, 0.5551600456237793, 0.5399741530418396], "text": " initialization", "score": 0.5773536115884781, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10968, "end": 10992, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120an", "\u0120ensemble", "\u0120of", "\u0120teachers"], "seq_scores": [0.9841344952583313, 0.9901590943336487, 0.9883455038070679, 0.996660590171814], "text": " an ensemble of teachers", "score": 0.9898249208927155, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11111, "end": 11146, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120compact", "\u0120question", "\u0120answering", "\u0120model"], "seq_scores": [0.9932876229286194, 0.9954688549041748, 0.9958991408348083, 0.9967734217643738, 0.9972841739654541], "text": " a compact question answering model", "score": 0.9957426428794861, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11151, "end": 11192, "seq_label": ["B-MLModelGeneric", "I-DatasetGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120set", "\u0120of", "\u0120large", "\u0120question", "\u0120answering", "\u0120models"], "seq_scores": [0.5139362812042236, 0.5017059445381165, 0.7658769488334656, 0.8819236159324646, 0.9943633079528809, 0.9963468909263611, 0.9960250854492188], "text": " a set of large question answering models", "score": 0.8071682964052472, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11318, "end": 11339, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120mult", "ilingual", "\u0120model"], "seq_scores": [0.9948127269744873, 0.9952621459960938, 0.9976621866226196, 0.9968315958976746], "text": " a multilingual model", "score": 0.9961421638727188, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11433, "end": 11447, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120teacher", "'s"], "seq_scores": [0.705697774887085, 0.8193646669387817, 0.5815219879150391], "text": " the teacher's", "score": 0.7021948099136353, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11528, "end": 11556, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["Other", "\u0120compression", "\u0120techniques"], "seq_scores": [0.771104633808136, 0.6563776731491089, 0.6350376009941101], "text": "Other compression techniques", "score": 0.687506635983785, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11623, "end": 11639, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120weights", "\u0120pr", "uning"], "seq_scores": [0.980679988861084, 0.9844037294387817, 0.9902492165565491], "text": " weights pruning", "score": 0.9851109782854716, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11690, "end": 11709, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120self", "-", "att", "ention"], "seq_scores": [0.5182453989982605, 0.40980085730552673, 0.514316201210022, 0.5061211585998535, 0.5543776750564575], "text": " the self-attention", "score": 0.5005722582340241, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 11770, "end": 11792, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Michel", "\u0120et", "\u0120al", ".", "\u0120[", "2019", "]."], "seq_scores": [0.9950337409973145, 0.9987139701843262, 0.999136745929718, 0.9989621639251709, 0.9981720447540283, 0.9986490607261658, 0.9848723411560059], "text": " Michel et al. [2019].", "score": 0.9962200096675328, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11867, "end": 11880, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120quant", "ization"], "seq_scores": [0.9588543176651001, 0.9794707894325256], "text": " quantization", "score": 0.9691625535488129, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 11907, "end": 11928, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Gu", "pta", "\u0120et", "\u0120al", ".", "\u0120[", "2015", "])."], "seq_scores": [0.9980332255363464, 0.998658299446106, 0.9990813732147217, 0.9990705847740173, 0.9990172386169434, 0.9983854293823242, 0.9985281229019165, 0.9822136163711548], "text": "Gupta et al. [2015]).", "score": 0.9966234862804413, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11928, "end": 11936, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120Pr", "uning"], "seq_scores": [0.9788025617599487, 0.9889194369316101], "text": " Pruning", "score": 0.9838609993457794, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11940, "end": 11953, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120quant", "ization"], "seq_scores": [0.9716913104057312, 0.9915881752967834], "text": " quantization", "score": 0.9816397428512573, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11586, "end": 11599, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120large", "\u0120models"], "seq_scores": [0.9891175627708435, 0.9896054267883301], "text": " large models", "score": 0.9893614947795868, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11890, "end": 11905, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120smaller", "\u0120models"], "seq_scores": [0.9548322558403015, 0.9443200826644897], "text": " smaller models", "score": 0.9495761692523956, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12033, "end": 12044, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.9963070154190063, 0.9967021346092224, 0.9975265860557556, 0.9974708557128906], "text": " DistilBERT", "score": 0.9970016479492188, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12086, "end": 12091, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9927438497543335, 0.9949159622192383], "text": " BERT", "score": 0.9938299059867859, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12141, "end": 12150, "seq_label": ["B-Task"], "seq_token": ["\u0120language"], "seq_scores": [0.6501606702804565], "text": " language", "score": 0.6501606702804565, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12259, "end": 12272, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120dist", "illation"], "seq_scores": [0.9809457063674927, 0.991097092628479], "text": " distillation", "score": 0.9860213994979858, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12361, "end": 12372, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Dist", "il", "BER", "T"], "seq_scores": [0.995019793510437, 0.9963877201080322, 0.9971942901611328, 0.9968558549880981], "text": " DistilBERT", "score": 0.996364414691925, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 12045, "end": 12091, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120general", "-", "purpose", "\u0120pre", "-", "trained", "\u0120version", "\u0120of", "\u0120B", "ERT"], "seq_scores": [0.9744978547096252, 0.9819813370704651, 0.9865819215774536, 0.9883467555046082, 0.9845746159553528, 0.9830251932144165, 0.9823821187019348, 0.972551167011261, 0.9395586848258972, 0.8360703587532043, 0.8524944186210632], "text": " a general-purpose pre-trained version of BERT", "score": 0.9529149478132074, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 12193, "end": 12226, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120general", "-", "purpose", "\u0120language", "\u0120model"], "seq_scores": [0.988038182258606, 0.9888265132904053, 0.9970711469650269, 0.9976428151130676, 0.9975487589836121, 0.9977134466171265], "text": " a general-purpose language model", "score": 0.9944734772046407, "type": "ScholarlyEntity"}]}, "filename": "00007_1910_01108.json", "id": "00007_1910_01108"}