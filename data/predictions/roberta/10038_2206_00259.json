{"text": "IDANI: Inference-time Domain Adaptation via Neuron-level Interventions\n\nAbstract:\nLarge pre-trained models are usually finetuned on downstream task data, and tested on unseen data. When the train and test data come from different domains, the model is likely to struggle, as it is not adapted to the test domain. We propose a new approach for domain adaptation (DA), using neuron-level interventions: We modify the representation of each test example in specific neurons, resulting in a counterfactual example from the source domain, which the model is more familiar with. The modified example is then fed back into the model. While most other DA methods are applied during training time, ours is applied during inference only, making it more efficient and applicable. Our experiments show that our method improves performance on unseen domains. 1 * Supported by the Viterbi Fellowship in the Center for Computer Engineering at the Technion.\n\nMain:\n\n\n\n1 Introduction\nA common assumption in NLP, and in machine learning in general, is that the training set and the test set are sampled from the same underlying distribution. However, this assumption does not always hold in real-world applications since test data may arrive from many (target) domains, often not seen during training. Indeed, when applied to such unseen target domains, the trained model typically encounters significant degradation in performance.\nDA algorithms aim to address this challenge by improving models' generalization to new domains, and algorithms for various DA scenarios have been developed (Daume III and Marcu, 2006; Reichart and Rappoport, 2007; Ben-David et al., 2007; Schnabel and Sch\u00fctze, 2014). This work focuses on unsupervised domain adaptation (UDA), the most explored DA setup in recent years, which assumes access to labeled data from the source domain and unlabeled data from both source and target domains. Algorithms for this setup typically use the target domain knowledge during training, attempting to bridge the gap between domains through representation learning (Blitzer et al., 2007; Ganin et al., 2016; Ziser and Reichart, 2018; Han and Eisenstein, 2019; David et al., 2020). Recently, Ben-David et al. (2021) and Volk et al. (2022) introduced an approach for inference-time DA, assuming no prior knowledge regarding the test domains but still modifying the training process to their gain.\nIn contrast to this line of work, we assume a more realistic scenario, in which the model was already trained on a source domain, and encounters unlabeled data from the target domain during inference time.\nGiven an example from a target domain, we would have liked to change it to a source domain example, so that the model would be more likely to perform well on it. Since this is difficult to achieve, we aim to change its representation in a fine-grained manner, such that we modify only information about the domain of the representation, without hurting other information. To do so, we take inspiration from work analyzing language models, which showed that linguistic properties are localized in certain neurons (dimensions in model representations) (Dalvi et al., 2019; Durrani et al., 2020; Torroba Hennigen et al., 2020; Antverg and Belinkov, 2022; Sajjad et al., 2021). We first rank the neurons by their importance for identifying the domain (source or target) of each example. Then, we modify target-domain representations only in the highest-ranked neurons, to change their domain to the source domain. Since the model was trained on examples from the source domain, we expect it to perform better on the modified representations. We name this method as Inference-time Domain Adaptation via Neuron-level Interventions (IDANI).\nFigure 1 : The language model-which was trained on some source domain, e.g., airline-creates a representation (CLS) for the review. Since the review is from a domain on which it was not trained, the model's classifier mistakenly classifies it as negative (bottom). In IDANI (top), the representation is fed into a neuron-ranking method. The k-highest ranked neurons are modified by an intervention, to change the domain of the review, and the new representation is fed into the classifier, which correctly classifies it as positive.\nWe follow a large body of previous work, testing IDANI on a variety of well known DA benchmarks, for a total of two text classification tasks (sentiment analysis, natural language inference) and one sequence tagging task (aspect identification), across 52 source-target domain pairs. We demonstrate that IDANI can improve results in many of these cases, with some significant gains.\n\n2 Method\nGiven a model M with a classification module f and hidden dimensionality d, which was fine-tuned on data from a source domain D s = {X s }, we receive unlabeled task data D t = {X t } from a target domain for inference. As s = t, M 's performance is likely to deteriorate when processing X t compared to X s . Thus, we would like to make the representation of X t more similar to that of X s (regardless of the labels). To do so, we apply the IDANI intervention method:\n1. We process X s and X t through M , producing representations H s , H t \u2286 R d . We also compute vs and vt , the element-wise mean representations of X s and X t .\n2. We apply existing ranking methods to rank the representation's neurons by their relevance for domain information, i.e., the highest-ranked neuron holds the most information about the representation's domain ( \u00a7 2.1). 2\n2 Following previous work (Antverg and Belinkov, 2022), 3. For each h t \u2208 H t , we would ideally like to have h s , its source domain counterpart. Since h s is impossible to get, we create a counterfactual hs that simulates it by modifying h t only in the k-highest ranked neurons {n 1 , ..., n k }, such that \u2200i \u2208 {1, ..., k},hs n i = h t n i + \u03b1 n i (v s n i \u2212 vt n i )\nTo allow stronger intervention on neurons that are ranked higher, we scale the intervention with \u03b1 \u2208 R d , a log-scaled sorted coefficients vector in the range [0, \u03b2] such that \u03b1 n 1 = \u03b2 and \u03b1 n d = 0, where \u03b2 is a hyperparameter (Antverg and Belinkov, 2022). We denote the new set of representations as Hs .\n4. Representations from Hs are fed into the classifier f -without re-training f -to predict the labels. Since Hs is more similar to H s than H t is to H s , we expect performance to improve. That is, for some scoring metric \u03b3, we expect to have \u03b3(f ( Hs )) > \u03b3(f (H t )).\nThe process is illustrated in Fig. 1.\n\n2.1 Ranking Methods\nWe consider two ranking methods for ranking the representations' neurons (step 2):\nour method assumes that neurons with the same index carry similar information. While this is not necessarily true, we perform extrinsic (Table 1) and intrinsic evaluations (Table 2) that support this assumption.\nLINEAR (Dalvi et al., 2019) This method trains a linear classifier on H s and H t to learn to predict the domain, using standard cross-entropy loss regularized by elastic net regularization (Zou and Hastie, 2005). Then, it uses the classifier's weights to rank the neurons according to their importance for domain information. Intuitively, neurons with a higher magnitude of absolute weights should be more important for predicting the domain.\n\nPROBELESS\nThe second ranking method is a simple one and does not rely on an external probe, and thus is very fast to obtain: it only depends on computing the mean representation of each domain (v s and vt ), and sorting the difference between them. For each neuron i \u2208 {1, ..., d}, we calculate the absolute difference between the means:r i = |v s i \u2212 vt i | (2)\nand obtain a ranking by arg-sorting r, i.e., the first neuron in the ranking corresponds to the highest value in r.  Antverg and Belinkov (2022) showed that for interventions for morphology information, this method outperforms LINEAR and another ranking method (Torroba Hennigen et al., 2020).\n3 Experiments\n\n3.1 Datasets\nWe experiment with two text classification tasks: sentiment analysis (classifying reviews to positive or negative (Blitzer et al., 2007)) and natural language inference (NLI; classifying whether two sentences entail or contradict each other (Bowman et al., 2015)), and a sequence tagging task: aspect prediction (identifying aspect terms within reviews (Hu and Liu, 2004; Toprak et al., 2010; Pontiki et al., 2014)). For each task, the model is trained on a single source domain and tested on different target domains. We explore a low-resource scenario, thus we use 2000-3000 examples from the source domain to form the training set. 3 For test, we use equivalent size data from the corresponding target domain. Further data details are in Appendix A.\n\n3.2 Experiments\nFor each task and pair of source and target domains, we fine-tune a pre-trained BERT-base-cased model (Devlin et al., 2019) on the training set of the source domain and evaluate its in-domain performance on the dev set of the source domain. 4 e intervene on representations from the last layer of the model: word representations for the aspect prediction task, and CLS token representation for the other tasks. We then test the model's out-ofdistribution (OOD) performance on the test set of the target domain, for different k (number of modified neurons) and \u03b2 (magnitude of the intervention) values: We perform grid search where k is in the range [0, d] (d = 768) and \u03b2 is in the range [1, 10]. We experiment with both ranking methods described in \u00a7 2.1. We consider the model's performance at k = 0 as its initial (unchanged) OOD performance (INIT), and report the difference between initial performance and performance using IDANI, with either PROBELESS (\u2206 P ) or LINEAR (\u2206 L ) rankings. A limitation of IDANI (which we further discuss later) is the inability to choose the best \u03b2 and k for each domain pair. Following Antverg and Belinkov (2022) we report results for \u03b2 = 8, k = 50 (\u2206 8,50 ), as well as oracle results (the best performance across all values, \u2206 O ). We consider the model's performance when fine-tuned on the target domain as an upper bound (UB). For all pairs, we repeat experiments using 5 different random seeds, and report mean INIT, \u2206 8,50 , \u2206 O and UB across seeds, alongside the standard error of the mean.\nSince we assume that the model is exposed to target domain data only during inference, we cannot experiment with UDA methods, as they require access to the data during training. Furthermore, experimenting with inference-time DA approaches (Ben-David et al., 2021; Volk et al., 2022) is also not possible since they assume multiple source domains for training.\n\n4 Results\nOverall, we have 52 source to target domain adaptation experiments. Table 1 aggregates results across all experiments in three different categories: experiments where we can be confident that we improved the initial performance (i.e., the mean result across seeds is greater than the standard error), damaged it (mean lower than the negative standard error) or did not significantly affect it. Detailed results per each source-target domain pair are in Appendix B. Some of these gains are quite impressive: In the aspect prediction task, we gain 18.8 and 14.4 F1 points when adapting the Restaurants source domain to the target domains Laptops and Service, respectively. In other domain pairs, the gain is marginal. On average we gain 4 points with \u2206 P O . In sentiment analysis, the airline domain (A) is quite different from the others, leading to lower INIT (initial performance) scores when it is the source domain. Adapting from A using IDANI results in a gain of up to 4.9 accuracy points. When other domains are used as source domains, we see mostly marginal gains, as the upper bound is closer to the initial performance, leaving less room for improvement in this task (UB \u2212 INIT is low).\nIn NLI, it seems harder to improve: the room for improvement is lower (3.3 F1 points on average), which may imply that domain information is not crucial for this task. Still, we do see some significant gains, e.g., an improvement of 2 F1 points when adapting from Slate to the Telephone domain.\nGenerally, across all tasks and domain pairs, PROBELESS provides better performance than LIN-EAR as \u2206 P O > \u2206 L O in 47 of the 52 experiments (Appendix B). This is in line with the insights from Antverg and Belinkov (2022), who observed that PROBELESS was better than LINEAR when used for intervening on morphological attributes.\n\n4.1 Qualitative Analysis\nTo analyze the benefits of IDANI, for each word in the dataset we record the change in results when classifying sentences containing the word (sentiment analysis) or when classifying the word itself (aspect prediction). We report the words with the greatest improvement in Table 2. When switching from the Airline domain to the DVD domain in the sentiment analysis task, those are mostly words that sound negative in an airline context, but may not imply a sentiment towards a movie (terrorist, kidnapped). In the aspect prediction task, those are mostly target domain related terms that are not likely to appear in the source domain.\n\n4.2 Default \u03b2 and k are Not Optimal\nWhile the potential for performance improvement with PROBELESS is high, the selection of \u03b2 = 8, k = 50 turns out as non optimal, as \u2206 P 8,50 is well below \u2206 P O across our experiments. This is also true for \u2206 L 8,50 compared to \u2206 L O , but to a lesser degree. Fig. 2 shows that a milder intervention-lower k value-would have been more ideal for the Airline \u2192 DVD scenario. Modifying too many neurons probably affects other encoded informationbesides domain information-damaging the task performance. Thus, we might lean towards smaller k values. However, this is not always the case: Fig. 2 also shows that for the Restaurant \u2192 Service scenario in the aspect prediction task, PROBELESS' performance reaches a saturation point around the value of k = 100 neurons. Thus there is no ideal value of k across all domain pairs. A similar phenomenon with \u03b2 is shown in Appendix C. Therefore, hyperparameters should be task-and domain-dependent, but it is unclear how to define them for each domain pair. Yet, in most real-world cases some labeled data should be available or could be manually created. In such cases, the best approach would be to grid-search over the hyperparameters on the available labeled data, and use the selected values for the (unlabeled) test data.\nAirline \u2192 DVD (Sentiment) immortal, insanely, terrorist, crossing, obsessive, buzz, kidnapped Laptops \u2192 Restaurant (Aspect) Food, soup, selection, sushi, food, atmosphere, menu, staff Restaurant \u2192 Laptops (Aspect) time, user, slot, speed, MAC, Acer, system, size, SSD, design Table 2: Words that are part of sentences for which accuracy has improved the most (sentiment analysis), and words for which F1 score has improved the most (aspect prediction), using IDANI.\n\n5 Conclusion\nIn this work, we demonstrated the ability to leverage neuron-intervention methods to improve OOD performance. We showed that in some cases, IDANI can significantly help models to adapt to new domains. IDANI performs best with oracle hyperparameters, but even with the default ones we see overall positive results. We showed that IDANI indeed focuses on domain-related information, as the gains come mostly from domain-related information, such as domain-specific aspect terms. Importantly, IDANI is applied only during inference, unlike most other DA methods.\n\nA Data Details\nWe test IDANI on three different tasks: sentiment analysis, natural language inference, and aspect prediction. Further details of the training, development, and test sets of each domain are provided in Table 3.\n\nSentiment Analysis\nWe follow a large body of prior DA work to focus on the task of binary sentiment classification. We experiment with the four legacy product review domains of Blitzer et al. (2007) : Books (B), DVDs (D), Electronic items (E) and Kitchen appliances (K). We also experiment in a more challenging setup, considering an airline review dataset (A) (Nguyen, 2015; Ziser and Reichart, 2018). This setup is more challenging because of the differences between the product and service domains.\nNatural Language Inference (Williams et al., 2018) This corpus is an extension of the SNLI dataset (Bowman et al., 2015). Each example consists of a pair of sentences, a premise and a hypothesis. The relationship between the two may be entailment, contradiction, or neutral. The corpus includes data from 10 domains: 5 are matched, with training, development and test sets, and 5 are mismatched, without a training set. Following Ben-David et al. (2021), we experiment only with the five matched domains: Fiction (F), Government (G), Slate (SL), Telephone (TL) and Travel (TR).\nSince the test sets of the MNLI dataset are not publicly available, we use the original development sets as our test sets for each target domain, while source domains use these sets for development. Following prior work (Ben-David et al., 2021; Volk et al., 2022) we explore a low-resource supervised scenario, which emphasizes the need for a DA algorithm. Thus, we randomly downsample each of the training sets by a factor of 30, resulting in 2,000-3,000 examples per set.\n\nAspect Prediction\nThe aspect prediction dataset is based on aspect-based sentiment analysis (ABSA) corpora from four domains: Device (D), Laptops (L), Restaurant (R), and Service (SE). The D data consists of reviews from Toprak et al. (2010), the SE data includes web service reviews (Hu and Liu, 2004), and the L and R domains consist of reviews from the SemEval-2014 ABSA challenge (Pontiki et al., 2014). The task is to identify aspect terms within reviews. For example, given  a sentence \"The price is reasonable, although the service is poor\", both \"price\" and \"service\" should be identified as aspect terms.\nWe follow the training and test splits defined by Gong et al. (2020) for the D and SE domains, while the splits for the L and R domains are taken from the SemEval-2014 ABSA challenge. To establish our development set, we randomly sample 10% out of the training data.\n\nB Detailed Results\nResults for all domain pairs are shown in Tables 4, 5  and 6\n\nC Performance for different \u03b2\nWhile our default hyperparameter values, \u03b2 = 8 and k = 50 improve performance in most cases, they are not optimal for all cases. Fig. 3 shows that when k = 50, the optimal \u03b2 value for the Airline \u2192 DVD case is 5, whereas for Restaurants \u2192 Service it is actually better to use a greater \u03b2. Thus, it is not possible to find one value that would be optimal for all cases.A \u2192 B A \u2192 D A \u2192 E A \u2192 K B \u2192 A B \u2192 D B \u2192 E INIT 77.4 \u00b1 1.3 75.5 \u00b1 2.2\n85.2 \u00b1 1.0 84.9 \u00b1 0.9 83.7 \u00b1 0.7 87.9 \u00b1 0.3 90.4 \u00b1 0.2 UB 88.0 \u00b1 0.5 89.2 \u00b1 0.5 92.4 \u00b1 0.4 92.4 \u00b1 0.2 88.0 \u00b1 0.1 89.2 \u00b1 0.5 92.4 \u00b1 0.4 \u2206 P 8,50 \u22124.4 \u00b1 4.8 \u22122.2 \u00b1 5.4 \u22121.2 \u00b1 2.4 \u22121.5 \u00b1 1.9 0.5 \u00b1 0.1 0.1 \u00b1 0.1 \u22120.0 \u00b1 0.0 \u2206 L 8,502.0 \u00b1 1.0 2.1 \u00b1 1.0 1.3 \u00b1 0.4 1.1 \u00b1 0.5 0.2 \u00b1 0.1 0.1 \u00b1 0.0 \u22120.0 \u00b1 0.0 \u2206 P O 3.0 \u00b1 1.3 4.9 \u00b1 1.8 2.3 \u00b1 0.8 2.3 \u00b1 1.0 0.9 \u00b1 0.2 0.3 \u00b1 0.1 0.1 \u00b1 0.0 \u2206 L O 2.9 \u00b1 1.3 4.2 \u00b1 1.8 2.3 \u00b1 0.8 2.2 \u00b1 0.9 0.3 \u00b1 0.1 0.1 \u00b1 0.0 0.0 \u00b1 0.0 B \u2192 K D \u2192 A D \u2192 B D \u2192 E D \u2192 K E \u2192 A E \u21920.1 \u00b1 0.0 0.8 \u00b1 0.2 0.1 \u00b1 0.1 \u22120.0 \u00b1 0.1 0.8 \u00b1 0.3 0.0 \u00b1 0.0 0.6 \u00b1 0.2 \u2206 L 8,50 0.1 \u00b1 0.0 0.5 \u00b1 0.1 0.1 \u00b1 0.0 0.1 \u00b1 0.0 0.2 \u00b1 0.1 0.0 \u00b1 0.0 0.1 \u00b1 0.1 \u2206 P O 0.4 \u00b1 0.1 1.4 \u00b1 0.3 0.3 \u00b1 0.1 0.3 \u00b1 0.1 1.4 \u00b1 0.5 0.2 \u00b1 0.0 1.0 \u00b1 0.3 \u2206 L O 0.2 \u00b1 0.0 0.8 \u00b1 0.1 0.2 \u00b1 0.1 0.1 \u00b1 0.0 0.5 \u00b1 0.2 0.1 \u00b1 0.0 0.3 \u00b1 0.1 E \u2192 D E \u2192 K K \u2192 A K \u2192 B K \u2192 D K \u2192 E AVG INIT 86.0.2 \u00b1 0.1 0.2 \u00b1 0.2 0.7 \u00b1 0.2 0.1 \u00b1 0.1 0.2 \u00b1 0.1 0.1 \u00b1 0.0 \u22120.2 \u00b1 1.7 \u2206 L 8,50 \u22120.1 \u00b1 0.1 \u22120.0 \u00b1 0.0 0.1 \u00b1 0.1 0.1 \u00b1 0.0 0.0 \u00b1 0.0 0.0 \u00b1 0.0 0.4 \u00b1 0.4 \u2206 P O 0.4 \u00b1 0.1 0.4 \u00b1 0.2 1.2 \u00b1 0.3 0.2 \u00b1 0.0 0.5 \u00b1 0.0 0.2 \u00b1 0.0 1.1 \u00b1 0.6 \u2206 L O 0.1 \u00b1 0.0 0.2 \u00b1 0.1 0.5 \u00b1 0.2 0.1 \u00b1 0.0 0.2 \u00b1 0.0 0.0 \u00b1 0.0 0.8 \u00b1 0.6F \u2192 G F \u2192 SL F \u2192 TL F \u2192 TR G \u2192 F G \u2192 SL G \u2192 TL INIT\n.2 \u00b1 0.8 63.7 \u00b1 0.8 67.4 \u00b1 1.3 65.6 \u00b1 0.8 59.9 \u00b1 0.8 62.1 \u00b1 0.5 64.9 \u00b1 0.9 UB 73.8 \u00b1 0.4 62.6 \u00b1 0.9 68.3 \u00b1 0.4 69.9 \u00b1 0.3 67.6 \u00b1 0.9 62.6 \u00b1 0.9 68.3 \u00b1 0.4 \u2206 P 8,50 0.5 \u00b1 0.5 0.4 \u00b1 0.4   2.2 \u00b1 0.5 2.4 \u00b1 0.6 0.0 \u00b1 0.1 \u22120.5 \u00b1 0.2 \u22120.7 \u00b1 0.4 0.3 \u00b1 0.3 \u2206 P O 14.4 \u00b1 0.9 18.8 \u00b1 0.9 0.9 \u00b1 0.2 0.3 \u00b1 0.2 0.3 \u00b1 0.2 4.0 \u00b1 0.5 \u2206 L O 5.7 \u00b1 0.9 6.8 \u00b1 0.7 0.3 \u00b1 0.1 0.2 \u00b1 0.1 0.2 \u00b1 0.1 1.5 \u00b1 0.40.1 \u00b1 0.4 \u22120.2 \u00b1 0.4 0.8 \u00b1 0.2 \u22120.2 \u00b1 0.2 0.4 \u00b1 0.3 \u2206 L 8,50 0.1 \u00b1 0.2 0.0 \u00b1 0.1 0.3 \u00b1 0.2 0.1 \u00b1 0.1 0.7 \u00b1 0.4 \u22120.2 \u00b1 0.1 0.1 \u00b1 0.1 \u2206 P O 1.2 \u00b1 0.4 0.9 \u00b1 0.3 0.9 \u00b1 0.3 0.7 \u00b1 0.2 1.8 \u00b1 0.6 0.4 \u00b1 0.1 1.2 \u00b1 0.2 \u2206 L O 0.6 \u00b1 0.2 0.6 \u00b1 0.2 0.8 \u00b1 0.3 0.5 \u00b1 0.2 1.5 \u00b1 0.5 0.2 \u00b1 0.0 0.9 \u00b1 0.2 G \u2192 TR SL \u2192 F SL \u2192 G SL \u2192 TL SL \u2192 TR TL \u2192 F TL \u2192 G INIT\u22120.0 \u00b1 0.1 0.8 \u00b1 0.4 \u22120.5 \u00b1 0.2 1.1 \u00b1 0.4 \u22120.1 \u00b1 0.1 \u22120.6 \u00b1 0.3 \u22121.1 \u00b1 0.6 \u2206 L 8,\n\nFootnotes:\n1: Our code is available at https://github.com/ technion-cs-nlp/idani.\n3: For development data we split our training set in a ratio of 80:20, where the smaller portion is used for development.\n4: For all experimented models, we define a maximum sequence length value of 256 and use a training batch size of 16.\n\nReferences:\n\n- Omer Antverg and Yonatan Belinkov. 2022. On the pitfalls of analyzing individual neurons in language models. In International Conference on Learning Representations.- Eyal Ben-David, Nadav Oved, and Roi Reichart. 2021. Pada: A prompt-based autoregressive approach for adaptation to unseen domains. arXiv preprint arXiv:2102.12206.\n\n- Shai Ben-David, John Blitzer, Koby Crammer, Fer- nando Pereira, et al. 2007. Analysis of representa- tions for domain adaptation. Advances in neural in- formation processing systems, 19:137.\n\n- John Blitzer, Mark Dredze, and Fernando Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In ACL 2007, Proceedings of the 45th Annual Meet- ing of the Association for Computational Linguistics, June 23-30, 2007, Prague, Czech Republic. The As- sociation for Computational Linguistics.\n\n- Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large anno- tated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empiri- cal Methods in Natural Language Processing, pages 632-642, Lisbon, Portugal. Association for Compu- tational Linguistics.\n\n- Fahim Dalvi, Nadir Durrani, Hassan Sajjad, Yonatan Belinkov, Anthony Bau, and James R. Glass. 2019. What is one grain of sand in the desert? analyzing individual neurons in deep NLP models. In The Thirty-Third AAAI Conference on Artificial Intelli- gence, AAAI 2019, The Thirty-First Innovative Ap- plications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019, Hon- olulu, Hawaii, USA, January 27 -February 1, 2019, pages 6309-6317. AAAI Press.\n\n- Hal Daume III and Daniel Marcu. 2006. Domain adap- tation for statistical classifiers. Journal of artificial Intelligence research, 26:101-126.\n\n- Eyal Ben David, Carmel Rabinovitz, and Roi Reichart. 2020. Perl: Pivot-based domain adaptation for pre-trained deep contextualized embedding models. Transactions of the Association for Computational Linguistics, 8(0):504-521.\n\n- Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- standing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Associ- ation for Computational Linguistics.\n\n- Nadir Durrani, Hassan Sajjad, Fahim Dalvi, and Yonatan Belinkov. 2020. Analyzing individual neu- rons in pre-trained language models. In Proceed- ings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4865-4880, Online. Association for Computational Linguistics.\n\n- Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas- cal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario March, and Victor Lempitsky. 2016. Domain- adversarial training of neural networks. Journal of Machine Learning Research, 17(59):1-35.\n\n- Chenggong Gong, Jianfei Yu, and Rui Xia. 2020. Uni- fied feature and instance based domain adaptation for aspect-based sentiment analysis. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, On- line, November 16-20, 2020, pages 7035-7045. As- sociation for Computational Linguistics.\n\n- Xiaochuang Han and Jacob Eisenstein. 2019. Unsu- pervised domain adaptation of contextualized em- beddings for sequence labeling. In Proceedings of the 2019 Conference on Empirical Methods in Nat- ural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, Novem- ber 3-7, 2019, pages 4237-4247. Association for Computational Linguistics.\n\n- Minqing Hu and Bing Liu. 2004. Mining and summa- rizing customer reviews. In Proceedings of the Tenth ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining, Seattle, Wash- ington, USA, August 22-25, 2004, pages 168-177. ACM.\n\n- Quang Nguyen. 2015. The airline review dataset. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. Semeval-2014 task 4: As- pect based sentiment analysis. In Proceedings of the 8th International Workshop on Semantic Evaluation, SemEval@COLING 2014, Dublin, Ireland, August 23-24, 2014, pages 27-35. The Association for Com- puter Linguistics.\n\n- Roi Reichart and Ari Rappoport. 2007. Self-training for enhancement and domain adaptation of statisti- cal parsers trained on small datasets. In Proceed- ings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 616-623, Prague, Czech Republic. Association for Computational Lin- guistics.\n\n- Hassan Sajjad, Nadir Durrani, and Fahim Dalvi. 2021. Neuron-level interpretation of deep nlp models: A survey. ArXiv, abs/2108.13138.\n\n- Tobias Schnabel and Hinrich Sch\u00fctze. 2014. Flors: Fast and simple domain adaptation for part-of- speech tagging. Transactions of the Association for Computational Linguistics, 2(0):15-26.\n\n- Cigdem Toprak, Niklas Jakob, and Iryna Gurevych. 2010. Sentence and expression level annotation of opinions in user-generated discourse. In ACL 2010, Proceedings of the 48th Annual Meeting of the As- sociation for Computational Linguistics, July 11-16, 2010, Uppsala, Sweden, pages 575-584. The Asso- ciation for Computer Linguistics.\n\n- Lucas Torroba Hennigen, Adina Williams, and Ryan Cotterell. 2020. Intrinsic probing through dimen- sion selection. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Processing (EMNLP), pages 197-216, Online. As- sociation for Computational Linguistics.\n\n- Tomer Volk, Eyal Ben-David, Ohad Amosy, Gal Chechik, and Roi Reichart. 2022. Example-based hypernetworks for out-of-distribution generalization. arXiv preprint arXiv:2203.14276.\n\n- Adina Williams, Nikita Nangia, and Samuel R Bow- man. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2018, pages 1112-1122.\n\n- Yftah Ziser and Roi Reichart. 2018. Pivot based lan- guage modeling for improved neural domain adapta- tion. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Technolo- gies, Volume 1 (Long Papers), pages 1241-1251, New Orleans, Louisiana. Association for Computa- tional Linguistics.\n\n- Hui Zou and Trevor Hastie. 2005. Regularization and variable selection via the elastic net. Journal of the royal statistical society: series B (statistical method- ology), 67(2):301-320.\n\n", "annotations": {"ReferenceToTable": [{"begin": 6754, "end": 6755, "target": "#tab_0", "idx": 0}, {"begin": 6790, "end": 6791, "idx": 1}, {"begin": 10704, "end": 10705, "target": "#tab_0", "idx": 2}, {"begin": 15681, "end": 15682, "target": "#tab_2", "idx": 3}, {"begin": 18190, "end": 18201, "target": "#tab_9", "idx": 4}], "ReferenceToFootnote": [{"begin": 8588, "end": 8589, "target": "#foot_1", "idx": 0}, {"begin": 8964, "end": 8965, "target": "#foot_2", "idx": 1}], "SectionMain": [{"begin": 949, "end": 20665, "idx": 0}], "SectionReference": [{"begin": 20990, "end": 27847, "idx": 0}], "SectionHeader": [{"begin": 0, "end": 949, "idx": 0}], "Div": [{"begin": 82, "end": 941, "idx": 0}, {"begin": 952, "end": 4648, "idx": 1}, {"begin": 4650, "end": 6506, "idx": 2}, {"begin": 6508, "end": 7266, "idx": 3}, {"begin": 7268, "end": 7938, "idx": 4}, {"begin": 7940, "end": 8705, "idx": 5}, {"begin": 8707, "end": 10618, "idx": 6}, {"begin": 10620, "end": 12451, "idx": 7}, {"begin": 12453, "end": 13112, "idx": 8}, {"begin": 13114, "end": 14882, "idx": 9}, {"begin": 14884, "end": 15456, "idx": 10}, {"begin": 15458, "end": 15683, "idx": 11}, {"begin": 15685, "end": 17238, "idx": 12}, {"begin": 17240, "end": 18120, "idx": 13}, {"begin": 18122, "end": 18201, "idx": 14}, {"begin": 18203, "end": 20665, "idx": 15}], "Head": [{"begin": 952, "end": 966, "n": "1", "idx": 0}, {"begin": 4650, "end": 4658, "n": "2", "idx": 1}, {"begin": 6508, "end": 6527, "n": "2.1", "idx": 2}, {"begin": 7268, "end": 7277, "idx": 3}, {"begin": 7940, "end": 7952, "n": "3.1", "idx": 4}, {"begin": 8707, "end": 8722, "n": "3.2", "idx": 5}, {"begin": 10620, "end": 10629, "n": "4", "idx": 6}, {"begin": 12453, "end": 12477, "n": "4.1", "idx": 7}, {"begin": 13114, "end": 13149, "n": "4.2", "idx": 8}, {"begin": 14884, "end": 14896, "n": "5", "idx": 9}, {"begin": 15458, "end": 15472, "idx": 10}, {"begin": 15685, "end": 15703, "idx": 11}, {"begin": 17240, "end": 17257, "idx": 12}, {"begin": 18122, "end": 18140, "idx": 13}, {"begin": 18203, "end": 18232, "idx": 14}], "Paragraph": [{"begin": 82, "end": 941, "idx": 0}, {"begin": 967, "end": 1414, "idx": 1}, {"begin": 1415, "end": 2392, "idx": 2}, {"begin": 2393, "end": 2598, "idx": 3}, {"begin": 2599, "end": 3732, "idx": 4}, {"begin": 3733, "end": 4265, "idx": 5}, {"begin": 4266, "end": 4648, "idx": 6}, {"begin": 4659, "end": 5128, "idx": 7}, {"begin": 5129, "end": 5293, "idx": 8}, {"begin": 5294, "end": 5515, "idx": 9}, {"begin": 5516, "end": 5843, "idx": 10}, {"begin": 5888, "end": 6196, "idx": 11}, {"begin": 6197, "end": 6468, "idx": 12}, {"begin": 6469, "end": 6506, "idx": 13}, {"begin": 6528, "end": 6610, "idx": 14}, {"begin": 6611, "end": 6822, "idx": 15}, {"begin": 6823, "end": 7266, "idx": 16}, {"begin": 7278, "end": 7605, "idx": 17}, {"begin": 7631, "end": 7924, "idx": 18}, {"begin": 7925, "end": 7938, "idx": 19}, {"begin": 7953, "end": 8705, "idx": 20}, {"begin": 8723, "end": 10258, "idx": 21}, {"begin": 10259, "end": 10618, "idx": 22}, {"begin": 10630, "end": 11826, "idx": 23}, {"begin": 11827, "end": 12121, "idx": 24}, {"begin": 12122, "end": 12451, "idx": 25}, {"begin": 12478, "end": 13112, "idx": 26}, {"begin": 13150, "end": 14416, "idx": 27}, {"begin": 14417, "end": 14882, "idx": 28}, {"begin": 14897, "end": 15456, "idx": 29}, {"begin": 15473, "end": 15683, "idx": 30}, {"begin": 15704, "end": 16186, "idx": 31}, {"begin": 16187, "end": 16764, "idx": 32}, {"begin": 16765, "end": 17238, "idx": 33}, {"begin": 17258, "end": 17853, "idx": 34}, {"begin": 17854, "end": 18120, "idx": 35}, {"begin": 18141, "end": 18201, "idx": 36}, {"begin": 18233, "end": 18601, "idx": 37}, {"begin": 18670, "end": 18897, "idx": 38}, {"begin": 19864, "end": 20245, "idx": 39}], "ReferenceToBib": [{"begin": 1571, "end": 1598, "target": "#b6", "idx": 0}, {"begin": 1599, "end": 1628, "target": "#b15", "idx": 1}, {"begin": 1629, "end": 1652, "target": "#b2", "idx": 2}, {"begin": 1653, "end": 1680, "target": "#b17", "idx": 3}, {"begin": 2063, "end": 2085, "target": "#b3", "idx": 4}, {"begin": 2086, "end": 2105, "target": "#b10", "idx": 5}, {"begin": 2106, "end": 2131, "target": "#b22", "idx": 6}, {"begin": 2132, "end": 2157, "target": "#b12", "idx": 7}, {"begin": 2158, "end": 2177, "target": "#b7", "idx": 8}, {"begin": 2189, "end": 2212, "target": "#b1", "idx": 9}, {"begin": 2217, "end": 2235, "target": "#b20", "idx": 10}, {"begin": 3149, "end": 3169, "target": "#b5", "idx": 11}, {"begin": 3170, "end": 3191, "target": "#b9", "idx": 12}, {"begin": 3192, "end": 3222, "target": "#b19", "idx": 13}, {"begin": 3223, "end": 3250, "target": "#b0", "idx": 14}, {"begin": 3251, "end": 3271, "target": "#b16", "idx": 15}, {"begin": 5542, "end": 5570, "target": "#b0", "idx": 16}, {"begin": 6118, "end": 6146, "target": "#b0", "idx": 17}, {"begin": 6830, "end": 6850, "target": "#b5", "idx": 18}, {"begin": 7013, "end": 7035, "target": "#b23", "idx": 19}, {"begin": 7748, "end": 7775, "target": "#b0", "idx": 20}, {"begin": 7892, "end": 7923, "target": "#b19", "idx": 21}, {"begin": 8067, "end": 8089, "target": "#b3", "idx": 22}, {"begin": 8194, "end": 8215, "target": "#b4", "idx": 23}, {"begin": 8306, "end": 8324, "target": "#b13", "idx": 24}, {"begin": 8325, "end": 8345, "target": "#b18", "idx": 25}, {"begin": 8346, "end": 8367, "target": "#b14", "idx": 26}, {"begin": 8825, "end": 8846, "target": "#b8", "idx": 27}, {"begin": 10498, "end": 10522, "target": "#b1", "idx": 28}, {"begin": 10523, "end": 10541, "target": "#b20", "idx": 29}, {"begin": 12317, "end": 12344, "target": "#b0", "idx": 30}, {"begin": 15862, "end": 15883, "target": "#b3", "idx": 31}, {"begin": 16046, "end": 16060, "target": "#b14", "idx": 32}, {"begin": 16061, "end": 16086, "target": "#b22", "idx": 33}, {"begin": 16214, "end": 16237, "target": "#b21", "idx": 34}, {"begin": 16286, "end": 16307, "target": "#b4", "idx": 35}, {"begin": 16617, "end": 16640, "target": "#b1", "idx": 36}, {"begin": 16985, "end": 17009, "target": "#b1", "idx": 37}, {"begin": 17010, "end": 17028, "target": "#b20", "idx": 38}, {"begin": 17461, "end": 17481, "target": "#b18", "idx": 39}, {"begin": 17524, "end": 17542, "target": "#b13", "idx": 40}, {"begin": 17624, "end": 17646, "target": "#b14", "idx": 41}, {"begin": 17904, "end": 17922, "target": "#b11", "idx": 42}], "ReferenceString": [{"begin": 21005, "end": 21170, "id": "b0", "idx": 0}, {"begin": 21172, "end": 21335, "id": "b1", "idx": 1}, {"begin": 21339, "end": 21529, "id": "b2", "idx": 2}, {"begin": 21533, "end": 21879, "id": "b3", "idx": 3}, {"begin": 21883, "end": 22206, "id": "b4", "idx": 4}, {"begin": 22210, "end": 22741, "id": "b5", "idx": 5}, {"begin": 22745, "end": 22888, "id": "b6", "idx": 6}, {"begin": 22892, "end": 23117, "id": "b7", "idx": 7}, {"begin": 23121, "end": 23543, "id": "b8", "idx": 8}, {"begin": 23547, "end": 23849, "id": "b9", "idx": 9}, {"begin": 23853, "end": 24097, "id": "b10", "idx": 10}, {"begin": 24101, "end": 24436, "id": "b11", "idx": 11}, {"begin": 24440, "end": 24855, "id": "b12", "idx": 12}, {"begin": 24859, "end": 25106, "id": "b13", "idx": 13}, {"begin": 25110, "end": 25522, "id": "b14", "idx": 14}, {"begin": 25526, "end": 25844, "id": "b15", "idx": 15}, {"begin": 25848, "end": 25981, "id": "b16", "idx": 16}, {"begin": 25985, "end": 26172, "id": "b17", "idx": 17}, {"begin": 26176, "end": 26510, "id": "b18", "idx": 18}, {"begin": 26514, "end": 26797, "id": "b19", "idx": 19}, {"begin": 26801, "end": 26978, "id": "b20", "idx": 20}, {"begin": 26982, "end": 27282, "id": "b21", "idx": 21}, {"begin": 27286, "end": 27655, "id": "b22", "idx": 22}, {"begin": 27659, "end": 27845, "id": "b23", "idx": 23}], "Sentence": [{"begin": 82, "end": 180, "idx": 0}, {"begin": 181, "end": 312, "idx": 1}, {"begin": 313, "end": 572, "idx": 2}, {"begin": 573, "end": 626, "idx": 3}, {"begin": 627, "end": 768, "idx": 4}, {"begin": 769, "end": 941, "idx": 5}, {"begin": 967, "end": 1123, "idx": 6}, {"begin": 1124, "end": 1283, "idx": 7}, {"begin": 1284, "end": 1414, "idx": 8}, {"begin": 1415, "end": 1681, "idx": 9}, {"begin": 1682, "end": 1900, "idx": 10}, {"begin": 1901, "end": 2178, "idx": 11}, {"begin": 2179, "end": 2392, "idx": 12}, {"begin": 2393, "end": 2598, "idx": 13}, {"begin": 2599, "end": 2760, "idx": 14}, {"begin": 2761, "end": 2970, "idx": 15}, {"begin": 2971, "end": 3272, "idx": 16}, {"begin": 3273, "end": 3381, "idx": 17}, {"begin": 3382, "end": 3508, "idx": 18}, {"begin": 3509, "end": 3636, "idx": 19}, {"begin": 3637, "end": 3732, "idx": 20}, {"begin": 3733, "end": 3864, "idx": 21}, {"begin": 3865, "end": 3997, "idx": 22}, {"begin": 3998, "end": 4069, "idx": 23}, {"begin": 4070, "end": 4265, "idx": 24}, {"begin": 4266, "end": 4549, "idx": 25}, {"begin": 4550, "end": 4648, "idx": 26}, {"begin": 4659, "end": 4878, "idx": 27}, {"begin": 4879, "end": 4968, "idx": 28}, {"begin": 4969, "end": 5078, "idx": 29}, {"begin": 5079, "end": 5128, "idx": 30}, {"begin": 5129, "end": 5210, "idx": 31}, {"begin": 5211, "end": 5293, "idx": 32}, {"begin": 5294, "end": 5515, "idx": 33}, {"begin": 5516, "end": 5574, "idx": 34}, {"begin": 5575, "end": 5662, "idx": 35}, {"begin": 5663, "end": 5843, "idx": 36}, {"begin": 5888, "end": 6147, "idx": 37}, {"begin": 6148, "end": 6196, "idx": 38}, {"begin": 6197, "end": 6300, "idx": 39}, {"begin": 6301, "end": 6387, "idx": 40}, {"begin": 6388, "end": 6468, "idx": 41}, {"begin": 6469, "end": 6506, "idx": 42}, {"begin": 6528, "end": 6610, "idx": 43}, {"begin": 6611, "end": 6689, "idx": 44}, {"begin": 6690, "end": 6822, "idx": 45}, {"begin": 6823, "end": 7036, "idx": 46}, {"begin": 7037, "end": 7149, "idx": 47}, {"begin": 7150, "end": 7266, "idx": 48}, {"begin": 7278, "end": 7516, "idx": 49}, {"begin": 7517, "end": 7605, "idx": 50}, {"begin": 7631, "end": 7746, "idx": 51}, {"begin": 7747, "end": 7924, "idx": 52}, {"begin": 7925, "end": 7938, "idx": 53}, {"begin": 7953, "end": 8369, "idx": 54}, {"begin": 8370, "end": 8471, "idx": 55}, {"begin": 8472, "end": 8665, "idx": 56}, {"begin": 8666, "end": 8705, "idx": 57}, {"begin": 8723, "end": 8965, "idx": 58}, {"begin": 8966, "end": 9133, "idx": 59}, {"begin": 9134, "end": 9419, "idx": 60}, {"begin": 9420, "end": 9479, "idx": 61}, {"begin": 9480, "end": 9714, "idx": 62}, {"begin": 9715, "end": 9835, "idx": 63}, {"begin": 9836, "end": 9994, "idx": 64}, {"begin": 9995, "end": 10091, "idx": 65}, {"begin": 10092, "end": 10258, "idx": 66}, {"begin": 10259, "end": 10436, "idx": 67}, {"begin": 10437, "end": 10618, "idx": 68}, {"begin": 10630, "end": 10697, "idx": 69}, {"begin": 10698, "end": 11023, "idx": 70}, {"begin": 11024, "end": 11300, "idx": 71}, {"begin": 11301, "end": 11345, "idx": 72}, {"begin": 11346, "end": 11386, "idx": 73}, {"begin": 11387, "end": 11549, "idx": 74}, {"begin": 11550, "end": 11625, "idx": 75}, {"begin": 11626, "end": 11826, "idx": 76}, {"begin": 11827, "end": 11901, "idx": 77}, {"begin": 11902, "end": 11994, "idx": 78}, {"begin": 11995, "end": 12121, "idx": 79}, {"begin": 12122, "end": 12277, "idx": 80}, {"begin": 12278, "end": 12451, "idx": 81}, {"begin": 12478, "end": 12697, "idx": 82}, {"begin": 12698, "end": 12759, "idx": 83}, {"begin": 12760, "end": 12984, "idx": 84}, {"begin": 12985, "end": 13112, "idx": 85}, {"begin": 13150, "end": 13334, "idx": 86}, {"begin": 13335, "end": 13409, "idx": 87}, {"begin": 13410, "end": 13522, "idx": 88}, {"begin": 13523, "end": 13649, "idx": 89}, {"begin": 13650, "end": 13695, "idx": 90}, {"begin": 13696, "end": 13912, "idx": 91}, {"begin": 13913, "end": 13971, "idx": 92}, {"begin": 13972, "end": 14146, "idx": 93}, {"begin": 14147, "end": 14244, "idx": 94}, {"begin": 14245, "end": 14416, "idx": 95}, {"begin": 14417, "end": 14882, "idx": 96}, {"begin": 14897, "end": 15006, "idx": 97}, {"begin": 15007, "end": 15097, "idx": 98}, {"begin": 15098, "end": 15210, "idx": 99}, {"begin": 15211, "end": 15373, "idx": 100}, {"begin": 15374, "end": 15456, "idx": 101}, {"begin": 15473, "end": 15583, "idx": 102}, {"begin": 15584, "end": 15683, "idx": 103}, {"begin": 15704, "end": 15800, "idx": 104}, {"begin": 15801, "end": 15955, "idx": 105}, {"begin": 15956, "end": 16087, "idx": 106}, {"begin": 16088, "end": 16186, "idx": 107}, {"begin": 16187, "end": 16308, "idx": 108}, {"begin": 16309, "end": 16382, "idx": 109}, {"begin": 16383, "end": 16461, "idx": 110}, {"begin": 16462, "end": 16606, "idx": 111}, {"begin": 16607, "end": 16764, "idx": 112}, {"begin": 16765, "end": 16963, "idx": 113}, {"begin": 16964, "end": 17121, "idx": 114}, {"begin": 17122, "end": 17238, "idx": 115}, {"begin": 17258, "end": 17424, "idx": 116}, {"begin": 17425, "end": 17647, "idx": 117}, {"begin": 17648, "end": 17700, "idx": 118}, {"begin": 17701, "end": 17853, "idx": 119}, {"begin": 17854, "end": 18037, "idx": 120}, {"begin": 18038, "end": 18120, "idx": 121}, {"begin": 18141, "end": 18201, "idx": 122}, {"begin": 18233, "end": 18361, "idx": 123}, {"begin": 18362, "end": 18521, "idx": 124}, {"begin": 18522, "end": 18601, "idx": 125}, {"begin": 18670, "end": 18897, "idx": 126}, {"begin": 19864, "end": 20245, "idx": 127}], "ReferenceToFigure": [{"begin": 3740, "end": 3741, "idx": 0}, {"begin": 6504, "end": 6505, "idx": 1}, {"begin": 13415, "end": 13416, "target": "#fig_0", "idx": 2}, {"begin": 13739, "end": 13740, "target": "#fig_0", "idx": 3}, {"begin": 18367, "end": 18368, "target": "#fig_2", "idx": 4}], "Abstract": [{"begin": 72, "end": 941, "idx": 0}], "SectionFootnote": [{"begin": 20667, "end": 20988, "idx": 0}], "Footnote": [{"begin": 20678, "end": 20748, "id": "foot_0", "n": "1", "idx": 0}, {"begin": 20749, "end": 20870, "id": "foot_1", "n": "3", "idx": 1}, {"begin": 20871, "end": 20988, "id": "foot_2", "n": "4", "idx": 2}], "ScholarlyEntity": [{"label": "Method", "begin": 119, "end": 128, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120fin", "et", "uned"], "seq_scores": [0.7847017049789429, 0.79298996925354, 0.75118088722229], "text": "finetuned", "score": 0.7762908538182577, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 343, "end": 360, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120domain", "\u0120adaptation"], "seq_scores": [0.9618691205978394, 0.9740923643112183], "text": "domain adaptation", "score": 0.9679807424545288, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 362, "end": 364, "seq_label": ["B-Method"], "seq_token": ["DA"], "seq_scores": [0.9911074042320251], "text": "DA", "score": 0.9911074042320251, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 373, "end": 399, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120neuron", "-", "level", "\u0120interventions"], "seq_scores": [0.984618604183197, 0.9951332211494446, 0.9922435879707336, 0.9933760762214661], "text": "neuron-level interventions", "score": 0.9913428723812103, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 644, "end": 646, "seq_label": ["B-Method"], "seq_token": ["\u0120DA"], "seq_scores": [0.8931103944778442], "text": "DA", "score": 0.8931103944778442, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 82, "end": 106, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["Large", "\u0120pre", "-", "trained", "\u0120models"], "seq_scores": [0.9978289008140564, 0.9988686442375183, 0.9994763731956482, 0.9995388984680176, 0.9991865754127502], "text": "Large pre-trained models", "score": 0.9989798784255981, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 132, "end": 152, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120downstream", "\u0120task", "\u0120data"], "seq_scores": [0.9975847005844116, 0.9968166947364807, 0.9994829893112183], "text": "downstream task data", "score": 0.9979614615440369, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 168, "end": 179, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120unseen", "\u0120data"], "seq_scores": [0.9990556836128235, 0.9983118772506714], "text": "unseen data", "score": 0.9986837804317474, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 186, "end": 209, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120train", "\u0120and", "\u0120test", "\u0120data"], "seq_scores": [0.9968296885490417, 0.9962158799171448, 0.9994363188743591, 0.9992167949676514, 0.9987809062004089], "text": "the train and test data", "score": 0.9980959177017212, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 239, "end": 248, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9877499938011169, 0.9950653910636902], "text": "the model", "score": 0.9914076924324036, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 540, "end": 549, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9745040535926819, 0.9888730645179749], "text": "the model", "score": 0.9816885590553284, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 616, "end": 625, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9887614846229553, 0.9933121800422668], "text": "the model", "score": 0.9910368323326111, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 1039, "end": 1055, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", "\u0120set"], "seq_scores": [0.9989339709281921, 0.9995338916778564, 0.9993150234222412], "text": "the training set", "score": 0.9992609620094299, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 1060, "end": 1072, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120test", "\u0120set"], "seq_scores": [0.9985472559928894, 0.9991555213928223, 0.9991720914840698], "text": "the test set", "score": 0.9989582896232605, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 1203, "end": 1212, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120test", "\u0120data"], "seq_scores": [0.9976709485054016, 0.9987503290176392], "text": "test data", "score": 0.9982106387615204, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 1336, "end": 1353, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120trained", "\u0120model"], "seq_scores": [0.998504638671875, 0.9995284080505371, 0.9990578293800354], "text": "the trained model", "score": 0.9990302920341492, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1415, "end": 1428, "seq_label": ["B-Method", "I-Method"], "seq_token": ["DA", "\u0120algorithms"], "seq_scores": [0.9900049567222595, 0.7403543591499329], "text": "DA algorithms", "score": 0.8651796579360962, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 1480, "end": 1487, "seq_label": ["B-Task"], "seq_token": ["\u0120general"], "seq_scores": [0.6674836874008179], "text": "general", "score": 0.6674836874008179, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1538, "end": 1540, "seq_label": ["B-Method"], "seq_token": ["\u0120DA"], "seq_scores": [0.8297659754753113], "text": "DA", "score": 0.8297659754753113, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1572, "end": 1597, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Da", "ume", "\u0120III", "\u0120and", "\u0120Marc", "u", ",", "\u01202006"], "seq_scores": [0.9995899796485901, 0.9996004700660706, 0.999658465385437, 0.9996299743652344, 0.9996941089630127, 0.9997361302375793, 0.9995637536048889, 0.9995858073234558], "text": "Daume III and Marcu, 2006", "score": 0.9996323361992836, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1599, "end": 1627, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Reich", "art", "\u0120and", "\u0120Rapp", "op", "ort", ",", "\u01202007"], "seq_scores": [0.9996579885482788, 0.9997290968894958, 0.9996297359466553, 0.999704897403717, 0.9997614026069641, 0.9997656941413879, 0.9995796084403992, 0.9996402263641357], "text": "Reichart and Rappoport, 2007", "score": 0.9996835812926292, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1629, "end": 1651, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ben", "-", "David", "\u0120et", "\u0120al", ".,", "\u01202007"], "seq_scores": [0.9996426105499268, 0.9995656609535217, 0.9997512698173523, 0.9997556805610657, 0.9998313188552856, 0.9997313618659973, 0.9997325539588928], "text": "Ben-David et al., 2007", "score": 0.9997157795088631, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1653, "end": 1679, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Schn", "abel", "\u0120and", "\u0120Sch", "\u00c3\u00bc", "t", "ze", ",", "\u01202014"], "seq_scores": [0.9996351003646851, 0.9997135996818542, 0.9996780157089233, 0.9997709393501282, 0.9997730851173401, 0.9997493624687195, 0.9997517466545105, 0.9996649026870728, 0.9996998310089111], "text": "Schnabel and Sch\u00fctze, 2014", "score": 0.9997151758935716, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1703, "end": 1733, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120un", "super", "vised", "\u0120domain", "\u0120adaptation"], "seq_scores": [0.8656931519508362, 0.8936257362365723, 0.8715062141418457, 0.809106707572937, 0.863913893699646], "text": "unsupervised domain adaptation", "score": 0.8607691407203675, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1735, "end": 1738, "seq_label": ["B-Method", "I-Method"], "seq_token": ["U", "DA"], "seq_scores": [0.961519181728363, 0.9879706501960754], "text": "UDA", "score": 0.9747449159622192, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1759, "end": 1761, "seq_label": ["B-Method"], "seq_token": ["\u0120DA"], "seq_scores": [0.8646953701972961], "text": "DA", "score": 0.8646953701972961, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1941, "end": 1968, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120target", "\u0120domain", "\u0120knowledge"], "seq_scores": [0.7197433114051819, 0.7324173450469971, 0.8932080268859863, 0.8829556703567505], "text": "the target domain knowledge", "score": 0.8070810884237289, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2039, "end": 2062, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120representation", "\u0120learning"], "seq_scores": [0.9867395162582397, 0.9821658730506897], "text": "representation learning", "score": 0.9844526946544647, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2064, "end": 2084, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Bl", "itzer", "\u0120et", "\u0120al", ".,", "\u01202007"], "seq_scores": [0.9996376037597656, 0.9995836615562439, 0.9996064305305481, 0.9997581839561462, 0.9995949864387512, 0.9994547963142395], "text": "Blitzer et al., 2007", "score": 0.9996059437592825, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2086, "end": 2104, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Gan", "in", "\u0120et", "\u0120al", ".,", "\u01202016"], "seq_scores": [0.9994480013847351, 0.999666690826416, 0.9996578693389893, 0.9997665286064148, 0.9996166229248047, 0.9996349811553955], "text": "Ganin et al., 2016", "score": 0.9996317823727926, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2106, "end": 2130, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Z", "iser", "\u0120and", "\u0120Reich", "art", ",", "\u01202018"], "seq_scores": [0.9996191263198853, 0.9995367527008057, 0.9996069073677063, 0.9997057318687439, 0.9997316002845764, 0.9995414018630981, 0.999582827091217], "text": "Ziser and Reichart, 2018", "score": 0.9996177639280047, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2132, "end": 2156, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Han", "\u0120and", "\u0120Eisen", "stein", ",", "\u01202019"], "seq_scores": [0.9994563460350037, 0.9995778203010559, 0.9995837807655334, 0.9996815919876099, 0.9995637536048889, 0.9995811581611633], "text": "Han and Eisenstein, 2019", "score": 0.9995740751425425, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2158, "end": 2176, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120David", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9996285438537598, 0.9997194409370422, 0.9998173117637634, 0.999754011631012, 0.9998121857643127], "text": "David et al., 2020", "score": 0.999746298789978, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2189, "end": 2204, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ben", "-", "David", "\u0120et", "\u0120al"], "seq_scores": [0.9995095729827881, 0.9994691014289856, 0.9996480941772461, 0.999763548374176, 0.9998061060905457], "text": "Ben-David et al", "score": 0.9996392846107482, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2217, "end": 2227, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120(", "20", "21", ")", "\u0120Vol", "k", "\u0120et", "\u0120al"], "seq_scores": [0.9990636706352234, 0.9991052746772766, 0.9993500113487244, 0.9574981927871704, 0.9994997978210449, 0.9997522234916687, 0.9997584223747253, 0.999789297580719], "text": "Volk et al", "score": 0.9942271113395691, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2263, "end": 2280, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120(", "20", "22", ")", "\u0120inference", "-", "time", "\u0120DA"], "seq_scores": [0.999197781085968, 0.9993159770965576, 0.9994388222694397, 0.9885616302490234, 0.9711897969245911, 0.9825970530509949, 0.9849653244018555, 0.9885970950126648], "text": "inference-time DA", "score": 0.9892329350113869, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 1809, "end": 1821, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120labeled", "\u0120data"], "seq_scores": [0.9987369179725647, 0.9991025924682617], "text": "labeled data", "score": 0.9989197552204132, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 1849, "end": 1863, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120unl", "abel", "ed", "\u0120data"], "seq_scores": [0.9984344840049744, 0.9996739625930786, 0.9995529055595398, 0.9987913966178894], "text": "unlabeled data", "score": 0.9991131871938705, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 2320, "end": 2328, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120test"], "seq_scores": [0.5088088512420654, 0.845682680606842], "text": "the test", "score": 0.6772457659244537, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2473, "end": 2482, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9984197616577148, 0.9983682036399841], "text": "the model", "score": 0.9983939826488495, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 2506, "end": 2507, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120a"], "seq_scores": [0.6808412075042725], "text": "a", "score": 0.6808412075042725, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 2538, "end": 2552, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120unl", "abel", "ed", "\u0120data"], "seq_scores": [0.9995248317718506, 0.99992835521698, 0.9999039173126221, 0.9997534155845642], "text": "unlabeled data", "score": 0.9997776299715042, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3126, "end": 3147, "seq_label": ["I-Method", "I-Method", "I-Method", "B-Method", "I-Method"], "seq_token": ["\u0120representation", "\u0120the", "\u0120representation", "\u0120model", "\u0120representations"], "seq_scores": [0.5633641481399536, 0.5966900587081909, 0.904823899269104, 0.5759333372116089, 0.5352261662483215], "text": "model representations", "score": 0.6352075219154358, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3150, "end": 3168, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["D", "al", "vi", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9996528625488281, 0.9997214674949646, 0.9996652603149414, 0.9994357228279114, 0.9997072815895081, 0.9994164705276489, 0.9994232654571533], "text": "Dalvi et al., 2019", "score": 0.9995746186801365, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3170, "end": 3190, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Dur", "ran", "i", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9996675252914429, 0.9997474551200867, 0.9996953010559082, 0.9996302127838135, 0.9997063279151917, 0.9995864033699036, 0.9995457530021667], "text": "Durrani et al., 2020", "score": 0.9996541397912162, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3192, "end": 3221, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Tor", "ro", "ba", "\u0120H", "enn", "igen", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9995847344398499, 0.9997054934501648, 0.9996901750564575, 0.9996529817581177, 0.9996819496154785, 0.9996410608291626, 0.9995749592781067, 0.9996516704559326, 0.9995025396347046, 0.9994972944259644], "text": "Torroba Hennigen et al., 2020", "score": 0.9996182858943939, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3223, "end": 3249, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ant", "ver", "g", "\u0120and", "\u0120Bel", "ink", "ov", ",", "\u01202022"], "seq_scores": [0.9995920062065125, 0.9996403455734253, 0.9996432065963745, 0.999530553817749, 0.9996858835220337, 0.9997096657752991, 0.9996129870414734, 0.9994813799858093, 0.9994311928749084], "text": "Antverg and Belinkov, 2022", "score": 0.9995919134881761, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3251, "end": 3270, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120S", "aj", "jad", "\u0120et", "\u0120al", ".,", "\u01202021"], "seq_scores": [0.9996403455734253, 0.9997639060020447, 0.9997437596321106, 0.999566376209259, 0.9997038245201111, 0.9995786547660828, 0.9996218681335449], "text": "Sajjad et al., 2021", "score": 0.9996598192623684, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3282, "end": 3286, "seq_label": ["B-Method"], "seq_token": ["\u0120rank"], "seq_scores": [0.5382965207099915], "text": "rank", "score": 0.5382965207099915, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3398, "end": 3427, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120target", "-", "domain", "\u0120representations"], "seq_scores": [0.8044589161872864, 0.9874420762062073, 0.9848399758338928, 0.9848543405532837], "text": "target-domain representations", "score": 0.9403988271951675, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3607, "end": 3635, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120modified", "\u0120representations"], "seq_scores": [0.6702832579612732, 0.6431018114089966, 0.8081299066543579], "text": "the modified representations", "score": 0.7071716586748759, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3660, "end": 3723, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120In", "ference", "-", "time", "\u0120Domain", "\u0120Adapt", "ation", "\u0120via", "\u0120Ne", "uron", "-", "level", "\u0120Inter", "ventions"], "seq_scores": [0.9816308617591858, 0.9983870983123779, 0.9950337409973145, 0.9956367611885071, 0.9952822327613831, 0.9939048886299133, 0.9930626749992371, 0.8878641724586487, 0.9713315963745117, 0.9882122874259949, 0.9761166572570801, 0.9869047999382019, 0.9799768924713135, 0.9911109209060669], "text": "Inference-time Domain Adaptation via Neuron-level Interventions", "score": 0.9810325418199811, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3725, "end": 3730, "seq_label": ["B-Method", "I-Method"], "seq_token": ["ID", "ANI"], "seq_scores": [0.6363751888275146, 0.5845595002174377], "text": "IDANI", "score": 0.6104673445224762, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2707, "end": 2716, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9958704113960266, 0.9969809651374817], "text": "the model", "score": 0.9964256882667542, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3021, "end": 3036, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120language", "\u0120models"], "seq_scores": [0.9974508881568909, 0.9987772107124329], "text": "language models", "score": 0.9981140494346619, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3515, "end": 3524, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9958490133285522, 0.9962886571884155], "text": "the model", "score": 0.9960688352584839, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3540, "end": 3548, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120examples"], "seq_scores": [0.7236350774765015], "text": "examples", "score": 0.7236350774765015, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3826, "end": 3842, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120a", "\u0120representation"], "seq_scores": [0.5248103141784668, 0.6490004062652588], "text": "a representation", "score": 0.5869053602218628, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3844, "end": 3847, "seq_label": ["B-Method", "I-Method"], "seq_token": ["CL", "S"], "seq_scores": [0.5761116147041321, 0.8801659941673279], "text": "CLS", "score": 0.72813880443573, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 4001, "end": 4006, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9802354574203491, 0.9932283759117126], "text": "IDANI", "score": 0.9867319166660309, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 4047, "end": 4061, "seq_label": ["I-Method", "B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120representation", "\u0120neuron", "-", "ranking"], "seq_scores": [0.6240748167037964, 0.4440007209777832, 0.5214391350746155, 0.5276484489440918], "text": "neuron-ranking", "score": 0.5292907804250717, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3744, "end": 3762, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120The", "\u0120language", "\u0120model"], "seq_scores": [0.9975747466087341, 0.999606192111969, 0.9990112781524658], "text": "The language model", "score": 0.998730738957723, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3871, "end": 3874, "seq_label": ["I-DatasetGeneric", "B-DatasetGeneric"], "seq_token": ["\u0120domain", "\u0120the"], "seq_scores": [0.5977121591567993, 0.6012647151947021], "text": "the", "score": 0.5994884371757507, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3928, "end": 3950, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model", "'s", "\u0120class", "ifier"], "seq_scores": [0.9984544515609741, 0.9916290044784546, 0.9993842840194702, 0.9990049004554749, 0.999284565448761], "text": "the model's classifier", "score": 0.997551441192627, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4207, "end": 4221, "seq_label": ["I-MLModelGeneric", "B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["-", "\u0120the", "\u0120class", "ifier"], "seq_scores": [0.5358924269676208, 0.9977446794509888, 0.9988125562667847, 0.9989736080169678], "text": "the classifier", "score": 0.8828558176755905, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 4315, "end": 4320, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9960936903953552, 0.9929099678993225], "text": "IDANI", "score": 0.9945018291473389, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 4382, "end": 4401, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120text", "\u0120classification"], "seq_scores": [0.9983735084533691, 0.9989916682243347], "text": "text classification", "score": 0.9986825883388519, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 4409, "end": 4427, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["sent", "iment", "\u0120analysis"], "seq_scores": [0.9974666833877563, 0.9995144605636597, 0.9996646642684937], "text": "sentiment analysis", "score": 0.9988819360733032, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 4429, "end": 4455, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["\u0120natural", "\u0120language", "\u0120inference"], "seq_scores": [0.995802104473114, 0.9990741014480591, 0.999261200428009], "text": "natural language inference", "score": 0.998045802116394, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 4465, "end": 4481, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120sequence", "\u0120tagging"], "seq_scores": [0.998489260673523, 0.9988282322883606], "text": "sequence tagging", "score": 0.9986587464809418, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 4488, "end": 4509, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["as", "pect", "\u0120identification"], "seq_scores": [0.9984837174415588, 0.9979561567306519, 0.9995208978652954], "text": "aspect identification", "score": 0.9986535906791687, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 4570, "end": 4575, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9966523051261902, 0.9945241212844849], "text": "IDANI", "score": 0.9955882132053375, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4324, "end": 4325, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120a"], "seq_scores": [0.7493078112602234], "text": "a", "score": 0.7493078112602234, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4519, "end": 4548, "seq_label": ["I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120of", "\u0120well", "\u0120known", "\u0120DA", "\u0120benchmarks", "\u012052", "\u0120source", "-", "target", "\u0120domain", "\u0120pairs"], "seq_scores": [0.5096328854560852, 0.9414058923721313, 0.9850931763648987, 0.987392246723175, 0.9912789463996887, 0.9873898029327393, 0.9886022210121155, 0.9984063506126404, 0.998002827167511, 0.9977372884750366, 0.9979217648506165], "text": "52 source-target domain pairs", "score": 0.9438966729424216, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 4682, "end": 4703, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120classification", "\u0120module"], "seq_scores": [0.48969799280166626, 0.5626080632209778], "text": "classification module", "score": 0.526153028011322, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 4704, "end": 4705, "seq_label": ["B-MLModel"], "seq_token": ["\u0120f"], "seq_scores": [0.5816388726234436], "text": "f", "score": 0.5816388726234436, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 4785, "end": 4786, "seq_label": ["B-Dataset"], "seq_token": ["\u0120D"], "seq_scores": [0.809656023979187], "text": "D", "score": 0.809656023979187, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 4830, "end": 4833, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120D", "\u0120t"], "seq_scores": [0.9215506315231323, 0.5292704701423645], "text": "D t", "score": 0.7254105508327484, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4665, "end": 4672, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120model"], "seq_scores": [0.9879716038703918, 0.9904276132583618], "text": "a model", "score": 0.9891996085643768, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4759, "end": 4763, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120data"], "seq_scores": [0.8935523629188538], "text": "data", "score": 0.8935523629188538, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4810, "end": 4829, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120unl", "abel", "ed", "\u0120task", "\u0120data"], "seq_scores": [0.9993969202041626, 0.9999129772186279, 0.9998961687088013, 0.9997825026512146, 0.9998619556427002], "text": "unlabeled task data", "score": 0.9997701048851013, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 5543, "end": 5569, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Ant", "ver", "g", "\u0120and", "\u0120Bel", "ink", "ov", ",", "\u01202022"], "seq_scores": [0.9990529417991638, 0.9975107908248901, 0.997536301612854, 0.997116208076477, 0.9972473978996277, 0.9982501864433289, 0.9973787069320679, 0.9958807229995728, 0.9967706203460693], "text": "Antverg and Belinkov, 2022", "score": 0.9974159863260057, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5768, "end": 5796, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120k", "-", "highest", "\u0120ranked", "\u0120neurons"], "seq_scores": [0.8230153918266296, 0.4137280285358429, 0.9475841522216797, 0.9386715292930603, 0.9338804483413696, 0.9050734639167786], "text": "the k-highest ranked neurons", "score": 0.8269921690225601, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6119, "end": 6145, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Ant", "ver", "g", "\u0120and", "\u0120Bel", "ink", "ov", ",", "\u01202022"], "seq_scores": [0.9980645775794983, 0.996101975440979, 0.9972389936447144, 0.9942203760147095, 0.9958005547523499, 0.9980341792106628, 0.9957281947135925, 0.9931455850601196, 0.9875467419624329], "text": "Antverg and Belinkov, 2022", "score": 0.9950979087087843, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 6263, "end": 6274, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120re", "-", "training"], "seq_scores": [0.6480816602706909, 0.8514622449874878, 0.7403427362442017], "text": "re-training", "score": 0.7466288805007935, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6237, "end": 6251, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120class", "ifier"], "seq_scores": [0.9914496541023254, 0.9956883788108826, 0.9960494637489319], "text": "the classifier", "score": 0.9943958322207133, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 6572, "end": 6591, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120representations"], "seq_scores": [0.5334948301315308, 0.5460419058799744], "text": "the representations", "score": 0.5397683680057526, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 6823, "end": 6829, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["LINE", "AR"], "seq_scores": [0.8543446063995361, 0.8311343193054199], "text": "LINEAR", "score": 0.842739462852478, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6831, "end": 6849, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["D", "al", "vi", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9993558526039124, 0.9991635084152222, 0.9989639520645142, 0.9983957409858704, 0.9989100694656372, 0.9979300498962402, 0.9984519481658936], "text": "Dalvi et al., 2019", "score": 0.9987387316567558, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 6952, "end": 6970, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120cross", "-", "ent", "ropy", "\u0120loss"], "seq_scores": [0.9902535080909729, 0.9993404746055603, 0.9994485974311829, 0.9994590878486633, 0.9986206293106079], "text": "cross-entropy loss", "score": 0.9974244594573974, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 6986, "end": 7012, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120elastic", "\u0120net", "\u0120regular", "ization"], "seq_scores": [0.9985973238945007, 0.9985470175743103, 0.9992775321006775, 0.9992517828941345], "text": "elastic net regularization", "score": 0.9989184141159058, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7014, "end": 7034, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Z", "ou", "\u0120and", "\u0120Hast", "ie", ",", "\u01202005"], "seq_scores": [0.9977129697799683, 0.9893013834953308, 0.9860527515411377, 0.9914563298225403, 0.9917843341827393, 0.9863858222961426, 0.9897356033325195], "text": "Zou and Hastie, 2005", "score": 0.9903470277786255, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6870, "end": 6889, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120linear", "\u0120class", "ifier"], "seq_scores": [0.9990761280059814, 0.999799907207489, 0.9997394680976868, 0.9998014569282532], "text": "a linear classifier", "score": 0.9996042400598526, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7051, "end": 7067, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120class", "ifier", "'s"], "seq_scores": [0.9860680103302002, 0.9920496344566345, 0.9951637983322144, 0.8543457388877869], "text": "the classifier's", "score": 0.956906795501709, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7655, "end": 7666, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120arg", "-", "s", "orting"], "seq_scores": [0.9841111898422241, 0.980748176574707, 0.9823765754699707, 0.967553973197937], "text": "arg-sorting", "score": 0.9786974787712097, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7748, "end": 7775, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ant", "ver", "g", "\u0120and", "\u0120Bel", "ink", "ov", "\u0120(", "20", "22", ")"], "seq_scores": [0.9994310736656189, 0.9994729161262512, 0.999518632888794, 0.9995378255844116, 0.9996848106384277, 0.9997586607933044, 0.9997244477272034, 0.9996638298034668, 0.9995425939559937, 0.9996808767318726, 0.9983571171760559], "text": "Antverg and Belinkov (2022)", "score": 0.9994884350083091, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7858, "end": 7864, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120LINE", "AR"], "seq_scores": [0.6525748372077942, 0.6069189310073853], "text": "LINEAR", "score": 0.6297468841075897, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7869, "end": 7891, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120another", "\u0120ranking", "\u0120method"], "seq_scores": [0.89899742603302, 0.9229341149330139, 0.9289003014564514], "text": "another ranking method", "score": 0.9169439474741617, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7893, "end": 7922, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Tor", "ro", "ba", "\u0120H", "enn", "igen", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9995284080505371, 0.9992982149124146, 0.9994223117828369, 0.9993232488632202, 0.9995162487030029, 0.9995357990264893, 0.9995019435882568, 0.9995809197425842, 0.9991845488548279, 0.9993390440940857], "text": "Torroba Hennigen et al., 2020", "score": 0.9994230687618255, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7834, "end": 7845, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120this", "\u0120method"], "seq_scores": [0.7229214906692505, 0.6596169471740723], "text": "this method", "score": 0.6912692189216614, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7869, "end": 7876, "seq_label": ["B-MLModelGeneric"], "seq_token": ["\u0120another"], "seq_scores": [0.5091888308525085], "text": "another", "score": 0.5091888308525085, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 7976, "end": 7995, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120text", "\u0120classification"], "seq_scores": [0.9953266382217407, 0.9988331198692322], "text": "text classification", "score": 0.9970798790454865, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 8003, "end": 8021, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120sentiment", "\u0120analysis"], "seq_scores": [0.9989367127418518, 0.999563992023468], "text": "sentiment analysis", "score": 0.9992503523826599, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 8023, "end": 8042, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["class", "ifying", "\u0120reviews"], "seq_scores": [0.9790400266647339, 0.9850799441337585, 0.5153423547744751], "text": "classifying reviews", "score": 0.8264874418576559, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8068, "end": 8088, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Bl", "itzer", "\u0120et", "\u0120al", ".,", "\u01202007"], "seq_scores": [0.9993756413459778, 0.9996209144592285, 0.9994578957557678, 0.9995902180671692, 0.999369204044342, 0.999480664730072], "text": "Blitzer et al., 2007", "score": 0.9994824230670929, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 8095, "end": 8121, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["\u0120natural", "\u0120language", "\u0120inference"], "seq_scores": [0.9988357424736023, 0.9993419051170349, 0.9992287158966064], "text": "natural language inference", "score": 0.9991354544957479, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 8123, "end": 8126, "seq_label": ["B-Task", "I-Task"], "seq_token": ["N", "LI"], "seq_scores": [0.9972796440124512, 0.9986206293106079], "text": "NLI", "score": 0.9979501366615295, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 8128, "end": 8139, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120class", "ifying"], "seq_scores": [0.9229227304458618, 0.7771204710006714], "text": "classifying", "score": 0.8500216007232666, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8195, "end": 8214, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Bow", "man", "\u0120et", "\u0120al", ".,", "\u01202015"], "seq_scores": [0.9995282888412476, 0.9996601343154907, 0.9995718598365784, 0.999679684638977, 0.9994576573371887, 0.9993805885314941], "text": "Bowman et al., 2015", "score": 0.9995463689168295, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 8224, "end": 8240, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120sequence", "\u0120tagging"], "seq_scores": [0.9905893802642822, 0.997316300868988], "text": "sequence tagging", "score": 0.9939528405666351, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 8247, "end": 8264, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120aspect", "\u0120prediction"], "seq_scores": [0.9984651803970337, 0.9993771910667419], "text": "aspect prediction", "score": 0.9989211857318878, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 8266, "end": 8290, "seq_label": ["B-Task", "I-Task", "I-Task", "I-Task"], "seq_token": ["ident", "ifying", "\u0120aspect", "\u0120terms"], "seq_scores": [0.9768452644348145, 0.9861739873886108, 0.9386163949966431, 0.9724122881889343], "text": "identifying aspect terms", "score": 0.9685119837522507, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8307, "end": 8323, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Hu", "\u0120and", "\u0120Liu", ",", "\u01202004"], "seq_scores": [0.9985490441322327, 0.9980735778808594, 0.9988728165626526, 0.998196542263031, 0.9983175992965698], "text": "Hu and Liu, 2004", "score": 0.9984019160270691, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8325, "end": 8344, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Top", "rak", "\u0120et", "\u0120al", ".,", "\u01202010"], "seq_scores": [0.9994291663169861, 0.9997183680534363, 0.9995446801185608, 0.9996968507766724, 0.9995368719100952, 0.9995555281639099], "text": "Toprak et al., 2010", "score": 0.9995802442232767, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8346, "end": 8366, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Pont", "iki", "\u0120et", "\u0120al", ".,", "\u01202014"], "seq_scores": [0.9994369149208069, 0.9996354579925537, 0.999488115310669, 0.999663233757019, 0.9995174407958984, 0.9995214939117432], "text": "Pontiki et al., 2014", "score": 0.9995437761147817, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 8298, "end": 8305, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120reviews"], "seq_scores": [0.9366657733917236], "text": "reviews", "score": 0.9366657733917236, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 8385, "end": 8394, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9959986209869385, 0.997765064239502], "text": "the model", "score": 0.9968818426132202, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 8446, "end": 8470, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120different", "\u0120target", "\u0120domains"], "seq_scores": [0.9429599046707153, 0.9819028377532959, 0.9732181429862976], "text": "different target domains", "score": 0.9660269618034363, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 8520, "end": 8538, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u01202000", "-", "3000", "\u0120examples"], "seq_scores": [0.9985841512680054, 0.9998950958251953, 0.999883770942688, 0.9997237324714661], "text": "2000-3000 examples", "score": 0.9995216876268387, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 8570, "end": 8586, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", "\u0120set"], "seq_scores": [0.9949033260345459, 0.9967166781425476, 0.9974621534347534], "text": "the training set", "score": 0.996360719203949, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 8607, "end": 8627, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120equivalent", "\u0120size", "\u0120data"], "seq_scores": [0.9989432692527771, 0.999591052532196, 0.999512791633606], "text": "equivalent size data", "score": 0.999349037806193, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8779, "end": 8783, "seq_label": ["B-Method"], "seq_token": ["\u0120fine"], "seq_scores": [0.6034063696861267], "text": "fine", "score": 0.6034063696861267, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8803, "end": 8813, "seq_label": ["I-Method", "I-Method", "B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["t", "une", "\u0120B", "ERT", "-", "base", "-"], "seq_scores": [0.5951938033103943, 0.6182615756988525, 0.8536691665649414, 0.913606584072113, 0.8700575232505798, 0.7663479447364807, 0.4960407018661499], "text": "BERT-base-", "score": 0.7304538999285016, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8826, "end": 8845, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Dev", "lin", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9995423555374146, 0.9992966651916504, 0.9991525411605835, 0.9994844198226929, 0.9988012313842773, 0.9991372227668762], "text": "Devlin et al., 2019", "score": 0.9992357393105825, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8981, "end": 8996, "seq_label": ["B-Method"], "seq_token": ["\u0120representations"], "seq_scores": [0.5767397284507751], "text": "representations", "score": 0.5767397284507751, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9031, "end": 9051, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120word", "\u0120representations"], "seq_scores": [0.998386025428772, 0.9983760118484497], "text": "word representations", "score": 0.9983810186386108, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 9060, "end": 9077, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120aspect", "\u0120prediction"], "seq_scores": [0.9931125044822693, 0.9936801195144653], "text": "aspect prediction", "score": 0.9933963119983673, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9088, "end": 9112, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120CLS", "\u0120token", "\u0120representation"], "seq_scores": [0.9989602565765381, 0.9989989399909973, 0.9985195994377136], "text": "CLS token representation", "score": 0.998826265335083, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9336, "end": 9347, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120grid", "\u0120search"], "seq_scores": [0.664334774017334, 0.5322645306587219], "text": "grid search", "score": 0.598299652338028, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9652, "end": 9657, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.6503036022186279, 0.9181413650512695], "text": "IDANI", "score": 0.7842224836349487, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9671, "end": 9680, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120PR", "OB", "EL", "ESS"], "seq_scores": [0.829326868057251, 0.77189701795578, 0.7569279074668884, 0.6892746686935425], "text": "PROBELESS", "score": 0.7618566155433655, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9691, "end": 9697, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120LINE", "AR"], "seq_scores": [0.8175209760665894, 0.735887348651886], "text": "LINEAR", "score": 0.7767041623592377, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9731, "end": 9736, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.7339712381362915, 0.9383805394172668], "text": "IDANI", "score": 0.8361758887767792, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 9846, "end": 9873, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ant", "ver", "g", "\u0120and", "\u0120Bel", "ink", "ov", "\u0120(", "20", "22", ")"], "seq_scores": [0.9991195797920227, 0.9994297623634338, 0.9994480013847351, 0.9986103773117065, 0.9995757937431335, 0.9995821118354797, 0.999337375164032, 0.999250590801239, 0.9991612434387207, 0.9993208646774292, 0.9934399724006653], "text": "Antverg and Belinkov (2022)", "score": 0.9987523339011453, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 8789, "end": 8824, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120pre", "-", "trained", "\u0120B", "ERT", "-", "base", "-", "c", "ased", "\u0120model"], "seq_scores": [0.9962522387504578, 0.9987264275550842, 0.9994182586669922, 0.9993184804916382, 0.9990277290344238, 0.9997733235359192, 0.9996041655540466, 0.9996658563613892, 0.9997679591178894, 0.9997621178627014, 0.9997774958610535, 0.9997462630271912], "text": "a pre-trained BERT-base-cased model", "score": 0.9992366929848989, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 8850, "end": 8866, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", "\u0120set"], "seq_scores": [0.9969966411590576, 0.9986240863800049, 0.9991697072982788], "text": "the training set", "score": 0.9982634782791138, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 8930, "end": 8941, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120dev", "\u0120set"], "seq_scores": [0.9981473684310913, 0.9986078143119812, 0.9975661039352417], "text": "the dev set", "score": 0.9981070955594381, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9020, "end": 9029, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.969906747341156, 0.9751899242401123], "text": "the model", "score": 0.9725483357906342, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9147, "end": 9158, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model", "'s"], "seq_scores": [0.9645417332649231, 0.9777538776397705, 0.8746483325958252], "text": "the model's", "score": 0.938981314500173, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 9199, "end": 9211, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120test", "\u0120set"], "seq_scores": [0.9937790036201477, 0.997620165348053, 0.993827760219574], "text": "the test set", "score": 0.9950756430625916, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9492, "end": 9503, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model", "'s"], "seq_scores": [0.9516358375549316, 0.9600588083267212, 0.8395633697509766], "text": "the model's", "score": 0.9170860052108765, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10007, "end": 10018, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model", "'s"], "seq_scores": [0.9732251167297363, 0.972838819026947, 0.8809290528297424], "text": "the model's", "score": 0.9423309961954752, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10372, "end": 10375, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120U", "DA"], "seq_scores": [0.9855835437774658, 0.9890497922897339], "text": "UDA", "score": 0.9873166680335999, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10469, "end": 10497, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120inference", "-", "time", "\u0120DA", "\u0120approaches"], "seq_scores": [0.9849041700363159, 0.9864250421524048, 0.9807677865028381, 0.9803512692451477, 0.7904913425445557], "text": "inference-time DA approaches", "score": 0.9445879220962524, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 10499, "end": 10521, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Ben", "-", "David", "\u0120et", "\u0120al", ".,", "\u01202021"], "seq_scores": [0.9993982315063477, 0.9993000030517578, 0.9993433356285095, 0.9992122650146484, 0.9994064569473267, 0.9990642666816711, 0.9992437362670898], "text": "Ben-David et al., 2021", "score": 0.9992811850139073, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 10523, "end": 10540, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Vol", "k", "\u0120et", "\u0120al", ".,", "\u01202022"], "seq_scores": [0.9995409250259399, 0.9995766282081604, 0.9995274543762207, 0.9996249675750732, 0.9994786381721497, 0.9995142221450806], "text": "Volk et al., 2022", "score": 0.9995438059171041, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10280, "end": 10289, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9986937642097473, 0.9988369345664978], "text": "the model", "score": 0.9987653493881226, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10304, "end": 10322, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120target", "\u0120domain", "\u0120data"], "seq_scores": [0.997431218624115, 0.9994609951972961, 0.9980917572975159], "text": "target domain data", "score": 0.9983279903729757, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10372, "end": 10375, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120U", "DA"], "seq_scores": [0.7770736813545227, 0.8522524237632751], "text": "UDA", "score": 0.8146630525588989, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10411, "end": 10419, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120data"], "seq_scores": [0.9976322650909424, 0.998770534992218], "text": "the data", "score": 0.9982014000415802, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10469, "end": 10497, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120inference", "-", "time", "\u0120DA", "\u0120approaches"], "seq_scores": [0.9904122948646545, 0.9976467490196228, 0.9972686767578125, 0.9971145391464233, 0.9882832765579224], "text": "inference-time DA approaches", "score": 0.9941451072692871, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10650, "end": 10684, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120source", "\u0120to", "\u0120target", "\u0120domain", "\u0120adaptation"], "seq_scores": [0.6232921481132507, 0.7978366017341614, 0.8330593109130859, 0.8152589797973633, 0.7707006335258484], "text": "source to target domain adaptation", "score": 0.768029534816742, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 11144, "end": 11161, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120aspect", "\u0120prediction"], "seq_scores": [0.9760403633117676, 0.9972532391548157], "text": "aspect prediction", "score": 0.9866468012332916, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 11390, "end": 11408, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120sentiment", "\u0120analysis"], "seq_scores": [0.9987242817878723, 0.9990041851997375], "text": "sentiment analysis", "score": 0.9988642334938049, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 11572, "end": 11577, "seq_label": ["I-Method", "B-Dataset", "I-Dataset"], "seq_token": ["ing", "\u0120ID", "ANI"], "seq_scores": [0.503350019454956, 0.927933931350708, 0.6344538927078247], "text": "IDANI", "score": 0.688579281171163, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 11830, "end": 11833, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.993427038192749, 0.9935153722763062], "text": "NLI", "score": 0.9934712052345276, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11946, "end": 11964, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120domain", "\u0120information"], "seq_scores": [0.75017249584198, 0.7999663352966309], "text": "domain information", "score": 0.7750694155693054, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12077, "end": 12085, "seq_label": ["B-Task"], "seq_token": ["\u0120adapting"], "seq_scores": [0.7593156099319458], "text": "adapting", "score": 0.7593156099319458, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 12091, "end": 12096, "seq_label": ["B-Dataset"], "seq_token": ["\u0120Slate"], "seq_scores": [0.9513402581214905], "text": "Slate", "score": 0.9513402581214905, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12168, "end": 12177, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120PR", "OB", "EL", "ESS"], "seq_scores": [0.9983289837837219, 0.9982720613479614, 0.9985116124153137, 0.9987239241600037], "text": "PROBELESS", "score": 0.9984591454267502, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12211, "end": 12218, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120LIN", "-", "EAR"], "seq_scores": [0.9971238970756531, 0.9990154504776001, 0.9986625909805298], "text": "LIN-EAR", "score": 0.9982673128445944, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 12317, "end": 12345, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ant", "ver", "g", "\u0120and", "\u0120Bel", "ink", "ov", "\u0120(", "20", "22", "),"], "seq_scores": [0.9990721940994263, 0.999632716178894, 0.9996639490127563, 0.9993000030517578, 0.9996507167816162, 0.9997583031654358, 0.9997096657752991, 0.9995574355125427, 0.9979332685470581, 0.9993823766708374, 0.9989070892333984], "text": "Antverg and Belinkov (2022),", "score": 0.9993243380026384, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12364, "end": 12373, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120PR", "OB", "EL", "ESS"], "seq_scores": [0.998181939125061, 0.998379111289978, 0.998502254486084, 0.9987486600875854], "text": "PROBELESS", "score": 0.9984529912471771, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12390, "end": 12396, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120LINE", "AR"], "seq_scores": [0.996319055557251, 0.9987236857414246], "text": "LINEAR", "score": 0.9975213706493378, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12505, "end": 12510, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9378694295883179, 0.9514939785003662], "text": "IDANI", "score": 0.944681704044342, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12578, "end": 12589, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120class", "ifying"], "seq_scores": [0.5792480707168579, 0.7747732400894165], "text": "classifying", "score": 0.6770106554031372, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12621, "end": 12639, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["sent", "iment", "\u0120analysis"], "seq_scores": [0.9987446069717407, 0.9988415837287903, 0.9992972612380981], "text": "sentiment analysis", "score": 0.9989611506462097, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12678, "end": 12695, "seq_label": ["I-Task", "B-Task", "I-Task", "I-Task"], "seq_token": ["ifying", "as", "pect", "\u0120prediction"], "seq_scores": [0.5385826826095581, 0.998043417930603, 0.9949150085449219, 0.99896240234375], "text": "aspect prediction", "score": 0.8826258778572083, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12824, "end": 12842, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120sentiment", "\u0120analysis"], "seq_scores": [0.9989640712738037, 0.999298095703125], "text": "sentiment analysis", "score": 0.9991310834884644, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12992, "end": 13009, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120aspect", "\u0120prediction"], "seq_scores": [0.9981836676597595, 0.99888676404953], "text": "aspect prediction", "score": 0.9985352158546448, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 12529, "end": 12540, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120dataset"], "seq_scores": [0.9989173412322998, 0.9987504482269287], "text": "the dataset", "score": 0.9988338947296143, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 12590, "end": 12599, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120sentences"], "seq_scores": [0.9068279266357422], "text": "sentences", "score": 0.9068279266357422, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 13203, "end": 13212, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120PR", "OB", "EL", "ESS"], "seq_scores": [0.9933059811592102, 0.9970255494117737, 0.9981474876403809, 0.9975337982177734], "text": "PROBELESS", "score": 0.9965032041072845, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 13802, "end": 13819, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120aspect", "\u0120prediction"], "seq_scores": [0.9875439405441284, 0.9949784874916077], "text": "aspect prediction", "score": 0.991261214017868, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 13826, "end": 13836, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120PR", "OB", "EL", "ESS", "'"], "seq_scores": [0.9850578904151917, 0.9960570335388184, 0.9963125586509705, 0.9947649240493774, 0.8388490676879883], "text": "PROBELESS'", "score": 0.9622082948684693, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 14177, "end": 14194, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120some", "\u0120labeled", "\u0120data"], "seq_scores": [0.9085820317268372, 0.9658712148666382, 0.998659610748291], "text": "some labeled data", "score": 0.9577042857805887, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 14330, "end": 14356, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120available", "\u0120labeled", "\u0120data"], "seq_scores": [0.9918252229690552, 0.9965268969535828, 0.9983886480331421, 0.9988020658493042], "text": "the available labeled data", "score": 0.9963857084512711, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 14390, "end": 14415, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120(", "un", "label", "ed", ")", "\u0120test", "\u0120data"], "seq_scores": [0.9982262253761292, 0.9907742142677307, 0.9984073042869568, 0.9994524121284485, 0.9994376301765442, 0.998330295085907, 0.9986269474029541, 0.9988382458686829], "text": "the (unlabeled) test data", "score": 0.9977616593241692, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 14777, "end": 14795, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["sent", "iment", "\u0120analysis"], "seq_scores": [0.9939226508140564, 0.9978669881820679, 0.9983277916908264], "text": "sentiment analysis", "score": 0.9967058102289835, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 14850, "end": 14867, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["as", "pect", "\u0120prediction"], "seq_scores": [0.9912307262420654, 0.9956953525543213, 0.9932984709739685], "text": "aspect prediction", "score": 0.993408183256785, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 14876, "end": 14881, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.8615230917930603, 0.9562536478042603], "text": "IDANI", "score": 0.9088883697986603, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 14725, "end": 14734, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120sentences"], "seq_scores": [0.5919579863548279], "text": "sentences", "score": 0.5919579863548279, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 14951, "end": 14978, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120neuron", "-", "inter", "vention", "\u0120methods"], "seq_scores": [0.957512617111206, 0.9887085556983948, 0.982308030128479, 0.9868549108505249, 0.9130561947822571], "text": "neuron-intervention methods", "score": 0.9656880617141723, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 14990, "end": 14993, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120O", "OD"], "seq_scores": [0.6258893013000488, 0.5198121666908264], "text": "OOD", "score": 0.5728507339954376, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 15037, "end": 15042, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9992237091064453, 0.9992781281471252], "text": "IDANI", "score": 0.9992509186267853, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 15098, "end": 15103, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9993661046028137, 0.9991962313652039], "text": "IDANI", "score": 0.9992811679840088, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 15123, "end": 15129, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120or", "acle"], "seq_scores": [0.8277164101600647, 0.6140492558479309], "text": "oracle", "score": 0.7208828330039978, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 15226, "end": 15231, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9993525147438049, 0.9993000030517578], "text": "IDANI", "score": 0.9993262588977814, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 15250, "end": 15276, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120domain", "-", "related", "\u0120information"], "seq_scores": [0.9099897742271423, 0.9353786706924438, 0.9076552391052246, 0.9269856214523315], "text": "domain-related information", "score": 0.9200023263692856, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 15387, "end": 15392, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9993287324905396, 0.9991922974586487], "text": "IDANI", "score": 0.9992605149745941, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 15416, "end": 15425, "seq_label": ["B-Task"], "seq_token": ["\u0120inference"], "seq_scores": [0.8601623773574829], "text": "inference", "score": 0.8601623773574829, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 15066, "end": 15072, "seq_label": ["B-MLModelGeneric"], "seq_token": ["\u0120models"], "seq_scores": [0.9802804589271545], "text": "models", "score": 0.9802804589271545, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 15439, "end": 15455, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120other", "\u0120DA", "\u0120methods"], "seq_scores": [0.5651745796203613, 0.7884085178375244, 0.9935503005981445], "text": "other DA methods", "score": 0.7823777993520101, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 15481, "end": 15486, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120ID", "ANI"], "seq_scores": [0.9968570470809937, 0.9949477910995483], "text": "IDANI", "score": 0.995902419090271, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 15513, "end": 15531, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120sentiment", "\u0120analysis"], "seq_scores": [0.9989405274391174, 0.9993921518325806], "text": "sentiment analysis", "score": 0.999166339635849, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 15533, "end": 15559, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["\u0120natural", "\u0120language", "\u0120inference"], "seq_scores": [0.9986783862113953, 0.9987682700157166, 0.9990309476852417], "text": "natural language inference", "score": 0.9988258679707845, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 15565, "end": 15582, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120aspect", "\u0120prediction"], "seq_scores": [0.9982865452766418, 0.9993576407432556], "text": "aspect prediction", "score": 0.9988220930099487, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15603, "end": 15643, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", ",", "\u0120development", ",", "\u0120and", "\u0120test", "\u0120sets"], "seq_scores": [0.9983623623847961, 0.9955618381500244, 0.9994292855262756, 0.9991249442100525, 0.9996070265769958, 0.9995526671409607, 0.9993364214897156, 0.9992595314979553], "text": "the training, development, and test sets", "score": 0.998779259622097, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 15736, "end": 15738, "seq_label": ["B-Method"], "seq_token": ["\u0120DA"], "seq_scores": [0.8718506693840027], "text": "DA", "score": 0.8718506693840027, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 15768, "end": 15799, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["\u0120binary", "\u0120sentiment", "\u0120classification"], "seq_scores": [0.9982529282569885, 0.9989888072013855, 0.9994425177574158], "text": "binary sentiment classification", "score": 0.9988947510719299, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 15862, "end": 15875, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Bl", "itzer", "\u0120et", "\u0120al"], "seq_scores": [0.9996129870414734, 0.9998599290847778, 0.9998242259025574, 0.9998817443847656], "text": "Blitzer et al", "score": 0.9997947216033936, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 16047, "end": 16059, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120(", "2007", ")", "N", "guyen", ",", "\u01202015"], "seq_scores": [0.9997460246086121, 0.9997672438621521, 0.9989062547683716, 0.9994202852249146, 0.9995656609535217, 0.9993606209754944, 0.9993717074394226], "text": "Nguyen, 2015", "score": 0.9994482568332127, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 16061, "end": 16085, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Z", "iser", "\u0120and", "\u0120Reich", "art", ",", "\u01202018"], "seq_scores": [0.9996123909950256, 0.9996824264526367, 0.9996854066848755, 0.9997290968894958, 0.9997833371162415, 0.9996163845062256, 0.9996826648712158], "text": "Ziser and Reichart, 2018", "score": 0.9996845296451023, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15820, "end": 15858, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120four", "\u0120legacy", "\u0120product", "\u0120review", "\u0120domains"], "seq_scores": [0.9488086700439453, 0.9630709290504456, 0.973732590675354, 0.9756320118904114, 0.9889680743217468, 0.9564980268478394], "text": "the four legacy product review domains", "score": 0.9677850504716238, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15886, "end": 15891, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Books"], "seq_scores": [0.9846667051315308], "text": "Books", "score": 0.9846667051315308, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15897, "end": 15901, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120DVDs"], "seq_scores": [0.9843920469284058], "text": "DVDs", "score": 0.9843920469284058, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15907, "end": 15923, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120Electronic", "\u0120items"], "seq_scores": [0.9788703918457031, 0.9899987578392029], "text": "Electronic items", "score": 0.984434574842453, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15932, "end": 15950, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120Kitchen", "\u0120appliances"], "seq_scores": [0.9830026030540466, 0.9889398217201233], "text": "Kitchen appliances", "score": 0.985971212387085, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16016, "end": 16041, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120an", "\u0120airline", "\u0120review", "\u0120dataset"], "seq_scores": [0.9991293549537659, 0.9996354579925537, 0.9998722076416016, 0.9996813535690308], "text": "an airline review dataset", "score": 0.999579593539238, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 16187, "end": 16213, "seq_label": ["B-Task", "I-Task", "I-Task", "I-Task"], "seq_token": ["Natural", "\u0120Language", "\u0120In", "ference"], "seq_scores": [0.9914333820343018, 0.9926481246948242, 0.9888579845428467, 0.9945968389511108], "text": "Natural Language Inference", "score": 0.9918840825557709, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 16215, "end": 16236, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Williams", "\u0120et", "\u0120al", ".,", "\u01202018"], "seq_scores": [0.9996139407157898, 0.9998332262039185, 0.9998644590377808, 0.9998315572738647, 0.9998317956924438], "text": "Williams et al., 2018", "score": 0.9997949957847595, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 16273, "end": 16277, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120SN", "LI"], "seq_scores": [0.997897744178772, 0.9969697594642639], "text": "SNLI", "score": 0.9974337518215179, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 16287, "end": 16306, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Bow", "man", "\u0120et", "\u0120al", ".,", "\u01202015"], "seq_scores": [0.9996803998947144, 0.9998140931129456, 0.9998142123222351, 0.9998553991317749, 0.9997947812080383, 0.9997523427009583], "text": "Bowman et al., 2015", "score": 0.9997852047284445, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 16617, "end": 16632, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ben", "-", "David", "\u0120et", "\u0120al"], "seq_scores": [0.9995335340499878, 0.9994780421257019, 0.9996629953384399, 0.9997664093971252, 0.9998206496238708], "text": "Ben-David et al", "score": 0.9996523261070251, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16238, "end": 16249, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120This", "\u0120corpus"], "seq_scores": [0.9977561831474304, 0.9978117346763611], "text": "This corpus", "score": 0.9977839589118958, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16253, "end": 16265, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120an", "\u0120extension"], "seq_scores": [0.6738275289535522, 0.8793209791183472], "text": "an extension", "score": 0.7765742540359497, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16462, "end": 16472, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120The", "\u0120corpus"], "seq_scores": [0.9989128112792969, 0.9989238381385803], "text": "The corpus", "score": 0.9989183247089386, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16482, "end": 16491, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120data", "\u0120from"], "seq_scores": [0.8340976238250732, 0.5086338520050049], "text": "data from", "score": 0.6713657379150391, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16504, "end": 16517, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u01205", "\u0120are", "\u0120matched"], "seq_scores": [0.9742480516433716, 0.5051318407058716, 0.6850769519805908], "text": "5 are matched", "score": 0.7214856147766113, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16524, "end": 16559, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120training", ",", "\u0120development", "\u0120and", "\u0120test", "\u0120sets"], "seq_scores": [0.9897485375404358, 0.9994681477546692, 0.9993581175804138, 0.9996602535247803, 0.9994257688522339, 0.9996127486228943], "text": "training, development and test sets", "score": 0.9978789289792379, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16565, "end": 16581, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u01205", "\u0120are", "\u0120mism", "atched"], "seq_scores": [0.9814831614494324, 0.7909805178642273, 0.861534595489502, 0.9684614539146423], "text": "5 are mismatched", "score": 0.900614932179451, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16591, "end": 16605, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120a", "\u0120training", "\u0120set"], "seq_scores": [0.9933203458786011, 0.9993507266044617, 0.9992057681083679], "text": "a training set", "score": 0.9972922801971436, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16666, "end": 16690, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120five", "\u0120matched", "\u0120domains"], "seq_scores": [0.994733452796936, 0.9942654967308044, 0.9953357577323914, 0.9913870692253113], "text": "the five matched domains", "score": 0.9939304441213608, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16692, "end": 16699, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Fiction"], "seq_scores": [0.9702181220054626], "text": "Fiction", "score": 0.9702181220054626, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16701, "end": 16702, "seq_label": ["B-DatasetGeneric"], "seq_token": ["F"], "seq_scores": [0.5640396475791931], "text": "F", "score": 0.5640396475791931, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16705, "end": 16715, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Government"], "seq_scores": [0.9786538481712341], "text": "Government", "score": 0.9786538481712341, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16717, "end": 16718, "seq_label": ["B-DatasetGeneric"], "seq_token": ["G"], "seq_scores": [0.7665736675262451], "text": "G", "score": 0.7665736675262451, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16721, "end": 16726, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Slate"], "seq_scores": [0.9532994627952576], "text": "Slate", "score": 0.9532994627952576, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16728, "end": 16730, "seq_label": ["B-DatasetGeneric"], "seq_token": ["SL"], "seq_scores": [0.562751829624176], "text": "SL", "score": 0.562751829624176, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16733, "end": 16742, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Telephone"], "seq_scores": [0.9737482070922852], "text": "Telephone", "score": 0.9737482070922852, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16744, "end": 16746, "seq_label": ["B-DatasetGeneric"], "seq_token": ["TL"], "seq_scores": [0.7591068744659424], "text": "TL", "score": 0.7591068744659424, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16752, "end": 16758, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Travel"], "seq_scores": [0.958972692489624], "text": "Travel", "score": 0.958972692489624, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 16792, "end": 16796, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9979310035705566, 0.9980886578559875], "text": "MNLI", "score": 0.9980098307132721, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 16986, "end": 17008, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Ben", "-", "David", "\u0120et", "\u0120al", ".,", "\u01202021"], "seq_scores": [0.9992144107818604, 0.9994522929191589, 0.9994819760322571, 0.9993895292282104, 0.9995225667953491, 0.9992377758026123, 0.9991995692253113], "text": "Ben-David et al., 2021", "score": 0.9993568743978228, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 17010, "end": 17027, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Vol", "k", "\u0120et", "\u0120al", ".,", "\u01202022"], "seq_scores": [0.9995238780975342, 0.9995986819267273, 0.999546229839325, 0.9996402263641357, 0.9994780421257019, 0.9995502829551697], "text": "Volk et al., 2022", "score": 0.9995562235514323, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 17106, "end": 17120, "seq_label": ["I-Method", "B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120supervised", "\u0120a", "\u0120DA", "\u0120algorithm"], "seq_scores": [0.6802473068237305, 0.9700549244880676, 0.7080574035644531, 0.9831070899963379], "text": "a DA algorithm", "score": 0.8353666812181473, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16771, "end": 16784, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120test", "\u0120sets"], "seq_scores": [0.9930620789527893, 0.9962977766990662, 0.9969232678413391], "text": "the test sets", "score": 0.9954277078310648, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16840, "end": 16869, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120original", "\u0120development", "\u0120sets"], "seq_scores": [0.9972767233848572, 0.999115526676178, 0.9994268417358398, 0.9992594122886658], "text": "the original development sets", "score": 0.9987696260213852, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16873, "end": 16886, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120our", "\u0120test", "\u0120sets"], "seq_scores": [0.8094926476478577, 0.9666327238082886, 0.9904549717903137], "text": "our test sets", "score": 0.92219344774882, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16936, "end": 16946, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120these", "\u0120sets"], "seq_scores": [0.993880033493042, 0.9954364895820618], "text": "these sets", "score": 0.9946582615375519, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17159, "end": 17176, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", "\u0120sets"], "seq_scores": [0.9917175769805908, 0.9975563287734985, 0.9977179765701294], "text": "the training sets", "score": 0.9956639607747396, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17209, "end": 17229, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u01202", ",", "000", "-", "3", ",", "000", "\u0120examples"], "seq_scores": [0.993876039981842, 0.9993583559989929, 0.9994476437568665, 0.9991857409477234, 0.999098539352417, 0.9993948936462402, 0.999147891998291, 0.9957422614097595], "text": "2,000-3,000 examples", "score": 0.9981564208865166, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 17262, "end": 17279, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120aspect", "\u0120prediction"], "seq_scores": [0.971920371055603, 0.9180691242218018], "text": "aspect prediction", "score": 0.9449947476387024, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 17300, "end": 17331, "seq_label": ["B-Task", "I-Task", "I-Task", "I-Task", "I-Task"], "seq_token": ["\u0120aspect", "-", "based", "\u0120sentiment", "\u0120analysis"], "seq_scores": [0.9875633716583252, 0.9874505996704102, 0.9897589683532715, 0.9868596196174622, 0.9930236339569092], "text": "aspect-based sentiment analysis", "score": 0.9889312386512756, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 17333, "end": 17337, "seq_label": ["B-Task", "I-Task"], "seq_token": ["AB", "SA"], "seq_scores": [0.970067024230957, 0.9867297410964966], "text": "ABSA", "score": 0.9783983826637268, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 17461, "end": 17473, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Top", "rak", "\u0120et", "\u0120al"], "seq_scores": [0.999377429485321, 0.999789297580719, 0.9997300505638123, 0.9998018145561218], "text": "Toprak et al", "score": 0.9996746480464935, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 17525, "end": 17541, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120(", "2010", "),", "Hu", "\u0120and", "\u0120Liu", ",", "\u01202004"], "seq_scores": [0.9996920824050903, 0.9997047781944275, 0.8402231931686401, 0.9985783100128174, 0.9990757703781128, 0.9994376301765442, 0.9990384578704834, 0.9992332458496094], "text": "Hu and Liu, 2004", "score": 0.9793729335069656, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 17596, "end": 17608, "seq_label": ["B-Dataset", "I-Dataset", "I-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120Sem", "E", "val", "-", "2014"], "seq_scores": [0.9575732350349426, 0.9785782098770142, 0.9700196981430054, 0.96950364112854, 0.9321017265319824], "text": "SemEval-2014", "score": 0.9615553021430969, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 17609, "end": 17613, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120AB", "SA"], "seq_scores": [0.9848204255104065, 0.9901667833328247], "text": "ABSA", "score": 0.9874936044216156, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 17625, "end": 17645, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Pont", "iki", "\u0120et", "\u0120al", ".,", "\u01202014"], "seq_scores": [0.999144434928894, 0.9996786117553711, 0.9995474219322205, 0.9997232556343079, 0.9995236396789551, 0.9995545744895935], "text": "Pontiki et al., 2014", "score": 0.9995286564032236, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17258, "end": 17287, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["The", "\u0120aspect", "\u0120prediction", "\u0120dataset"], "seq_scores": [0.9965824484825134, 0.9983295798301697, 0.9987927675247192, 0.9992818236351013], "text": "The aspect prediction dataset", "score": 0.9982466548681259, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17300, "end": 17346, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120aspect", "-", "based", "\u0120sentiment", "\u0120analysis", "\u0120(", "AB", "SA", ")", "\u0120corpor", "a"], "seq_scores": [0.9990515112876892, 0.9995879530906677, 0.9995754361152649, 0.9993963241577148, 0.9998311996459961, 0.9996633529663086, 0.999226450920105, 0.9998592138290405, 0.9997870326042175, 0.999603807926178, 0.9998571872711182], "text": "aspect-based sentiment analysis (ABSA) corpora", "score": 0.9995854063467546, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17366, "end": 17372, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Device"], "seq_scores": [0.8648949861526489], "text": "Device", "score": 0.8648949861526489, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17391, "end": 17401, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Restaurant"], "seq_scores": [0.865515947341919], "text": "Restaurant", "score": 0.865515947341919, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17411, "end": 17418, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120Service"], "seq_scores": [0.9563701748847961], "text": "Service", "score": 0.9563701748847961, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17425, "end": 17435, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120The", "\u0120D", "\u0120data"], "seq_scores": [0.983923614025116, 0.975834846496582, 0.9912520051002502], "text": "The D data", "score": 0.983670155207316, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17448, "end": 17455, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120reviews"], "seq_scores": [0.9934013485908508], "text": "reviews", "score": 0.9934013485908508, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17483, "end": 17494, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120SE", "\u0120data"], "seq_scores": [0.9768175482749939, 0.9394645094871521, 0.9799652099609375], "text": "the SE data", "score": 0.9654157559076945, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17504, "end": 17523, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120web", "\u0120service", "\u0120reviews"], "seq_scores": [0.998613715171814, 0.999461829662323, 0.9995028972625732], "text": "web service reviews", "score": 0.9991928140322367, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17548, "end": 17567, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120L", "\u0120and", "\u0120R", "\u0120domains"], "seq_scores": [0.7002299427986145, 0.8513774275779724, 0.9228867888450623, 0.9278441071510315, 0.8362320065498352], "text": "the L and R domains", "score": 0.8477140545845032, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17579, "end": 17586, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120reviews"], "seq_scores": [0.9870631098747253], "text": "reviews", "score": 0.9870631098747253, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17692, "end": 17699, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120reviews"], "seq_scores": [0.9879093766212463], "text": "reviews", "score": 0.9879093766212463, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 17904, "end": 17914, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Gong", "\u0120et", "\u0120al"], "seq_scores": [0.9994069337844849, 0.9997166991233826, 0.9998036026954651], "text": "Gong et al", "score": 0.9996424118677775, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 18009, "end": 18021, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-Dataset", "I-Dataset", "I-Dataset", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120(", "2020", ")", "\u0120Sem", "E", "val", "-", "2014"], "seq_scores": [0.9997953772544861, 0.9998125433921814, 0.9992677569389343, 0.9736097455024719, 0.9886552095413208, 0.9890130758285522, 0.9887714982032776, 0.9791858792304993], "text": "SemEval-2014", "score": 0.9897638857364655, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17864, "end": 17892, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", "\u0120and", "\u0120test", "\u0120splits"], "seq_scores": [0.5018293261528015, 0.8880050182342529, 0.9531756043434143, 0.9631322026252747, 0.9228472113609314], "text": "the training and test splits", "score": 0.8457978725433349, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 18051, "end": 18070, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120our", "\u0120development", "\u0120set"], "seq_scores": [0.9914664030075073, 0.9957297444343567, 0.9966620206832886], "text": "our development set", "score": 0.9946193893750509, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 18091, "end": 18094, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u012010", "%"], "seq_scores": [0.7715160846710205, 0.8517963290214539], "text": "10%", "score": 0.8116562068462372, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 18102, "end": 18119, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", "\u0120data"], "seq_scores": [0.9973656535148621, 0.9996039271354675, 0.9987737536430359], "text": "the training data", "score": 0.9985811114311218, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 18458, "end": 18469, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120Restaur", "ants"], "seq_scores": [0.7016180753707886, 0.6046313047409058], "text": "Restaurants", "score": 0.6531246900558472, "type": "ScholarlyEntity"}]}, "filename": "10038_2206_00259.json", "id": "10038_2206_00259"}