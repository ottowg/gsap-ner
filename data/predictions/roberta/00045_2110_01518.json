{"text": "Generalization in NLI: Ways (Not) To Go Beyond Simple Heuristics\n\nAbstract:\nMuch of recent progress in NLU was shown to be due to models' learning dataset-specific heuristics. We conduct a case study of generalization in NLI (from MNLI to the adversarially constructed HANS dataset) in a range of BERT-based architectures (adapters, Siamese Transformers, HEX debiasing), as well as with subsampling the data and increasing the model size. We report 2 successful and 3 unsuccessful strategies, all providing insights into how Transformer-based models learn to generalize.\n1 Most models we used were provided by HuggingFace Transformers library. In scope of this project we ported the smaller BERT versions by Turc et al. (2019) for that library.\n2 https://github.com/prajjwal1/ generalize_lm_nli 3 https://github.com/vecto-ai/langmo 4 Since HANS contains only two labels (entailment, nonentailment), and a model trained on MNLI would have three (entailment, contradiction, neutral), a completely random model would be biased towards the \"non-entailment\". For direct comparison with MNLI we report the average accuracy for the two HANS labels, unless specified otherwise.\n\n\n1 Introduction\nMany popular NLP datasets contain spurious patterns, which get learned instead of the actual task (Gururangan et al., 2018; Belinkov et al., 2019; Rogers et al., 2020a; Gardner et al., 2021). This raises the issue of learning methods that would avoid that problem. We present a case study of generalization to adversarial data in Natural Language Inference (NLI), reporting both positive and negative results for a range of BERT-based approaches.\n\n2 Methodology\nData. NLI is a 3-class classification task: does the premise entails, contradicts, or is neutral with respect to the hypothesis? MNLI (Williams et al., 2018) is one of the most popular resources for this task, but it has been shown to suffer from both annotation artifacts (Gururangan et al., 2018; Poliak et al., 2018) and annotator bias (Geva et al., 2019). A cartography (Swayamdipta et al., 2020) map of MNLI (fig. 1) suggests that most of its examples are easy to learn, which explains why vanilla finetuning with modern models is sufficient to achieve high accuracy on MNLI benchmark.\nWe measure generalization of models fine-tuned on MNLI with HANS (McCoy et al., 2019b), a synthetic dataset targeting lexical overlap, subsequence and constituent heuristics. According to 2019b), a model trained on MNLI is likely to learn these heuristics and thus predict the \"entailment\" label for most HANS examples. E.g. it would incorrectly predict that \"The doctor was paid by the actor\" entails \"The doctor paid the actor\", simply because these sentences contain the same words. See Appendix A for more examples.\nMethodology. We experiment with variants 1 of BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and ALBERT (Lan et al., 2020). Our implementation 2 is based on Transformers (Wolf et al., 2019) and Pytorch (Paszke et al., 2019), and for two experiments we also report results with a custom Pytorch-Lightning trainer 3 . HANS has 30K examples used only for testing, where we report the accuracy 4 . MNLI test set is not public, and we report accuracy on the \"matched\" dev set (20K examples, 393K for training).\nThere are two main directions for solving the generalization challenge: modifying the training distribution and the model itself. For the former we experimented with subsampling ( \u00a73.1), and for the latter -with bottlenecking with Siamese Transformers ( \u00a73.2) and adapters ( \u00a73.3), explicit debiasing ( \u00a73.4), and increasing model size ( \u00a73.5). This section presents the motivation and setup for all experiments, and all the results are shown in \u00a74. \u00a73.1 Subsampling the training data with cartography. Data cartography (Swayamdipta et al., 2020) characterizes training data points via the model's confidence in the true class, and the variability of this confidence across epochs. Figure 1 shows that MNLI examples form a spectrum: some are consistently \"easy\" (high-confidence) and \"hard\" (low-confidence) across epochs. \"Ambiguous\" samples have midrange confidence and high variability. If much of MNLI is \"easy\", presumably these samples are less informative.\nExperiments. We partition MNLI based on the training dynamics of RoBERTa-large and BERTbase, and train the respective models on varying amounts of \"hard\" and \"ambiguous\" examples (preceded by 25% of \"easy\" samples for 2 epochs). See appendix B for more details. \u00a73.2 Siamese Networks. In this architecture predictions are based on a pair of inputs (Chopra et al., 2005; Koch et al., 2015). It was successful on NLI (Chen et al., 2017) and in conjunction with BERT encoders (Reimers and Gurevych, 2019). One of their properties is forcing the model to consider the relation between two sequences in a more holistic way than with cross-attention between concatenated premise+hypothesis (as in standard BERT fine-tuning). Intuitively, encoding premise and hypothesis separately could bottleneck 5 their interaction and encourage learning more abstract patterns, which is what we need here: ideally, an NLI model would learn logical rules rather than numerous lexical or syntactic patterns.\nExperiments. Our Siamese Transformer consists of a MLP and two BERT encoders which receive hypotheses and premises in a segregated manner. We used mean-pooled outputs of last transformer layer (CLS embedding yielded similar results) combined as [U, V, U \u2212V, U * V ] as inputs to MLP classifier. We experiment with base and large BERTs, with both frozen and trainable encoders. \u00a73.3 Adapter Networks. Intuitively, standard fine-tuning of BERT changes the amount of taskindependent linguistic knowledge that the model can store, and may corrupt it (if the supervised task has significant artifacts). Therefore, by adding separate task-specific components rather than changing the language model weights, we could expect to increase the amount of non-task-specific knowledge in the model. This could be done with adapters (Houlsby et al., 2019; Pfeiffer et al., 2020) : trainable MLPs inserted within each sub-layer of encoder. Concretely, in a transformer layer l, additional adapter parameters \u03c6 l are introduced to learn task specific parameters while keeping pretrained parameters intact. Having smaller trainable components should also bottleneck the model and encourage it to learn higher-level patterns.\nExperiments. We add adapters in each sub-layer as proposed in Houlsby et al. (2019) to BERT and RoBERTa with the configuration defined in Pfeiffer et al. (2020). The adapter consists of two linear layers (up and down) with a bottleneck of reduction factor of 16 and the ReLU non-linearity. \u00a73.4 Explicit De-biasing. If MNLI 'teaches' to rely on superficial features, we could try to avoid them. Following Zhou and Bansal (2020), we use HEX projection (Wang et al., 2019). The system includes the main Transformer encoder and a 'naive' model learning superficial features. HEX orthogonally projects the Transformer representation into the affine space the most different from the 'naive' representation, hopefully removing the bias.\nExperiments. We extract pooled representations from our main model (BERT-base). The 'naive' model is a CBOW model with a self-attention layer (Vaswani et al., 2017) to capture co-occurrence information from the sequence with input and token embeddings. See Wang et al. (2019) for more details on the method, and Appendix C for implementation and hyperparameter details. During inference, we use logits from BERT only. \u00a73.5 Increasing Model Size. Scaling language models to massive amounts of data has been a reliable source of success on NLP leaderboards, and yielded some interesting emergent properties (Brown et al., 2020; Raffel et al., 2020) training \"teaches\" transferable linguistic knowledge, the models absorbing more data could be expected to generalize better.\nExperiments. We perform standard fine-tuning on MNLI with variants of BERT: tiny, mini, small, medium by Turc et al. (2019), base and large by Devlin et al. (2019), as well as RoBERTa (Liu et al., 2019) and ALBERT (Lan et al., 2020). In this and the Siamese network experiment we report not only the results obtained with the HuggingFace Trainer, but also with our custom implementation based on Pytorch Lightning (also with the AdamW optimizer and with similar learning rates).\n\n4 Results and Discussion\n\n\n4.1 Negative Results\nTable 1 shows that Siamese networks and HEX debiasing perform at chance level on HANS. Adapters work better, but do not match vanilla fine-tuning of their base models. While it is impossible to prove the negative, our experience suggests that, given a reasonable amount of effort, these approaches are not the most promising for the generalization problem we considered. The paper is accompanied by code for our implementations.\nOur Siamese model would be expected to fail if high performance of vanilla BERT was largely due to cross-attention across [premise + hypothesis], enabling it to learn many specific patterns (such as negation in the hypothesis). Our bottleneck MLP would not have the capacity to do that, and it clearly also fails to find a more abstract pattern in the representations it receives. Further experiments are needed to verify this hypothesis. Whether or not overall we would like our NLI models to be able to operate with independent representations of premise and hypothesis rather than cross-attention within one representation, is an open question.\nFor HEX, Zhou and Bansal (2020) suggest that the problem might be that it has access only to the final output of BERT, which could contain more information about the predicted NLI labels than the input sequence as such. Then there would be little to debias. Our results support this hypothesis, but more qualitative research is needed to verify it.\nThe RoBERTa-large MNLI results of our adapter implementation is on par with the recent stateof-the-art Compacter adapters on T5 (Mahabadi et al., 2021), but generalization in both BERT and RoBERTa is overall worse than with vanilla finetuning. Following on the recent report of adapter efficacy in low-resource setting (He et al., 2021), we conducted an additional experiment with adapters and RoBERTa-large, where the model had to learn from a small, more informative subsample. At 1024 training examples adapters performed better when the MNLI subsample was diverse (selected with K-means-based clustering, see appendix D) rather than randomly selected: 80.7% vs 85%. But the generalization to HANS was still not very impressive: 67.8% vs 57.5%, respectively. This strategy does seem to select more informative examples for MNLI distribution, but not for HANS.\n\n4.2 (Cautiously) Positive Results\nFigure 2 shows that when trained on the \"hard\" samples, for RoBERTa-large there does exist a MNLI subsample (at about 25% training data) yielding good performance on both HANS and MNLI. Further 13% addition of biased MNLI data makes the model lose its performance on HANS. But we could not find such a sample for BERT-base, although the cartography samples were modelspecific. This also does not happen for either model when training on the \"ambiguous\" subsamples: RoBERTa initially \"learns\" HANS at 5% of training data, but \"loses\" it before reaching even 60% accuracy on MNLI (see fig. 4 in the Appendix).\nThe most encouraging results come from the increased model size with our custom trainer, as shown in fig. 3. For BERT, RoBERTa and AL-BERT, the \"large\" versions generalize consistently better than the \"base\" versions. Concurrent work (Anonymous, 2021) focusing specifically on the effect of model size on the learning of lexical overlap heuristic came to a similar conclusion.\nHowever, \"larger is better\" is not the whole story. The improvement occurs only past a certain threshold: going from BERT-tiny to BERT-medium does not help generalization. At the same time, both AL-BERTs have fewer parameters than BERT-small, but they do generalize, which suggests that their parameter sharing is truly effective. Also RoBERTabase learns to generalize more consistently than BERT-large, which may be either due to some inherent superiority of RoBERTa, or because this instance of RoBERTa happens to be better than this instance of BERT. One point that is clear is that better generalization also requires longer fine-tuning, which interestingly barely affects the core MNLI performance on the larger models, but makes a lot of difference for the smaller BERTs.\n\n5 Related work\nSeveral studies have reported successful generalization from MNLI to HANS. Among data-based strategies, it has been achieved via augmenting MNLI data with predicate-argument structures (Moosavi et al., 2020) and syntactic transformations (Min et al., 2020). Although there are many reports of syntactic knowledge in pre-trained BERT (Rogers et al., 2020b), Min et al. (2020) suggest that pre-training does not yield a strong inductive bias to use syntax in downstream tasks, and augmentation \"nudges\" the model towards that.\nTheoretically, subsampling that reduces the saliency of spurious patterns should have a similar effect, but our cartography-based subsampling did not work consistently, possibly because MNLI has little counter-evidence to spurious patterns, and the right subsample is hard to find reliably. We have additional negative results for subsampling with K-means clustering (see Appendix D for details).\nThe idea of using shallow models to identify biases before training and \"teach\" the model to treat them differently has been successfully explored by Utama et al. ( 2020), Clark et al. (2020), and Sanh et al. (2021). Our negative results with HEX debiasing after training complements these reports.\nOur results corroborate that generalization is improved by larger models (Anonymous, 2021) and longer fine-tuning (Tu et al., 2020). The latter work shows that this happens thanks to the few HANSlike samples in MNLI: they take longer to learn, and without them longer fine-tuning does not help.\nA general challenge for DL-based NLP research is variability due to extraneous factors. Generalization from MNLI to HANS may be much improved simply with a lucky fine-tuning initialization (Mc-Coy et al., 2019a). For QA Crane (2018) show that there are many other external factors (down to linear algebra library version) that also play a role, and for Transformers overall implementations make a big difference (Narang et al., 2021). Our work provides an illustration of that phenomenon in NLI. The reported HANS performance of vanilla fine-tuned BERT-base varies in the published studies from 50.0% to 62.5%. Our Pytorch-Lightning implementation at 4 epochs achieves 69% (avg. of 16 runs), not due to any architectural differences. Overall it also has higher variability between runs, possibly due to batch size differences.\n\n6 Analysis: Bias Under Low Confidence\nOur overall ratio of positive to negative results illustrates the difficulty of the spurious patterns problem.\nOnce the model learns that some pattern is a strong signal for a label, it will over-rely on it. But how much heuristic-matching evidence does it need?\nIn this experiment we fine-tune the base versions of BERT and RoBERTa for 4 epochs. We use the dataset cartography to identify the \"hard\" training samples for both models. As shown in Figure 1, the classifier has overall low confidence for the \"hard\" samples. We corrupt these \"hard \" samples by inserting extra characters randomly in 30% content words in the sequence. For example: The corrupted sequences remain relatively readable for humans, but this reduces the signal from direct lexical matches seen by the model (even with BERT tokenization). Note that the model has already seen these samples 4 times before corruption. We repeated this experiment with substituting, deleting and swapping characters.\nSince the classifier confidence for the \"hard\" examples is low, and the perturbations are random, they could be expected to just flip the predictions in random directions, equally across MNLI labels. Instead, with all corruption strategies and for both models we see the pattern shown in Table 2 : the accuracy drops significantly for contradiction (by 10-20 points), and improves significantly for entailment (by 10-30 points). For the neutral class the change is not as large (mostly gaining 5-13 points).\nThese results suggest that in low-confidence context even decreased lexical overlap still nudges the model towards entailment rather than contradiction. This runs contrary to the overall strategy shown by HANS, and it is not due to the majority class bias (as MNLI train set is balanced between entailment and contradiction). One possible explanation is that if it is non-entailment that the generalizing models slowly learn from the little supporting evidence in MNLI (Tu et al., 2020), then corruption would make that already-difficult job even harder for the model, decreasing the accuracy on non-entailment. On the other hand, even corrupted MNLI examples still have some lexical overlap, and so the model, unable to recognize any subtler patterns, might default to that. This finding has implications for high-cost-oferror applications where false positives are preferable to false negatives. If the data has spurious patterns, the model may score well on a generalization benchmark, but be still biased towards a certain label when its confidence is low. Consider e.g. most of COVID detection models are \"at high risk of bias\" due to noisy data (Wynants et al., 2020).\n\n7 Conclusion\nMost supervised datasets are biased in one way or the other, and task-independent techniques to improve NLP model generalization are crucial for further advances. We experimented with 5 strategies to improve generalization of BERT-class models for NLI task: explicit debiasing, bottlenecking the model, adapters, data subsampling, and increasing model size. We find the latter strategy the most promising, but we also report all the negative results, which contribute to the overall knowledge about generalization in BERT-based models. cartographyF A = f ([U, V ]; \u03be), F G = f ([0, V ]; \u03be)\nwhere F A , F G denotes both concatenated representations and zero matrix prepended with network B's representation [, ] denotes concatenation operation along the non-batch dimension.\nFollowing Vaswani et al. (2017), we project F A :F L = (I \u2212 F G (F T G F G + \u03bbI) \u22121 F T G )F A\nTable 4 shows hyperparameter search for \u03bb. During inference, we use logits obtained through BERT only.\nWe follow a slight variation of Equation 2 to smoothen the process of optimization. The addition of \u03bb hyper-parameter has been done to ensure that inverse is carried out on a non-singular matrix. The value of \u03bb plays a significant role in determining how these representations are being learned. In our experiments, 1e \u2212 4 worked well and was used for initializing it after which it was set as a model's parameter. We observe that pseudo-inverse of F T G F G is unstable and can make optimization  process hard, so we make U and V square matrices to obtain inverse instead. Additionally, during inference time, we directly feed outputs from the main network to the MLP layer to obtain logit vectors instead of using F L . It has been reported (Wang et al., 2019) that this doesn't have any profound impact on the logit vector and makes inference faster. We also applied L1 and L2 normalization on U and V to account for differences in scale but did not see any noticeable improvement. We found that values of \u03bb greater than 0.0001 do not aid the network in learning.\n\nD Subsampling the Training Data with K-means clustering\nMotivation. Fundamentally, the problem is the mismatch between MNLI and HANS distributions. For a biased dataset, one solution could be to find such a subsample that would enable the model to perform well on both distributions.\nExperiments. We encode MNLI examples as BERT [CLS] embeddings and cluster them in 512 clusters using K-means. We then fine-tune BERTbase on varying amounts of MNLI data, progressively increasing the amount of training examples by 10%. The data in the sub-sample is selected (a) randomly (as a control), (b) so as to maximize the diversity of examples within the sample (Katharopoulos and Fleuret, 2018). At the smallest subsample size we sample the data from all clusters. As data size increases, smaller clusters are exhausted while the larger ones remain, so the smallest subsamples are the most diverse, and the diversity decreases as the sample size increases. The experiment is repeated with 5 random seeds.\nResults. Figure 6 shows that on MNLI, diverse sampling yields much more variation with small amounts of data than random sampling, but as the subsample approaches the full dataset the performance also becomes the same. Neither subsampling strategy improves generalization: the model still predicts \"entailment\" for most HANS examples. Thus overall the result for this strategy is negative.\n\nFootnotes:\n5: The information bottleneck idea (Tishby et al., 2000; Alemi et al., 2016) has recently been successfully adapted for BERT fine-tuning to avoid overfitting in a low-resource setting by Mahabadi et al. (2020), who propose a regularization term suppressing the learning of irrelevant information.\n6: https://github.com/allenai/\n\nReferences:\n\n- Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, and Kevin Murphy. 2016. Deep Variational Information Bottleneck.- Anonymous. 2021. Largely, right for better rea- sons:lexical generalization improves with model size. (Under review).\n\n- Yonatan Belinkov, Adam Poliak, Stuart Shieber, Ben- jamin Van Durme, and Alexander Rush. 2019. Don't take the premise for granted: Mitigating ar- tifacts in natural language inference. In Proceed- ings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 877-891, Flo- rence, Italy. Association for Computational Linguis- tics.\n\n- Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert- Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. 33:1877-1901.\n\n- Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, and Diana Inkpen. 2017. Enhanced LSTM for natural language inference. In Proceedings of the 55th Annual Meeting of the Association for Com- putational Linguistics (Volume 1: Long Papers), pages 1657-1668, Vancouver, Canada. Association for Computational Linguistics.\n\n- Sumit Chopra, Raia Hadsell, and Yann LeCun. 2005. Learning a similarity metric discriminatively, with application to face verification. In Proceed- ings of the 2005 IEEE Computer Society Confer- ence on Computer Vision and Pattern Recognition (CVPR'05) -Volume 1 -Volume 01, CVPR '05, page 539-546, USA. IEEE Computer Society.\n\n- Christopher Clark, Mark Yatskar, and Luke Zettle- moyer. 2020. Learning to Model and Ignore Dataset Bias with Mixed Capacity Ensembles. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3031-3045, Online. Associa- tion for Computational Linguistics.\n\n- Matt Crane. 2018. Questionable Answers in Question Answering Research: Reproducibility and Variabil- ity of Published Results. Transactions of the Associ- ation for Computational Linguistics, 6:241-252.\n\n- Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- standing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Associ- ation for Computational Linguistics.\n\n- Matt Gardner, William Merrill, Jesse Dodge, Matthew E. Peters, Alexis Ross, Sameer Singh, and Noah Smith. 2021. Competency Problems: On Finding and Removing Artifacts in Language Data. arXiv:2104.08646 [cs].\n\n- Mor Geva, Yoav Goldberg, and Jonathan Berant. 2019. Are We Modeling the Task or the Annotator? An In- vestigation of Annotator Bias in Natural Language Understanding Datasets. In Proceedings of the 2019 Conference on Empirical Methods in Natu- ral Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 1161-1166, Hong Kong, China. Association for Computational Linguistics.\n\n- Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman, and Noah A. Smith. 2018. Annotation artifacts in natural lan- guage inference data. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 107-112, New Orleans, Louisiana. Associa- tion for Computational Linguistics.\n\n- Ruidan He, Linlin Liu, Hai Ye, Qingyu Tan, Bosheng Ding, Liying Cheng, Jiawei Low, Lidong Bing, and Luo Si. 2021. On the Effectiveness of Adapter- based Tuning for Pretrained Language Model Adap- tation. In Proceedings of the 59th Annual Meet- ing of the Association for Computational Linguistics and the 11th International Joint Conference on Nat- ural Language Processing (Volume 1: Long Papers), pages 2208-2222, Online. Association for Computa- tional Linguistics.\n\n- Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficient transfer learning for NLP. In Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 2790-2799, Long Beach, California, USA. PMLR.\n\n- Angelos Katharopoulos and Fran\u00e7ois Fleuret. 2018. Not all samples are created equal: Deep learning with importance sampling. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan, Stockholm, Sweden, July 10-15, 2018, volume 80 of Proceedings of Ma- chine Learning Research, pages 2530-2539. PMLR.\n\n- Gregory Koch, Richard Zemel, and Ruslan Salakhutdi- nov. 2015. Siamese neural networks for one-shot im- age recognition. In ICML deep learning workshop, volume 2. Lille.\n\n- Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2020. Albert: A lite bert for self-supervised learning of language representations. In International Con- ference on Learning Representations.\n\n- Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized BERT pretraining ap- proach. CoRR, abs/1907.11692.\n\n- Rabeeh Karimi Mahabadi, Yonatan Belinkov, and James Henderson. 2020. Variational Information Bottleneck for Effective Low-Resource Fine-Tuning. In International Conference on Learning Represen- tations.\n\n- Rabeeh Karimi Mahabadi, James Henderson, and Se- bastian Ruder. 2021. Compacter: Efficient low-rank hypercomplex adapter layers.\n\n- R. Thomas McCoy, Junghyun Min, and Tal Linzen. 2019a. BERTs of a feather do not general- ize together: Large variability in generalization across models with similar test set performance. arXiv:1911.02969 [cs].\n\n- Tom McCoy, Ellie Pavlick, and Tal Linzen. 2019b. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference. In Proceed- ings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3428-3448, Florence, Italy. Association for Computational Lin- guistics.\n\n- Junghyun Min, R. Thomas McCoy, Dipanjan Das, Emily Pitler, and Tal Linzen. 2020. Syntactic data augmentation increases robustness to inference heuristics. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics, pages 2339-2352, Online. Association for Computa- tional Linguistics.\n\n- Nafise Sadat Moosavi, Marcel de Boer, Prasetya Ajie Utama, and Iryna Gurevych. 2020. Improving Ro- bustness by Augmenting Training Sentences with Predicate-Argument Structures. arXiv:2010.12510 [cs].\n\n- Sharan Narang, Hyung Won Chung, Yi Tay, William Fedus, Thibault Fevry, Michael Matena, Karishma Malkan, Noah Fiedel, Noam Shazeer, Zhenzhong Lan, Yanqi Zhou, Wei Li, Nan Ding, Jake Marcus, Adam Roberts, and Colin Raffel. 2021. Do Trans- former Modifications Transfer Across Implementa- tions and Applications? arXiv:2102.11972 [cs].\n\n- Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Te- jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. Py- torch: An imperative style, high-performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9 Buc, E. Fox, and R. Gar- nett, editors, Advances in Neural Information Pro- cessing Systems 32, pages 8024-8035. Curran Asso- ciates, Inc.\n\n- Jonas Pfeiffer, Aishwarya Kamath, Andreas R\u00fcckl\u00e9, Kyunghyun Cho, and Iryna Gurevych. 2020. Adapterfusion: Non-destructive task composition for transfer learning.\n\n- Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, and Benjamin Van Durme. 2018. Hypothesis only baselines in natural language in- ference. In Proceedings of the Seventh Joint Con- ference on Lexical and Computational Semantics, pages 180-191, New Orleans, Louisiana. Associa- tion for Computational Linguistics.\n\n- Colin Raffel, Noam Shazeer, Adam Roberts, Kather- ine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to- text transformer. Journal of Machine Learning Re- search, 21(140):1-67.\n\n- Nils Reimers and Iryna Gurevych. 2019. Sentence- BERT: Sentence embeddings using Siamese BERT- networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu- ral Language Processing (EMNLP-IJCNLP), pages 3982-3992, Hong Kong, China. Association for Computational Linguistics.\n\n- Anna Rogers, Olga Kovaleva, Matthew Downey, and Anna Rumshisky. 2020a. Getting Closer to AI Com- plete Question Answering: A Set of Prerequisite Real Tasks. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 8722-8731.\n\n- Anna Rogers, Olga Kovaleva, and Anna Rumshisky. 2020b. A Primer in BERTology: What We Know About How BERT Works. Transactions of the Asso- ciation for Computational Linguistics, 8:842-866.\n\n- Victor Sanh, Thomas Wolf, Yonatan Belinkov, and Alexander M. Rush. 2021. Learning from others' mistakes: Avoiding dataset biases without modeling them. In International Conference on Learning Rep- resentations.\n\n- Swabha Swayamdipta, Roy Schwartz, Nicholas Lourie, Yizhong Wang, Hannaneh Hajishirzi, Noah A. Smith, and Yejin Choi. 2020. Dataset cartography: Mapping and diagnosing datasets with training dy- namics. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 9275-9293, Online. Associa- tion for Computational Linguistics.\n\n- Naftali Tishby, Fernando C. Pereira, and William Bialek. 2000. The information bottleneck method. arXiv:physics/0004057.\n\n- Lifu Tu, Garima Lalwani, Spandana Gella, and He He. 2020. An Empirical Study on Robustness to Spuri- ous Correlations using Pre-trained Language Mod- els. Transactions of the Association for Computa- tional Linguistics, 8:621-633.\n\n- Iulia Turc, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Well-read students learn better: On the importance of pre-training compact models.\n\n- Prasetya Ajie Utama, Nafise Sadat Moosavi, and Iryna Gurevych. 2020. Towards debiasing NLU models from unknown biases. In Proceedings of the 2020 Conference on Empirical Methods in Natural Lan- guage Processing (EMNLP), pages 7597-7610, On- line. Association for Computational Linguistics.\n\n- Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141 ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Gar- nett, editors, Advances in Neural Information Pro- cessing Systems 30, pages 5998-6008. Curran Asso- ciates, Inc.\n\n- Haohan Wang, Zexue He, Zachary L. Lipton, and Eric P. Xing. 2019. Learning robust representations by projecting superficial statistics out. In Interna- tional Conference on Learning Representations.\n\n- Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sen- tence understanding through inference. In Proceed- ings of the 2018 Conference of the North American Chapter of the Association for Computational Lin- guistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112-1122. Association for Computational Linguistics.\n\n- Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, R'emi Louf, Morgan Funtow- icz, and Jamie Brew. 2019. Huggingface's trans- formers: State-of-the-art natural language process- ing. ArXiv, abs/1910.03771.\n\n- Laure Wynants, Ben Van Calster, Gary S. Collins, Richard D. Riley, Georg Heinze, Ewoud Schuit, Marc M. J. Bonten, Darren L. Dahly, Johanna A. Damen, Thomas P. A. Debray, Valentijn M. T. de Jong, Maarten De Vos, Paula Dhiman, Maria C. Haller, Michael O. Harhay, Liesbet Henckaerts, Pauline Heus, Michael Kammer, Nina Kreuzberger, Anna Lohmann, Kim Luijken, Jie Ma, Glen P. Martin, David J. McLernon, Constanza L. Andaur Navarro, Johannes B. Reitsma, Jamie C. Sergeant, Chunhu Shi, Nicole Skoetz, Luc J. M. Smits, Kym I. E. Snell, Matthew Sperrin, Ren\u00e9 Spijker, Ewout W. Steyerberg, Toshihiko Takada, Ioanna Tzoulaki, Sander M. J. van Kuijk, Bas C. T. van Bus- sel, Iwan C. C. van der Horst, Florien S. van Royen, Jan Y. Verbakel, Christine Wallisch, Jack Wilkinson, Robert Wolff, Lotty Hooft, Karel G. M. Moons, and Maarten van Smeden. 2020. Prediction models for diagnosis and prognosis of covid-19: Systematic re- view and critical appraisal. 369:m1328.\n\n- Xiang Zhou and Mohit Bansal. 2020. Towards robusti- fying NLI models against lexical dataset biases. In Proceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 8759- 8771, Online. Association for Computational Lin- guistics.\n\n", "annotations": {"Abstract": [{"begin": 66, "end": 1169, "idx": 0}], "Head": [{"begin": 1172, "end": 1186, "n": "1", "idx": 0}, {"begin": 1635, "end": 1648, "n": "2", "idx": 1}, {"begin": 8418, "end": 8442, "n": "4", "idx": 2}, {"begin": 8445, "end": 8465, "n": "4.1", "idx": 3}, {"begin": 10756, "end": 10789, "n": "4.2", "idx": 4}, {"begin": 12554, "end": 12568, "n": "5", "idx": 5}, {"begin": 14913, "end": 14950, "n": "6", "idx": 6}, {"begin": 17608, "end": 17620, "n": "7", "idx": 7}, {"begin": 19661, "end": 19716, "idx": 8}], "ReferenceToBib": [{"begin": 708, "end": 726, "target": "#b36", "idx": 0}, {"begin": 1285, "end": 1310, "target": "#b11", "idx": 1}, {"begin": 1311, "end": 1333, "target": "#b2", "idx": 2}, {"begin": 1334, "end": 1355, "target": "#b30", "idx": 3}, {"begin": 1356, "end": 1377, "target": "#b9", "idx": 4}, {"begin": 1783, "end": 1806, "target": "#b40", "idx": 5}, {"begin": 1922, "end": 1947, "target": "#b11", "idx": 6}, {"begin": 1948, "end": 1968, "target": "#b27", "idx": 7}, {"begin": 1988, "end": 2007, "target": "#b10", "idx": 8}, {"begin": 2023, "end": 2049, "target": "#b33", "idx": 9}, {"begin": 2305, "end": 2326, "target": "#b21", "idx": 10}, {"begin": 2811, "end": 2832, "target": "#b8", "idx": 11}, {"begin": 2842, "end": 2860, "target": "#b17", "idx": 12}, {"begin": 2873, "end": 2891, "target": "#b16", "idx": 13}, {"begin": 2939, "end": 2958, "target": "#b41", "idx": 14}, {"begin": 2971, "end": 2992, "target": "#b25", "idx": 15}, {"begin": 3795, "end": 3821, "target": "#b33", "idx": 16}, {"begin": 4587, "end": 4608, "target": "#b5", "idx": 17}, {"begin": 4609, "end": 4627, "target": "#b15", "idx": 18}, {"begin": 4654, "end": 4673, "target": "#b4", "idx": 19}, {"begin": 4712, "end": 4740, "target": "#b29", "idx": 20}, {"begin": 6045, "end": 6067, "target": "#b13", "idx": 21}, {"begin": 6068, "end": 6090, "target": "#b26", "idx": 22}, {"begin": 6496, "end": 6517, "target": "#b13", "idx": 23}, {"begin": 6572, "end": 6594, "target": "#b26", "idx": 24}, {"begin": 6839, "end": 6861, "target": "#b43", "idx": 25}, {"begin": 6885, "end": 6904, "target": "#b39", "idx": 26}, {"begin": 7308, "end": 7330, "target": "#b38", "idx": 27}, {"begin": 7423, "end": 7441, "target": "#b39", "idx": 28}, {"begin": 7771, "end": 7791, "target": "#b3", "idx": 29}, {"begin": 7792, "end": 7812, "target": "#b28", "idx": 30}, {"begin": 8043, "end": 8061, "target": "#b36", "idx": 31}, {"begin": 8081, "end": 8101, "target": "#b8", "idx": 32}, {"begin": 8122, "end": 8140, "target": "#b17", "idx": 33}, {"begin": 8152, "end": 8170, "target": "#b16", "idx": 34}, {"begin": 9552, "end": 9574, "target": "#b43", "idx": 35}, {"begin": 10020, "end": 10043, "target": "#b19", "idx": 36}, {"begin": 10211, "end": 10228, "target": "#b12", "idx": 37}, {"begin": 12754, "end": 12776, "target": "#b23", "idx": 38}, {"begin": 12807, "end": 12825, "target": "#b22", "idx": 39}, {"begin": 12902, "end": 12924, "target": "#b31", "idx": 40}, {"begin": 12926, "end": 12943, "target": "#b22", "idx": 41}, {"begin": 13663, "end": 13687, "target": "#b6", "idx": 42}, {"begin": 13688, "end": 13706, "target": "#b32", "idx": 43}, {"begin": 13904, "end": 13921, "target": "#b35", "idx": 44}, {"begin": 14274, "end": 14296, "idx": 45}, {"begin": 14305, "end": 14317, "target": "#b7", "idx": 46}, {"begin": 14497, "end": 14518, "target": "#b24", "idx": 47}, {"begin": 16901, "end": 16918, "target": "#b35", "idx": 48}, {"begin": 17583, "end": 17605, "target": "#b42", "idx": 49}, {"begin": 18405, "end": 18426, "target": "#b38", "idx": 50}, {"begin": 19336, "end": 19355, "target": "#b39", "idx": 51}, {"begin": 20314, "end": 20347, "target": "#b14", "idx": 52}, {"begin": 21095, "end": 21116, "target": "#b34", "idx": 53}, {"begin": 21117, "end": 21136, "target": "#b0", "idx": 54}, {"begin": 21247, "end": 21269, "target": "#b18", "idx": 55}], "ReferenceToFootnote": [{"begin": 5031, "end": 5032, "target": "#foot_0", "idx": 0}], "SectionFootnote": [{"begin": 21049, "end": 21387, "idx": 0}], "ReferenceString": [{"begin": 21404, "end": 21519, "id": "b0", "idx": 0}, {"begin": 21521, "end": 21638, "id": "b1", "idx": 1}, {"begin": 21642, "end": 21999, "id": "b2", "idx": 2}, {"begin": 22003, "end": 22535, "id": "b3", "idx": 3}, {"begin": 22539, "end": 22863, "id": "b4", "idx": 4}, {"begin": 22867, "end": 23193, "id": "b5", "idx": 5}, {"begin": 23197, "end": 23476, "id": "b6", "idx": 6}, {"begin": 23480, "end": 23682, "id": "b7", "idx": 7}, {"begin": 23686, "end": 24108, "id": "b8", "idx": 8}, {"begin": 24112, "end": 24319, "id": "b9", "idx": 9}, {"begin": 24323, "end": 24758, "id": "b10", "idx": 10}, {"begin": 24762, "end": 25180, "id": "b11", "idx": 11}, {"begin": 25184, "end": 25652, "id": "b12", "idx": 12}, {"begin": 25656, "end": 26032, "id": "b13", "idx": 13}, {"begin": 26036, "end": 26379, "id": "b14", "idx": 14}, {"begin": 26383, "end": 26552, "id": "b15", "idx": 15}, {"begin": 26556, "end": 26792, "id": "b16", "idx": 16}, {"begin": 26796, "end": 27020, "id": "b17", "idx": 17}, {"begin": 27024, "end": 27226, "id": "b18", "idx": 18}, {"begin": 27230, "end": 27358, "id": "b19", "idx": 19}, {"begin": 27362, "end": 27572, "id": "b20", "idx": 20}, {"begin": 27576, "end": 27889, "id": "b21", "idx": 21}, {"begin": 27893, "end": 28211, "id": "b22", "idx": 22}, {"begin": 28215, "end": 28414, "id": "b23", "idx": 23}, {"begin": 28418, "end": 28750, "id": "b24", "idx": 24}, {"begin": 28754, "end": 29346, "id": "b25", "idx": 25}, {"begin": 29350, "end": 29511, "id": "b26", "idx": 26}, {"begin": 29515, "end": 29842, "id": "b27", "idx": 27}, {"begin": 29846, "end": 30117, "id": "b28", "idx": 28}, {"begin": 30121, "end": 30485, "id": "b29", "idx": 29}, {"begin": 30489, "end": 30728, "id": "b30", "idx": 30}, {"begin": 30732, "end": 30920, "id": "b31", "idx": 31}, {"begin": 30924, "end": 31134, "id": "b32", "idx": 32}, {"begin": 31138, "end": 31510, "id": "b33", "idx": 33}, {"begin": 31514, "end": 31634, "id": "b34", "idx": 34}, {"begin": 31638, "end": 31868, "id": "b35", "idx": 35}, {"begin": 31872, "end": 32024, "id": "b36", "idx": 36}, {"begin": 32028, "end": 32317, "id": "b37", "idx": 37}, {"begin": 32321, "end": 32684, "id": "b38", "idx": 38}, {"begin": 32688, "end": 32886, "id": "b39", "idx": 39}, {"begin": 32890, "end": 33262, "id": "b40", "idx": 40}, {"begin": 33266, "end": 33539, "id": "b41", "idx": 41}, {"begin": 33543, "end": 34497, "id": "b42", "idx": 42}, {"begin": 34501, "end": 34766, "id": "b43", "idx": 43}], "ReferenceToTable": [{"begin": 8472, "end": 8473, "target": "#tab_0", "idx": 0}, {"begin": 16218, "end": 16219, "idx": 1}, {"begin": 18496, "end": 18497, "target": "#tab_2", "idx": 2}], "Footnote": [{"begin": 21060, "end": 21356, "id": "foot_0", "n": "5", "idx": 0}, {"begin": 21357, "end": 21387, "id": "foot_1", "n": "6", "idx": 1}], "ReferenceToFormula": [{"begin": 2428, "end": 2433, "idx": 0}, {"begin": 13656, "end": 13660, "idx": 1}], "Paragraph": [{"begin": 76, "end": 570, "idx": 0}, {"begin": 571, "end": 744, "idx": 1}, {"begin": 745, "end": 1169, "idx": 2}, {"begin": 1187, "end": 1633, "idx": 3}, {"begin": 1649, "end": 2239, "idx": 4}, {"begin": 2240, "end": 2759, "idx": 5}, {"begin": 2760, "end": 3274, "idx": 6}, {"begin": 3275, "end": 4238, "idx": 7}, {"begin": 4239, "end": 5225, "idx": 8}, {"begin": 5226, "end": 6433, "idx": 9}, {"begin": 6434, "end": 7165, "idx": 10}, {"begin": 7166, "end": 7937, "idx": 11}, {"begin": 7938, "end": 8416, "idx": 12}, {"begin": 8466, "end": 8894, "idx": 13}, {"begin": 8895, "end": 9542, "idx": 14}, {"begin": 9543, "end": 9891, "idx": 15}, {"begin": 9892, "end": 10754, "idx": 16}, {"begin": 10790, "end": 11397, "idx": 17}, {"begin": 11398, "end": 11774, "idx": 18}, {"begin": 11775, "end": 12552, "idx": 19}, {"begin": 12569, "end": 13093, "idx": 20}, {"begin": 13094, "end": 13490, "idx": 21}, {"begin": 13491, "end": 13789, "idx": 22}, {"begin": 13790, "end": 14084, "idx": 23}, {"begin": 14085, "end": 14911, "idx": 24}, {"begin": 14951, "end": 15061, "idx": 25}, {"begin": 15062, "end": 15213, "idx": 26}, {"begin": 15214, "end": 15923, "idx": 27}, {"begin": 15924, "end": 16431, "idx": 28}, {"begin": 16432, "end": 17606, "idx": 29}, {"begin": 17621, "end": 18168, "idx": 30}, {"begin": 18211, "end": 18394, "idx": 31}, {"begin": 18395, "end": 18444, "idx": 32}, {"begin": 18490, "end": 18592, "idx": 33}, {"begin": 18593, "end": 19659, "idx": 34}, {"begin": 19717, "end": 19944, "idx": 35}, {"begin": 19945, "end": 20657, "idx": 36}, {"begin": 20658, "end": 21047, "idx": 37}], "SectionHeader": [{"begin": 0, "end": 1169, "idx": 0}], "SectionReference": [{"begin": 21389, "end": 34768, "idx": 0}], "Sentence": [{"begin": 76, "end": 175, "idx": 0}, {"begin": 176, "end": 438, "idx": 1}, {"begin": 439, "end": 570, "idx": 2}, {"begin": 571, "end": 643, "idx": 3}, {"begin": 644, "end": 744, "idx": 4}, {"begin": 745, "end": 776, "idx": 5}, {"begin": 777, "end": 833, "idx": 6}, {"begin": 834, "end": 1053, "idx": 7}, {"begin": 1054, "end": 1169, "idx": 8}, {"begin": 1187, "end": 1378, "idx": 9}, {"begin": 1379, "end": 1451, "idx": 10}, {"begin": 1452, "end": 1633, "idx": 11}, {"begin": 1649, "end": 1654, "idx": 12}, {"begin": 1655, "end": 1777, "idx": 13}, {"begin": 1778, "end": 2008, "idx": 14}, {"begin": 2009, "end": 2239, "idx": 15}, {"begin": 2240, "end": 2414, "idx": 16}, {"begin": 2415, "end": 2559, "idx": 17}, {"begin": 2560, "end": 2725, "idx": 18}, {"begin": 2726, "end": 2759, "idx": 19}, {"begin": 2760, "end": 2772, "idx": 20}, {"begin": 2773, "end": 2892, "idx": 21}, {"begin": 2893, "end": 3084, "idx": 22}, {"begin": 3085, "end": 3162, "idx": 23}, {"begin": 3163, "end": 3274, "idx": 24}, {"begin": 3275, "end": 3404, "idx": 25}, {"begin": 3405, "end": 3619, "idx": 26}, {"begin": 3620, "end": 3724, "idx": 27}, {"begin": 3725, "end": 3777, "idx": 28}, {"begin": 3778, "end": 3956, "idx": 29}, {"begin": 3957, "end": 4097, "idx": 30}, {"begin": 4098, "end": 4164, "idx": 31}, {"begin": 4165, "end": 4238, "idx": 32}, {"begin": 4239, "end": 4251, "idx": 33}, {"begin": 4252, "end": 4467, "idx": 34}, {"begin": 4468, "end": 4500, "idx": 35}, {"begin": 4501, "end": 4523, "idx": 36}, {"begin": 4524, "end": 4628, "idx": 37}, {"begin": 4629, "end": 4741, "idx": 38}, {"begin": 4742, "end": 4957, "idx": 39}, {"begin": 4958, "end": 5225, "idx": 40}, {"begin": 5226, "end": 5238, "idx": 41}, {"begin": 5239, "end": 5364, "idx": 42}, {"begin": 5365, "end": 5520, "idx": 43}, {"begin": 5521, "end": 5602, "idx": 44}, {"begin": 5603, "end": 5625, "idx": 45}, {"begin": 5626, "end": 5823, "idx": 46}, {"begin": 5824, "end": 6011, "idx": 47}, {"begin": 6012, "end": 6150, "idx": 48}, {"begin": 6151, "end": 6315, "idx": 49}, {"begin": 6316, "end": 6433, "idx": 50}, {"begin": 6434, "end": 6446, "idx": 51}, {"begin": 6447, "end": 6595, "idx": 52}, {"begin": 6596, "end": 6723, "idx": 53}, {"begin": 6724, "end": 6749, "idx": 54}, {"begin": 6750, "end": 6828, "idx": 55}, {"begin": 6829, "end": 6905, "idx": 56}, {"begin": 6906, "end": 7005, "idx": 57}, {"begin": 7006, "end": 7165, "idx": 58}, {"begin": 7166, "end": 7178, "idx": 59}, {"begin": 7179, "end": 7245, "idx": 60}, {"begin": 7246, "end": 7418, "idx": 61}, {"begin": 7419, "end": 7535, "idx": 62}, {"begin": 7536, "end": 7583, "idx": 63}, {"begin": 7584, "end": 7611, "idx": 64}, {"begin": 7612, "end": 7937, "idx": 65}, {"begin": 7938, "end": 7950, "idx": 66}, {"begin": 7951, "end": 8171, "idx": 67}, {"begin": 8172, "end": 8416, "idx": 68}, {"begin": 8466, "end": 8552, "idx": 69}, {"begin": 8553, "end": 8633, "idx": 70}, {"begin": 8634, "end": 8836, "idx": 71}, {"begin": 8837, "end": 8894, "idx": 72}, {"begin": 8895, "end": 9122, "idx": 73}, {"begin": 9123, "end": 9275, "idx": 74}, {"begin": 9276, "end": 9333, "idx": 75}, {"begin": 9334, "end": 9542, "idx": 76}, {"begin": 9543, "end": 9762, "idx": 77}, {"begin": 9763, "end": 9800, "idx": 78}, {"begin": 9801, "end": 9891, "idx": 79}, {"begin": 9892, "end": 10135, "idx": 80}, {"begin": 10136, "end": 10371, "idx": 81}, {"begin": 10372, "end": 10561, "idx": 82}, {"begin": 10562, "end": 10653, "idx": 83}, {"begin": 10654, "end": 10754, "idx": 84}, {"begin": 10790, "end": 10975, "idx": 85}, {"begin": 10976, "end": 11062, "idx": 86}, {"begin": 11063, "end": 11166, "idx": 87}, {"begin": 11167, "end": 11397, "idx": 88}, {"begin": 11398, "end": 11506, "idx": 89}, {"begin": 11507, "end": 11615, "idx": 90}, {"begin": 11616, "end": 11774, "idx": 91}, {"begin": 11775, "end": 11826, "idx": 92}, {"begin": 11827, "end": 11946, "idx": 93}, {"begin": 11947, "end": 12105, "idx": 94}, {"begin": 12106, "end": 12328, "idx": 95}, {"begin": 12329, "end": 12552, "idx": 96}, {"begin": 12569, "end": 12643, "idx": 97}, {"begin": 12644, "end": 12826, "idx": 98}, {"begin": 12827, "end": 13093, "idx": 99}, {"begin": 13094, "end": 13384, "idx": 100}, {"begin": 13385, "end": 13490, "idx": 101}, {"begin": 13491, "end": 13707, "idx": 102}, {"begin": 13708, "end": 13789, "idx": 103}, {"begin": 13790, "end": 13922, "idx": 104}, {"begin": 13923, "end": 14084, "idx": 105}, {"begin": 14085, "end": 14172, "idx": 106}, {"begin": 14173, "end": 14297, "idx": 107}, {"begin": 14298, "end": 14519, "idx": 108}, {"begin": 14520, "end": 14580, "idx": 109}, {"begin": 14581, "end": 14695, "idx": 110}, {"begin": 14696, "end": 14818, "idx": 111}, {"begin": 14819, "end": 14911, "idx": 112}, {"begin": 14951, "end": 15061, "idx": 113}, {"begin": 15062, "end": 15158, "idx": 114}, {"begin": 15159, "end": 15213, "idx": 115}, {"begin": 15214, "end": 15297, "idx": 116}, {"begin": 15298, "end": 15385, "idx": 117}, {"begin": 15386, "end": 15473, "idx": 118}, {"begin": 15474, "end": 15583, "idx": 119}, {"begin": 15584, "end": 15764, "idx": 120}, {"begin": 15765, "end": 15842, "idx": 121}, {"begin": 15843, "end": 15923, "idx": 122}, {"begin": 15924, "end": 16123, "idx": 123}, {"begin": 16124, "end": 16352, "idx": 124}, {"begin": 16353, "end": 16431, "idx": 125}, {"begin": 16432, "end": 16584, "idx": 126}, {"begin": 16585, "end": 16757, "idx": 127}, {"begin": 16758, "end": 17043, "idx": 128}, {"begin": 17044, "end": 17207, "idx": 129}, {"begin": 17208, "end": 17329, "idx": 130}, {"begin": 17330, "end": 17492, "idx": 131}, {"begin": 17493, "end": 17506, "idx": 132}, {"begin": 17507, "end": 17606, "idx": 133}, {"begin": 17621, "end": 17783, "idx": 134}, {"begin": 17784, "end": 17978, "idx": 135}, {"begin": 17979, "end": 18156, "idx": 136}, {"begin": 18157, "end": 18168, "idx": 137}, {"begin": 18211, "end": 18394, "idx": 138}, {"begin": 18395, "end": 18444, "idx": 139}, {"begin": 18490, "end": 18532, "idx": 140}, {"begin": 18533, "end": 18592, "idx": 141}, {"begin": 18593, "end": 18676, "idx": 142}, {"begin": 18677, "end": 18788, "idx": 143}, {"begin": 18789, "end": 18888, "idx": 144}, {"begin": 18889, "end": 19007, "idx": 145}, {"begin": 19008, "end": 19166, "idx": 146}, {"begin": 19167, "end": 19314, "idx": 147}, {"begin": 19315, "end": 19446, "idx": 148}, {"begin": 19447, "end": 19577, "idx": 149}, {"begin": 19578, "end": 19659, "idx": 150}, {"begin": 19717, "end": 19728, "idx": 151}, {"begin": 19729, "end": 19808, "idx": 152}, {"begin": 19809, "end": 19944, "idx": 153}, {"begin": 19945, "end": 19957, "idx": 154}, {"begin": 19958, "end": 20054, "idx": 155}, {"begin": 20055, "end": 20179, "idx": 156}, {"begin": 20180, "end": 20348, "idx": 157}, {"begin": 20349, "end": 20417, "idx": 158}, {"begin": 20418, "end": 20609, "idx": 159}, {"begin": 20610, "end": 20657, "idx": 160}, {"begin": 20658, "end": 20876, "idx": 161}, {"begin": 20877, "end": 20992, "idx": 162}, {"begin": 20993, "end": 21047, "idx": 163}], "ReferenceToFigure": [{"begin": 2068, "end": 2069, "target": "#fig_0", "idx": 0}, {"begin": 3964, "end": 3965, "target": "#fig_0", "idx": 1}, {"begin": 10797, "end": 10798, "target": "#fig_1", "idx": 2}, {"begin": 11378, "end": 11379, "idx": 3}, {"begin": 11504, "end": 11505, "target": "#fig_2", "idx": 4}, {"begin": 15405, "end": 15406, "target": "#fig_0", "idx": 5}, {"begin": 20674, "end": 20675, "target": "#fig_5", "idx": 6}], "Div": [{"begin": 76, "end": 1169, "idx": 0}, {"begin": 1172, "end": 1633, "idx": 1}, {"begin": 1635, "end": 8416, "idx": 2}, {"begin": 8418, "end": 8443, "idx": 3}, {"begin": 8445, "end": 10754, "idx": 4}, {"begin": 10756, "end": 12552, "idx": 5}, {"begin": 12554, "end": 14911, "idx": 6}, {"begin": 14913, "end": 17606, "idx": 7}, {"begin": 17608, "end": 19659, "idx": 8}, {"begin": 19661, "end": 21047, "idx": 9}], "SectionMain": [{"begin": 1169, "end": 21047, "idx": 0}], "ScholarlyEntity": [{"label": "Task", "begin": 103, "end": 106, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "U"], "seq_scores": [0.9971051812171936, 0.9989780187606812], "text": "NLU", "score": 0.9980415999889374, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 138, "end": 146, "seq_label": ["B-Method"], "seq_token": ["\u0120learning"], "seq_scores": [0.6890791654586792], "text": "learning", "score": 0.6890791654586792, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 147, "end": 174, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120dataset", "-", "specific", "\u0120he", "ur", "istics"], "seq_scores": [0.6170004606246948, 0.9908871650695801, 0.9918748736381531, 0.9922645092010498, 0.9941838383674622, 0.9931116104125977], "text": "dataset-specific heuristics", "score": 0.929887076218923, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 203, "end": 217, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120general", "ization"], "seq_scores": [0.8185858130455017, 0.7846614122390747], "text": "generalization", "score": 0.8016236126422882, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 221, "end": 224, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.996817946434021, 0.9992734789848328], "text": "NLI", "score": 0.9980457127094269, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 231, "end": 235, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9981825351715088, 0.9983429908752441], "text": "MNLI", "score": 0.9982627630233765, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 269, "end": 273, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.9982514977455139, 0.9987465143203735], "text": "HANS", "score": 0.9984990060329437, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 297, "end": 307, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "based"], "seq_scores": [0.8092090487480164, 0.814220130443573, 0.6182712316513062, 0.49723559617996216], "text": "BERT-based", "score": 0.6847340017557144, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 323, "end": 325, "seq_label": ["B-ModelArchitecture"], "seq_token": ["ad"], "seq_scores": [0.5551545023918152], "text": "ad", "score": 0.5551545023918152, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 333, "end": 353, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Si", "ames", "e", "\u0120Transformers"], "seq_scores": [0.678561806678772, 0.5375707149505615, 0.4802291989326477, 0.4550296366214752], "text": "Siamese Transformers", "score": 0.5378478392958641, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 355, "end": 368, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120H", "EX", "\u0120deb", "i", "asing"], "seq_scores": [0.9902555346488953, 0.9916451573371887, 0.9875720739364624, 0.9880630373954773, 0.9917420148849487], "text": "HEX debiasing", "score": 0.9898555636405945, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 387, "end": 398, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120subs", "am", "pling"], "seq_scores": [0.9198062419891357, 0.8473826050758362, 0.8840917944908142], "text": "subsampling", "score": 0.8837602138519287, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 412, "end": 422, "seq_label": ["B-Method"], "seq_token": ["\u0120increasing"], "seq_scores": [0.7291602492332458], "text": "increasing", "score": 0.7291602492332458, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 525, "end": 530, "seq_label": ["I-Method", "B-ModelArchitecture"], "seq_token": ["\u0120size", "\u0120Trans"], "seq_scores": [0.5917502045631409, 0.4281819760799408], "text": "Trans", "score": 0.5099660903215408, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 559, "end": 569, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120general", "ize"], "seq_scores": [0.7992225289344788, 0.7732382416725159], "text": "generalize", "score": 0.7862303853034973, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 130, "end": 136, "seq_label": ["B-MLModelGeneric"], "seq_token": ["\u0120models"], "seq_scores": [0.8375820517539978], "text": "models", "score": 0.8375820517539978, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 399, "end": 407, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120data"], "seq_scores": [0.9440727829933167, 0.9084452390670776], "text": "the data", "score": 0.9262590110301971, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 525, "end": 549, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120Trans", "former", "-", "based", "\u0120models"], "seq_scores": [0.9933383464813232, 0.9972629547119141, 0.996543824672699, 0.9969117045402527, 0.9974716901779175], "text": "Transformer-based models", "score": 0.9963057041168213, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 610, "end": 634, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Hug", "ging", "Face", "\u0120Transformers"], "seq_scores": [0.965692400932312, 0.9731950163841248, 0.9786378741264343, 0.9840402007102966], "text": "HuggingFace Transformers", "score": 0.9753913730382919, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 691, "end": 695, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9980271458625793, 0.9984244108200073], "text": "BERT", "score": 0.9982257783412933, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 708, "end": 726, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Tur", "c", "\u0120et", "\u0120al", ".", "\u0120(", "2019", ")"], "seq_scores": [0.9996720552444458, 0.999681830406189, 0.999687671661377, 0.9997504353523254, 0.9997147917747498, 0.9995872378349304, 0.9997549653053284, 0.9984195232391357], "text": "Turc et al. (2019)", "score": 0.9995335638523102, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 573, "end": 584, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120Most", "\u0120models"], "seq_scores": [0.9771029949188232, 0.9894137382507324], "text": "Most models", "score": 0.9832583665847778, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 745, "end": 746, "seq_label": ["B-ReferenceLink"], "seq_token": ["2"], "seq_scores": [0.52494877576828], "text": "2", "score": 0.52494877576828, "type": "ScholarlyEntity"}, {"label": "URL", "begin": 747, "end": 794, "seq_label": ["B-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL"], "seq_token": ["\u0120https", "://", "github", ".", "com", "/", "p", "ra", "jj", "wal", "1", "/", "\u0120general", "ize", "_", "l", "m", "_", "n", "li"], "seq_scores": [0.9224176406860352, 0.9913263916969299, 0.9852898716926575, 0.8315085768699646, 0.9943045973777771, 0.996591329574585, 0.9906775951385498, 0.9966118931770325, 0.9969388246536255, 0.9961460828781128, 0.9966829419136047, 0.9953227639198303, 0.9786239862442017, 0.9940213561058044, 0.996347963809967, 0.994511604309082, 0.9959734082221985, 0.9967777132987976, 0.9969486594200134, 0.9951600432395935], "text": "https://github.com/prajjwal1/ generalize_lm_nli", "score": 0.9821091622114182, "type": "ScholarlyEntity"}, {"label": "URL", "begin": 797, "end": 831, "seq_label": ["B-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL", "I-URL"], "seq_token": ["\u0120https", "://", "github", ".", "com", "/", "ve", "ct", "o", "-", "ai", "/", "lang", "mo"], "seq_scores": [0.922027587890625, 0.9907748103141785, 0.9872025847434998, 0.8315086960792542, 0.9944148063659668, 0.9961971044540405, 0.9830530285835266, 0.9958696961402893, 0.995793342590332, 0.9967935681343079, 0.9953331351280212, 0.9942218661308289, 0.9879652261734009, 0.9929641485214233], "text": "https://github.com/vecto-ai/langmo", "score": 0.9760085429464068, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 832, "end": 833, "seq_label": ["B-ReferenceLink"], "seq_token": ["\u01204"], "seq_scores": [0.41605040431022644], "text": "4", "score": 0.41605040431022644, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 922, "end": 926, "seq_label": ["I-Task", "B-Dataset", "I-Dataset"], "seq_token": ["ANS", "\u0120MN", "LI"], "seq_scores": [0.37364107370376587, 0.990088939666748, 0.9895234704017639], "text": "MNLI", "score": 0.7844178279240926, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 1081, "end": 1085, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9935731291770935, 0.9926754832267761], "text": "MNLI", "score": 0.9931243062019348, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 903, "end": 910, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120model"], "seq_scores": [0.9792405962944031, 0.9808228611946106], "text": "a model", "score": 0.9800317287445068, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 982, "end": 1007, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120completely", "\u0120random", "\u0120model"], "seq_scores": [0.9938648343086243, 0.9984110593795776, 0.9982109069824219, 0.9984996318817139], "text": "a completely random model", "score": 0.9972466081380844, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1286, "end": 1309, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["G", "ur", "ur", "angan", "\u0120et", "\u0120al", ".,", "\u01202018"], "seq_scores": [0.9997498393058777, 0.9997337460517883, 0.9997681975364685, 0.9997612833976746, 0.9997885823249817, 0.9998006224632263, 0.9997263550758362, 0.9997108578681946], "text": "Gururangan et al., 2018", "score": 0.999754935503006, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1311, "end": 1332, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Bel", "ink", "ov", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9997437596321106, 0.9998072981834412, 0.999782145023346, 0.9998075366020203, 0.999810516834259, 0.9997106194496155, 0.9997585415840149], "text": "Belinkov et al., 2019", "score": 0.9997743453298297, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1334, "end": 1354, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Rogers", "\u0120et", "\u0120al", ".,", "\u01202020", "a"], "seq_scores": [0.9997348189353943, 0.9997465014457703, 0.9997835755348206, 0.9996777772903442, 0.9996182918548584, 0.9995518326759338], "text": "Rogers et al., 2020a", "score": 0.9996854662895203, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1356, "end": 1376, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Gardner", "\u0120et", "\u0120al", ".,", "\u01202021"], "seq_scores": [0.9996316432952881, 0.9997482895851135, 0.9997751116752625, 0.9997178912162781, 0.9996805191040039], "text": "Gardner et al., 2021", "score": 0.9997106909751892, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 1479, "end": 1493, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120general", "ization"], "seq_scores": [0.6514832377433777, 0.7086504697799683], "text": "generalization", "score": 0.680066853761673, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 1517, "end": 1543, "seq_label": ["B-Task", "I-Task", "I-Task", "I-Task"], "seq_token": ["\u0120Natural", "\u0120Language", "\u0120In", "ference"], "seq_scores": [0.8125702738761902, 0.9031976461410522, 0.6857746243476868, 0.8800520896911621], "text": "Natural Language Inference", "score": 0.8203986585140228, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 1545, "end": 1548, "seq_label": ["B-Task", "I-Dataset"], "seq_token": ["N", "LI"], "seq_scores": [0.5798231959342957, 0.5718227028846741], "text": "NLI", "score": 0.5758229494094849, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 1611, "end": 1621, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "based"], "seq_scores": [0.9591933488845825, 0.9361910820007324, 0.8072960376739502, 0.47166943550109863], "text": "BERT-based", "score": 0.7935874760150909, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 1187, "end": 1212, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["Many", "\u0120popular", "\u0120N", "LP", "\u0120datasets"], "seq_scores": [0.9958648681640625, 0.9974652528762817, 0.9986384510993958, 0.9998606443405151, 0.9998643398284912], "text": "Many popular NLP datasets", "score": 0.9983387112617492, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 1497, "end": 1513, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120advers", "arial", "\u0120data"], "seq_scores": [0.9987277388572693, 0.998236894607544, 0.9979512095451355], "text": "adversarial data", "score": 0.9983052810033163, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 1655, "end": 1658, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.8438397645950317, 0.700972855091095], "text": "NLI", "score": 0.7724063098430634, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 1664, "end": 1686, "seq_label": ["B-Task", "I-Task", "I-Task", "I-Task"], "seq_token": ["\u01203", "-", "class", "\u0120classification"], "seq_scores": [0.9864310622215271, 0.9879493713378906, 0.9759671092033386, 0.9932470321655273], "text": "3-class classification", "score": 0.9858986437320709, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 1778, "end": 1782, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9992964267730713, 0.9996618032455444], "text": "MNLI", "score": 0.9994791150093079, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1784, "end": 1805, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Williams", "\u0120et", "\u0120al", ".,", "\u01202018"], "seq_scores": [0.9995835423469543, 0.9996216297149658, 0.9996422529220581, 0.999535083770752, 0.999609649181366], "text": "Williams et al., 2018", "score": 0.9995984315872193, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1923, "end": 1946, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["G", "ur", "ur", "angan", "\u0120et", "\u0120al", ".,", "\u01202018"], "seq_scores": [0.9995587468147278, 0.9995947480201721, 0.9996291399002075, 0.999591052532196, 0.9995978474617004, 0.9995741248130798, 0.9994860887527466, 0.9995635151863098], "text": "Gururangan et al., 2018", "score": 0.9995744079351425, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1948, "end": 1967, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Pol", "iak", "\u0120et", "\u0120al", ".,", "\u01202018"], "seq_scores": [0.9995941519737244, 0.9996730089187622, 0.9995856881141663, 0.9995914101600647, 0.9995068311691284, 0.9996522665023804], "text": "Poliak et al., 2018", "score": 0.9996005594730377, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 1989, "end": 2006, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["G", "eva", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9995680451393127, 0.999686598777771, 0.9996134638786316, 0.9996222257614136, 0.9995425939559937, 0.9996813535690308], "text": "Geva et al., 2019", "score": 0.9996190468470255, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2024, "end": 2048, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["S", "way", "amd", "ipt", "a", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9991248250007629, 0.999342143535614, 0.9994851350784302, 0.9995457530021667, 0.9995614886283875, 0.9994574189186096, 0.9994838237762451, 0.9994194507598877, 0.999370276927948], "text": "Swayamdipta et al., 2020", "score": 0.9994211461808946, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 2057, "end": 2061, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9990743398666382, 0.9995183944702148], "text": "MNLI", "score": 0.9992963671684265, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2144, "end": 2162, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120vanilla", "\u0120fin", "et", "uning"], "seq_scores": [0.9762241244316101, 0.9901975393295288, 0.9920579791069031, 0.9904388785362244], "text": "vanilla finetuning", "score": 0.9872296303510666, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 2224, "end": 2228, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9991958737373352, 0.999649167060852], "text": "MNLI", "score": 0.9994225203990936, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 1817, "end": 1843, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120most", "\u0120popular", "\u0120resources"], "seq_scores": [0.4385068416595459, 0.8270763158798218, 0.8766104578971863, 0.854926586151123], "text": "the most popular resources", "score": 0.7492800503969193, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 2093, "end": 2105, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120its", "\u0120examples"], "seq_scores": [0.7884567975997925, 0.9775226712226868], "text": "its examples", "score": 0.8829897344112396, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2168, "end": 2181, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120modern", "\u0120models"], "seq_scores": [0.9920308589935303, 0.9946666955947876], "text": "modern models", "score": 0.9933487772941589, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 2290, "end": 2294, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9959750771522522, 0.9977951049804688], "text": "MNLI", "score": 0.9968850910663605, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2300, "end": 2304, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.7811264991760254, 0.7492478489875793], "text": "HANS", "score": 0.7651871740818024, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2306, "end": 2325, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["McC", "oy", "\u0120et", "\u0120al", ".,", "\u01202019", "b"], "seq_scores": [0.9994195699691772, 0.999607503414154, 0.9993895292282104, 0.9995686411857605, 0.999491810798645, 0.9988526105880737, 0.9981698989868164], "text": "McCoy et al., 2019b", "score": 0.9992142234529767, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2358, "end": 2373, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120lex", "ical", "\u0120overlap"], "seq_scores": [0.8879376649856567, 0.7717319130897522, 0.8438016772270203], "text": "lexical overlap", "score": 0.8344904184341431, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2375, "end": 2413, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120subsequ", "ence", "\u0120and", "\u0120constituent", "\u0120he", "ur", "istics"], "seq_scores": [0.9106281399726868, 0.9354409575462341, 0.9487001895904541, 0.9644675850868225, 0.9650835990905762, 0.9657527804374695, 0.9750994443893433], "text": "subsequence and constituent heuristics", "score": 0.9521675280162266, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 2455, "end": 2459, "seq_label": ["I-ReferenceLink", "B-Dataset", "I-Dataset"], "seq_token": ["b", "\u0120MN", "LI"], "seq_scores": [0.81301349401474, 0.9964179992675781, 0.9972466230392456], "text": "MNLI", "score": 0.9355593721071879, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2545, "end": 2549, "seq_label": ["I-Method", "I-Method", "B-Method", "I-Method"], "seq_token": ["ur", "istics", "\u0120H", "ANS"], "seq_scores": [0.6540088653564453, 0.5583573579788208, 0.42620402574539185, 0.4812581539154053], "text": "HANS", "score": 0.5299571007490158, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2269, "end": 2275, "seq_label": ["B-MLModelGeneric"], "seq_token": ["\u0120models"], "seq_scores": [0.9894800186157227], "text": "models", "score": 0.9894800186157227, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 2328, "end": 2347, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120a", "\u0120synthetic", "\u0120dataset"], "seq_scores": [0.9994552731513977, 0.9996833801269531, 0.9996598958969116], "text": "a synthetic dataset", "score": 0.9995995163917542, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2436, "end": 2443, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120model"], "seq_scores": [0.997285008430481, 0.9989250302314758], "text": "a model", "score": 0.9981050193309784, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 2540, "end": 2558, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120most", "\u0120H", "ANS", "\u0120examples"], "seq_scores": [0.6260997653007507, 0.952290415763855, 0.9926868677139282, 0.9892427325248718], "text": "most HANS examples", "score": 0.8900799453258514, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 2806, "end": 2810, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9967085123062134, 0.996319055557251], "text": "BERT", "score": 0.9965137839317322, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2812, "end": 2831, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Dev", "lin", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.999190628528595, 0.9989192485809326, 0.9983841180801392, 0.9986718893051147, 0.9985097050666809, 0.9987919926643372], "text": "Devlin et al., 2019", "score": 0.9987445970376333, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 2834, "end": 2841, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9956195950508118, 0.9975823163986206, 0.9974116683006287], "text": "RoBERTa", "score": 0.9968711932500204, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2843, "end": 2859, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["L", "iu", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9991970658302307, 0.9983408451080322, 0.9977895021438599, 0.9982035160064697, 0.997848629951477, 0.9985306262969971], "text": "Liu et al., 2019", "score": 0.9983183642228445, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 2866, "end": 2872, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120AL", "BER", "T"], "seq_scores": [0.9961744546890259, 0.9971299767494202, 0.9960973858833313], "text": "ALBERT", "score": 0.9964672724405924, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2874, "end": 2890, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["L", "an", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9992457628250122, 0.9979815483093262, 0.9971510767936707, 0.9976806640625, 0.9971187114715576, 0.9981385469436646], "text": "Lan et al., 2020", "score": 0.9978860517342886, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 2926, "end": 2938, "seq_label": ["B-ModelArchitecture"], "seq_token": ["\u0120Transformers"], "seq_scores": [0.5492129921913147], "text": "Transformers", "score": 0.5492129921913147, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2940, "end": 2957, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Wolf", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9987035989761353, 0.9868306517601013, 0.991848349571228, 0.9902777075767517, 0.9921173453330994], "text": "Wolf et al., 2019", "score": 0.9919555306434631, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 2963, "end": 2970, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Py", "tor", "ch"], "seq_scores": [0.912542998790741, 0.9658794403076172, 0.9552319049835205], "text": "Pytorch", "score": 0.9445514480272929, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 2972, "end": 2991, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["P", "as", "z", "ke", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.996383786201477, 0.990843653678894, 0.990801990032196, 0.9898537993431091, 0.9805605411529541, 0.9867839813232422, 0.9834709763526917, 0.9864241480827332], "text": "Paszke et al., 2019", "score": 0.9881403595209122, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3055, "end": 3072, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Py", "tor", "ch", "-", "Light", "ning"], "seq_scores": [0.7560325264930725, 0.9007004499435425, 0.9346145987510681, 0.8509272933006287, 0.8888025283813477, 0.897612988948822], "text": "Pytorch-Lightning", "score": 0.8714483976364136, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 3085, "end": 3089, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.9943724870681763, 0.9965851306915283], "text": "HANS", "score": 0.9954788088798523, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 3163, "end": 3167, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9985820055007935, 0.9994409680366516], "text": "MNLI", "score": 0.9990114867687225, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 2893, "end": 2896, "seq_label": ["B-MLModelGeneric"], "seq_token": ["\u0120Our"], "seq_scores": [0.5080644488334656], "text": "Our", "score": 0.5080644488334656, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 3046, "end": 3080, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120custom", "\u0120Py", "tor", "ch", "-", "Light", "ning", "\u0120trainer"], "seq_scores": [0.9924390316009521, 0.9917699098587036, 0.996536374092102, 0.9983219504356384, 0.9982025623321533, 0.9968996047973633, 0.997600257396698, 0.9974020719528198, 0.991765558719635], "text": "a custom Pytorch-Lightning trainer", "score": 0.9956597023540072, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3094, "end": 3106, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u012030", "K", "\u0120examples"], "seq_scores": [0.9990222454071045, 0.9997420907020569, 0.9991875290870667], "text": "30K examples", "score": 0.9993172883987427, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3163, "end": 3176, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120MN", "LI", "\u0120test", "\u0120set"], "seq_scores": [0.9976959824562073, 0.9988570213317871, 0.9954791069030762, 0.9980376362800598], "text": "MNLI test set", "score": 0.9975174367427826, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3218, "end": 3239, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120\"", "matched", "\"", "\u0120dev", "\u0120set"], "seq_scores": [0.9994066953659058, 0.9996365308761597, 0.9997335076332092, 0.9996864795684814, 0.9995604157447815, 0.999584972858429], "text": "the \"matched\" dev set", "score": 0.9996014336744944, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3241, "end": 3253, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["20", "K", "\u0120examples"], "seq_scores": [0.9984768033027649, 0.9996716976165771, 0.9981464147567749], "text": "20K examples", "score": 0.9987649718920389, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3255, "end": 3259, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u012039", "3", "K"], "seq_scores": [0.9979329109191895, 0.9994431138038635, 0.9985320568084717], "text": "393K", "score": 0.9986360271771749, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3441, "end": 3452, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120subs", "am", "pling"], "seq_scores": [0.9333464503288269, 0.9564562439918518, 0.9685420989990234], "text": "subsampling", "score": 0.952781597773234, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 3506, "end": 3526, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Si", "ames", "e", "\u0120Transformers"], "seq_scores": [0.8548805713653564, 0.8482505679130554, 0.8123189806938171, 0.805800199508667], "text": "Siamese Transformers", "score": 0.830312579870224, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3557, "end": 3575, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120explicit", "\u0120deb", "i", "asing"], "seq_scores": [0.9765253663063049, 0.9895666837692261, 0.9975882768630981, 0.9971057772636414], "text": "explicit debiasing", "score": 0.9901965260505676, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3589, "end": 3610, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120increasing", "\u0120model", "\u0120size"], "seq_scores": [0.8822851777076721, 0.6774081587791443, 0.9143710136413574], "text": "increasing model size", "score": 0.8246881167093912, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3730, "end": 3741, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Sub", "sam", "pling"], "seq_scores": [0.9154884815216064, 0.9077122211456299, 0.9141727089881897], "text": "Subsampling", "score": 0.912457803885142, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3765, "end": 3776, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120cart", "ography"], "seq_scores": [0.9532536268234253, 0.9847832322120667], "text": "cartography", "score": 0.969018429517746, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 3778, "end": 3794, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Data", "\u0120cart", "ography"], "seq_scores": [0.988122284412384, 0.9896211624145508, 0.9928497076034546], "text": "Data cartography", "score": 0.9901977181434631, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 3796, "end": 3820, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["S", "way", "amd", "ipt", "a", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.998610258102417, 0.9916620254516602, 0.9960179924964905, 0.9969967603683472, 0.9980350136756897, 0.9986379742622375, 0.9987633228302002, 0.9982640147209167, 0.9975334405899048], "text": "Swayamdipta et al., 2020", "score": 0.9971689780553182, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 3977, "end": 3981, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9646035432815552, 0.9486479163169861], "text": "MNLI", "score": 0.9566257297992706, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 4176, "end": 4180, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9650812745094299, 0.9542049765586853], "text": "MNLI", "score": 0.9596431255340576, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3742, "end": 3759, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120training", "\u0120data"], "seq_scores": [0.9924628734588623, 0.9959297776222229, 0.9909120798110962], "text": "the training data", "score": 0.9931015769640604, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3836, "end": 3856, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120training", "\u0120data", "\u0120points"], "seq_scores": [0.9926396608352661, 0.9925004839897156, 0.9889761209487915], "text": "training data points", "score": 0.9913720885912577, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 3977, "end": 3990, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120MN", "LI", "\u0120examples"], "seq_scores": [0.9943534135818481, 0.9995409250259399, 0.9983558058738708], "text": "MNLI examples", "score": 0.9974167148272196, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4098, "end": 4117, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120\"", "Amb", "iguous", "\"", "\u0120samples"], "seq_scores": [0.9879258871078491, 0.993738055229187, 0.9981864094734192, 0.9930919408798218, 0.9953905344009399], "text": "\"Ambiguous\" samples", "score": 0.9936665654182434, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4203, "end": 4216, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120these", "\u0120samples"], "seq_scores": [0.9745036363601685, 0.9759830832481384], "text": "these samples", "score": 0.9752433598041534, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 4265, "end": 4269, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9967336654663086, 0.9978470802307129], "text": "MNLI", "score": 0.9972903728485107, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 4304, "end": 4317, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta", "-", "large"], "seq_scores": [0.9993234872817993, 0.9996453523635864, 0.9996813535690308, 0.9996795654296875, 0.999648928642273], "text": "RoBERTa-large", "score": 0.9995957374572754, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 4322, "end": 4330, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "base"], "seq_scores": [0.9989274144172668, 0.9997357726097107, 0.9997503161430359], "text": "BERTbase", "score": 0.9994711677233378, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 4506, "end": 4522, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120Si", "ames", "e", "\u0120Networks"], "seq_scores": [0.8826128840446472, 0.9606667160987854, 0.969610333442688, 0.9710803627967834], "text": "Siamese Networks", "score": 0.945992574095726, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 4588, "end": 4607, "seq_label": ["I-Method", "I-Method", "I-Method", "B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120pair", "\u0120of", "\u0120inputs", "Ch", "op", "ra", "\u0120et", "\u0120al", ".,", "\u01202005"], "seq_scores": [0.5544036030769348, 0.7207111120223999, 0.6549592614173889, 0.9993314743041992, 0.9993788003921509, 0.9993323683738708, 0.998847484588623, 0.999029278755188, 0.9986279010772705, 0.9987004995346069], "text": "Chopra et al., 2005", "score": 0.8923321783542633, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 4609, "end": 4626, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Koch", "\u0120et", "\u0120al", ".,", "\u01202015"], "seq_scores": [0.9990361928939819, 0.9990461468696594, 0.9991758465766907, 0.9989227652549744, 0.9988106489181519], "text": "Koch et al., 2015", "score": 0.9989983201026916, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 4650, "end": 4653, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.9904268980026245, 0.9962743520736694], "text": "NLI", "score": 0.993350625038147, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 4655, "end": 4672, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["C", "hen", "\u0120et", "\u0120al", ".,", "\u01202017"], "seq_scores": [0.9994022846221924, 0.9990504384040833, 0.9989782571792603, 0.9990218877792358, 0.9987621307373047, 0.9989350438117981], "text": "Chen et al., 2017", "score": 0.9990250070889791, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 4698, "end": 4711, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120B", "ERT", "\u0120enc", "od", "ers"], "seq_scores": [0.9174626469612122, 0.8991583585739136, 0.5058593153953552, 0.709700345993042, 0.7642275094985962], "text": "BERT encoders", "score": 0.7592816352844238, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 4713, "end": 4739, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Re", "im", "ers", "\u0120and", "\u0120G", "ure", "vy", "ch", ",", "\u01202019"], "seq_scores": [0.9994090795516968, 0.9993929862976074, 0.9994329810142517, 0.9989938139915466, 0.9994722008705139, 0.9994970560073853, 0.9995043277740479, 0.9993929862976074, 0.9991286396980286, 0.9991438388824463], "text": "Reimers and Gurevych, 2019", "score": 0.9993367910385131, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 4867, "end": 4882, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120cross", "-", "att", "ention"], "seq_scores": [0.9725555777549744, 0.9487485289573669, 0.923413097858429, 0.9310073256492615], "text": "cross-attention", "score": 0.9439311325550079, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 4939, "end": 4955, "seq_label": ["B-MLModel", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120B", "ERT", "\u0120fine", "-", "tun", "ing"], "seq_scores": [0.5165714621543884, 0.6383706331253052, 0.6957389712333679, 0.9974005222320557, 0.9967214465141296, 0.9940621256828308], "text": "BERT fine-tuning", "score": 0.8064775268236796, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 5138, "end": 5141, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.7984440326690674, 0.9227479100227356], "text": "NLI", "score": 0.8605959713459015, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4342, "end": 4363, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120respective", "\u0120models"], "seq_scores": [0.9927444458007812, 0.9958718419075012, 0.9976209998130798], "text": "the respective models", "score": 0.9954124291737875, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4367, "end": 4417, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120varying", "\u0120amounts", "\u0120of", "\u0120\"", "hard", "\"", "\u0120and", "\u0120\"", "amb", "iguous", "\"", "\u0120examples"], "seq_scores": [0.8365241289138794, 0.8425235152244568, 0.7380738854408264, 0.5221467614173889, 0.9999092817306519, 0.9999351501464844, 0.9999188184738159, 0.9998966455459595, 0.9998927116394043, 0.999942421913147, 0.9999347925186157, 0.9999169111251831], "text": "varying amounts of \"hard\" and \"ambiguous\" examples", "score": 0.9115512520074844, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 4431, "end": 4452, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u012025", "%", "\u0120of", "\u0120\"", "easy", "\"", "\u0120samples"], "seq_scores": [0.9967367053031921, 0.9998306035995483, 0.9998641014099121, 0.9998492002487183, 0.9999194145202637, 0.9998856782913208, 0.9998592138290405], "text": "25% of \"easy\" samples", "score": 0.999420702457428, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4527, "end": 4544, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120this", "\u0120architecture"], "seq_scores": [0.7003445625305176, 0.6071425676345825], "text": "this architecture", "score": 0.65374356508255, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4698, "end": 4711, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120B", "ERT", "\u0120enc", "od", "ers"], "seq_scores": [0.9951779842376709, 0.9977957010269165, 0.9981036186218262, 0.9989359974861145, 0.9972889423370361], "text": "BERT encoders", "score": 0.9974604487419129, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 4777, "end": 4786, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9947789907455444, 0.9970857501029968], "text": "the model", "score": 0.9959323704242706, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5135, "end": 5147, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120an", "\u0120NL", "I", "\u0120model"], "seq_scores": [0.9973766803741455, 0.9988333582878113, 0.9997946619987488, 0.9996471405029297], "text": "an NLI model", "score": 0.9989129602909088, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 5243, "end": 5262, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Si", "ames", "e", "\u0120Trans", "former"], "seq_scores": [0.9628036618232727, 0.9291030168533325, 0.9280516505241394, 0.9157792925834656, 0.8192840218544006], "text": "Siamese Transformer", "score": 0.9110043287277222, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 5277, "end": 5280, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120ML", "P"], "seq_scores": [0.7665321826934814, 0.7282174229621887], "text": "MLP", "score": 0.7473748028278351, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 5289, "end": 5293, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.8689505457878113, 0.8994221091270447], "text": "BERT", "score": 0.884186327457428, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 5294, "end": 5302, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120enc", "od", "ers"], "seq_scores": [0.5047117471694946, 0.7674725651741028, 0.9049862623214722], "text": "encoders", "score": 0.7257235248883566, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5373, "end": 5392, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120mean", "-", "pool", "ed", "\u0120outputs"], "seq_scores": [0.9016067981719971, 0.922661542892456, 0.9352511763572693, 0.9343665242195129, 0.8206284046173096], "text": "mean-pooled outputs", "score": 0.902902889251709, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 5396, "end": 5418, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120last", "\u0120transformer", "\u0120layer"], "seq_scores": [0.926226794719696, 0.9588344693183899, 0.916739284992218], "text": "last transformer layer", "score": 0.9339335163434347, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5420, "end": 5433, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["CL", "S", "\u0120embed", "ding"], "seq_scores": [0.9964208602905273, 0.9975458979606628, 0.9975142478942871, 0.9957224130630493], "text": "CLS embedding", "score": 0.9968008548021317, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 5549, "end": 5554, "seq_label": ["B-MLModel"], "seq_token": ["\u0120large"], "seq_scores": [0.6037834286689758], "text": "large", "score": 0.6037834286689758, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 5555, "end": 5560, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "s"], "seq_scores": [0.6450986266136169, 0.81968092918396, 0.8061929941177368], "text": "BERTs", "score": 0.7569908499717712, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 5608, "end": 5624, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120Adapter", "\u0120Networks"], "seq_scores": [0.9326742887496948, 0.9467624425888062], "text": "Adapter Networks", "score": 0.9397183656692505, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5639, "end": 5659, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120standard", "\u0120fine", "-", "tun", "ing"], "seq_scores": [0.5215197801589966, 0.7910361289978027, 0.9900328516960144, 0.9878242015838623, 0.9788596630096436], "text": "standard fine-tuning", "score": 0.853854525089264, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 5663, "end": 5667, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9607091546058655, 0.937798261642456], "text": "BERT", "score": 0.9492537081241608, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5690, "end": 5726, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120task", "independent", "\u0120linguistic", "\u0120knowledge"], "seq_scores": [0.613122820854187, 0.8918970227241516, 0.9178703427314758, 0.9106430411338806], "text": "taskindependent linguistic knowledge", "score": 0.8333833068609238, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 5970, "end": 5997, "seq_label": ["I-Method", "I-Method", "I-Method", "I-Method", "B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120task", "-", "specific", "\u0120components", "\u0120non", "-", "task", "-", "specific", "\u0120knowledge"], "seq_scores": [0.6231533885002136, 0.6674259305000305, 0.7153517007827759, 0.565540611743927, 0.5026925206184387, 0.9251694679260254, 0.9118961095809937, 0.9560997486114502, 0.9358062148094177, 0.9157615303993225], "text": "non-task-specific knowledge", "score": 0.7718897223472595, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 6036, "end": 6044, "seq_label": ["B-ModelArchitecture"], "seq_token": ["\u0120adapters"], "seq_scores": [0.9371430277824402], "text": "adapters", "score": 0.9371430277824402, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6046, "end": 6066, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["H", "ouls", "by", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9992974996566772, 0.9984012246131897, 0.998902440071106, 0.9982500672340393, 0.9984368681907654, 0.9980983138084412, 0.9983038902282715], "text": "Houlsby et al., 2019", "score": 0.9985271862574986, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6068, "end": 6089, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120P", "fe", "iff", "er", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9995123147964478, 0.999024510383606, 0.9990677237510681, 0.9991121888160706, 0.9985829591751099, 0.998751163482666, 0.9984739422798157, 0.9986577033996582], "text": "Pfeiffer et al., 2020", "score": 0.9988978132605553, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 6142, "end": 6149, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120enc", "oder"], "seq_scores": [0.9841474294662476, 0.9766076803207397], "text": "encoder", "score": 0.9803775548934937, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 6166, "end": 6185, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120a", "\u0120transformer", "\u0120layer"], "seq_scores": [0.7576252222061157, 0.8216599225997925, 0.9431755542755127], "text": "a transformer layer", "score": 0.8408202330271403, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5275, "end": 5280, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120ML", "P"], "seq_scores": [0.9978165626525879, 0.99933260679245, 0.9990161657333374], "text": "a MLP", "score": 0.9987217783927917, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5285, "end": 5302, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120two", "\u0120B", "ERT", "\u0120enc", "od", "ers"], "seq_scores": [0.9973244667053223, 0.9957996010780334, 0.9994077682495117, 0.9994088411331177, 0.9996138215065002, 0.999413251876831], "text": "two BERT encoders", "score": 0.9984946250915527, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 5317, "end": 5327, "seq_label": ["B-DatasetGeneric"], "seq_token": ["\u0120hypotheses"], "seq_scores": [0.766576886177063], "text": "hypotheses", "score": 0.766576886177063, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5505, "end": 5519, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120ML", "P", "\u0120class", "ifier"], "seq_scores": [0.9959073066711426, 0.9978887438774109, 0.9970910549163818, 0.9972793459892273], "text": "MLP classifier", "score": 0.9970416128635406, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5572, "end": 5601, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120frozen", "\u0120and", "\u0120train", "able", "\u0120enc", "od", "ers"], "seq_scores": [0.975239098072052, 0.9886429905891418, 0.9902921319007874, 0.997776448726654, 0.9951371550559998, 0.9986924529075623, 0.9985067248344421], "text": "frozen and trainable encoders", "score": 0.9920410002980914, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5608, "end": 5624, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120Adapter", "\u0120Networks"], "seq_scores": [0.782243013381958, 0.7904653549194336], "text": "Adapter Networks", "score": 0.7863541841506958, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 5732, "end": 5741, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9881625771522522, 0.9888108968734741], "text": "the model", "score": 0.9884867370128632, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6001, "end": 6010, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9921395182609558, 0.9883415102958679], "text": "the model", "score": 0.9902405142784119, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6093, "end": 6107, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120train", "able", "\u0120ML", "Ps"], "seq_scores": [0.9767957925796509, 0.9938461184501648, 0.9920571446418762, 0.9973465204238892], "text": "trainable MLPs", "score": 0.9900113940238953, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6142, "end": 6149, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120enc", "oder"], "seq_scores": [0.6731420755386353, 0.6799800992012024], "text": "encoder", "score": 0.6765610873699188, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6375, "end": 6384, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9836817979812622, 0.991269588470459], "text": "the model", "score": 0.9874756932258606, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6496, "end": 6509, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120H", "ouls", "by", "\u0120et", "\u0120al"], "seq_scores": [0.999717652797699, 0.999647855758667, 0.9997648596763611, 0.9997166991233826, 0.999752938747406], "text": "Houlsby et al", "score": 0.9997200012207031, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 6521, "end": 6525, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-MLModel", "I-MLModel"], "seq_token": ["\u0120(", "2019", ")", "\u0120B", "ERT"], "seq_scores": [0.9995738863945007, 0.9996531009674072, 0.9957934617996216, 0.998977541923523, 0.9984989166259766], "text": "BERT", "score": 0.9984993815422059, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 6530, "end": 6537, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9987868666648865, 0.9991532564163208, 0.9990606904029846], "text": "RoBERTa", "score": 0.9990002711613973, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6572, "end": 6595, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120P", "fe", "iff", "er", "\u0120et", "\u0120al", ".", "\u0120(", "2020", ")."], "seq_scores": [0.9997461438179016, 0.9996720552444458, 0.9997383952140808, 0.999756395816803, 0.9997350573539734, 0.9997667670249939, 0.9996728897094727, 0.9995905756950378, 0.9996360540390015, 0.9983237385749817], "text": "Pfeiffer et al. (2020).", "score": 0.9995638072490692, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 6704, "end": 6722, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Re", "LU", "\u0120non", "-", "linear", "ity"], "seq_scores": [0.9567521810531616, 0.9904887676239014, 0.7156494855880737, 0.8766818046569824, 0.7817775011062622, 0.7694568037986755], "text": "ReLU non-linearity", "score": 0.8484677573045095, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 6753, "end": 6757, "seq_label": ["I-Method", "I-Method", "I-Method", "B-Dataset", "I-Dataset"], "seq_token": ["-", "bi", "asing", "\u0120MN", "LI"], "seq_scores": [0.6239417791366577, 0.6894068121910095, 0.6628738045692444, 0.9735324382781982, 0.9731382131576538], "text": "MNLI", "score": 0.7845786094665528, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6839, "end": 6862, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Zhou", "\u0120and", "\u0120Bans", "al", "\u0120(", "2020", "),"], "seq_scores": [0.999401330947876, 0.9995263814926147, 0.9996751546859741, 0.9996637105941772, 0.9994088411331177, 0.9995253086090088, 0.9963821172714233], "text": "Zhou and Bansal (2020),", "score": 0.999083263533456, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 6870, "end": 6884, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120H", "EX", "\u0120projection"], "seq_scores": [0.9980649352073669, 0.99760901927948, 0.9977349042892456], "text": "HEX projection", "score": 0.9978029529253641, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 6886, "end": 6903, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["W", "ang", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9995715022087097, 0.9992789626121521, 0.9993650317192078, 0.9994858503341675, 0.9993228912353516, 0.9994766116142273], "text": "Wang et al., 2019", "score": 0.9994168082873026, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 6935, "end": 6954, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120Trans", "former", "\u0120enc", "oder"], "seq_scores": [0.6323025226593018, 0.9893919229507446, 0.8871910572052002, 0.9667972922325134], "text": "Transformer encoder", "score": 0.86892069876194, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7006, "end": 7009, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120H", "EX"], "seq_scores": [0.9971144199371338, 0.9959433674812317], "text": "HEX", "score": 0.9965288937091827, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 7036, "end": 7047, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120Trans", "former"], "seq_scores": [0.8462037444114685, 0.9792037010192871], "text": "Transformer", "score": 0.9127037227153778, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6906, "end": 6916, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120The", "\u0120system"], "seq_scores": [0.9918162226676941, 0.9900418519973755], "text": "The system", "score": 0.9909290373325348, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6926, "end": 6954, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120main", "\u0120Trans", "former", "\u0120enc", "oder"], "seq_scores": [0.8121922016143799, 0.7640816569328308, 0.8163405060768127, 0.8274549841880798, 0.5588737726211548, 0.5858520269393921], "text": "the main Transformer encoder", "score": 0.7274658580621084, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 6959, "end": 6974, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120'", "na", "ive", "'", "\u0120model"], "seq_scores": [0.9980136156082153, 0.9997637867927551, 0.9997583031654358, 0.9997847676277161, 0.9997585415840149, 0.9996999502182007], "text": "a 'naive' model", "score": 0.999463160832723, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7190, "end": 7212, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120pooled", "\u0120representations"], "seq_scores": [0.8606789112091064, 0.9120604991912842], "text": "pooled representations", "score": 0.8863697052001953, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7234, "end": 7243, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["BER", "T", "-", "base"], "seq_scores": [0.9984890222549438, 0.9995802044868469, 0.9994490742683411, 0.9996482133865356], "text": "BERT-base", "score": 0.9992916285991669, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 7287, "end": 7307, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120self", "-", "att", "ention", "\u0120layer"], "seq_scores": [0.5658114552497864, 0.9104311466217041, 0.9126276969909668, 0.9207234978675842, 0.834556519985199], "text": "self-attention layer", "score": 0.8288300633430481, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7309, "end": 7329, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["V", "as", "w", "ani", "\u0120et", "\u0120al", ".,", "\u01202017"], "seq_scores": [0.9989368319511414, 0.9990845918655396, 0.9991828799247742, 0.9990787506103516, 0.9982184767723083, 0.9988040924072266, 0.9985356330871582, 0.9986648559570312], "text": "Vaswani et al., 2017", "score": 0.9988132640719414, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7391, "end": 7396, "seq_label": ["B-Method"], "seq_token": ["\u0120input"], "seq_scores": [0.616225004196167], "text": "input", "score": 0.616225004196167, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7401, "end": 7417, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120token", "\u0120embed", "d", "ings"], "seq_scores": [0.7375484108924866, 0.9870656728744507, 0.9885156154632568, 0.9799704551696777], "text": "token embeddings", "score": 0.923275038599968, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7423, "end": 7441, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Wang", "\u0120et", "\u0120al", ".", "\u0120(", "2019", ")"], "seq_scores": [0.9995073080062866, 0.9995324611663818, 0.9996311664581299, 0.999605119228363, 0.9995343685150146, 0.9995173215866089, 0.997715950012207], "text": "Wang et al. (2019)", "score": 0.9992919564247131, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 7573, "end": 7577, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9987722039222717, 0.999210000038147], "text": "BERT", "score": 0.9989911019802094, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7612, "end": 7619, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120Sc", "aling"], "seq_scores": [0.9771630764007568, 0.983173668384552], "text": "Scaling", "score": 0.9801683723926544, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7772, "end": 7790, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Brown", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9991284012794495, 0.9988266825675964, 0.9989891648292542, 0.9987680315971375, 0.9988465309143066], "text": "Brown et al., 2020", "score": 0.9989117622375489, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 7792, "end": 7811, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120R", "aff", "el", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9991033673286438, 0.9992731213569641, 0.999180018901825, 0.9986701011657715, 0.998916745185852, 0.9986323714256287, 0.9987566471099854], "text": "Raffel et al., 2020", "score": 0.9989331960678101, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7813, "end": 7821, "seq_label": ["B-Method"], "seq_token": ["\u0120training"], "seq_scores": [0.9155635237693787], "text": "training", "score": 0.9155635237693787, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7832, "end": 7865, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120transfer", "able", "\u0120linguistic", "\u0120knowledge"], "seq_scores": [0.7928400039672852, 0.8340641260147095, 0.7594332098960876, 0.8351468443870544], "text": "transferable linguistic knowledge", "score": 0.8053710460662842, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7218, "end": 7232, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120our", "\u0120main", "\u0120model"], "seq_scores": [0.9990352392196655, 0.9995737671852112, 0.9990670084953308], "text": "our main model", "score": 0.9992253383000692, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7246, "end": 7263, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120The", "\u0120'", "na", "ive", "'", "\u0120model"], "seq_scores": [0.9975997805595398, 0.9974944591522217, 0.9979810118675232, 0.9974672794342041, 0.9940780401229858, 0.9961418509483337], "text": "The 'naive' model", "score": 0.9967937370141348, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7267, "end": 7279, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120a", "\u0120CB", "OW", "\u0120model"], "seq_scores": [0.985663115978241, 0.9972266554832458, 0.9968461394309998, 0.993353009223938], "text": "a CBOW model", "score": 0.9932722300291061, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7620, "end": 7635, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120language", "\u0120models"], "seq_scores": [0.9976775050163269, 0.9990336894989014], "text": "language models", "score": 0.9983555972576141, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 7639, "end": 7662, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120massive", "\u0120amounts", "\u0120of", "\u0120data"], "seq_scores": [0.9667192697525024, 0.9916203022003174, 0.9872843027114868, 0.9828181862831116], "text": "massive amounts of data", "score": 0.9821105152368546, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7867, "end": 7877, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120models"], "seq_scores": [0.9886336326599121, 0.9975518584251404], "text": "the models", "score": 0.9930927455425262, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 7888, "end": 7897, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120more", "\u0120data"], "seq_scores": [0.9174027442932129, 0.8432430624961853], "text": "more data", "score": 0.8803229033946991, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 7962, "end": 7982, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120standard", "\u0120fine", "-", "tun", "ing"], "seq_scores": [0.9797532558441162, 0.9568586945533752, 0.9969794750213623, 0.9957654476165771, 0.9965206384658813], "text": "standard fine-tuning", "score": 0.9851755023002624, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 7986, "end": 7990, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9962628483772278, 0.9973598122596741], "text": "MNLI", "score": 0.9968113303184509, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8008, "end": 8012, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9966521859169006, 0.9903733730316162], "text": "BERT", "score": 0.9935127794742584, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8014, "end": 8018, "seq_label": ["B-MLModel"], "seq_token": ["\u0120tiny"], "seq_scores": [0.9944139719009399], "text": "tiny", "score": 0.9944139719009399, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8020, "end": 8024, "seq_label": ["B-MLModel"], "seq_token": ["\u0120mini"], "seq_scores": [0.9797015190124512], "text": "mini", "score": 0.9797015190124512, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8026, "end": 8031, "seq_label": ["B-MLModel"], "seq_token": ["\u0120small"], "seq_scores": [0.9393807649612427], "text": "small", "score": 0.9393807649612427, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8043, "end": 8053, "seq_label": ["I-MLModel", "B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120medium", "\u0120Tur", "c", "\u0120et", "\u0120al"], "seq_scores": [0.6779689788818359, 0.9992842078208923, 0.9996023774147034, 0.9993409514427185, 0.9996389150619507], "text": "Turc et al", "score": 0.9351670861244201, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8063, "end": 8067, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-MLModel"], "seq_token": ["\u0120(", "2019", "),", "\u0120base"], "seq_scores": [0.9992538094520569, 0.9995299577713013, 0.9233851432800293, 0.9895888566970825], "text": "base", "score": 0.9779394418001175, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8072, "end": 8077, "seq_label": ["B-MLModel"], "seq_token": ["\u0120large"], "seq_scores": [0.9515437483787537], "text": "large", "score": 0.9515437483787537, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8081, "end": 8093, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Dev", "lin", "\u0120et", "\u0120al"], "seq_scores": [0.9995848536491394, 0.9996782541275024, 0.9995890259742737, 0.9997130036354065], "text": "Devlin et al", "score": 0.9996412843465805, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8114, "end": 8121, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120(", "2019", "),", "\u0120Ro", "BER", "Ta"], "seq_scores": [0.9994478821754456, 0.9996294975280762, 0.9811936020851135, 0.997836172580719, 0.9984863996505737, 0.9985092282295227], "text": "RoBERTa", "score": 0.9958504637082418, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8123, "end": 8139, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["L", "iu", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.999505877494812, 0.9990324974060059, 0.9991439580917358, 0.9992702603340149, 0.9989532232284546, 0.9993541836738586], "text": "Liu et al., 2019", "score": 0.999210000038147, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8145, "end": 8151, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120AL", "BER", "T"], "seq_scores": [0.996161937713623, 0.997789740562439, 0.9971755743026733], "text": "ALBERT", "score": 0.9970424175262451, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 8153, "end": 8169, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["L", "an", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9995236396789551, 0.9988723397254944, 0.9989858269691467, 0.9991331696510315, 0.9988002777099609, 0.9992626309394836], "text": "Lan et al., 2020", "score": 0.9990963141123453, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 8264, "end": 8271, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120Hug", "ging"], "seq_scores": [0.5808918476104736, 0.35933390259742737], "text": "Hugging", "score": 0.4701128751039505, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8334, "end": 8351, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Py", "tor", "ch", "\u0120Lightning"], "seq_scores": [0.9828413724899292, 0.9807479381561279, 0.9793615937232971, 0.9791132807731628], "text": "Pytorch Lightning", "score": 0.9805160462856293, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8363, "end": 8366, "seq_label": ["B-Method"], "seq_token": ["\u0120the"], "seq_scores": [0.7066288590431213], "text": "the", "score": 0.7066288590431213, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8367, "end": 8382, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Adam", "W", "\u0120optim", "izer"], "seq_scores": [0.766033411026001, 0.9985193610191345, 0.9913908243179321, 0.9767711162567139], "text": "AdamW optimizer", "score": 0.9331786781549454, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 7996, "end": 8012, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120variants", "\u0120of", "\u0120B", "ERT"], "seq_scores": [0.7300079464912415, 0.9592280983924866, 0.9659999012947083, 0.9582082033157349], "text": "variants of BERT", "score": 0.9033610373735428, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 8299, "end": 8324, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120our", "\u0120custom", "\u0120implementation"], "seq_scores": [0.9134616851806641, 0.8863730430603027, 0.8667381405830383], "text": "our custom implementation", "score": 0.8888576229413351, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8485, "end": 8501, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Si", "ames", "e", "\u0120networks"], "seq_scores": [0.9693928360939026, 0.977756917476654, 0.974294126033783, 0.9647585153579712], "text": "Siamese networks", "score": 0.9715505987405777, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8506, "end": 8519, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120H", "EX", "\u0120deb", "i", "asing"], "seq_scores": [0.9959409236907959, 0.9976740479469299, 0.9980624318122864, 0.9979224801063538, 0.9982509016990662], "text": "HEX debiasing", "score": 0.9975701570510864, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8547, "end": 8551, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.9903143048286438, 0.9894950985908508], "text": "HANS", "score": 0.9899047017097473, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8592, "end": 8611, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120vanilla", "\u0120fine", "-", "tun", "ing"], "seq_scores": [0.9976035952568054, 0.9981184005737305, 0.998717188835144, 0.9982819557189941, 0.9983105659484863], "text": "vanilla fine-tuning", "score": 0.9982063412666321, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 8615, "end": 8632, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120their", "\u0120base", "\u0120models"], "seq_scores": [0.9798641204833984, 0.9858174920082092, 0.9979787468910217], "text": "their base models", "score": 0.9878867864608765, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 8962, "end": 8974, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120vanilla", "\u0120B", "ERT"], "seq_scores": [0.9986875653266907, 0.9994814991950989, 0.9997389912605286], "text": "vanilla BERT", "score": 0.9993026852607727, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 8994, "end": 9016, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120cross", "-", "att", "ention", "\u0120across"], "seq_scores": [0.9966539144515991, 0.995859682559967, 0.9959839582443237, 0.9954280853271484, 0.5724976062774658], "text": "cross-attention across", "score": 0.9112846493721009, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 9375, "end": 9378, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.9344577193260193, 0.9324679970741272], "text": "NLI", "score": 0.9334628582000732, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9413, "end": 9440, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120independent", "\u0120representations"], "seq_scores": [0.8124907612800598, 0.7219550609588623], "text": "independent representations", "score": 0.7672229111194611, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 9479, "end": 9494, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120cross", "-", "att", "ention"], "seq_scores": [0.9335577487945557, 0.7432574033737183, 0.9376245141029358, 0.9466903209686279], "text": "cross-attention", "score": 0.8902824968099594, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 8895, "end": 8912, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["Our", "\u0120Si", "ames", "e", "\u0120model"], "seq_scores": [0.94564288854599, 0.9673352241516113, 0.9240894913673401, 0.9299139976501465, 0.9147414565086365], "text": "Our Siamese model", "score": 0.9363446116447449, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9123, "end": 9141, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120Our", "\u0120bottleneck", "\u0120ML", "P"], "seq_scores": [0.9908410310745239, 0.9858741760253906, 0.9941157102584839, 0.998403012752533], "text": "Our bottleneck MLP", "score": 0.9923084825277328, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9371, "end": 9385, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120our", "\u0120NL", "I", "\u0120models"], "seq_scores": [0.9828652143478394, 0.9933977127075195, 0.9996912479400635, 0.9992695450782776], "text": "our NLI models", "score": 0.993805930018425, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9547, "end": 9550, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120H", "EX"], "seq_scores": [0.3492557108402252, 0.3839210867881775], "text": "HEX", "score": 0.36658839881420135, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 9552, "end": 9574, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Zhou", "\u0120and", "\u0120Bans", "al", "\u0120(", "2020", ")"], "seq_scores": [0.9993809461593628, 0.9997288584709167, 0.9997689127922058, 0.9998257756233215, 0.9997554421424866, 0.9997138381004333, 0.9990500807762146], "text": "Zhou and Bansal (2020)", "score": 0.999603407723563, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9656, "end": 9660, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9985462427139282, 0.9986976385116577], "text": "BERT", "score": 0.998621940612793, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 9719, "end": 9722, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.7335833311080933, 0.9371362924575806], "text": "NLI", "score": 0.8353598117828369, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 9896, "end": 9909, "seq_label": ["B-Dataset", "I-MLModel", "I-MLModel", "I-Dataset", "I-Dataset"], "seq_token": ["\u0120Ro", "BER", "Ta", "-", "large"], "seq_scores": [0.6761967539787292, 0.9876619577407837, 0.9442505836486816, 0.9731297492980957, 0.9639458060264587], "text": "RoBERTa-large", "score": 0.9090369701385498, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 9910, "end": 9914, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9729390144348145, 0.9841839075088501], "text": "MNLI", "score": 0.9785614609718323, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 9995, "end": 10004, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120Comp", "acter"], "seq_scores": [0.8689466118812561, 0.9383062720298767], "text": "Compacter", "score": 0.9036264419555664, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 10017, "end": 10019, "seq_label": ["B-MLModel", "I-Dataset"], "seq_token": ["\u0120T", "5"], "seq_scores": [0.4444277882575989, 0.41221994161605835], "text": "T5", "score": 0.4283238649368286, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 10021, "end": 10042, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Mah", "ab", "adi", "\u0120et", "\u0120al", ".,", "\u01202021"], "seq_scores": [0.9995934367179871, 0.999816358089447, 0.9997506737709045, 0.9996826648712158, 0.9997009038925171, 0.9995896220207214, 0.9996482133865356], "text": "Mahabadi et al., 2021", "score": 0.9996831246784755, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 10072, "end": 10076, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9993667006492615, 0.9996863603591919], "text": "BERT", "score": 0.9995265305042267, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 10081, "end": 10088, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9993689656257629, 0.9997051358222961, 0.9996544122695923], "text": "RoBERTa", "score": 0.9995761712392172, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10116, "end": 10134, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120vanilla", "\u0120fin", "et", "uning"], "seq_scores": [0.9720386266708374, 0.9793590903282166, 0.99078768491745, 0.9918179512023926], "text": "vanilla finetuning", "score": 0.9835008382797241, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 10212, "end": 10227, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["He", "\u0120et", "\u0120al", ".,", "\u01202021"], "seq_scores": [0.9993649125099182, 0.9991841912269592, 0.999098539352417, 0.9990301132202148, 0.9993032217025757], "text": "He et al., 2021", "score": 0.999196195602417, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 10286, "end": 10299, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta", "-", "large"], "seq_scores": [0.9992631077766418, 0.9996613264083862, 0.9996125102043152, 0.9994574189186096, 0.9994250535964966], "text": "RoBERTa-large", "score": 0.9994838833808899, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 10433, "end": 10437, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9812164902687073, 0.9683669805526733], "text": "MNLI", "score": 0.9747917354106903, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 10475, "end": 10499, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120K", "-", "me", "ans", "-", "based", "\u0120clust", "ering"], "seq_scores": [0.9379513263702393, 0.9871897101402283, 0.9855577349662781, 0.9865407347679138, 0.9885112047195435, 0.9842879772186279, 0.9813721179962158, 0.9864294528961182], "text": "K-means-based clustering", "score": 0.9797300323843956, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 10588, "end": 10592, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.7332150936126709, 0.8250331878662109], "text": "HANS", "score": 0.7791241407394409, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 10718, "end": 10722, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9198670387268066, 0.9058236479759216], "text": "MNLI", "score": 0.9128453433513641, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 10749, "end": 10753, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.7616355419158936, 0.8528690934181213], "text": "HANS", "score": 0.8072523176670074, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9926, "end": 9952, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120our", "\u0120adapter", "\u0120implementation"], "seq_scores": [0.762342095375061, 0.7578674554824829, 0.5321248173713684], "text": "our adapter implementation", "score": 0.6841114560763041, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 9968, "end": 9971, "seq_label": ["B-MLModelGeneric"], "seq_token": ["\u0120the"], "seq_scores": [0.5281477570533752], "text": "the", "score": 0.5281477570533752, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 10307, "end": 10316, "seq_label": ["I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120state", "of", "-", "the", "-", "art", "\u0120Comp", "acter", "\u0120adapters", "\u0120the", "\u0120model"], "seq_scores": [0.6560616493225098, 0.7902703285217285, 0.8078450560569763, 0.8177186250686646, 0.8487057089805603, 0.817173957824707, 0.7259295582771301, 0.8988016843795776, 0.8103429079055786, 0.9959588646888733, 0.9967514276504517], "text": "the model", "score": 0.8332327062433417, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10335, "end": 10370, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120a", "\u0120small", ",", "\u0120more", "\u0120informative", "\u0120subs", "ample"], "seq_scores": [0.9980801343917847, 0.9977485537528992, 0.9958951473236084, 0.9990496039390564, 0.9994101524353027, 0.9992647767066956, 0.9984785914421082], "text": "a small, more informative subsample", "score": 0.9982752799987793, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10375, "end": 10397, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u01201024", "\u0120training", "\u0120examples"], "seq_scores": [0.9972372055053711, 0.9987130165100098, 0.9984681010246277], "text": "1024 training examples", "score": 0.9981394410133362, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10429, "end": 10447, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120MN", "LI", "\u0120subs", "ample"], "seq_scores": [0.998099148273468, 0.9960189461708069, 0.9996355772018433, 0.9995006322860718, 0.9991378784179688], "text": "the MNLI subsample", "score": 0.9984784364700318, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10688, "end": 10713, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120more", "\u0120informative", "\u0120examples"], "seq_scores": [0.9343870282173157, 0.9730495810508728, 0.9125187397003174], "text": "more informative examples", "score": 0.9399851163228353, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 10850, "end": 10863, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta", "-", "large"], "seq_scores": [0.9996422529220581, 0.9997710585594177, 0.9998072981834412, 0.9997678399085999, 0.9996525049209595], "text": "RoBERTa-large", "score": 0.9997281908988953, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 10883, "end": 10887, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9970677495002747, 0.9960739612579346], "text": "MNLI", "score": 0.9965708553791046, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 10961, "end": 10965, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.9347123503684998, 0.9651763439178467], "text": "HANS", "score": 0.9499443471431732, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 10970, "end": 10974, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9947534799575806, 0.9951660633087158], "text": "MNLI", "score": 0.9949597716331482, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 11007, "end": 11011, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9928334951400757, 0.9929884076118469], "text": "MNLI", "score": 0.9929109513759613, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 11057, "end": 11061, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.9457895755767822, 0.9568338394165039], "text": "HANS", "score": 0.9513117074966431, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 11103, "end": 11112, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "base"], "seq_scores": [0.9994869232177734, 0.9996293783187866, 0.9997758269309998, 0.9996979236602783], "text": "BERT-base", "score": 0.9996475130319595, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 11255, "end": 11262, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9995741248130798, 0.9997323155403137, 0.9997861981391907], "text": "RoBERTa", "score": 0.9996975461641947, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 11282, "end": 11286, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.8817629814147949, 0.8901593685150146], "text": "HANS", "score": 0.8859611749649048, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 11363, "end": 11367, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.994955837726593, 0.9973397850990295], "text": "MNLI", "score": 0.9961478114128113, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10826, "end": 10844, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120\"", "hard", "\"", "\u0120samples"], "seq_scores": [0.9974055886268616, 0.9914980530738831, 0.9994288086891174, 0.9998457431793213, 0.9998331069946289], "text": "the \"hard\" samples", "score": 0.9976022601127624, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10881, "end": 10897, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120a", "\u0120MN", "LI", "\u0120subs", "ample"], "seq_scores": [0.9984997510910034, 0.999612033367157, 0.9997442364692688, 0.9996458292007446, 0.9993376135826111], "text": "a MNLI subsample", "score": 0.999367892742157, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 10908, "end": 10925, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u012025", "%", "\u0120training", "\u0120data"], "seq_scores": [0.9110708236694336, 0.9518325924873352, 0.9597272276878357, 0.9993407130241394], "text": "25% training data", "score": 0.955492839217186, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 11000, "end": 11016, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120biased", "\u0120MN", "LI", "\u0120data"], "seq_scores": [0.9939001798629761, 0.998428225517273, 0.9998505115509033, 0.9995704293251038], "text": "biased MNLI data", "score": 0.997937336564064, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11023, "end": 11032, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9949016571044922, 0.9979081153869629], "text": "the model", "score": 0.9964048862457275, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 11123, "end": 11146, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120cart", "ography", "\u0120samples"], "seq_scores": [0.9966283440589905, 0.9975638389587402, 0.9991844296455383, 0.9986119270324707], "text": "the cartography samples", "score": 0.9979971349239349, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11197, "end": 11209, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120either", "\u0120model"], "seq_scores": [0.9960674047470093, 0.9969162940979004], "text": "either model", "score": 0.9964918494224548, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 11227, "end": 11253, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120\"", "amb", "iguous", "\"", "\u0120subs", "amples"], "seq_scores": [0.9981352090835571, 0.9895093441009521, 0.999275267124176, 0.9998512268066406, 0.9997575879096985, 0.9996532201766968, 0.9998288154602051], "text": "the \"ambiguous\" subsamples", "score": 0.9980015243802752, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 11290, "end": 11309, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u01205", "%", "\u0120of", "\u0120training", "\u0120data"], "seq_scores": [0.9926778078079224, 0.9910449981689453, 0.9929065704345703, 0.9908068776130676, 0.99918133020401], "text": "5% of training data", "score": 0.9933235168457031, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 11511, "end": 11515, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.998508870601654, 0.9990159273147583], "text": "BERT", "score": 0.9987623989582062, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 11517, "end": 11524, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9982333183288574, 0.9994078874588013, 0.9995015859603882], "text": "RoBERTa", "score": 0.999047597249349, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 11529, "end": 11536, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120AL", "-", "BER", "T"], "seq_scores": [0.9983939528465271, 0.9994953870773315, 0.9992988109588623, 0.9992504715919495], "text": "AL-BERT", "score": 0.9991096556186676, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 11633, "end": 11648, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Anonymous", ",", "\u01202021"], "seq_scores": [0.9986435770988464, 0.9979812502861023, 0.9983704686164856], "text": "Anonymous, 2021", "score": 0.9983317653338114, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11703, "end": 11706, "seq_label": ["B-Method"], "seq_token": ["\u0120the"], "seq_scores": [0.5490889549255371], "text": "the", "score": 0.5490889549255371, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 11719, "end": 11734, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120lex", "ical", "\u0120overlap"], "seq_scores": [0.7462104558944702, 0.7378879189491272, 0.7456393241882324], "text": "lexical overlap", "score": 0.7432458996772766, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11467, "end": 11485, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120our", "\u0120custom", "\u0120trainer"], "seq_scores": [0.9937124848365784, 0.9887979626655579, 0.9930900931358337], "text": "our custom trainer", "score": 0.9918668468793234, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11538, "end": 11558, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120\"", "large", "\"", "\u0120versions"], "seq_scores": [0.9900391697883606, 0.986909806728363, 0.9929637312889099, 0.9940510392189026, 0.9910376071929932], "text": "the \"large\" versions", "score": 0.9910002708435058, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 11595, "end": 11614, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120\"", "base", "\"", "\u0120versions"], "seq_scores": [0.9835150241851807, 0.985679566860199, 0.9917043447494507, 0.994503378868103, 0.9895999431610107], "text": "the \"base\" versions", "score": 0.9890004515647888, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 11892, "end": 11901, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "tiny"], "seq_scores": [0.9993565678596497, 0.9993094205856323, 0.9994925260543823, 0.9995055198669434], "text": "BERT-tiny", "score": 0.9994160085916519, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 11905, "end": 11916, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "medium"], "seq_scores": [0.9992862343788147, 0.9995244741439819, 0.9995878338813782, 0.9993914365768433], "text": "BERT-medium", "score": 0.9994474947452545, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 11931, "end": 11938, "seq_label": ["B-Task"], "seq_token": ["\u0120general"], "seq_scores": [0.8195482492446899], "text": "general", "score": 0.8195482492446899, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 11970, "end": 11978, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120AL", "-", "BER", "Ts"], "seq_scores": [0.9843699932098389, 0.9942077398300171, 0.9948544502258301, 0.9959635734558105], "text": "AL-BERTs", "score": 0.9923489391803741, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12006, "end": 12016, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "small"], "seq_scores": [0.9993100166320801, 0.9995488524436951, 0.9996286630630493, 0.999534010887146], "text": "BERT-small", "score": 0.9995053857564926, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12062, "end": 12085, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120their", "\u0120parameter", "\u0120sharing"], "seq_scores": [0.9826787710189819, 0.979438066482544, 0.993305504322052], "text": "their parameter sharing", "score": 0.9851407806078593, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12111, "end": 12122, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "T", "abase"], "seq_scores": [0.9991450309753418, 0.999250590801239, 0.9992923736572266, 0.9978511333465576], "text": "RoBERTabase", "score": 0.9988847821950912, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12133, "end": 12140, "seq_label": ["B-Task"], "seq_token": ["\u0120general"], "seq_scores": [0.7493352890014648], "text": "general", "score": 0.7493352890014648, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12167, "end": 12177, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "large"], "seq_scores": [0.9992163181304932, 0.9996024966239929, 0.9996657371520996, 0.9994440674781799], "text": "BERT-large", "score": 0.9994821548461914, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12235, "end": 12242, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9991506338119507, 0.9991705417633057, 0.9991235136985779], "text": "RoBERTa", "score": 0.9991482297579447, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12272, "end": 12279, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9984748959541321, 0.998849630355835, 0.99870765209198], "text": "RoBERTa", "score": 0.998677392800649, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12323, "end": 12327, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9979754090309143, 0.9969232678413391], "text": "BERT", "score": 0.9974493384361267, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12368, "end": 12375, "seq_label": ["B-Task"], "seq_token": ["\u0120general"], "seq_scores": [0.5444071292877197], "text": "general", "score": 0.5444071292877197, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12397, "end": 12415, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120longer", "\u0120fine", "-", "tun", "ing"], "seq_scores": [0.8566898107528687, 0.9375834465026855, 0.9793729186058044, 0.9770111441612244, 0.9790159463882446], "text": "longer fine-tuning", "score": 0.9459346532821655, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 12461, "end": 12465, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9405971765518188, 0.9633051753044128], "text": "MNLI", "score": 0.9519511759281158, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12546, "end": 12551, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "s"], "seq_scores": [0.8400765657424927, 0.9366292357444763, 0.9664695858955383], "text": "BERTs", "score": 0.9143917957941691, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 12255, "end": 12274, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120this", "\u0120instance", "\u0120of", "\u0120Ro"], "seq_scores": [0.9623125195503235, 0.7498183846473694, 0.7870025038719177, 0.7247210741043091], "text": "this instance of Ro", "score": 0.8059636205434799, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 12306, "end": 12327, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120this", "\u0120instance", "\u0120of", "\u0120B", "ERT"], "seq_scores": [0.9236757755279541, 0.8166055083274841, 0.8518238663673401, 0.792000949382782, 0.5689791440963745], "text": "this instance of BERT", "score": 0.790617048740387, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 12481, "end": 12498, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120larger", "\u0120models"], "seq_scores": [0.9920593500137329, 0.9976430535316467, 0.995984673500061], "text": "the larger models", "score": 0.9952290256818136, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 12534, "end": 12551, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120smaller", "\u0120B", "ERT", "s"], "seq_scores": [0.5402262210845947, 0.6034702658653259, 0.7570826411247253, 0.7982003688812256, 0.7610211968421936], "text": "the smaller BERTs", "score": 0.6920001387596131, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 12630, "end": 12634, "seq_label": ["I-Task", "B-Dataset", "I-Dataset"], "seq_token": ["ization", "\u0120MN", "LI"], "seq_scores": [0.5304771661758423, 0.9950259327888489, 0.9953976273536682], "text": "MNLI", "score": 0.8403002421061198, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 12638, "end": 12642, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.8992551565170288, 0.9287909865379333], "text": "HANS", "score": 0.9140230715274811, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12650, "end": 12671, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120data", "-", "based", "\u0120strategies"], "seq_scores": [0.9919410943984985, 0.9945514798164368, 0.9946459531784058, 0.9931560158729553], "text": "data-based strategies", "score": 0.9935736358165741, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12698, "end": 12708, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120augment", "ing"], "seq_scores": [0.9338000416755676, 0.9662384986877441], "text": "augmenting", "score": 0.9500192701816559, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 12709, "end": 12713, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9974238872528076, 0.9972628355026245], "text": "MNLI", "score": 0.9973433613777161, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12724, "end": 12753, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120predicate", "-", "argument", "\u0120structures"], "seq_scores": [0.9832882285118103, 0.9785021543502808, 0.9763796925544739, 0.9800317287445068], "text": "predicate-argument structures", "score": 0.9795504510402679, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 12755, "end": 12775, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["M", "oos", "avi", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9992889165878296, 0.9995174407958984, 0.99949049949646, 0.9992803931236267, 0.9992920160293579, 0.9990357160568237, 0.9990310668945312], "text": "Moosavi et al., 2020", "score": 0.9992765784263611, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12781, "end": 12806, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120synt", "actic", "\u0120transformations"], "seq_scores": [0.996399998664856, 0.9968063831329346, 0.9970809817314148], "text": "syntactic transformations", "score": 0.9967624545097351, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 12808, "end": 12824, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Min", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9991790652275085, 0.999251663684845, 0.9993466734886169, 0.9991469383239746, 0.9992768168449402], "text": "Min et al., 2020", "score": 0.999240231513977, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12862, "end": 12881, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120synt", "actic", "\u0120knowledge"], "seq_scores": [0.9620195031166077, 0.9770711064338684, 0.9820472002029419], "text": "syntactic knowledge", "score": 0.9737126032511393, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 12885, "end": 12901, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120pre", "-", "trained", "\u0120B", "ERT"], "seq_scores": [0.9629956483840942, 0.991995096206665, 0.9833606481552124, 0.7754591107368469, 0.9982298016548157], "text": "pre-trained BERT", "score": 0.9424080610275268, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 12903, "end": 12923, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Rog", "ers", "\u0120et", "\u0120al", ".,", "\u01202020", "b"], "seq_scores": [0.9996832609176636, 0.9996386766433716, 0.9995296001434326, 0.9995537400245667, 0.9995105266571045, 0.9995002746582031, 0.9989964365959167], "text": "Rogers et al., 2020b", "score": 0.9994875022343227, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 12926, "end": 12935, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Min", "\u0120et", "\u0120al"], "seq_scores": [0.999686598777771, 0.9996949434280396, 0.9997223019599915], "text": "Min et al", "score": 0.9997012813886007, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 12957, "end": 12969, "seq_label": ["I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120(", "2020", ")", "\u0120pre", "-", "training"], "seq_scores": [0.9996333122253418, 0.9997023940086365, 0.9933382272720337, 0.9969854950904846, 0.9977061748504639, 0.9974976181983948], "text": "pre-training", "score": 0.9974772036075592, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 13048, "end": 13060, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120aug", "mentation"], "seq_scores": [0.993945300579071, 0.9881860017776489], "text": "augmentation", "score": 0.99106565117836, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 12709, "end": 12718, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120MN", "LI", "\u0120data"], "seq_scores": [0.9937801957130432, 0.9978721141815186, 0.9830442070960999], "text": "MNLI data", "score": 0.9915655056635538, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 12885, "end": 12889, "seq_label": ["I-DatasetGeneric", "I-DatasetGeneric", "B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["-", "argument", "\u0120pre", "-"], "seq_scores": [0.6246271729469299, 0.5022552609443665, 0.8473294973373413, 0.6202776432037354], "text": "pre-", "score": 0.6486223936080933, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 13070, "end": 13079, "seq_label": ["I-MLModelGeneric", "I-MLModelGeneric", "B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120B", "ERT", "\u0120the", "\u0120model"], "seq_scores": [0.8314281105995178, 0.837268590927124, 0.9929896593093872, 0.9953624606132507], "text": "the model", "score": 0.91426220536232, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 13109, "end": 13120, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120subs", "am", "pling"], "seq_scores": [0.5665351152420044, 0.4981003701686859, 0.5954423546791077], "text": "subsampling", "score": 0.5533592800299326, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 13280, "end": 13284, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9949325919151306, 0.9949224591255188], "text": "MNLI", "score": 0.9949275255203247, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 13425, "end": 13436, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120subs", "am", "pling"], "seq_scores": [0.5379742980003357, 0.5855820178985596, 0.6955353021621704], "text": "subsampling", "score": 0.6063638726870219, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 13442, "end": 13460, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120K", "-", "me", "ans", "\u0120clust", "ering"], "seq_scores": [0.6532846689224243, 0.7389568090438843, 0.7746535539627075, 0.7640219926834106, 0.6600565314292908, 0.7121936678886414], "text": "K-means clustering", "score": 0.7171945373217264, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 13339, "end": 13358, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120right", "\u0120subs", "ample"], "seq_scores": [0.5819435715675354, 0.6708394885063171, 0.8317156434059143, 0.7829310297966003], "text": "the right subsample", "score": 0.7168574333190918, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 13641, "end": 13662, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Ut", "ama", "\u0120et", "\u0120al", ".", "\u0120(", "\u01202020", "),"], "seq_scores": [0.9992623925209045, 0.9998039603233337, 0.9998038411140442, 0.9998113512992859, 0.756271243095398, 0.9994825124740601, 0.9993743300437927, 0.9962138533592224], "text": "Utama et al. ( 2020),", "score": 0.9687529355287552, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 13663, "end": 13683, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Clark", "\u0120et", "\u0120al", ".", "\u0120(", "2020", "),"], "seq_scores": [0.9993927478790283, 0.9998021721839905, 0.9998088479042053, 0.9996376037597656, 0.9995916485786438, 0.9991745352745056, 0.9982624650001526], "text": "Clark et al. (2020),", "score": 0.9993814315114703, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 13688, "end": 13707, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120San", "h", "\u0120et", "\u0120al", ".", "\u0120(", "20", "21", ")."], "seq_scores": [0.999040424823761, 0.9997569918632507, 0.9997941851615906, 0.9998142123222351, 0.7562713623046875, 0.9995821118354797, 0.9983879327774048, 0.9996160268783569, 0.9966413974761963], "text": "Sanh et al. (2021).", "score": 0.9721005161603292, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 13734, "end": 13747, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120H", "EX", "\u0120deb", "i", "asing"], "seq_scores": [0.9956896901130676, 0.9952940344810486, 0.984779417514801, 0.9901335835456848, 0.9914069175720215], "text": "HEX debiasing", "score": 0.9914607286453248, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 13509, "end": 13523, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120shallow", "\u0120models"], "seq_scores": [0.9979063272476196, 0.9995120763778687], "text": "shallow models", "score": 0.9987092018127441, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 13571, "end": 13580, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9964446425437927, 0.9974151849746704], "text": "the model", "score": 0.9969299137592316, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 13819, "end": 13833, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120general", "ization"], "seq_scores": [0.922184407711029, 0.7325791120529175], "text": "generalization", "score": 0.8273817598819733, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 13864, "end": 13879, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Anonymous", ",", "\u01202021"], "seq_scores": [0.9992415904998779, 0.9983437061309814, 0.9984392523765564], "text": "Anonymous, 2021", "score": 0.9986748496691386, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 13885, "end": 13903, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120longer", "\u0120fine", "-", "tun", "ing"], "seq_scores": [0.9980554580688477, 0.9982470273971558, 0.9992926120758057, 0.9990890026092529, 0.9991850256919861], "text": "longer fine-tuning", "score": 0.9987738251686096, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 13905, "end": 13920, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Tu", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9989126920700073, 0.9972062706947327, 0.9967645406723022, 0.9940715432167053, 0.9972386360168457], "text": "Tu et al., 2020", "score": 0.9968387365341187, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 14001, "end": 14005, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9969214200973511, 0.9979113936424255], "text": "MNLI", "score": 0.9974164068698883, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 14051, "end": 14069, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120longer", "\u0120fine", "-", "tun", "ing"], "seq_scores": [0.9958105087280273, 0.9972789883613586, 0.9987465143203735, 0.9986845850944519, 0.9985775947570801], "text": "longer fine-tuning", "score": 0.9978196382522583, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 13849, "end": 13862, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120larger", "\u0120models"], "seq_scores": [0.9941768646240234, 0.9980899691581726], "text": "larger models", "score": 0.996133416891098, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 13973, "end": 13997, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120few", "\u0120H", "ANS", "like", "\u0120samples"], "seq_scores": [0.9937514662742615, 0.9981504082679749, 0.9980332255363464, 0.9990659356117249, 0.9989263415336609, 0.9981386661529541], "text": "the few HANSlike samples", "score": 0.9976776738961538, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 14109, "end": 14121, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120DL", "-", "based", "\u0120N", "LP"], "seq_scores": [0.8038115501403809, 0.5270847678184509, 0.5400418639183044, 0.5497881174087524, 0.603399395942688], "text": "DL-based NLP", "score": 0.6048251390457153, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 14193, "end": 14197, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9316560626029968, 0.9732165336608887], "text": "MNLI", "score": 0.9524362981319427, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 14201, "end": 14205, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.9262486696243286, 0.8580842018127441], "text": "HANS", "score": 0.8921664357185364, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 14241, "end": 14273, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120lucky", "\u0120fine", "-", "tun", "ing", "\u0120initialization"], "seq_scores": [0.5717557072639465, 0.9764238595962524, 0.982218325138092, 0.9760021567344666, 0.9733641743659973, 0.773629367351532], "text": "lucky fine-tuning initialization", "score": 0.8755655984083811, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 14275, "end": 14295, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Mc", "-", "C", "oy", "\u0120et", "\u0120al", ".,", "\u01202019", "a"], "seq_scores": [0.9995483756065369, 0.9995782971382141, 0.9996390342712402, 0.999738872051239, 0.9995392560958862, 0.9995833039283752, 0.9994879961013794, 0.9996030926704407, 0.9993002414703369], "text": "Mc-Coy et al., 2019a", "score": 0.9995576077037387, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 14302, "end": 14304, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120Q", "A"], "seq_scores": [0.951074481010437, 0.9539441466331482], "text": "QA", "score": 0.9525093138217926, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 14305, "end": 14317, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Crane", "\u0120(", "2018", ")"], "seq_scores": [0.999136745929718, 0.9994586110115051, 0.99960857629776, 0.998630940914154], "text": "Crane (2018)", "score": 0.9992087185382843, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 14498, "end": 14517, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Nar", "ang", "\u0120et", "\u0120al", ".,", "\u01202021"], "seq_scores": [0.9997691512107849, 0.9996753931045532, 0.9995471835136414, 0.9995939135551453, 0.9995390176773071, 0.9996863603591919], "text": "Narang et al., 2021", "score": 0.9996351699034373, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 14576, "end": 14579, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.987021267414093, 0.9894367456436157], "text": "NLI", "score": 0.9882290065288544, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 14614, "end": 14632, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120vanilla", "\u0120fine", "-", "tun", "ed"], "seq_scores": [0.9853203892707825, 0.9773195385932922, 0.9962145686149597, 0.9913864135742188, 0.9945515990257263], "text": "vanilla fine-tuned", "score": 0.9889585018157959, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 14633, "end": 14642, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "base"], "seq_scores": [0.8923791646957397, 0.9995613694190979, 0.999531626701355, 0.9993066787719727], "text": "BERT-base", "score": 0.9726947098970413, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 14700, "end": 14717, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120Py", "tor", "ch", "-", "Light", "ning"], "seq_scores": [0.9890284538269043, 0.9943171143531799, 0.9958490133285522, 0.9959481358528137, 0.9966745376586914, 0.9962669014930725], "text": "Pytorch-Lightning", "score": 0.9946806927522024, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 14614, "end": 14642, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120vanilla", "\u0120fine", "-", "tun", "ed", "\u0120B", "ERT", "-", "base"], "seq_scores": [0.8111783862113953, 0.9583166837692261, 0.9842243194580078, 0.9829784035682678, 0.9841392636299133, 0.977655291557312, 0.9933692812919617, 0.9905175566673279, 0.981717050075531], "text": "vanilla fine-tuned BERT-base", "score": 0.9626773595809937, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 14696, "end": 14717, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120Our", "\u0120Py", "tor", "ch", "-", "Light", "ning"], "seq_scores": [0.5664370656013489, 0.7671310305595398, 0.8542883992195129, 0.838921844959259, 0.8735605478286743, 0.8840242624282837, 0.843924880027771], "text": "Our Pytorch-Lightning", "score": 0.8040411472320557, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 15067, "end": 15076, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9943074584007263, 0.9965382814407349], "text": "the model", "score": 0.9954228699207306, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 15236, "end": 15245, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120fine", "-", "t", "une"], "seq_scores": [0.8640101552009583, 0.9187188744544983, 0.924415647983551, 0.9080291986465454], "text": "fine-tune", "score": 0.9037934690713882, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 15267, "end": 15271, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9989311099052429, 0.9991230368614197], "text": "BERT", "score": 0.9990270733833313, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 15276, "end": 15283, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120Ro", "BER", "Ta"], "seq_scores": [0.9988927245140076, 0.9995119571685791, 0.9995972514152527], "text": "RoBERTa", "score": 0.9993339776992798, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 15745, "end": 15762, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120B", "ERT", "\u0120token", "ization"], "seq_scores": [0.9692907929420471, 0.9502097964286804, 0.973360002040863, 0.9888667464256287], "text": "BERT tokenization", "score": 0.9704318344593048, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 15246, "end": 15266, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120base", "\u0120versions", "\u0120of"], "seq_scores": [0.8722832798957825, 0.8457531929016113, 0.6922743320465088, 0.5173554420471191], "text": "the base versions of", "score": 0.7319165617227554, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15305, "end": 15316, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120dataset"], "seq_scores": [0.9851521253585815, 0.9660099148750305], "text": "the dataset", "score": 0.975581020116806, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15341, "end": 15368, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120\"", "hard", "\"", "\u0120training", "\u0120samples"], "seq_scores": [0.9933449029922485, 0.9964123368263245, 0.9986899495124817, 0.9955821633338928, 0.9940627217292786, 0.9983177185058594], "text": "the \"hard\" training samples", "score": 0.9960682988166809, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 15373, "end": 15384, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120both", "\u0120models"], "seq_scores": [0.9985541701316833, 0.9987015724182129], "text": "both models", "score": 0.9986278712749481, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 15408, "end": 15422, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120class", "ifier"], "seq_scores": [0.9984922409057617, 0.9989377856254578, 0.9991125464439392], "text": "the classifier", "score": 0.9988475243250529, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15454, "end": 15472, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120\"", "hard", "\"", "\u0120samples"], "seq_scores": [0.9317218065261841, 0.9775043725967407, 0.9948961138725281, 0.9897109866142273, 0.9944763779640198], "text": "the \"hard\" samples", "score": 0.97766193151474, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15485, "end": 15506, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120these", "\u0120\"", "hard", "\u0120\"", "\u0120samples"], "seq_scores": [0.7951534390449524, 0.7914153933525085, 0.9803950190544128, 0.8753370642662048, 0.9762672781944275], "text": "these \"hard \" samples", "score": 0.8837136387825012, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 15724, "end": 15733, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9977278113365173, 0.99732506275177], "text": "the model", "score": 0.9975264370441437, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 15775, "end": 15784, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.998505711555481, 0.9981573224067688], "text": "the model", "score": 0.9983315169811249, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 15992, "end": 16009, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120the", "\u0120pert", "urb", "ations"], "seq_scores": [0.760772168636322, 0.7716819643974304, 0.8908023238182068, 0.8687951564788818], "text": "the perturbations", "score": 0.8230129033327103, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 16111, "end": 16115, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.8812875747680664, 0.8488966822624207], "text": "MNLI", "score": 0.8650921285152435, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 16259, "end": 16272, "seq_label": ["B-Task"], "seq_token": ["\u0120contradiction"], "seq_scores": [0.6559344530105591], "text": "contradiction", "score": 0.6559344530105591, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 16323, "end": 16333, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120entail", "ment"], "seq_scores": [0.764442503452301, 0.8788269758224487], "text": "entailment", "score": 0.8216347396373749, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 15960, "end": 15979, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120\"", "hard", "\"", "\u0120examples"], "seq_scores": [0.8990321159362793, 0.8747126460075378, 0.9107422232627869, 0.9066970348358154, 0.8262677192687988], "text": "the \"hard\" examples", "score": 0.8834903478622437, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 16172, "end": 16183, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120both", "\u0120models"], "seq_scores": [0.9935110211372375, 0.9961238503456116], "text": "both models", "score": 0.9948174357414246, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 16637, "end": 16641, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.9904581308364868, 0.9910549521446228], "text": "HANS", "score": 0.9907565414905548, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 16692, "end": 16696, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9966109395027161, 0.9967652559280396], "text": "MNLI", "score": 0.9966880977153778, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 16896, "end": 16900, "seq_label": ["I-Task", "B-Dataset", "I-Dataset"], "seq_token": ["ment", "\u0120MN", "LI"], "seq_scores": [0.546154797077179, 0.9977497458457947, 0.9976346492767334], "text": "MNLI", "score": 0.8471797307332357, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 16902, "end": 16917, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["Tu", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9996812343597412, 0.9997424483299255, 0.9997853636741638, 0.9996764659881592, 0.9996609687805176], "text": "Tu et al., 2020", "score": 0.9997092962265015, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 17078, "end": 17082, "seq_label": ["I-Task", "I-Task", "B-Dataset", "I-Dataset"], "seq_token": ["ent", "ment", "\u0120MN", "LI"], "seq_scores": [0.49992454051971436, 0.5076583027839661, 0.9932116270065308, 0.9947762489318848], "text": "MNLI", "score": 0.748892679810524, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 17515, "end": 17520, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120CO", "VID"], "seq_scores": [0.8617753982543945, 0.9147409200668335], "text": "COVID", "score": 0.888258159160614, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 17584, "end": 17604, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["W", "yn", "ants", "\u0120et", "\u0120al", ".,", "\u01202020"], "seq_scores": [0.9997462630271912, 0.9995730519294739, 0.999782383441925, 0.9997742772102356, 0.9998016953468323, 0.999620795249939, 0.9996376037597656], "text": "Wynants et al., 2020", "score": 0.9997051528521946, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 16529, "end": 16538, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9940171241760254, 0.997200608253479], "text": "the model", "score": 0.9956088662147522, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 16692, "end": 16706, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120MN", "LI", "\u0120train", "\u0120set"], "seq_scores": [0.9979433417320251, 0.9988777041435242, 0.9933051466941833, 0.9932041168212891], "text": "MNLI train set", "score": 0.9958325773477554, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 16820, "end": 16843, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120general", "izing", "\u0120models"], "seq_scores": [0.9959068298339844, 0.9983708262443542, 0.9991999268531799, 0.9993163347244263], "text": "the generalizing models", "score": 0.9981984794139862, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 16990, "end": 16999, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9959306120872498, 0.9973336458206177], "text": "the model", "score": 0.9966321289539337, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 17132, "end": 17141, "seq_label": ["I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120corrupted", "\u0120MN", "LI", "\u0120examples", "\u0120the", "\u0120model"], "seq_scores": [0.6500454545021057, 0.9655600190162659, 0.9997057318687439, 0.9991306662559509, 0.9970658421516418, 0.9982612729072571], "text": "the model", "score": 0.9349614977836609, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17333, "end": 17341, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120data"], "seq_scores": [0.9908815622329712, 0.9843683838844299], "text": "the data", "score": 0.9876249730587006, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 17365, "end": 17374, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9954309463500977, 0.9976373910903931], "text": "the model", "score": 0.9965341687202454, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 17507, "end": 17537, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120most", "\u0120of", "\u0120CO", "VID", "\u0120detection", "\u0120models"], "seq_scores": [0.5954607129096985, 0.7374609112739563, 0.9512392282485962, 0.9993706345558167, 0.9991286396980286, 0.9994246959686279], "text": "most of COVID detection models", "score": 0.880347470442454, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17572, "end": 17582, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120noisy", "\u0120data"], "seq_scores": [0.9959003329277039, 0.9916324019432068], "text": "noisy data", "score": 0.9937663674354553, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 17829, "end": 17836, "seq_label": ["B-Task"], "seq_token": ["\u0120general"], "seq_scores": [0.5608543753623962], "text": "general", "score": 0.5608543753623962, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 17847, "end": 17857, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "class"], "seq_scores": [0.9695430994033813, 0.9614763259887695, 0.8185539245605469, 0.584355354309082], "text": "BERT-class", "score": 0.833482176065445, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 17869, "end": 17872, "seq_label": ["B-Task", "I-Task"], "seq_token": ["\u0120NL", "I"], "seq_scores": [0.9949551224708557, 0.9967807531356812], "text": "NLI", "score": 0.9958679378032684, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 17879, "end": 17897, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120explicit", "\u0120deb", "i", "asing"], "seq_scores": [0.9932172894477844, 0.9937667846679688, 0.998448371887207, 0.997810423374176], "text": "explicit debiasing", "score": 0.9958107173442841, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 17899, "end": 17912, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120bottleneck", "ing"], "seq_scores": [0.9744836688041687, 0.987218976020813], "text": "bottlenecking", "score": 0.9808513224124908, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 17924, "end": 17932, "seq_label": ["B-Method"], "seq_token": ["\u0120adapters"], "seq_scores": [0.5252835154533386], "text": "adapters", "score": 0.5252835154533386, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 17934, "end": 17950, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120data", "\u0120subs", "am", "pling"], "seq_scores": [0.9894575476646423, 0.9909021258354187, 0.9944122433662415, 0.9948909282684326], "text": "data subsampling", "score": 0.9924157112836838, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 17956, "end": 17977, "seq_label": ["B-Method", "I-Method", "I-Method"], "seq_token": ["\u0120increasing", "\u0120model", "\u0120size"], "seq_scores": [0.9649381637573242, 0.8279048204421997, 0.9788082838058472], "text": "increasing model size", "score": 0.9238837560017904, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 18138, "end": 18148, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "-", "based"], "seq_scores": [0.9534224271774292, 0.9278759360313416, 0.7936376333236694, 0.7195659279823303], "text": "BERT-based", "score": 0.8486254811286926, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 17621, "end": 17645, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["Most", "\u0120supervised", "\u0120datasets"], "seq_scores": [0.9889283180236816, 0.9727485775947571, 0.9987927675247192], "text": "Most supervised datasets", "score": 0.9868232210477194, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 17847, "end": 17864, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120B", "ERT", "-", "class", "\u0120models"], "seq_scores": [0.9131708145141602, 0.9784916639328003, 0.9870775938034058, 0.9878571033477783, 0.9941697120666504], "text": "BERT-class models", "score": 0.9721533775329589, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 17913, "end": 17922, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9617258906364441, 0.9727134704589844], "text": "the model", "score": 0.9672196805477142, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 18138, "end": 18155, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120B", "ERT", "-", "based", "\u0120models"], "seq_scores": [0.8907270431518555, 0.9679262042045593, 0.9851932525634766, 0.9786337614059448, 0.9899721145629883], "text": "BERT-based models", "score": 0.9624904751777649, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 18405, "end": 18427, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["\u0120Vas", "w", "ani", "\u0120et", "\u0120al", ".", "\u0120(", "2017", "),"], "seq_scores": [0.9997034668922424, 0.9997186064720154, 0.9997636675834656, 0.999832272529602, 0.9998472929000854, 0.7528314590454102, 0.9997928738594055, 0.999754011631012, 0.9988983869552612], "text": "Vaswani et al. (2017),", "score": 0.9722380042076111, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 18582, "end": 18586, "seq_label": ["B-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT"], "seq_scores": [0.9986257553100586, 0.9993662238121033], "text": "BERT", "score": 0.9989959895610809, "type": "ScholarlyEntity"}, {"label": "ModelArchitecture", "begin": 19254, "end": 19267, "seq_label": ["B-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture", "I-ModelArchitecture"], "seq_token": ["\u0120the", "\u0120ML", "P", "\u0120layer"], "seq_scores": [0.8367813229560852, 0.7379894256591797, 0.9091418981552124, 0.8062791228294373], "text": "the MLP layer", "score": 0.8225479423999786, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 19337, "end": 19354, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["W", "ang", "\u0120et", "\u0120al", ".,", "\u01202019"], "seq_scores": [0.9993165731430054, 0.9987939596176147, 0.9989245533943176, 0.9990563988685608, 0.9985665678977966, 0.9986898303031921], "text": "Wang et al., 2019", "score": 0.9988913138707479, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 19463, "end": 19486, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120L", "1", "\u0120and", "\u0120L", "2", "\u0120normal", "ization"], "seq_scores": [0.9491295218467712, 0.9304288625717163, 0.8297892212867737, 0.8497506976127625, 0.9110153317451477, 0.8899750113487244, 0.9260185956954956], "text": "L1 and L2 normalization", "score": 0.8980153203010559, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 19234, "end": 19250, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120main", "\u0120network"], "seq_scores": [0.7491664290428162, 0.7289887070655823, 0.629982054233551], "text": "the main network", "score": 0.7027123967806498, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 19635, "end": 19646, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120network"], "seq_scores": [0.7475188374519348, 0.7957219481468201], "text": "the network", "score": 0.7716203927993774, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 19780, "end": 19784, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9847723245620728, 0.9825934767723083], "text": "MNLI", "score": 0.9836829006671906, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 19789, "end": 19793, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.7867868542671204, 0.6180020570755005], "text": "HANS", "score": 0.7023944556713104, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 19813, "end": 19829, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120a", "\u0120biased", "\u0120dataset"], "seq_scores": [0.9992586970329285, 0.9996907711029053, 0.9996907711029053], "text": "a biased dataset", "score": 0.999546746412913, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 19866, "end": 19877, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120a", "\u0120subs", "ample"], "seq_scores": [0.9055589437484741, 0.9011780619621277, 0.7864251136779785], "text": "a subsample", "score": 0.8643873731295267, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 19896, "end": 19905, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.994207501411438, 0.9944623112678528], "text": "the model", "score": 0.9943349063396454, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 19968, "end": 19972, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9043467044830322, 0.9314525723457336], "text": "MNLI", "score": 0.9178996384143829, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 19985, "end": 20006, "seq_label": ["B-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method", "I-Method"], "seq_token": ["\u0120B", "ERT", "\u0120[", "CL", "S", "]", "\u0120embed", "d", "ings"], "seq_scores": [0.9681402444839478, 0.9895695447921753, 0.9948238134384155, 0.9953768253326416, 0.9960880279541016, 0.9934828877449036, 0.9960176348686218, 0.9943242073059082, 0.9956426620483398], "text": "BERT [CLS] embeddings", "score": 0.991496205329895, "type": "ScholarlyEntity"}, {"label": "MLModel", "begin": 20073, "end": 20081, "seq_label": ["B-MLModel", "I-MLModel", "I-MLModel"], "seq_token": ["\u0120B", "ERT", "base"], "seq_scores": [0.9992263317108154, 0.9995049238204956, 0.9993632435798645], "text": "BERTbase", "score": 0.9993648330370585, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 20104, "end": 20108, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.9667092561721802, 0.9667127132415771], "text": "MNLI", "score": 0.9667109847068787, "type": "ScholarlyEntity"}, {"label": "ReferenceLink", "begin": 20315, "end": 20346, "seq_label": ["B-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink", "I-ReferenceLink"], "seq_token": ["K", "ath", "ar", "opoulos", "\u0120and", "\u0120Fle", "ure", "t", ",", "\u01202018"], "seq_scores": [0.9997126460075378, 0.999107301235199, 0.9995786547660828, 0.9994994401931763, 0.9996318817138672, 0.9996896982192993, 0.9997227787971497, 0.9996854066848755, 0.9997052550315857, 0.9996258020401001], "text": "Katharopoulos and Fleuret, 2018", "score": 0.9995958864688873, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 19968, "end": 19981, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120MN", "LI", "\u0120examples"], "seq_scores": [0.9990230798721313, 0.9998650550842285, 0.9996505975723267], "text": "MNLI examples", "score": 0.9995129108428955, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 20104, "end": 20113, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120MN", "LI", "\u0120data"], "seq_scores": [0.9802308678627014, 0.9998337030410767, 0.9994813799858093], "text": "MNLI data", "score": 0.9931819836298624, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 20154, "end": 20171, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120training", "\u0120examples"], "seq_scores": [0.9841809272766113, 0.9987877011299133], "text": "training examples", "score": 0.9914843142032623, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 20180, "end": 20188, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120The", "\u0120data"], "seq_scores": [0.9920006990432739, 0.9944379329681396], "text": "The data", "score": 0.9932193160057068, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 20390, "end": 20398, "seq_label": ["I-DatasetGeneric", "B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120control", "\u0120the", "\u0120data"], "seq_scores": [0.5325971841812134, 0.9469504356384277, 0.8962252140045166], "text": "the data", "score": 0.7919242779413859, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 20506, "end": 20529, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120smallest", "\u0120subs", "amples"], "seq_scores": [0.9983879327774048, 0.9992890357971191, 0.9988725781440735, 0.9975800514221191], "text": "the smallest subsamples", "score": 0.9985323995351791, "type": "ScholarlyEntity"}, {"label": "Dataset", "begin": 20690, "end": 20694, "seq_label": ["B-Dataset", "I-Dataset"], "seq_token": ["\u0120MN", "LI"], "seq_scores": [0.996484637260437, 0.9979181885719299], "text": "MNLI", "score": 0.9972014129161835, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 20696, "end": 20712, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120diverse", "\u0120sampling"], "seq_scores": [0.9896474480628967, 0.9950029253959656], "text": "diverse sampling", "score": 0.9923251867294312, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 20772, "end": 20787, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120random", "\u0120sampling"], "seq_scores": [0.9892830848693848, 0.9950923919677734], "text": "random sampling", "score": 0.9921877384185791, "type": "ScholarlyEntity"}, {"label": "Task", "begin": 20957, "end": 20967, "seq_label": ["B-Task", "I-Task", "I-Task"], "seq_token": ["ent", "ail", "ment"], "seq_scores": [0.7658568620681763, 0.793580949306488, 0.9000638723373413], "text": "entailment", "score": 0.8198338945706686, "type": "ScholarlyEntity"}, {"label": "Method", "begin": 20978, "end": 20982, "seq_label": ["B-Method", "I-Method"], "seq_token": ["\u0120H", "ANS"], "seq_scores": [0.736325740814209, 0.5721150040626526], "text": "HANS", "score": 0.6542203724384308, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 20745, "end": 20766, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120small", "\u0120amounts", "\u0120of", "\u0120data"], "seq_scores": [0.9985559582710266, 0.9992020726203918, 0.9991270899772644, 0.9986516833305359], "text": "small amounts of data", "score": 0.9988842010498047, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 20796, "end": 20804, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120subs"], "seq_scores": [0.7389447689056396, 0.7699329853057861], "text": "the subs", "score": 0.7544388771057129, "type": "ScholarlyEntity"}, {"label": "DatasetGeneric", "begin": 20821, "end": 20837, "seq_label": ["B-DatasetGeneric", "I-DatasetGeneric", "I-DatasetGeneric"], "seq_token": ["\u0120the", "\u0120full", "\u0120dataset"], "seq_scores": [0.9990586638450623, 0.9991389513015747, 0.9989872574806213], "text": "the full dataset", "score": 0.9990616242090861, "type": "ScholarlyEntity"}, {"label": "MLModelGeneric", "begin": 20931, "end": 20940, "seq_label": ["B-MLModelGeneric", "I-MLModelGeneric"], "seq_token": ["\u0120the", "\u0120model"], "seq_scores": [0.9967252612113953, 0.9967535138130188], "text": "the model", "score": 0.996739387512207, "type": "ScholarlyEntity"}]}, "filename": "00045_2110_01518.json", "id": "00045_2110_01518"}